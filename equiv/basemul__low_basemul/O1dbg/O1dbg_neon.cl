proc main(
    # input
    sint16 arr000_a, sint16 arr001_a, sint16 arr002_a, sint16 arr003_a, sint16 arr004_a, sint16 arr005_a, sint16 arr006_a, sint16 arr007_a,
    sint16 arr010_a, sint16 arr011_a, sint16 arr012_a, sint16 arr013_a, sint16 arr014_a, sint16 arr015_a, sint16 arr016_a, sint16 arr017_a,
    sint16 arr100_a, sint16 arr101_a, sint16 arr102_a, sint16 arr103_a, sint16 arr104_a, sint16 arr105_a, sint16 arr106_a, sint16 arr107_a,
    sint16 arr110_a, sint16 arr111_a, sint16 arr112_a, sint16 arr113_a, sint16 arr114_a, sint16 arr115_a, sint16 arr116_a, sint16 arr117_a,
    sint16 arr200_a, sint16 arr201_a, sint16 arr202_a, sint16 arr203_a, sint16 arr204_a, sint16 arr205_a, sint16 arr206_a, sint16 arr207_a,
    sint16 arr210_a, sint16 arr211_a, sint16 arr212_a, sint16 arr213_a, sint16 arr214_a, sint16 arr215_a, sint16 arr216_a, sint16 arr217_a,
    sint16 arr300_a, sint16 arr301_a, sint16 arr302_a, sint16 arr303_a, sint16 arr304_a, sint16 arr305_a, sint16 arr306_a, sint16 arr307_a,
    sint16 arr310_a, sint16 arr311_a, sint16 arr312_a, sint16 arr313_a, sint16 arr314_a, sint16 arr315_a, sint16 arr316_a, sint16 arr317_a,
    sint16 arr400_a, sint16 arr401_a, sint16 arr402_a, sint16 arr403_a, sint16 arr404_a, sint16 arr405_a, sint16 arr406_a, sint16 arr407_a,
    sint16 arr410_a, sint16 arr411_a, sint16 arr412_a, sint16 arr413_a, sint16 arr414_a, sint16 arr415_a, sint16 arr416_a, sint16 arr417_a,
    sint16 arr500_a, sint16 arr501_a, sint16 arr502_a, sint16 arr503_a, sint16 arr504_a, sint16 arr505_a, sint16 arr506_a, sint16 arr507_a,
    sint16 arr510_a, sint16 arr511_a, sint16 arr512_a, sint16 arr513_a, sint16 arr514_a, sint16 arr515_a, sint16 arr516_a, sint16 arr517_a,
    sint16 arr600_a, sint16 arr601_a, sint16 arr602_a, sint16 arr603_a, sint16 arr604_a, sint16 arr605_a, sint16 arr606_a, sint16 arr607_a,
    sint16 arr610_a, sint16 arr611_a, sint16 arr612_a, sint16 arr613_a, sint16 arr614_a, sint16 arr615_a, sint16 arr616_a, sint16 arr617_a,
    sint16 arr700_a, sint16 arr701_a, sint16 arr702_a, sint16 arr703_a, sint16 arr704_a, sint16 arr705_a, sint16 arr706_a, sint16 arr707_a,
    sint16 arr710_a, sint16 arr711_a, sint16 arr712_a, sint16 arr713_a, sint16 arr714_a, sint16 arr715_a, sint16 arr716_a, sint16 arr717_a,
    sint16 arr800_a, sint16 arr801_a, sint16 arr802_a, sint16 arr803_a, sint16 arr804_a, sint16 arr805_a, sint16 arr806_a, sint16 arr807_a,
    sint16 arr810_a, sint16 arr811_a, sint16 arr812_a, sint16 arr813_a, sint16 arr814_a, sint16 arr815_a, sint16 arr816_a, sint16 arr817_a,
    sint16 arr900_a, sint16 arr901_a, sint16 arr902_a, sint16 arr903_a, sint16 arr904_a, sint16 arr905_a, sint16 arr906_a, sint16 arr907_a,
    sint16 arr910_a, sint16 arr911_a, sint16 arr912_a, sint16 arr913_a, sint16 arr914_a, sint16 arr915_a, sint16 arr916_a, sint16 arr917_a,

    sint16 arr000_b, sint16 arr001_b, sint16 arr002_b, sint16 arr003_b, sint16 arr004_b, sint16 arr005_b, sint16 arr006_b, sint16 arr007_b,
    sint16 arr010_b, sint16 arr011_b, sint16 arr012_b, sint16 arr013_b, sint16 arr014_b, sint16 arr015_b, sint16 arr016_b, sint16 arr017_b,
    sint16 arr100_b, sint16 arr101_b, sint16 arr102_b, sint16 arr103_b, sint16 arr104_b, sint16 arr105_b, sint16 arr106_b, sint16 arr107_b,
    sint16 arr110_b, sint16 arr111_b, sint16 arr112_b, sint16 arr113_b, sint16 arr114_b, sint16 arr115_b, sint16 arr116_b, sint16 arr117_b,
    sint16 arr200_b, sint16 arr201_b, sint16 arr202_b, sint16 arr203_b, sint16 arr204_b, sint16 arr205_b, sint16 arr206_b, sint16 arr207_b,
    sint16 arr210_b, sint16 arr211_b, sint16 arr212_b, sint16 arr213_b, sint16 arr214_b, sint16 arr215_b, sint16 arr216_b, sint16 arr217_b,
    sint16 arr300_b, sint16 arr301_b, sint16 arr302_b, sint16 arr303_b, sint16 arr304_b, sint16 arr305_b, sint16 arr306_b, sint16 arr307_b,
    sint16 arr310_b, sint16 arr311_b, sint16 arr312_b, sint16 arr313_b, sint16 arr314_b, sint16 arr315_b, sint16 arr316_b, sint16 arr317_b,
    sint16 arr400_b, sint16 arr401_b, sint16 arr402_b, sint16 arr403_b, sint16 arr404_b, sint16 arr405_b, sint16 arr406_b, sint16 arr407_b,
    sint16 arr410_b, sint16 arr411_b, sint16 arr412_b, sint16 arr413_b, sint16 arr414_b, sint16 arr415_b, sint16 arr416_b, sint16 arr417_b,
    sint16 arr500_b, sint16 arr501_b, sint16 arr502_b, sint16 arr503_b, sint16 arr504_b, sint16 arr505_b, sint16 arr506_b, sint16 arr507_b,
    sint16 arr510_b, sint16 arr511_b, sint16 arr512_b, sint16 arr513_b, sint16 arr514_b, sint16 arr515_b, sint16 arr516_b, sint16 arr517_b,
    sint16 arr600_b, sint16 arr601_b, sint16 arr602_b, sint16 arr603_b, sint16 arr604_b, sint16 arr605_b, sint16 arr606_b, sint16 arr607_b,
    sint16 arr610_b, sint16 arr611_b, sint16 arr612_b, sint16 arr613_b, sint16 arr614_b, sint16 arr615_b, sint16 arr616_b, sint16 arr617_b,
    sint16 arr700_b, sint16 arr701_b, sint16 arr702_b, sint16 arr703_b, sint16 arr704_b, sint16 arr705_b, sint16 arr706_b, sint16 arr707_b,
    sint16 arr710_b, sint16 arr711_b, sint16 arr712_b, sint16 arr713_b, sint16 arr714_b, sint16 arr715_b, sint16 arr716_b, sint16 arr717_b,
    sint16 arr800_b, sint16 arr801_b, sint16 arr802_b, sint16 arr803_b, sint16 arr804_b, sint16 arr805_b, sint16 arr806_b, sint16 arr807_b,
    sint16 arr810_b, sint16 arr811_b, sint16 arr812_b, sint16 arr813_b, sint16 arr814_b, sint16 arr815_b, sint16 arr816_b, sint16 arr817_b,
    sint16 arr900_b, sint16 arr901_b, sint16 arr902_b, sint16 arr903_b, sint16 arr904_b, sint16 arr905_b, sint16 arr906_b, sint16 arr907_b,
    sint16 arr910_b, sint16 arr911_b, sint16 arr912_b, sint16 arr913_b, sint16 arr914_b, sint16 arr915_b, sint16 arr916_b, sint16 arr917_b,

    # ghost
    sint16 W10, sint16 W9
) =
{
    W10 = -1610 /\ W9 = -1606 /\
    [arr000_a, arr001_a, arr002_a, arr003_a, arr004_a, arr005_a, arr006_a, arr007_a] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr010_a, arr011_a, arr012_a, arr013_a, arr014_a, arr015_a, arr016_a, arr017_a] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr100_a, arr101_a, arr102_a, arr103_a, arr104_a, arr105_a, arr106_a, arr107_a] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr110_a, arr111_a, arr112_a, arr113_a, arr114_a, arr115_a, arr116_a, arr117_a] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr200_a, arr201_a, arr202_a, arr203_a, arr204_a, arr205_a, arr206_a, arr207_a] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr210_a, arr211_a, arr212_a, arr213_a, arr214_a, arr215_a, arr216_a, arr217_a] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr300_a, arr301_a, arr302_a, arr303_a, arr304_a, arr305_a, arr306_a, arr307_a] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr310_a, arr311_a, arr312_a, arr313_a, arr314_a, arr315_a, arr316_a, arr317_a] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr400_a, arr401_a, arr402_a, arr403_a, arr404_a, arr405_a, arr406_a, arr407_a] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr410_a, arr411_a, arr412_a, arr413_a, arr414_a, arr415_a, arr416_a, arr417_a] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr500_a, arr501_a, arr502_a, arr503_a, arr504_a, arr505_a, arr506_a, arr507_a] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr510_a, arr511_a, arr512_a, arr513_a, arr514_a, arr515_a, arr516_a, arr517_a] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr600_a, arr601_a, arr602_a, arr603_a, arr604_a, arr605_a, arr606_a, arr607_a] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr610_a, arr611_a, arr612_a, arr613_a, arr614_a, arr615_a, arr616_a, arr617_a] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr700_a, arr701_a, arr702_a, arr703_a, arr704_a, arr705_a, arr706_a, arr707_a] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr710_a, arr711_a, arr712_a, arr713_a, arr714_a, arr715_a, arr716_a, arr717_a] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr800_a, arr801_a, arr802_a, arr803_a, arr804_a, arr805_a, arr806_a, arr807_a] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr810_a, arr811_a, arr812_a, arr813_a, arr814_a, arr815_a, arr816_a, arr817_a] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr900_a, arr901_a, arr902_a, arr903_a, arr904_a, arr905_a, arr906_a, arr907_a] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr910_a, arr911_a, arr912_a, arr913_a, arr914_a, arr915_a, arr916_a, arr917_a] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr000_b, arr001_b, arr002_b, arr003_b, arr004_b, arr005_b, arr006_b, arr007_b] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr010_b, arr011_b, arr012_b, arr013_b, arr014_b, arr015_b, arr016_b, arr017_b] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr100_b, arr101_b, arr102_b, arr103_b, arr104_b, arr105_b, arr106_b, arr107_b] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr110_b, arr111_b, arr112_b, arr113_b, arr114_b, arr115_b, arr116_b, arr117_b] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr200_b, arr201_b, arr202_b, arr203_b, arr204_b, arr205_b, arr206_b, arr207_b] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr210_b, arr211_b, arr212_b, arr213_b, arr214_b, arr215_b, arr216_b, arr217_b] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr300_b, arr301_b, arr302_b, arr303_b, arr304_b, arr305_b, arr306_b, arr307_b] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr310_b, arr311_b, arr312_b, arr313_b, arr314_b, arr315_b, arr316_b, arr317_b] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr400_b, arr401_b, arr402_b, arr403_b, arr404_b, arr405_b, arr406_b, arr407_b] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr410_b, arr411_b, arr412_b, arr413_b, arr414_b, arr415_b, arr416_b, arr417_b] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr500_b, arr501_b, arr502_b, arr503_b, arr504_b, arr505_b, arr506_b, arr507_b] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr510_b, arr511_b, arr512_b, arr513_b, arr514_b, arr515_b, arr516_b, arr517_b] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr600_b, arr601_b, arr602_b, arr603_b, arr604_b, arr605_b, arr606_b, arr607_b] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr610_b, arr611_b, arr612_b, arr613_b, arr614_b, arr615_b, arr616_b, arr617_b] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr700_b, arr701_b, arr702_b, arr703_b, arr704_b, arr705_b, arr706_b, arr707_b] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr710_b, arr711_b, arr712_b, arr713_b, arr714_b, arr715_b, arr716_b, arr717_b] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr800_b, arr801_b, arr802_b, arr803_b, arr804_b, arr805_b, arr806_b, arr807_b] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr810_b, arr811_b, arr812_b, arr813_b, arr814_b, arr815_b, arr816_b, arr817_b] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr900_b, arr901_b, arr902_b, arr903_b, arr904_b, arr905_b, arr906_b, arr907_b] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\
    [arr910_b, arr911_b, arr912_b, arr913_b, arr914_b, arr915_b, arr916_b, arr917_b] <= [21565, 21565, 21565, 21565, 21565, 21565, 21565, 21565] /\

    [arr000_a, arr001_a, arr002_a, arr003_a, arr004_a, arr005_a, arr006_a, arr007_a] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr010_a, arr011_a, arr012_a, arr013_a, arr014_a, arr015_a, arr016_a, arr017_a] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr100_a, arr101_a, arr102_a, arr103_a, arr104_a, arr105_a, arr106_a, arr107_a] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr110_a, arr111_a, arr112_a, arr113_a, arr114_a, arr115_a, arr116_a, arr117_a] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr200_a, arr201_a, arr202_a, arr203_a, arr204_a, arr205_a, arr206_a, arr207_a] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr210_a, arr211_a, arr212_a, arr213_a, arr214_a, arr215_a, arr216_a, arr217_a] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr300_a, arr301_a, arr302_a, arr303_a, arr304_a, arr305_a, arr306_a, arr307_a] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr310_a, arr311_a, arr312_a, arr313_a, arr314_a, arr315_a, arr316_a, arr317_a] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr400_a, arr401_a, arr402_a, arr403_a, arr404_a, arr405_a, arr406_a, arr407_a] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr410_a, arr411_a, arr412_a, arr413_a, arr414_a, arr415_a, arr416_a, arr417_a] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr500_a, arr501_a, arr502_a, arr503_a, arr504_a, arr505_a, arr506_a, arr507_a] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr510_a, arr511_a, arr512_a, arr513_a, arr514_a, arr515_a, arr516_a, arr517_a] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr600_a, arr601_a, arr602_a, arr603_a, arr604_a, arr605_a, arr606_a, arr607_a] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr610_a, arr611_a, arr612_a, arr613_a, arr614_a, arr615_a, arr616_a, arr617_a] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr700_a, arr701_a, arr702_a, arr703_a, arr704_a, arr705_a, arr706_a, arr707_a] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr710_a, arr711_a, arr712_a, arr713_a, arr714_a, arr715_a, arr716_a, arr717_a] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr800_a, arr801_a, arr802_a, arr803_a, arr804_a, arr805_a, arr806_a, arr807_a] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr810_a, arr811_a, arr812_a, arr813_a, arr814_a, arr815_a, arr816_a, arr817_a] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr900_a, arr901_a, arr902_a, arr903_a, arr904_a, arr905_a, arr906_a, arr907_a] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr910_a, arr911_a, arr912_a, arr913_a, arr914_a, arr915_a, arr916_a, arr917_a] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr000_b, arr001_b, arr002_b, arr003_b, arr004_b, arr005_b, arr006_b, arr007_b] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr010_b, arr011_b, arr012_b, arr013_b, arr014_b, arr015_b, arr016_b, arr017_b] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr100_b, arr101_b, arr102_b, arr103_b, arr104_b, arr105_b, arr106_b, arr107_b] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr110_b, arr111_b, arr112_b, arr113_b, arr114_b, arr115_b, arr116_b, arr117_b] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr200_b, arr201_b, arr202_b, arr203_b, arr204_b, arr205_b, arr206_b, arr207_b] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr210_b, arr211_b, arr212_b, arr213_b, arr214_b, arr215_b, arr216_b, arr217_b] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr300_b, arr301_b, arr302_b, arr303_b, arr304_b, arr305_b, arr306_b, arr307_b] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr310_b, arr311_b, arr312_b, arr313_b, arr314_b, arr315_b, arr316_b, arr317_b] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr400_b, arr401_b, arr402_b, arr403_b, arr404_b, arr405_b, arr406_b, arr407_b] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr410_b, arr411_b, arr412_b, arr413_b, arr414_b, arr415_b, arr416_b, arr417_b] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr500_b, arr501_b, arr502_b, arr503_b, arr504_b, arr505_b, arr506_b, arr507_b] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr510_b, arr511_b, arr512_b, arr513_b, arr514_b, arr515_b, arr516_b, arr517_b] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr600_b, arr601_b, arr602_b, arr603_b, arr604_b, arr605_b, arr606_b, arr607_b] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr610_b, arr611_b, arr612_b, arr613_b, arr614_b, arr615_b, arr616_b, arr617_b] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr700_b, arr701_b, arr702_b, arr703_b, arr704_b, arr705_b, arr706_b, arr707_b] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr710_b, arr711_b, arr712_b, arr713_b, arr714_b, arr715_b, arr716_b, arr717_b] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr800_b, arr801_b, arr802_b, arr803_b, arr804_b, arr805_b, arr806_b, arr807_b] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr810_b, arr811_b, arr812_b, arr813_b, arr814_b, arr815_b, arr816_b, arr817_b] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr900_b, arr901_b, arr902_b, arr903_b, arr904_b, arr905_b, arr906_b, arr907_b] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565] /\
    [arr910_b, arr911_b, arr912_b, arr913_b, arr914_b, arr915_b, arr916_b, arr917_b] >= [-21565, -21565, -21565, -21565, -21565, -21565, -21565, -21565]
  &&
    [arr000_a, arr001_a, arr002_a, arr003_a, arr004_a, arr005_a, arr006_a, arr007_a] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr010_a, arr011_a, arr012_a, arr013_a, arr014_a, arr015_a, arr016_a, arr017_a] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr100_a, arr101_a, arr102_a, arr103_a, arr104_a, arr105_a, arr106_a, arr107_a] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr110_a, arr111_a, arr112_a, arr113_a, arr114_a, arr115_a, arr116_a, arr117_a] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr200_a, arr201_a, arr202_a, arr203_a, arr204_a, arr205_a, arr206_a, arr207_a] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr210_a, arr211_a, arr212_a, arr213_a, arr214_a, arr215_a, arr216_a, arr217_a] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr300_a, arr301_a, arr302_a, arr303_a, arr304_a, arr305_a, arr306_a, arr307_a] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr310_a, arr311_a, arr312_a, arr313_a, arr314_a, arr315_a, arr316_a, arr317_a] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr400_a, arr401_a, arr402_a, arr403_a, arr404_a, arr405_a, arr406_a, arr407_a] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr410_a, arr411_a, arr412_a, arr413_a, arr414_a, arr415_a, arr416_a, arr417_a] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr500_a, arr501_a, arr502_a, arr503_a, arr504_a, arr505_a, arr506_a, arr507_a] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr510_a, arr511_a, arr512_a, arr513_a, arr514_a, arr515_a, arr516_a, arr517_a] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr600_a, arr601_a, arr602_a, arr603_a, arr604_a, arr605_a, arr606_a, arr607_a] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr610_a, arr611_a, arr612_a, arr613_a, arr614_a, arr615_a, arr616_a, arr617_a] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr700_a, arr701_a, arr702_a, arr703_a, arr704_a, arr705_a, arr706_a, arr707_a] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr710_a, arr711_a, arr712_a, arr713_a, arr714_a, arr715_a, arr716_a, arr717_a] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr800_a, arr801_a, arr802_a, arr803_a, arr804_a, arr805_a, arr806_a, arr807_a] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr810_a, arr811_a, arr812_a, arr813_a, arr814_a, arr815_a, arr816_a, arr817_a] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr900_a, arr901_a, arr902_a, arr903_a, arr904_a, arr905_a, arr906_a, arr907_a] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr910_a, arr911_a, arr912_a, arr913_a, arr914_a, arr915_a, arr916_a, arr917_a] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr000_b, arr001_b, arr002_b, arr003_b, arr004_b, arr005_b, arr006_b, arr007_b] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr010_b, arr011_b, arr012_b, arr013_b, arr014_b, arr015_b, arr016_b, arr017_b] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr100_b, arr101_b, arr102_b, arr103_b, arr104_b, arr105_b, arr106_b, arr107_b] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr110_b, arr111_b, arr112_b, arr113_b, arr114_b, arr115_b, arr116_b, arr117_b] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr200_b, arr201_b, arr202_b, arr203_b, arr204_b, arr205_b, arr206_b, arr207_b] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr210_b, arr211_b, arr212_b, arr213_b, arr214_b, arr215_b, arr216_b, arr217_b] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr300_b, arr301_b, arr302_b, arr303_b, arr304_b, arr305_b, arr306_b, arr307_b] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr310_b, arr311_b, arr312_b, arr313_b, arr314_b, arr315_b, arr316_b, arr317_b] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr400_b, arr401_b, arr402_b, arr403_b, arr404_b, arr405_b, arr406_b, arr407_b] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr410_b, arr411_b, arr412_b, arr413_b, arr414_b, arr415_b, arr416_b, arr417_b] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr500_b, arr501_b, arr502_b, arr503_b, arr504_b, arr505_b, arr506_b, arr507_b] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr510_b, arr511_b, arr512_b, arr513_b, arr514_b, arr515_b, arr516_b, arr517_b] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr600_b, arr601_b, arr602_b, arr603_b, arr604_b, arr605_b, arr606_b, arr607_b] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr610_b, arr611_b, arr612_b, arr613_b, arr614_b, arr615_b, arr616_b, arr617_b] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr700_b, arr701_b, arr702_b, arr703_b, arr704_b, arr705_b, arr706_b, arr707_b] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr710_b, arr711_b, arr712_b, arr713_b, arr714_b, arr715_b, arr716_b, arr717_b] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr800_b, arr801_b, arr802_b, arr803_b, arr804_b, arr805_b, arr806_b, arr807_b] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr810_b, arr811_b, arr812_b, arr813_b, arr814_b, arr815_b, arr816_b, arr817_b] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr900_b, arr901_b, arr902_b, arr903_b, arr904_b, arr905_b, arr906_b, arr907_b] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\
    [arr910_b, arr911_b, arr912_b, arr913_b, arr914_b, arr915_b, arr916_b, arr917_b] <=s [21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16, 21565@16] /\

    [arr000_a, arr001_a, arr002_a, arr003_a, arr004_a, arr005_a, arr006_a, arr007_a] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr010_a, arr011_a, arr012_a, arr013_a, arr014_a, arr015_a, arr016_a, arr017_a] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr100_a, arr101_a, arr102_a, arr103_a, arr104_a, arr105_a, arr106_a, arr107_a] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr110_a, arr111_a, arr112_a, arr113_a, arr114_a, arr115_a, arr116_a, arr117_a] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr200_a, arr201_a, arr202_a, arr203_a, arr204_a, arr205_a, arr206_a, arr207_a] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr210_a, arr211_a, arr212_a, arr213_a, arr214_a, arr215_a, arr216_a, arr217_a] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr300_a, arr301_a, arr302_a, arr303_a, arr304_a, arr305_a, arr306_a, arr307_a] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr310_a, arr311_a, arr312_a, arr313_a, arr314_a, arr315_a, arr316_a, arr317_a] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr400_a, arr401_a, arr402_a, arr403_a, arr404_a, arr405_a, arr406_a, arr407_a] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr410_a, arr411_a, arr412_a, arr413_a, arr414_a, arr415_a, arr416_a, arr417_a] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr500_a, arr501_a, arr502_a, arr503_a, arr504_a, arr505_a, arr506_a, arr507_a] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr510_a, arr511_a, arr512_a, arr513_a, arr514_a, arr515_a, arr516_a, arr517_a] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr600_a, arr601_a, arr602_a, arr603_a, arr604_a, arr605_a, arr606_a, arr607_a] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr610_a, arr611_a, arr612_a, arr613_a, arr614_a, arr615_a, arr616_a, arr617_a] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr700_a, arr701_a, arr702_a, arr703_a, arr704_a, arr705_a, arr706_a, arr707_a] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr710_a, arr711_a, arr712_a, arr713_a, arr714_a, arr715_a, arr716_a, arr717_a] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr800_a, arr801_a, arr802_a, arr803_a, arr804_a, arr805_a, arr806_a, arr807_a] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr810_a, arr811_a, arr812_a, arr813_a, arr814_a, arr815_a, arr816_a, arr817_a] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr900_a, arr901_a, arr902_a, arr903_a, arr904_a, arr905_a, arr906_a, arr907_a] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr910_a, arr911_a, arr912_a, arr913_a, arr914_a, arr915_a, arr916_a, arr917_a] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr000_b, arr001_b, arr002_b, arr003_b, arr004_b, arr005_b, arr006_b, arr007_b] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr010_b, arr011_b, arr012_b, arr013_b, arr014_b, arr015_b, arr016_b, arr017_b] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr100_b, arr101_b, arr102_b, arr103_b, arr104_b, arr105_b, arr106_b, arr107_b] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr110_b, arr111_b, arr112_b, arr113_b, arr114_b, arr115_b, arr116_b, arr117_b] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr200_b, arr201_b, arr202_b, arr203_b, arr204_b, arr205_b, arr206_b, arr207_b] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr210_b, arr211_b, arr212_b, arr213_b, arr214_b, arr215_b, arr216_b, arr217_b] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr300_b, arr301_b, arr302_b, arr303_b, arr304_b, arr305_b, arr306_b, arr307_b] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr310_b, arr311_b, arr312_b, arr313_b, arr314_b, arr315_b, arr316_b, arr317_b] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr400_b, arr401_b, arr402_b, arr403_b, arr404_b, arr405_b, arr406_b, arr407_b] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr410_b, arr411_b, arr412_b, arr413_b, arr414_b, arr415_b, arr416_b, arr417_b] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr500_b, arr501_b, arr502_b, arr503_b, arr504_b, arr505_b, arr506_b, arr507_b] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr510_b, arr511_b, arr512_b, arr513_b, arr514_b, arr515_b, arr516_b, arr517_b] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr600_b, arr601_b, arr602_b, arr603_b, arr604_b, arr605_b, arr606_b, arr607_b] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr610_b, arr611_b, arr612_b, arr613_b, arr614_b, arr615_b, arr616_b, arr617_b] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr700_b, arr701_b, arr702_b, arr703_b, arr704_b, arr705_b, arr706_b, arr707_b] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr710_b, arr711_b, arr712_b, arr713_b, arr714_b, arr715_b, arr716_b, arr717_b] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr800_b, arr801_b, arr802_b, arr803_b, arr804_b, arr805_b, arr806_b, arr807_b] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr810_b, arr811_b, arr812_b, arr813_b, arr814_b, arr815_b, arr816_b, arr817_b] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr900_b, arr901_b, arr902_b, arr903_b, arr904_b, arr905_b, arr906_b, arr907_b] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16] /\
    [arr910_b, arr911_b, arr912_b, arr913_b, arr914_b, arr915_b, arr916_b, arr917_b] >=s [(-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16, (-21565)@16]
}

# setup

mov [L0x55555526f0, L0x55555526f2, L0x55555526f4, L0x55555526f6, L0x55555526f8, L0x55555526fa, L0x55555526fc, L0x55555526fe] [4591@sint16, 29@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16];
mov [L0x5555552700, L0x5555552702, L0x5555552704, L0x5555552706, L0x5555552708, L0x555555270a, L0x555555270c, L0x555555270e] [1005@sint16, 918@sint16, (-818)@sint16, (-1736)@sint16, 7173@sint16, 6552@sint16, (-5838)@sint16, (-12391)@sint16];
mov [L0x5555552710, L0x5555552712, L0x5555552714, L0x5555552716, L0x5555552718, L0x555555271a, L0x555555271c, L0x555555271e] [(-2274)@sint16, (-16231)@sint16, 1610@sint16, 11491@sint16, (-2113)@sint16, (-15081)@sint16, (-1815)@sint16, (-12954)@sint16];
mov [L0x5555552720, L0x5555552722, L0x5555552724, L0x5555552726, L0x5555552728, L0x555555272a, L0x555555272c, L0x555555272e] [(-2274)@sint16, (-16231)@sint16, 1610@sint16, 11491@sint16, (-2113)@sint16, (-15081)@sint16, (-1815)@sint16, (-12954)@sint16];
mov [L0x5555552730, L0x5555552732, L0x5555552734, L0x5555552736, L0x5555552738, L0x555555273a, L0x555555273c, L0x555555273e] [2113@sint16, 15081@sint16, (-2274)@sint16, (-16231)@sint16, 1815@sint16, 12954@sint16, 1610@sint16, 11491@sint16];
mov [L0x5555552740, L0x5555552742, L0x5555552744, L0x5555552746, L0x5555552748, L0x555555274a, L0x555555274c, L0x555555274e] [(-2113)@sint16, (-15081)@sint16, 2274@sint16, 16231@sint16, (-1815)@sint16, (-12954)@sint16, (-1610)@sint16, (-11491)@sint16];
mov [L0x5555552750, L0x5555552752, L0x5555552754, L0x5555552756, L0x5555552758, L0x555555275a, L0x555555275c, L0x555555275e] [1@sint16, 7@sint16, 1@sint16, 7@sint16, 1@sint16, 7@sint16, 1@sint16, 7@sint16];
mov [L0x5555552760, L0x5555552762, L0x5555552764, L0x5555552766, L0x5555552768, L0x555555276a, L0x555555276c, L0x555555276e] [1@sint16, 7@sint16, 1@sint16, 7@sint16, 1@sint16, 7@sint16, 1@sint16, 7@sint16];
mov [L0x5555552770, L0x5555552772, L0x5555552774, L0x5555552776, L0x5555552778, L0x555555277a, L0x555555277c, L0x555555277e] [(-1610)@sint16, (-11491)@sint16, (-1815)@sint16, (-12954)@sint16, 2274@sint16, 16231@sint16, (-2113)@sint16, (-15081)@sint16];
mov [L0x5555552780, L0x5555552782, L0x5555552784, L0x5555552786, L0x5555552788, L0x555555278a, L0x555555278c, L0x555555278e] [1610@sint16, 11491@sint16, 1815@sint16, 12954@sint16, (-2274)@sint16, (-16231)@sint16, 2113@sint16, 15081@sint16];
mov [L0x5555552790, L0x5555552792, L0x5555552794, L0x5555552796, L0x5555552798, L0x555555279a, L0x555555279c, L0x555555279e] [(-1815)@sint16, (-12954)@sint16, (-2113)@sint16, (-15081)@sint16, 1610@sint16, 11491@sint16, (-2274)@sint16, (-16231)@sint16];
mov [L0x55555527a0, L0x55555527a2, L0x55555527a4, L0x55555527a6, L0x55555527a8, L0x55555527aa, L0x55555527ac, L0x55555527ae] [(-1815)@sint16, (-12954)@sint16, (-2113)@sint16, (-15081)@sint16, 1610@sint16, 11491@sint16, (-2274)@sint16, (-16231)@sint16];
mov [L0x55555527b0, L0x55555527b2, L0x55555527b4, L0x55555527b6, L0x55555527b8, L0x55555527ba, L0x55555527bc, L0x55555527be] [2274@sint16, 16231@sint16, 1610@sint16, 11491@sint16, 2113@sint16, 15081@sint16, (-1815)@sint16, (-12954)@sint16];
mov [L0x55555527c0, L0x55555527c2, L0x55555527c4, L0x55555527c6, L0x55555527c8, L0x55555527ca, L0x55555527cc, L0x55555527ce] [(-2274)@sint16, (-16231)@sint16, (-1610)@sint16, (-11491)@sint16, (-2113)@sint16, (-15081)@sint16, 1815@sint16, 12954@sint16];
mov [L0x55555527d0, L0x55555527d2, L0x55555527d4, L0x55555527d6, L0x55555527d8, L0x55555527da, L0x55555527dc, L0x55555527de] [(-2113)@sint16, (-15081)@sint16, (-2274)@sint16, (-16231)@sint16, (-1815)@sint16, (-12954)@sint16, 1610@sint16, 11491@sint16];
mov [L0x55555527e0, L0x55555527e2, L0x55555527e4, L0x55555527e6, L0x55555527e8, L0x55555527ea, L0x55555527ec, L0x55555527ee] [(-2113)@sint16, (-15081)@sint16, (-2274)@sint16, (-16231)@sint16, (-1815)@sint16, (-12954)@sint16, 1610@sint16, 11491@sint16];
mov [L0x55555527f0, L0x55555527f2, L0x55555527f4, L0x55555527f6, L0x55555527f8, L0x55555527fa, L0x55555527fc, L0x55555527fe] [(-1)@sint16, (-7)@sint16, 1@sint16, 7@sint16, (-1)@sint16, (-7)@sint16, 1@sint16, 7@sint16];
mov [L0x5555552800, L0x5555552802, L0x5555552804, L0x5555552806, L0x5555552808, L0x555555280a, L0x555555280c, L0x555555280e] [1@sint16, 7@sint16, (-1)@sint16, (-7)@sint16, 1@sint16, 7@sint16, (-1)@sint16, (-7)@sint16];
mov [L0x5555552810, L0x5555552812, L0x5555552814, L0x5555552816, L0x5555552818, L0x555555281a, L0x555555281c, L0x555555281e] [1610@sint16, 11491@sint16, (-1815)@sint16, (-12954)@sint16, (-2274)@sint16, (-16231)@sint16, (-2113)@sint16, (-15081)@sint16];
mov [L0x5555552820, L0x5555552822, L0x5555552824, L0x5555552826, L0x5555552828, L0x555555282a, L0x555555282c, L0x555555282e] [1610@sint16, 11491@sint16, (-1815)@sint16, (-12954)@sint16, (-2274)@sint16, (-16231)@sint16, (-2113)@sint16, (-15081)@sint16];
mov [L0x5555552830, L0x5555552832, L0x5555552834, L0x5555552836, L0x5555552838, L0x555555283a, L0x555555283c, L0x555555283e] [4591@sint16, 29235@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16];
mov [L0x5555552840, L0x5555552842, L0x5555552844, L0x5555552846, L0x5555552848, L0x555555284a, L0x555555284c, L0x555555284e] [(-621)@sint16, 1891@sint16, (-803)@sint16, 0@sint16, (-4432)@sint16, 13497@sint16, (-5731)@sint16, (-17729)@sint16];
mov [L0x5555552850, L0x5555552852, L0x5555552854, L0x5555552856, L0x5555552858, L0x555555285a, L0x555555285c, L0x555555285e] [4591@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16];
mov [L0x5555552860, L0x5555552862, L0x5555552864, L0x5555552866, L0x5555552868, L0x555555286a, L0x555555286c, L0x555555286e] [(-28264)@sint16, (-16381)@sint16, (-28264)@sint16, (-16381)@sint16, (-2295)@sint16, (-2295)@sint16, 7@sint16, 1@sint16];
mov [L0x5555552870, L0x5555552872, L0x5555552874, L0x5555552876, L0x5555552878, L0x555555287a, L0x555555287c, L0x555555287e] [(-28264)@sint16, (-16381)@sint16, 557@sint16, 12983@sint16, (-2295)@sint16, 1819@sint16, 12241@sint16, 1715@sint16];
mov [L0x5555552880, L0x5555552882, L0x5555552884, L0x5555552886, L0x5555552888, L0x555555288a, L0x555555288c, L0x555555288e] [(-28264)@sint16, (-16381)@sint16, (-6267)@sint16, 13496@sint16, (-2295)@sint16, 1891@sint16, (-11463)@sint16, (-1606)@sint16];
mov [L0x5555552890, L0x5555552892, L0x5555552894, L0x5555552896, L0x5555552898, L0x555555289a, L0x555555289c, L0x555555289e] [(-28264)@sint16, (-16381)@sint16, 8365@sint16, 15274@sint16, (-2295)@sint16, 2140@sint16, 2213@sint16, 310@sint16];
mov [L0x55555528a0, L0x55555528a2, L0x55555528a4, L0x55555528a6, L0x55555528a8, L0x55555528aa, L0x55555528ac, L0x55555528ae] [(-28264)@sint16, (-16381)@sint16, 23468@sint16, (-7252)@sint16, (-2295)@sint16, (-1016)@sint16, (-6467)@sint16, (-906)@sint16];
mov [L0x55555528b0, L0x55555528b2, L0x55555528b4, L0x55555528b6, L0x55555528b8, L0x55555528ba, L0x55555528bc, L0x55555528be] [(-28264)@sint16, (-16381)@sint16, (-17144)@sint16, (-3234)@sint16, (-2295)@sint16, (-453)@sint16, (-14503)@sint16, (-2032)@sint16];
mov [L0x55555528c0, L0x55555528c2, L0x55555528c4, L0x55555528c6, L0x55555528c8, L0x55555528ca, L0x55555528cc, L0x55555528ce] [(-28264)@sint16, (-16381)@sint16, 19899@sint16, 1106@sint16, (-2295)@sint16, 155@sint16, (-2220)@sint16, (-311)@sint16];
mov [L0x55555528d0, L0x55555528d2, L0x55555528d4, L0x55555528d6, L0x55555528d8, L0x55555528da, L0x55555528dc, L0x55555528de] [(-28264)@sint16, (-16381)@sint16, (-24025)@sint16, (-5732)@sint16, (-2295)@sint16, (-803)@sint16, (-5774)@sint16, (-809)@sint16];
mov [L0x55555528e0, L0x55555528e2, L0x55555528e4, L0x55555528e6, L0x55555528e8, L0x55555528ea, L0x55555528ec, L0x55555528ee] [(-28264)@sint16, (-16381)@sint16, 23411@sint16, (-10264)@sint16, (-2295)@sint16, (-1438)@sint16, (-6802)@sint16, (-953)@sint16];
mov [L0x55555528f0, L0x55555528f2, L0x55555528f4, L0x55555528f6, L0x55555528f8, L0x55555528fa, L0x55555528fc, L0x55555528fe] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, (-11491)@sint16, (-1610)@sint16];
mov [L0x5555552900, L0x5555552902, L0x5555552904, L0x5555552906, L0x5555552908, L0x555555290a, L0x555555290c, L0x555555290e] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 6616@sint16, 927@sint16];
mov [L0x5555552910, L0x5555552912, L0x5555552914, L0x5555552916, L0x5555552918, L0x555555291a, L0x555555291c, L0x555555291e] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, (-9122)@sint16, (-1278)@sint16];
mov [L0x5555552920, L0x5555552922, L0x5555552924, L0x5555552926, L0x5555552928, L0x555555292a, L0x555555292c, L0x555555292e] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 2077@sint16, 291@sint16];
mov [L0x5555552930, L0x5555552932, L0x5555552934, L0x5555552936, L0x5555552938, L0x555555293a, L0x555555293c, L0x555555293e] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 6681@sint16, 936@sint16];
mov [L0x5555552940, L0x5555552942, L0x5555552944, L0x5555552946, L0x5555552948, L0x555555294a, L0x555555294c, L0x555555294e] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, (-13982)@sint16, (-1959)@sint16];
mov [L0x5555552950, L0x5555552952, L0x5555552954, L0x5555552956, L0x5555552958, L0x555555295a, L0x555555295c, L0x555555295e] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 9414@sint16, 1319@sint16];
mov [L0x5555552960, L0x5555552962, L0x5555552964, L0x5555552966, L0x5555552968, L0x555555296a, L0x555555296c, L0x555555296e] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, (-13297)@sint16, (-1863)@sint16];
mov [L0x5555552970, L0x5555552972, L0x5555552974, L0x5555552976, L0x5555552978, L0x555555297a, L0x555555297c, L0x555555297e] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, (-9664)@sint16, (-1354)@sint16];
mov [L0x5555552980, L0x5555552982, L0x5555552984, L0x5555552986, L0x5555552988, L0x555555298a, L0x555555298c, L0x555555298e] [(-28264)@sint16, (-16381)@sint16, 19114@sint16, 8843@sint16, (-2295)@sint16, 1239@sint16, 11491@sint16, 1610@sint16];
mov [L0x5555552990, L0x5555552992, L0x5555552994, L0x5555552996, L0x5555552998, L0x555555299a, L0x555555299c, L0x555555299e] [(-28264)@sint16, (-16381)@sint16, 3297@sint16, (-6281)@sint16, (-2295)@sint16, (-880)@sint16, 13982@sint16, 1959@sint16];
mov [L0x55555529a0, L0x55555529a2, L0x55555529a4, L0x55555529a6, L0x55555529a8, L0x55555529aa, L0x55555529ac, L0x55555529ae] [(-28264)@sint16, (-16381)@sint16, 3212@sint16, (-10799)@sint16, (-2295)@sint16, (-1513)@sint16, (-6616)@sint16, (-927)@sint16];
mov [L0x55555529b0, L0x55555529b2, L0x55555529b4, L0x55555529b6, L0x55555529b8, L0x55555529ba, L0x55555529bc, L0x55555529be] [(-28264)@sint16, (-16381)@sint16, 19300@sint16, 2248@sint16, (-2295)@sint16, 315@sint16, (-9414)@sint16, (-1319)@sint16];
mov [L0x55555529c0, L0x55555529c2, L0x55555529c4, L0x55555529c6, L0x55555529c8, L0x55555529ca, L0x55555529cc, L0x55555529ce] [(-28264)@sint16, (-16381)@sint16, 23054@sint16, (-12705)@sint16, (-2295)@sint16, (-1780)@sint16, 9122@sint16, 1278@sint16];
mov [L0x55555529d0, L0x55555529d2, L0x55555529d4, L0x55555529d6, L0x55555529d8, L0x55555529da, L0x55555529dc, L0x55555529de] [(-28264)@sint16, (-16381)@sint16, (-15845)@sint16, 16137@sint16, (-2295)@sint16, 2261@sint16, 13297@sint16, 1863@sint16];
mov [L0x55555529e0, L0x55555529e2, L0x55555529e4, L0x55555529e6, L0x55555529e8, L0x55555529ea, L0x55555529ec, L0x55555529ee] [(-28264)@sint16, (-16381)@sint16, 27122@sint16, (-11092)@sint16, (-2295)@sint16, (-1554)@sint16, (-2077)@sint16, (-291)@sint16];
mov [L0x55555529f0, L0x55555529f2, L0x55555529f4, L0x55555529f6, L0x55555529f8, L0x55555529fa, L0x55555529fc, L0x55555529fe] [(-28264)@sint16, (-16381)@sint16, (-26351)@sint16, (-13783)@sint16, (-2295)@sint16, (-1931)@sint16, 9664@sint16, 1354@sint16];
mov [L0x5555552a00, L0x5555552a02, L0x5555552a04, L0x5555552a06, L0x5555552a08, L0x5555552a0a, L0x5555552a0c, L0x5555552a0e] [(-28264)@sint16, (-16381)@sint16, 12633@sint16, (-5339)@sint16, (-2295)@sint16, (-748)@sint16, (-6681)@sint16, (-936)@sint16];
mov [L0x5555552a10, L0x5555552a12, L0x5555552a14, L0x5555552a16, L0x5555552a18, L0x5555552a1a, L0x5555552a1c, L0x5555552a1e] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 16231@sint16, 2274@sint16];
mov [L0x5555552a20, L0x5555552a22, L0x5555552a24, L0x5555552a26, L0x5555552a28, L0x5555552a2a, L0x5555552a2c, L0x5555552a2e] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, (-15695)@sint16, (-2199)@sint16];
mov [L0x5555552a30, L0x5555552a32, L0x5555552a34, L0x5555552a36, L0x5555552a38, L0x5555552a3a, L0x5555552a3c, L0x5555552a3e] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 7958@sint16, 1115@sint16];
mov [L0x5555552a40, L0x5555552a42, L0x5555552a44, L0x5555552a46, L0x5555552a48, L0x5555552a4a, L0x5555552a4c, L0x5555552a4e] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, (-1427)@sint16, (-200)@sint16];
mov [L0x5555552a50, L0x5555552a52, L0x5555552a54, L0x5555552a56, L0x5555552a58, L0x5555552a5a, L0x5555552a5c, L0x5555552a5e] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, (-1213)@sint16, (-170)@sint16];
mov [L0x5555552a60, L0x5555552a62, L0x5555552a64, L0x5555552a66, L0x5555552a68, L0x5555552a6a, L0x5555552a6c, L0x5555552a6e] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 15353@sint16, 2151@sint16];
mov [L0x5555552a70, L0x5555552a72, L0x5555552a74, L0x5555552a76, L0x5555552a78, L0x5555552a7a, L0x5555552a7c, L0x5555552a7e] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, (-14803)@sint16, (-2074)@sint16];
mov [L0x5555552a80, L0x5555552a82, L0x5555552a84, L0x5555552a86, L0x5555552a88, L0x5555552a8a, L0x5555552a8c, L0x5555552a8e] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, (-15859)@sint16, (-2222)@sint16];
mov [L0x5555552a90, L0x5555552a92, L0x5555552a94, L0x5555552a96, L0x5555552a98, L0x5555552a9a, L0x5555552a9c, L0x5555552a9e] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 9457@sint16, 1325@sint16];
mov [L0x5555552aa0, L0x5555552aa2, L0x5555552aa4, L0x5555552aa6, L0x5555552aa8, L0x5555552aaa, L0x5555552aac, L0x5555552aae] [(-28264)@sint16, (-16381)@sint16, (-17858)@sint16, (-8116)@sint16, (-2295)@sint16, (-1137)@sint16, (-12954)@sint16, (-1815)@sint16];
mov [L0x5555552ab0, L0x5555552ab2, L0x5555552ab4, L0x5555552ab6, L0x5555552ab8, L0x5555552aba, L0x5555552abc, L0x5555552abe] [(-28264)@sint16, (-16381)@sint16, (-20799)@sint16, 606@sint16, (-2295)@sint16, 85@sint16, (-193)@sint16, (-27)@sint16];
mov [L0x5555552ac0, L0x5555552ac2, L0x5555552ac4, L0x5555552ac6, L0x5555552ac8, L0x5555552aca, L0x5555552acc, L0x5555552ace] [(-28264)@sint16, (-16381)@sint16, 29106@sint16, 11655@sint16, (-2295)@sint16, 1633@sint16, (-2819)@sint16, (-395)@sint16];
mov [L0x5555552ad0, L0x5555552ad2, L0x5555552ad4, L0x5555552ad6, L0x5555552ad8, L0x5555552ada, L0x5555552adc, L0x5555552ade] [(-28264)@sint16, (-16381)@sint16, (-16759)@sint16, 713@sint16, (-2295)@sint16, 100@sint16, 14582@sint16, 2043@sint16];
mov [L0x5555552ae0, L0x5555552ae2, L0x5555552ae4, L0x5555552ae6, L0x5555552ae8, L0x5555552aea, L0x5555552aec, L0x5555552aee] [(-28264)@sint16, (-16381)@sint16, (-19728)@sint16, 7929@sint16, (-2295)@sint16, 1111@sint16, 5796@sint16, 812@sint16];
mov [L0x5555552af0, L0x5555552af2, L0x5555552af4, L0x5555552af6, L0x5555552af8, L0x5555552afa, L0x5555552afc, L0x5555552afe] [(-28264)@sint16, (-16381)@sint16, (-8151)@sint16, 12404@sint16, (-2295)@sint16, 1738@sint16, 10756@sint16, 1507@sint16];
mov [L0x5555552b00, L0x5555552b02, L0x5555552b04, L0x5555552b06, L0x5555552b08, L0x5555552b0a, L0x5555552b0c, L0x5555552b0e] [(-28264)@sint16, (-16381)@sint16, (-30919)@sint16, 7401@sint16, (-2295)@sint16, 1037@sint16, (-1627)@sint16, (-228)@sint16];
mov [L0x5555552b10, L0x5555552b12, L0x5555552b14, L0x5555552b16, L0x5555552b18, L0x5555552b1a, L0x5555552b1c, L0x5555552b1e] [(-28264)@sint16, (-16381)@sint16, (-25010)@sint16, (-8537)@sint16, (-2295)@sint16, (-1196)@sint16, (-5603)@sint16, (-785)@sint16];
mov [L0x5555552b20, L0x5555552b22, L0x5555552b24, L0x5555552b26, L0x5555552b28, L0x5555552b2a, L0x5555552b2c, L0x5555552b2e] [(-28264)@sint16, (-16381)@sint16, (-20956)@sint16, 8707@sint16, (-2295)@sint16, 1220@sint16, (-7937)@sint16, (-1112)@sint16];
mov [L0x5555552b30, L0x5555552b32, L0x5555552b34, L0x5555552b36, L0x5555552b38, L0x5555552b3a, L0x5555552b3c, L0x5555552b3e] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, (-7)@sint16, (-1)@sint16];
mov [L0x5555552b40, L0x5555552b42, L0x5555552b44, L0x5555552b46, L0x5555552b48, L0x5555552b4a, L0x5555552b4c, L0x5555552b4e] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 11463@sint16, 1606@sint16];
mov [L0x5555552b50, L0x5555552b52, L0x5555552b54, L0x5555552b56, L0x5555552b58, L0x5555552b5a, L0x5555552b5c, L0x5555552b5e] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 6467@sint16, 906@sint16];
mov [L0x5555552b60, L0x5555552b62, L0x5555552b64, L0x5555552b66, L0x5555552b68, L0x5555552b6a, L0x5555552b6c, L0x5555552b6e] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 2220@sint16, 311@sint16];
mov [L0x5555552b70, L0x5555552b72, L0x5555552b74, L0x5555552b76, L0x5555552b78, L0x5555552b7a, L0x5555552b7c, L0x5555552b7e] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 6802@sint16, 953@sint16];
mov [L0x5555552b80, L0x5555552b82, L0x5555552b84, L0x5555552b86, L0x5555552b88, L0x5555552b8a, L0x5555552b8c, L0x5555552b8e] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, (-12241)@sint16, (-1715)@sint16];
mov [L0x5555552b90, L0x5555552b92, L0x5555552b94, L0x5555552b96, L0x5555552b98, L0x5555552b9a, L0x5555552b9c, L0x5555552b9e] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, (-2213)@sint16, (-310)@sint16];
mov [L0x5555552ba0, L0x5555552ba2, L0x5555552ba4, L0x5555552ba6, L0x5555552ba8, L0x5555552baa, L0x5555552bac, L0x5555552bae] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 14503@sint16, 2032@sint16];
mov [L0x5555552bb0, L0x5555552bb2, L0x5555552bb4, L0x5555552bb6, L0x5555552bb8, L0x5555552bba, L0x5555552bbc, L0x5555552bbe] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 5774@sint16, 809@sint16];
mov [L0x5555552bc0, L0x5555552bc2, L0x5555552bc4, L0x5555552bc6, L0x5555552bc8, L0x5555552bca, L0x5555552bcc, L0x5555552bce] [(-28264)@sint16, (-16381)@sint16, (-15031)@sint16, 9906@sint16, (-2295)@sint16, 1388@sint16, (-16231)@sint16, (-2274)@sint16];
mov [L0x5555552bd0, L0x5555552bd2, L0x5555552bd4, L0x5555552bd6, L0x5555552bd8, L0x5555552bda, L0x5555552bdc, L0x5555552bde] [(-28264)@sint16, (-16381)@sint16, (-27408)@sint16, (-3969)@sint16, (-2295)@sint16, (-556)@sint16, (-15353)@sint16, (-2151)@sint16];
mov [L0x5555552be0, L0x5555552be2, L0x5555552be4, L0x5555552be6, L0x5555552be8, L0x5555552bea, L0x5555552bec, L0x5555552bee] [(-28264)@sint16, (-16381)@sint16, (-29249)@sint16, 13582@sint16, (-2295)@sint16, 1903@sint16, 15695@sint16, 2199@sint16];
mov [L0x5555552bf0, L0x5555552bf2, L0x5555552bf4, L0x5555552bf6, L0x5555552bf8, L0x5555552bfa, L0x5555552bfc, L0x5555552bfe] [(-28264)@sint16, (-16381)@sint16, 21726@sint16, (-814)@sint16, (-2295)@sint16, (-114)@sint16, 14803@sint16, 2074@sint16];
mov [L0x5555552c00, L0x5555552c02, L0x5555552c04, L0x5555552c06, L0x5555552c08, L0x5555552c0a, L0x5555552c0c, L0x5555552c0e] [(-28264)@sint16, (-16381)@sint16, 4140@sint16, (-11006)@sint16, (-2295)@sint16, (-1542)@sint16, (-7958)@sint16, (-1115)@sint16];
mov [L0x5555552c10, L0x5555552c12, L0x5555552c14, L0x5555552c16, L0x5555552c18, L0x5555552c1a, L0x5555552c1c, L0x5555552c1e] [(-28264)@sint16, (-16381)@sint16, (-12990)@sint16, 2897@sint16, (-2295)@sint16, 406@sint16, 15859@sint16, 2222@sint16];
mov [L0x5555552c20, L0x5555552c22, L0x5555552c24, L0x5555552c26, L0x5555552c28, L0x5555552c2a, L0x5555552c2c, L0x5555552c2e] [(-28264)@sint16, (-16381)@sint16, (-6695)@sint16, (-9094)@sint16, (-2295)@sint16, (-1274)@sint16, 1427@sint16, 200@sint16];
mov [L0x5555552c30, L0x5555552c32, L0x5555552c34, L0x5555552c36, L0x5555552c38, L0x5555552c3a, L0x5555552c3c, L0x5555552c3e] [(-28264)@sint16, (-16381)@sint16, 23268@sint16, 14974@sint16, (-2295)@sint16, 2098@sint16, (-9457)@sint16, (-1325)@sint16];
mov [L0x5555552c40, L0x5555552c42, L0x5555552c44, L0x5555552c46, L0x5555552c48, L0x5555552c4a, L0x5555552c4c, L0x5555552c4e] [(-28264)@sint16, (-16381)@sint16, (-23297)@sint16, 16287@sint16, (-2295)@sint16, 2282@sint16, 1213@sint16, 170@sint16];
mov [L0x5555552c50, L0x5555552c52, L0x5555552c54, L0x5555552c56, L0x5555552c58, L0x5555552c5a, L0x5555552c5c, L0x5555552c5e] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 12954@sint16, 1815@sint16];
mov [L0x5555552c60, L0x5555552c62, L0x5555552c64, L0x5555552c66, L0x5555552c68, L0x5555552c6a, L0x5555552c6c, L0x5555552c6e] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 2819@sint16, 395@sint16];
mov [L0x5555552c70, L0x5555552c72, L0x5555552c74, L0x5555552c76, L0x5555552c78, L0x5555552c7a, L0x5555552c7c, L0x5555552c7e] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, (-5796)@sint16, (-812)@sint16];
mov [L0x5555552c80, L0x5555552c82, L0x5555552c84, L0x5555552c86, L0x5555552c88, L0x5555552c8a, L0x5555552c8c, L0x5555552c8e] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 1627@sint16, 228@sint16];
mov [L0x5555552c90, L0x5555552c92, L0x5555552c94, L0x5555552c96, L0x5555552c98, L0x5555552c9a, L0x5555552c9c, L0x5555552c9e] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 7937@sint16, 1112@sint16];
mov [L0x5555552ca0, L0x5555552ca2, L0x5555552ca4, L0x5555552ca6, L0x5555552ca8, L0x5555552caa, L0x5555552cac, L0x5555552cae] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 193@sint16, 27@sint16];
mov [L0x5555552cb0, L0x5555552cb2, L0x5555552cb4, L0x5555552cb6, L0x5555552cb8, L0x5555552cba, L0x5555552cbc, L0x5555552cbe] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, (-14582)@sint16, (-2043)@sint16];
mov [L0x5555552cc0, L0x5555552cc2, L0x5555552cc4, L0x5555552cc6, L0x5555552cc8, L0x5555552cca, L0x5555552ccc, L0x5555552cce] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, (-10756)@sint16, (-1507)@sint16];
mov [L0x5555552cd0, L0x5555552cd2, L0x5555552cd4, L0x5555552cd6, L0x5555552cd8, L0x5555552cda, L0x5555552cdc, L0x5555552cde] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 5603@sint16, 785@sint16];
mov [L0x5555552ce0, L0x5555552ce2, L0x5555552ce4, L0x5555552ce6, L0x5555552ce8, L0x5555552cea, L0x5555552cec, L0x5555552cee] [(-28264)@sint16, (-16381)@sint16, (-23496)@sint16, 5745@sint16, (-2295)@sint16, 805@sint16, (-15081)@sint16, (-2113)@sint16];
mov [L0x5555552cf0, L0x5555552cf2, L0x5555552cf4, L0x5555552cf6, L0x5555552cf8, L0x5555552cfa, L0x5555552cfc, L0x5555552cfe] [(-28264)@sint16, (-16381)@sint16, (-21184)@sint16, (-3341)@sint16, (-2295)@sint16, (-468)@sint16, (-10678)@sint16, (-1496)@sint16];
mov [L0x5555552d00, L0x5555552d02, L0x5555552d04, L0x5555552d06, L0x5555552d08, L0x5555552d0a, L0x5555552d0c, L0x5555552d0e] [(-28264)@sint16, (-16381)@sint16, 3198@sint16, 4832@sint16, (-2295)@sint16, 677@sint16, 5203@sint16, 729@sint16];
mov [L0x5555552d10, L0x5555552d12, L0x5555552d14, L0x5555552d16, L0x5555552d18, L0x5555552d1a, L0x5555552d1c, L0x5555552d1e] [(-28264)@sint16, (-16381)@sint16, (-32632)@sint16, 15345@sint16, (-2295)@sint16, 2150@sint16, 10585@sint16, 1483@sint16];
mov [L0x5555552d20, L0x5555552d22, L0x5555552d24, L0x5555552d26, L0x5555552d28, L0x5555552d2a, L0x5555552d2c, L0x5555552d2e] [(-28264)@sint16, (-16381)@sint16, (-30934)@sint16, (-9736)@sint16, (-2295)@sint16, (-1364)@sint16, (-492)@sint16, (-69)@sint16];
mov [L0x5555552d30, L0x5555552d32, L0x5555552d34, L0x5555552d36, L0x5555552d38, L0x5555552d3a, L0x5555552d3c, L0x5555552d3e] [(-28264)@sint16, (-16381)@sint16, (-11406)@sint16, 4560@sint16, (-2295)@sint16, 639@sint16, 7359@sint16, 1031@sint16];
mov [L0x5555552d40, L0x5555552d42, L0x5555552d44, L0x5555552d46, L0x5555552d48, L0x5555552d4a, L0x5555552d4c, L0x5555552d4e] [(-28264)@sint16, (-16381)@sint16, (-9407)@sint16, 11676@sint16, (-2295)@sint16, 1636@sint16, 4497@sint16, 630@sint16];
mov [L0x5555552d50, L0x5555552d52, L0x5555552d54, L0x5555552d56, L0x5555552d58, L0x5555552d5a, L0x5555552d5c, L0x5555552d5e] [(-28264)@sint16, (-16381)@sint16, (-13418)@sint16, 13075@sint16, (-2295)@sint16, 1832@sint16, 11170@sint16, 1565@sint16];
mov [L0x5555552d60, L0x5555552d62, L0x5555552d64, L0x5555552d66, L0x5555552d68, L0x5555552d6a, L0x5555552d6c, L0x5555552d6e] [(-28264)@sint16, (-16381)@sint16, 8208@sint16, (-9393)@sint16, (-2295)@sint16, (-1316)@sint16, (-12562)@sint16, (-1760)@sint16];
mov [L0x5555552d70, L0x5555552d72, L0x5555552d74, L0x5555552d76, L0x5555552d78, L0x5555552d7a, L0x5555552d7c, L0x5555552d7e] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 15081@sint16, 2113@sint16];
mov [L0x5555552d80, L0x5555552d82, L0x5555552d84, L0x5555552d86, L0x5555552d88, L0x5555552d8a, L0x5555552d8c, L0x5555552d8e] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, (-5203)@sint16, (-729)@sint16];
mov [L0x5555552d90, L0x5555552d92, L0x5555552d94, L0x5555552d96, L0x5555552d98, L0x5555552d9a, L0x5555552d9c, L0x5555552d9e] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 492@sint16, 69@sint16];
mov [L0x5555552da0, L0x5555552da2, L0x5555552da4, L0x5555552da6, L0x5555552da8, L0x5555552daa, L0x5555552dac, L0x5555552dae] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, (-4497)@sint16, (-630)@sint16];
mov [L0x5555552db0, L0x5555552db2, L0x5555552db4, L0x5555552db6, L0x5555552db8, L0x5555552dba, L0x5555552dbc, L0x5555552dbe] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 12562@sint16, 1760@sint16];
mov [L0x5555552dc0, L0x5555552dc2, L0x5555552dc4, L0x5555552dc6, L0x5555552dc8, L0x5555552dca, L0x5555552dcc, L0x5555552dce] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 10678@sint16, 1496@sint16];
mov [L0x5555552dd0, L0x5555552dd2, L0x5555552dd4, L0x5555552dd6, L0x5555552dd8, L0x5555552dda, L0x5555552ddc, L0x5555552dde] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, (-10585)@sint16, (-1483)@sint16];
mov [L0x5555552de0, L0x5555552de2, L0x5555552de4, L0x5555552de6, L0x5555552de8, L0x5555552dea, L0x5555552dec, L0x5555552dee] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, (-7359)@sint16, (-1031)@sint16];
mov [L0x5555552df0, L0x5555552df2, L0x5555552df4, L0x5555552df6, L0x5555552df8, L0x5555552dfa, L0x5555552dfc, L0x5555552dfe] [9007@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, (-11170)@sint16, (-1565)@sint16];
mov [L0x5555552e00, L0x5555552e02, L0x5555552e04, L0x5555552e06, L0x5555552e08, L0x5555552e0a, L0x5555552e0c, L0x5555552e0e] [1@sint16, 7@sint16, (-478)@sint16, (-3412)@sint16, (-478)@sint16, (-3412)@sint16, 4591@sint16, 15631@sint16];
mov [L0x5555552e10, L0x5555552e12, L0x5555552e14, L0x5555552e16, L0x5555552e18, L0x5555552e1a, L0x5555552e1c, L0x5555552e1e] [(-1610)@sint16, (-11491)@sint16, 1175@sint16, 8386@sint16, 0@sint16, 0@sint16, 4591@sint16, 15631@sint16];
mov [L0x5555552e20, L0x5555552e22, L0x5555552e24, L0x5555552e26, L0x5555552e28, L0x5555552e2a, L0x5555552e2c, L0x5555552e2e] [1610@sint16, 11491@sint16, (-129)@sint16, (-921)@sint16, 1708@sint16, 12191@sint16, 4591@sint16, 15631@sint16];
mov [L0x5555552e30, L0x5555552e32, L0x5555552e34, L0x5555552e36, L0x5555552e38, L0x5555552e3a, L0x5555552e3c, L0x5555552e3e] [2274@sint16, 16231@sint16, 2190@sint16, 15631@sint16, 0@sint16, 0@sint16, 4591@sint16, 15631@sint16];
mov [L0x5555552e40, L0x5555552e42, L0x5555552e44, L0x5555552e46, L0x5555552e48, L0x5555552e4a, L0x5555552e4c, L0x5555552e4e] [(-1815)@sint16, (-12954)@sint16, (-6)@sint16, (-43)@sint16, (-129)@sint16, (-921)@sint16, 4591@sint16, 15631@sint16];
mov [L0x5555552e50, L0x5555552e52, L0x5555552e54, L0x5555552e56, L0x5555552e58, L0x5555552e5a, L0x5555552e5c, L0x5555552e5e] [(-1)@sint16, (-7)@sint16, 956@sint16, 6823@sint16, 0@sint16, 0@sint16, 4591@sint16, 15631@sint16];
mov [L0x5555552e60, L0x5555552e62, L0x5555552e64, L0x5555552e66, L0x5555552e68, L0x5555552e6a, L0x5555552e6c, L0x5555552e6e] [(-2274)@sint16, (-16231)@sint16, 1708@sint16, 12191@sint16, (-1095)@sint16, (-7815)@sint16, 4591@sint16, 15631@sint16];
mov [L0x5555552e70, L0x5555552e72, L0x5555552e74, L0x5555552e76, L0x5555552e78, L0x5555552e7a, L0x5555552e7c, L0x5555552e7e] [1815@sint16, 12954@sint16, 258@sint16, 1841@sint16, 0@sint16, 0@sint16, 4591@sint16, 15631@sint16];
mov [L0x5555552e80, L0x5555552e82, L0x5555552e84, L0x5555552e86, L0x5555552e88, L0x5555552e8a, L0x5555552e8c, L0x5555552e8e] [(-2113)@sint16, (-15081)@sint16, (-1095)@sint16, (-7815)@sint16, (-6)@sint16, (-43)@sint16, 4591@sint16, 15631@sint16];
mov [L0x5555552e90, L0x5555552e92, L0x5555552e94, L0x5555552e96, L0x5555552e98, L0x5555552e9a, L0x5555552e9c, L0x5555552e9e] [2113@sint16, 15081@sint16, 12@sint16, 86@sint16, 0@sint16, 0@sint16, 4591@sint16, 15631@sint16];
mov [L0x5555552ea0, L0x5555552ea2, L0x5555552ea4, L0x5555552ea6, L0x5555552ea8, L0x5555552eaa, L0x5555552eac, L0x5555552eae] [4591@sint16, 7@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16];
mov [L0x5555552eb0, L0x5555552eb2, L0x5555552eb4, L0x5555552eb6, L0x5555552eb8, L0x5555552eba, L0x5555552ebc, L0x5555552ebe] [(-27)@sint16, (-193)@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16, 0@sint16];
mov [L0x5555552ec0, L0x5555552ec2, L0x5555552ec4, L0x5555552ec6, L0x5555552ec8, L0x5555552eca, L0x5555552ecc, L0x5555552ece] [4591@sint16, 4591@sint16, 4591@sint16, 4591@sint16, 4591@sint16, 4591@sint16, 4591@sint16, 4591@sint16];
mov [L0x5555552ed0, L0x5555552ed2, L0x5555552ed4, L0x5555552ed6, L0x5555552ed8, L0x5555552eda, L0x5555552edc, L0x5555552ede] [2295@sint16, 2295@sint16, 2295@sint16, 2295@sint16, 2295@sint16, 2295@sint16, 2295@sint16, 2295@sint16];
mov [L0x5555552ee0, L0x5555552ee2, L0x5555552ee4, L0x5555552ee6, L0x5555552ee8, L0x5555552eea, L0x5555552eec, L0x5555552eee] [(-2295)@sint16, (-2295)@sint16, (-2295)@sint16, (-2295)@sint16, (-2295)@sint16, (-2295)@sint16, (-2295)@sint16, (-2295)@sint16];

mov [L0x7fffffe430, L0x7fffffe432, L0x7fffffe434, L0x7fffffe436, L0x7fffffe438, L0x7fffffe43a, L0x7fffffe43c, L0x7fffffe43e] [arr000_a, arr001_a, arr002_a, arr003_a, arr004_a, arr005_a, arr006_a, arr007_a];
mov [L0x7fffffe440, L0x7fffffe442, L0x7fffffe444, L0x7fffffe446, L0x7fffffe448, L0x7fffffe44a, L0x7fffffe44c, L0x7fffffe44e] [arr010_a, arr011_a, arr012_a, arr013_a, arr014_a, arr015_a, arr016_a, arr017_a];
mov [L0x7fffffe450, L0x7fffffe452, L0x7fffffe454, L0x7fffffe456, L0x7fffffe458, L0x7fffffe45a, L0x7fffffe45c, L0x7fffffe45e] [arr100_a, arr101_a, arr102_a, arr103_a, arr104_a, arr105_a, arr106_a, arr107_a];
mov [L0x7fffffe460, L0x7fffffe462, L0x7fffffe464, L0x7fffffe466, L0x7fffffe468, L0x7fffffe46a, L0x7fffffe46c, L0x7fffffe46e] [arr110_a, arr111_a, arr112_a, arr113_a, arr114_a, arr115_a, arr116_a, arr117_a];
mov [L0x7fffffe470, L0x7fffffe472, L0x7fffffe474, L0x7fffffe476, L0x7fffffe478, L0x7fffffe47a, L0x7fffffe47c, L0x7fffffe47e] [arr200_a, arr201_a, arr202_a, arr203_a, arr204_a, arr205_a, arr206_a, arr207_a];
mov [L0x7fffffe480, L0x7fffffe482, L0x7fffffe484, L0x7fffffe486, L0x7fffffe488, L0x7fffffe48a, L0x7fffffe48c, L0x7fffffe48e] [arr210_a, arr211_a, arr212_a, arr213_a, arr214_a, arr215_a, arr216_a, arr217_a];
mov [L0x7fffffe490, L0x7fffffe492, L0x7fffffe494, L0x7fffffe496, L0x7fffffe498, L0x7fffffe49a, L0x7fffffe49c, L0x7fffffe49e] [arr300_a, arr301_a, arr302_a, arr303_a, arr304_a, arr305_a, arr306_a, arr307_a];
mov [L0x7fffffe4a0, L0x7fffffe4a2, L0x7fffffe4a4, L0x7fffffe4a6, L0x7fffffe4a8, L0x7fffffe4aa, L0x7fffffe4ac, L0x7fffffe4ae] [arr310_a, arr311_a, arr312_a, arr313_a, arr314_a, arr315_a, arr316_a, arr317_a];
mov [L0x7fffffe4b0, L0x7fffffe4b2, L0x7fffffe4b4, L0x7fffffe4b6, L0x7fffffe4b8, L0x7fffffe4ba, L0x7fffffe4bc, L0x7fffffe4be] [arr400_a, arr401_a, arr402_a, arr403_a, arr404_a, arr405_a, arr406_a, arr407_a];
mov [L0x7fffffe4c0, L0x7fffffe4c2, L0x7fffffe4c4, L0x7fffffe4c6, L0x7fffffe4c8, L0x7fffffe4ca, L0x7fffffe4cc, L0x7fffffe4ce] [arr410_a, arr411_a, arr412_a, arr413_a, arr414_a, arr415_a, arr416_a, arr417_a];
mov [L0x7fffffe4d0, L0x7fffffe4d2, L0x7fffffe4d4, L0x7fffffe4d6, L0x7fffffe4d8, L0x7fffffe4da, L0x7fffffe4dc, L0x7fffffe4de] [arr500_a, arr501_a, arr502_a, arr503_a, arr504_a, arr505_a, arr506_a, arr507_a];
mov [L0x7fffffe4e0, L0x7fffffe4e2, L0x7fffffe4e4, L0x7fffffe4e6, L0x7fffffe4e8, L0x7fffffe4ea, L0x7fffffe4ec, L0x7fffffe4ee] [arr510_a, arr511_a, arr512_a, arr513_a, arr514_a, arr515_a, arr516_a, arr517_a];
mov [L0x7fffffe4f0, L0x7fffffe4f2, L0x7fffffe4f4, L0x7fffffe4f6, L0x7fffffe4f8, L0x7fffffe4fa, L0x7fffffe4fc, L0x7fffffe4fe] [arr600_a, arr601_a, arr602_a, arr603_a, arr604_a, arr605_a, arr606_a, arr607_a];
mov [L0x7fffffe500, L0x7fffffe502, L0x7fffffe504, L0x7fffffe506, L0x7fffffe508, L0x7fffffe50a, L0x7fffffe50c, L0x7fffffe50e] [arr610_a, arr611_a, arr612_a, arr613_a, arr614_a, arr615_a, arr616_a, arr617_a];
mov [L0x7fffffe510, L0x7fffffe512, L0x7fffffe514, L0x7fffffe516, L0x7fffffe518, L0x7fffffe51a, L0x7fffffe51c, L0x7fffffe51e] [arr700_a, arr701_a, arr702_a, arr703_a, arr704_a, arr705_a, arr706_a, arr707_a];
mov [L0x7fffffe520, L0x7fffffe522, L0x7fffffe524, L0x7fffffe526, L0x7fffffe528, L0x7fffffe52a, L0x7fffffe52c, L0x7fffffe52e] [arr710_a, arr711_a, arr712_a, arr713_a, arr714_a, arr715_a, arr716_a, arr717_a];
mov [L0x7fffffe530, L0x7fffffe532, L0x7fffffe534, L0x7fffffe536, L0x7fffffe538, L0x7fffffe53a, L0x7fffffe53c, L0x7fffffe53e] [arr800_a, arr801_a, arr802_a, arr803_a, arr804_a, arr805_a, arr806_a, arr807_a];
mov [L0x7fffffe540, L0x7fffffe542, L0x7fffffe544, L0x7fffffe546, L0x7fffffe548, L0x7fffffe54a, L0x7fffffe54c, L0x7fffffe54e] [arr810_a, arr811_a, arr812_a, arr813_a, arr814_a, arr815_a, arr816_a, arr817_a];
mov [L0x7fffffe550, L0x7fffffe552, L0x7fffffe554, L0x7fffffe556, L0x7fffffe558, L0x7fffffe55a, L0x7fffffe55c, L0x7fffffe55e] [arr900_a, arr901_a, arr902_a, arr903_a, arr904_a, arr905_a, arr906_a, arr907_a];
mov [L0x7fffffe560, L0x7fffffe562, L0x7fffffe564, L0x7fffffe566, L0x7fffffe568, L0x7fffffe56a, L0x7fffffe56c, L0x7fffffe56e] [arr910_a, arr911_a, arr912_a, arr913_a, arr914_a, arr915_a, arr916_a, arr917_a];

mov [L0x7fffffe2f0, L0x7fffffe2f2, L0x7fffffe2f4, L0x7fffffe2f6, L0x7fffffe2f8, L0x7fffffe2fa, L0x7fffffe2fc, L0x7fffffe2fe] [arr000_b, arr001_b, arr002_b, arr003_b, arr004_b, arr005_b, arr006_b, arr007_b];
mov [L0x7fffffe300, L0x7fffffe302, L0x7fffffe304, L0x7fffffe306, L0x7fffffe308, L0x7fffffe30a, L0x7fffffe30c, L0x7fffffe30e] [arr010_b, arr011_b, arr012_b, arr013_b, arr014_b, arr015_b, arr016_b, arr017_b];
mov [L0x7fffffe310, L0x7fffffe312, L0x7fffffe314, L0x7fffffe316, L0x7fffffe318, L0x7fffffe31a, L0x7fffffe31c, L0x7fffffe31e] [arr100_b, arr101_b, arr102_b, arr103_b, arr104_b, arr105_b, arr106_b, arr107_b];
mov [L0x7fffffe320, L0x7fffffe322, L0x7fffffe324, L0x7fffffe326, L0x7fffffe328, L0x7fffffe32a, L0x7fffffe32c, L0x7fffffe32e] [arr110_b, arr111_b, arr112_b, arr113_b, arr114_b, arr115_b, arr116_b, arr117_b];
mov [L0x7fffffe330, L0x7fffffe332, L0x7fffffe334, L0x7fffffe336, L0x7fffffe338, L0x7fffffe33a, L0x7fffffe33c, L0x7fffffe33e] [arr200_b, arr201_b, arr202_b, arr203_b, arr204_b, arr205_b, arr206_b, arr207_b];
mov [L0x7fffffe340, L0x7fffffe342, L0x7fffffe344, L0x7fffffe346, L0x7fffffe348, L0x7fffffe34a, L0x7fffffe34c, L0x7fffffe34e] [arr210_b, arr211_b, arr212_b, arr213_b, arr214_b, arr215_b, arr216_b, arr217_b];
mov [L0x7fffffe350, L0x7fffffe352, L0x7fffffe354, L0x7fffffe356, L0x7fffffe358, L0x7fffffe35a, L0x7fffffe35c, L0x7fffffe35e] [arr300_b, arr301_b, arr302_b, arr303_b, arr304_b, arr305_b, arr306_b, arr307_b];
mov [L0x7fffffe360, L0x7fffffe362, L0x7fffffe364, L0x7fffffe366, L0x7fffffe368, L0x7fffffe36a, L0x7fffffe36c, L0x7fffffe36e] [arr310_b, arr311_b, arr312_b, arr313_b, arr314_b, arr315_b, arr316_b, arr317_b];
mov [L0x7fffffe370, L0x7fffffe372, L0x7fffffe374, L0x7fffffe376, L0x7fffffe378, L0x7fffffe37a, L0x7fffffe37c, L0x7fffffe37e] [arr400_b, arr401_b, arr402_b, arr403_b, arr404_b, arr405_b, arr406_b, arr407_b];
mov [L0x7fffffe380, L0x7fffffe382, L0x7fffffe384, L0x7fffffe386, L0x7fffffe388, L0x7fffffe38a, L0x7fffffe38c, L0x7fffffe38e] [arr410_b, arr411_b, arr412_b, arr413_b, arr414_b, arr415_b, arr416_b, arr417_b];
mov [L0x7fffffe390, L0x7fffffe392, L0x7fffffe394, L0x7fffffe396, L0x7fffffe398, L0x7fffffe39a, L0x7fffffe39c, L0x7fffffe39e] [arr500_b, arr501_b, arr502_b, arr503_b, arr504_b, arr505_b, arr506_b, arr507_b];
mov [L0x7fffffe3a0, L0x7fffffe3a2, L0x7fffffe3a4, L0x7fffffe3a6, L0x7fffffe3a8, L0x7fffffe3aa, L0x7fffffe3ac, L0x7fffffe3ae] [arr510_b, arr511_b, arr512_b, arr513_b, arr514_b, arr515_b, arr516_b, arr517_b];
mov [L0x7fffffe3b0, L0x7fffffe3b2, L0x7fffffe3b4, L0x7fffffe3b6, L0x7fffffe3b8, L0x7fffffe3ba, L0x7fffffe3bc, L0x7fffffe3be] [arr600_b, arr601_b, arr602_b, arr603_b, arr604_b, arr605_b, arr606_b, arr607_b];
mov [L0x7fffffe3c0, L0x7fffffe3c2, L0x7fffffe3c4, L0x7fffffe3c6, L0x7fffffe3c8, L0x7fffffe3ca, L0x7fffffe3cc, L0x7fffffe3ce] [arr610_b, arr611_b, arr612_b, arr613_b, arr614_b, arr615_b, arr616_b, arr617_b];
mov [L0x7fffffe3d0, L0x7fffffe3d2, L0x7fffffe3d4, L0x7fffffe3d6, L0x7fffffe3d8, L0x7fffffe3da, L0x7fffffe3dc, L0x7fffffe3de] [arr700_b, arr701_b, arr702_b, arr703_b, arr704_b, arr705_b, arr706_b, arr707_b];
mov [L0x7fffffe3e0, L0x7fffffe3e2, L0x7fffffe3e4, L0x7fffffe3e6, L0x7fffffe3e8, L0x7fffffe3ea, L0x7fffffe3ec, L0x7fffffe3ee] [arr710_b, arr711_b, arr712_b, arr713_b, arr714_b, arr715_b, arr716_b, arr717_b];
mov [L0x7fffffe3f0, L0x7fffffe3f2, L0x7fffffe3f4, L0x7fffffe3f6, L0x7fffffe3f8, L0x7fffffe3fa, L0x7fffffe3fc, L0x7fffffe3fe] [arr800_b, arr801_b, arr802_b, arr803_b, arr804_b, arr805_b, arr806_b, arr807_b];
mov [L0x7fffffe400, L0x7fffffe402, L0x7fffffe404, L0x7fffffe406, L0x7fffffe408, L0x7fffffe40a, L0x7fffffe40c, L0x7fffffe40e] [arr810_b, arr811_b, arr812_b, arr813_b, arr814_b, arr815_b, arr816_b, arr817_b];
mov [L0x7fffffe410, L0x7fffffe412, L0x7fffffe414, L0x7fffffe416, L0x7fffffe418, L0x7fffffe41a, L0x7fffffe41c, L0x7fffffe41e] [arr900_b, arr901_b, arr902_b, arr903_b, arr904_b, arr905_b, arr906_b, arr907_b];
mov [L0x7fffffe420, L0x7fffffe422, L0x7fffffe424, L0x7fffffe426, L0x7fffffe428, L0x7fffffe42a, L0x7fffffe42c, L0x7fffffe42e] [arr910_b, arr911_b, arr912_b, arr913_b, arr914_b, arr915_b, arr916_b, arr917_b];


# prologue

(* #! -> SP = 0x7fffffe170 *)
#! 0x7fffffe170 = 0x7fffffe170;
(* #b	0x5555551d34 <_ZN6xpower7basemul11low_basemulEPA2_A8_sS3_S3_+532>#! PC = 0x5555551b40 *)
#b	0x5555551d34 <_ZN6xpower7basemul11low_basemulEPA2_A8_sS3_S3_+532>#! 0x5555551b40 = 0x5555551b40;

cut (* 0 *)
    [L0x7fffffe430, L0x7fffffe432, L0x7fffffe434, L0x7fffffe436, L0x7fffffe438, L0x7fffffe43a, L0x7fffffe43c, L0x7fffffe43e] = [arr000_a, arr001_a, arr002_a, arr003_a, arr004_a, arr005_a, arr006_a, arr007_a] /\
    [L0x7fffffe440, L0x7fffffe442, L0x7fffffe444, L0x7fffffe446, L0x7fffffe448, L0x7fffffe44a, L0x7fffffe44c, L0x7fffffe44e] = [arr010_a, arr011_a, arr012_a, arr013_a, arr014_a, arr015_a, arr016_a, arr017_a] /\
    [L0x7fffffe450, L0x7fffffe452, L0x7fffffe454, L0x7fffffe456, L0x7fffffe458, L0x7fffffe45a, L0x7fffffe45c, L0x7fffffe45e] = [arr100_a, arr101_a, arr102_a, arr103_a, arr104_a, arr105_a, arr106_a, arr107_a] /\
    [L0x7fffffe460, L0x7fffffe462, L0x7fffffe464, L0x7fffffe466, L0x7fffffe468, L0x7fffffe46a, L0x7fffffe46c, L0x7fffffe46e] = [arr110_a, arr111_a, arr112_a, arr113_a, arr114_a, arr115_a, arr116_a, arr117_a] /\
    [L0x7fffffe470, L0x7fffffe472, L0x7fffffe474, L0x7fffffe476, L0x7fffffe478, L0x7fffffe47a, L0x7fffffe47c, L0x7fffffe47e] = [arr200_a, arr201_a, arr202_a, arr203_a, arr204_a, arr205_a, arr206_a, arr207_a] /\
    [L0x7fffffe480, L0x7fffffe482, L0x7fffffe484, L0x7fffffe486, L0x7fffffe488, L0x7fffffe48a, L0x7fffffe48c, L0x7fffffe48e] = [arr210_a, arr211_a, arr212_a, arr213_a, arr214_a, arr215_a, arr216_a, arr217_a] /\
    [L0x7fffffe490, L0x7fffffe492, L0x7fffffe494, L0x7fffffe496, L0x7fffffe498, L0x7fffffe49a, L0x7fffffe49c, L0x7fffffe49e] = [arr300_a, arr301_a, arr302_a, arr303_a, arr304_a, arr305_a, arr306_a, arr307_a] /\
    [L0x7fffffe4a0, L0x7fffffe4a2, L0x7fffffe4a4, L0x7fffffe4a6, L0x7fffffe4a8, L0x7fffffe4aa, L0x7fffffe4ac, L0x7fffffe4ae] = [arr310_a, arr311_a, arr312_a, arr313_a, arr314_a, arr315_a, arr316_a, arr317_a] /\
    [L0x7fffffe4b0, L0x7fffffe4b2, L0x7fffffe4b4, L0x7fffffe4b6, L0x7fffffe4b8, L0x7fffffe4ba, L0x7fffffe4bc, L0x7fffffe4be] = [arr400_a, arr401_a, arr402_a, arr403_a, arr404_a, arr405_a, arr406_a, arr407_a] /\
    [L0x7fffffe4c0, L0x7fffffe4c2, L0x7fffffe4c4, L0x7fffffe4c6, L0x7fffffe4c8, L0x7fffffe4ca, L0x7fffffe4cc, L0x7fffffe4ce] = [arr410_a, arr411_a, arr412_a, arr413_a, arr414_a, arr415_a, arr416_a, arr417_a] /\
    [L0x7fffffe4d0, L0x7fffffe4d2, L0x7fffffe4d4, L0x7fffffe4d6, L0x7fffffe4d8, L0x7fffffe4da, L0x7fffffe4dc, L0x7fffffe4de] = [arr500_a, arr501_a, arr502_a, arr503_a, arr504_a, arr505_a, arr506_a, arr507_a] /\
    [L0x7fffffe4e0, L0x7fffffe4e2, L0x7fffffe4e4, L0x7fffffe4e6, L0x7fffffe4e8, L0x7fffffe4ea, L0x7fffffe4ec, L0x7fffffe4ee] = [arr510_a, arr511_a, arr512_a, arr513_a, arr514_a, arr515_a, arr516_a, arr517_a] /\
    [L0x7fffffe4f0, L0x7fffffe4f2, L0x7fffffe4f4, L0x7fffffe4f6, L0x7fffffe4f8, L0x7fffffe4fa, L0x7fffffe4fc, L0x7fffffe4fe] = [arr600_a, arr601_a, arr602_a, arr603_a, arr604_a, arr605_a, arr606_a, arr607_a] /\
    [L0x7fffffe500, L0x7fffffe502, L0x7fffffe504, L0x7fffffe506, L0x7fffffe508, L0x7fffffe50a, L0x7fffffe50c, L0x7fffffe50e] = [arr610_a, arr611_a, arr612_a, arr613_a, arr614_a, arr615_a, arr616_a, arr617_a] /\
    [L0x7fffffe510, L0x7fffffe512, L0x7fffffe514, L0x7fffffe516, L0x7fffffe518, L0x7fffffe51a, L0x7fffffe51c, L0x7fffffe51e] = [arr700_a, arr701_a, arr702_a, arr703_a, arr704_a, arr705_a, arr706_a, arr707_a] /\
    [L0x7fffffe520, L0x7fffffe522, L0x7fffffe524, L0x7fffffe526, L0x7fffffe528, L0x7fffffe52a, L0x7fffffe52c, L0x7fffffe52e] = [arr710_a, arr711_a, arr712_a, arr713_a, arr714_a, arr715_a, arr716_a, arr717_a] /\
    [L0x7fffffe530, L0x7fffffe532, L0x7fffffe534, L0x7fffffe536, L0x7fffffe538, L0x7fffffe53a, L0x7fffffe53c, L0x7fffffe53e] = [arr800_a, arr801_a, arr802_a, arr803_a, arr804_a, arr805_a, arr806_a, arr807_a] /\
    [L0x7fffffe540, L0x7fffffe542, L0x7fffffe544, L0x7fffffe546, L0x7fffffe548, L0x7fffffe54a, L0x7fffffe54c, L0x7fffffe54e] = [arr810_a, arr811_a, arr812_a, arr813_a, arr814_a, arr815_a, arr816_a, arr817_a] /\
    [L0x7fffffe550, L0x7fffffe552, L0x7fffffe554, L0x7fffffe556, L0x7fffffe558, L0x7fffffe55a, L0x7fffffe55c, L0x7fffffe55e] = [arr900_a, arr901_a, arr902_a, arr903_a, arr904_a, arr905_a, arr906_a, arr907_a] /\
    [L0x7fffffe560, L0x7fffffe562, L0x7fffffe564, L0x7fffffe566, L0x7fffffe568, L0x7fffffe56a, L0x7fffffe56c, L0x7fffffe56e] = [arr910_a, arr911_a, arr912_a, arr913_a, arr914_a, arr915_a, arr916_a, arr917_a] /\
    [L0x7fffffe2f0, L0x7fffffe2f2, L0x7fffffe2f4, L0x7fffffe2f6, L0x7fffffe2f8, L0x7fffffe2fa, L0x7fffffe2fc, L0x7fffffe2fe] = [arr000_b, arr001_b, arr002_b, arr003_b, arr004_b, arr005_b, arr006_b, arr007_b] /\
    [L0x7fffffe300, L0x7fffffe302, L0x7fffffe304, L0x7fffffe306, L0x7fffffe308, L0x7fffffe30a, L0x7fffffe30c, L0x7fffffe30e] = [arr010_b, arr011_b, arr012_b, arr013_b, arr014_b, arr015_b, arr016_b, arr017_b] /\
    [L0x7fffffe310, L0x7fffffe312, L0x7fffffe314, L0x7fffffe316, L0x7fffffe318, L0x7fffffe31a, L0x7fffffe31c, L0x7fffffe31e] = [arr100_b, arr101_b, arr102_b, arr103_b, arr104_b, arr105_b, arr106_b, arr107_b] /\
    [L0x7fffffe320, L0x7fffffe322, L0x7fffffe324, L0x7fffffe326, L0x7fffffe328, L0x7fffffe32a, L0x7fffffe32c, L0x7fffffe32e] = [arr110_b, arr111_b, arr112_b, arr113_b, arr114_b, arr115_b, arr116_b, arr117_b] /\
    [L0x7fffffe330, L0x7fffffe332, L0x7fffffe334, L0x7fffffe336, L0x7fffffe338, L0x7fffffe33a, L0x7fffffe33c, L0x7fffffe33e] = [arr200_b, arr201_b, arr202_b, arr203_b, arr204_b, arr205_b, arr206_b, arr207_b] /\
    [L0x7fffffe340, L0x7fffffe342, L0x7fffffe344, L0x7fffffe346, L0x7fffffe348, L0x7fffffe34a, L0x7fffffe34c, L0x7fffffe34e] = [arr210_b, arr211_b, arr212_b, arr213_b, arr214_b, arr215_b, arr216_b, arr217_b] /\
    [L0x7fffffe350, L0x7fffffe352, L0x7fffffe354, L0x7fffffe356, L0x7fffffe358, L0x7fffffe35a, L0x7fffffe35c, L0x7fffffe35e] = [arr300_b, arr301_b, arr302_b, arr303_b, arr304_b, arr305_b, arr306_b, arr307_b] /\
    [L0x7fffffe360, L0x7fffffe362, L0x7fffffe364, L0x7fffffe366, L0x7fffffe368, L0x7fffffe36a, L0x7fffffe36c, L0x7fffffe36e] = [arr310_b, arr311_b, arr312_b, arr313_b, arr314_b, arr315_b, arr316_b, arr317_b] /\
    [L0x7fffffe370, L0x7fffffe372, L0x7fffffe374, L0x7fffffe376, L0x7fffffe378, L0x7fffffe37a, L0x7fffffe37c, L0x7fffffe37e] = [arr400_b, arr401_b, arr402_b, arr403_b, arr404_b, arr405_b, arr406_b, arr407_b] /\
    [L0x7fffffe380, L0x7fffffe382, L0x7fffffe384, L0x7fffffe386, L0x7fffffe388, L0x7fffffe38a, L0x7fffffe38c, L0x7fffffe38e] = [arr410_b, arr411_b, arr412_b, arr413_b, arr414_b, arr415_b, arr416_b, arr417_b] /\
    [L0x7fffffe390, L0x7fffffe392, L0x7fffffe394, L0x7fffffe396, L0x7fffffe398, L0x7fffffe39a, L0x7fffffe39c, L0x7fffffe39e] = [arr500_b, arr501_b, arr502_b, arr503_b, arr504_b, arr505_b, arr506_b, arr507_b] /\
    [L0x7fffffe3a0, L0x7fffffe3a2, L0x7fffffe3a4, L0x7fffffe3a6, L0x7fffffe3a8, L0x7fffffe3aa, L0x7fffffe3ac, L0x7fffffe3ae] = [arr510_b, arr511_b, arr512_b, arr513_b, arr514_b, arr515_b, arr516_b, arr517_b] /\
    [L0x7fffffe3b0, L0x7fffffe3b2, L0x7fffffe3b4, L0x7fffffe3b6, L0x7fffffe3b8, L0x7fffffe3ba, L0x7fffffe3bc, L0x7fffffe3be] = [arr600_b, arr601_b, arr602_b, arr603_b, arr604_b, arr605_b, arr606_b, arr607_b] /\
    [L0x7fffffe3c0, L0x7fffffe3c2, L0x7fffffe3c4, L0x7fffffe3c6, L0x7fffffe3c8, L0x7fffffe3ca, L0x7fffffe3cc, L0x7fffffe3ce] = [arr610_b, arr611_b, arr612_b, arr613_b, arr614_b, arr615_b, arr616_b, arr617_b] /\
    [L0x7fffffe3d0, L0x7fffffe3d2, L0x7fffffe3d4, L0x7fffffe3d6, L0x7fffffe3d8, L0x7fffffe3da, L0x7fffffe3dc, L0x7fffffe3de] = [arr700_b, arr701_b, arr702_b, arr703_b, arr704_b, arr705_b, arr706_b, arr707_b] /\
    [L0x7fffffe3e0, L0x7fffffe3e2, L0x7fffffe3e4, L0x7fffffe3e6, L0x7fffffe3e8, L0x7fffffe3ea, L0x7fffffe3ec, L0x7fffffe3ee] = [arr710_b, arr711_b, arr712_b, arr713_b, arr714_b, arr715_b, arr716_b, arr717_b] /\
    [L0x7fffffe3f0, L0x7fffffe3f2, L0x7fffffe3f4, L0x7fffffe3f6, L0x7fffffe3f8, L0x7fffffe3fa, L0x7fffffe3fc, L0x7fffffe3fe] = [arr800_b, arr801_b, arr802_b, arr803_b, arr804_b, arr805_b, arr806_b, arr807_b] /\
    [L0x7fffffe400, L0x7fffffe402, L0x7fffffe404, L0x7fffffe406, L0x7fffffe408, L0x7fffffe40a, L0x7fffffe40c, L0x7fffffe40e] = [arr810_b, arr811_b, arr812_b, arr813_b, arr814_b, arr815_b, arr816_b, arr817_b] /\
    [L0x7fffffe410, L0x7fffffe412, L0x7fffffe414, L0x7fffffe416, L0x7fffffe418, L0x7fffffe41a, L0x7fffffe41c, L0x7fffffe41e] = [arr900_b, arr901_b, arr902_b, arr903_b, arr904_b, arr905_b, arr906_b, arr907_b] /\
    [L0x7fffffe420, L0x7fffffe422, L0x7fffffe424, L0x7fffffe426, L0x7fffffe428, L0x7fffffe42a, L0x7fffffe42c, L0x7fffffe42e] = [arr910_b, arr911_b, arr912_b, arr913_b, arr914_b, arr915_b, arr916_b, arr917_b]
  &&
    [L0x7fffffe430, L0x7fffffe432, L0x7fffffe434, L0x7fffffe436, L0x7fffffe438, L0x7fffffe43a, L0x7fffffe43c, L0x7fffffe43e] = [arr000_a, arr001_a, arr002_a, arr003_a, arr004_a, arr005_a, arr006_a, arr007_a] /\
    [L0x7fffffe440, L0x7fffffe442, L0x7fffffe444, L0x7fffffe446, L0x7fffffe448, L0x7fffffe44a, L0x7fffffe44c, L0x7fffffe44e] = [arr010_a, arr011_a, arr012_a, arr013_a, arr014_a, arr015_a, arr016_a, arr017_a] /\
    [L0x7fffffe450, L0x7fffffe452, L0x7fffffe454, L0x7fffffe456, L0x7fffffe458, L0x7fffffe45a, L0x7fffffe45c, L0x7fffffe45e] = [arr100_a, arr101_a, arr102_a, arr103_a, arr104_a, arr105_a, arr106_a, arr107_a] /\
    [L0x7fffffe460, L0x7fffffe462, L0x7fffffe464, L0x7fffffe466, L0x7fffffe468, L0x7fffffe46a, L0x7fffffe46c, L0x7fffffe46e] = [arr110_a, arr111_a, arr112_a, arr113_a, arr114_a, arr115_a, arr116_a, arr117_a] /\
    [L0x7fffffe470, L0x7fffffe472, L0x7fffffe474, L0x7fffffe476, L0x7fffffe478, L0x7fffffe47a, L0x7fffffe47c, L0x7fffffe47e] = [arr200_a, arr201_a, arr202_a, arr203_a, arr204_a, arr205_a, arr206_a, arr207_a] /\
    [L0x7fffffe480, L0x7fffffe482, L0x7fffffe484, L0x7fffffe486, L0x7fffffe488, L0x7fffffe48a, L0x7fffffe48c, L0x7fffffe48e] = [arr210_a, arr211_a, arr212_a, arr213_a, arr214_a, arr215_a, arr216_a, arr217_a] /\
    [L0x7fffffe490, L0x7fffffe492, L0x7fffffe494, L0x7fffffe496, L0x7fffffe498, L0x7fffffe49a, L0x7fffffe49c, L0x7fffffe49e] = [arr300_a, arr301_a, arr302_a, arr303_a, arr304_a, arr305_a, arr306_a, arr307_a] /\
    [L0x7fffffe4a0, L0x7fffffe4a2, L0x7fffffe4a4, L0x7fffffe4a6, L0x7fffffe4a8, L0x7fffffe4aa, L0x7fffffe4ac, L0x7fffffe4ae] = [arr310_a, arr311_a, arr312_a, arr313_a, arr314_a, arr315_a, arr316_a, arr317_a] /\
    [L0x7fffffe4b0, L0x7fffffe4b2, L0x7fffffe4b4, L0x7fffffe4b6, L0x7fffffe4b8, L0x7fffffe4ba, L0x7fffffe4bc, L0x7fffffe4be] = [arr400_a, arr401_a, arr402_a, arr403_a, arr404_a, arr405_a, arr406_a, arr407_a] /\
    [L0x7fffffe4c0, L0x7fffffe4c2, L0x7fffffe4c4, L0x7fffffe4c6, L0x7fffffe4c8, L0x7fffffe4ca, L0x7fffffe4cc, L0x7fffffe4ce] = [arr410_a, arr411_a, arr412_a, arr413_a, arr414_a, arr415_a, arr416_a, arr417_a] /\
    [L0x7fffffe4d0, L0x7fffffe4d2, L0x7fffffe4d4, L0x7fffffe4d6, L0x7fffffe4d8, L0x7fffffe4da, L0x7fffffe4dc, L0x7fffffe4de] = [arr500_a, arr501_a, arr502_a, arr503_a, arr504_a, arr505_a, arr506_a, arr507_a] /\
    [L0x7fffffe4e0, L0x7fffffe4e2, L0x7fffffe4e4, L0x7fffffe4e6, L0x7fffffe4e8, L0x7fffffe4ea, L0x7fffffe4ec, L0x7fffffe4ee] = [arr510_a, arr511_a, arr512_a, arr513_a, arr514_a, arr515_a, arr516_a, arr517_a] /\
    [L0x7fffffe4f0, L0x7fffffe4f2, L0x7fffffe4f4, L0x7fffffe4f6, L0x7fffffe4f8, L0x7fffffe4fa, L0x7fffffe4fc, L0x7fffffe4fe] = [arr600_a, arr601_a, arr602_a, arr603_a, arr604_a, arr605_a, arr606_a, arr607_a] /\
    [L0x7fffffe500, L0x7fffffe502, L0x7fffffe504, L0x7fffffe506, L0x7fffffe508, L0x7fffffe50a, L0x7fffffe50c, L0x7fffffe50e] = [arr610_a, arr611_a, arr612_a, arr613_a, arr614_a, arr615_a, arr616_a, arr617_a] /\
    [L0x7fffffe510, L0x7fffffe512, L0x7fffffe514, L0x7fffffe516, L0x7fffffe518, L0x7fffffe51a, L0x7fffffe51c, L0x7fffffe51e] = [arr700_a, arr701_a, arr702_a, arr703_a, arr704_a, arr705_a, arr706_a, arr707_a] /\
    [L0x7fffffe520, L0x7fffffe522, L0x7fffffe524, L0x7fffffe526, L0x7fffffe528, L0x7fffffe52a, L0x7fffffe52c, L0x7fffffe52e] = [arr710_a, arr711_a, arr712_a, arr713_a, arr714_a, arr715_a, arr716_a, arr717_a] /\
    [L0x7fffffe530, L0x7fffffe532, L0x7fffffe534, L0x7fffffe536, L0x7fffffe538, L0x7fffffe53a, L0x7fffffe53c, L0x7fffffe53e] = [arr800_a, arr801_a, arr802_a, arr803_a, arr804_a, arr805_a, arr806_a, arr807_a] /\
    [L0x7fffffe540, L0x7fffffe542, L0x7fffffe544, L0x7fffffe546, L0x7fffffe548, L0x7fffffe54a, L0x7fffffe54c, L0x7fffffe54e] = [arr810_a, arr811_a, arr812_a, arr813_a, arr814_a, arr815_a, arr816_a, arr817_a] /\
    [L0x7fffffe550, L0x7fffffe552, L0x7fffffe554, L0x7fffffe556, L0x7fffffe558, L0x7fffffe55a, L0x7fffffe55c, L0x7fffffe55e] = [arr900_a, arr901_a, arr902_a, arr903_a, arr904_a, arr905_a, arr906_a, arr907_a] /\
    [L0x7fffffe560, L0x7fffffe562, L0x7fffffe564, L0x7fffffe566, L0x7fffffe568, L0x7fffffe56a, L0x7fffffe56c, L0x7fffffe56e] = [arr910_a, arr911_a, arr912_a, arr913_a, arr914_a, arr915_a, arr916_a, arr917_a] /\
    [L0x7fffffe2f0, L0x7fffffe2f2, L0x7fffffe2f4, L0x7fffffe2f6, L0x7fffffe2f8, L0x7fffffe2fa, L0x7fffffe2fc, L0x7fffffe2fe] = [arr000_b, arr001_b, arr002_b, arr003_b, arr004_b, arr005_b, arr006_b, arr007_b] /\
    [L0x7fffffe300, L0x7fffffe302, L0x7fffffe304, L0x7fffffe306, L0x7fffffe308, L0x7fffffe30a, L0x7fffffe30c, L0x7fffffe30e] = [arr010_b, arr011_b, arr012_b, arr013_b, arr014_b, arr015_b, arr016_b, arr017_b] /\
    [L0x7fffffe310, L0x7fffffe312, L0x7fffffe314, L0x7fffffe316, L0x7fffffe318, L0x7fffffe31a, L0x7fffffe31c, L0x7fffffe31e] = [arr100_b, arr101_b, arr102_b, arr103_b, arr104_b, arr105_b, arr106_b, arr107_b] /\
    [L0x7fffffe320, L0x7fffffe322, L0x7fffffe324, L0x7fffffe326, L0x7fffffe328, L0x7fffffe32a, L0x7fffffe32c, L0x7fffffe32e] = [arr110_b, arr111_b, arr112_b, arr113_b, arr114_b, arr115_b, arr116_b, arr117_b] /\
    [L0x7fffffe330, L0x7fffffe332, L0x7fffffe334, L0x7fffffe336, L0x7fffffe338, L0x7fffffe33a, L0x7fffffe33c, L0x7fffffe33e] = [arr200_b, arr201_b, arr202_b, arr203_b, arr204_b, arr205_b, arr206_b, arr207_b] /\
    [L0x7fffffe340, L0x7fffffe342, L0x7fffffe344, L0x7fffffe346, L0x7fffffe348, L0x7fffffe34a, L0x7fffffe34c, L0x7fffffe34e] = [arr210_b, arr211_b, arr212_b, arr213_b, arr214_b, arr215_b, arr216_b, arr217_b] /\
    [L0x7fffffe350, L0x7fffffe352, L0x7fffffe354, L0x7fffffe356, L0x7fffffe358, L0x7fffffe35a, L0x7fffffe35c, L0x7fffffe35e] = [arr300_b, arr301_b, arr302_b, arr303_b, arr304_b, arr305_b, arr306_b, arr307_b] /\
    [L0x7fffffe360, L0x7fffffe362, L0x7fffffe364, L0x7fffffe366, L0x7fffffe368, L0x7fffffe36a, L0x7fffffe36c, L0x7fffffe36e] = [arr310_b, arr311_b, arr312_b, arr313_b, arr314_b, arr315_b, arr316_b, arr317_b] /\
    [L0x7fffffe370, L0x7fffffe372, L0x7fffffe374, L0x7fffffe376, L0x7fffffe378, L0x7fffffe37a, L0x7fffffe37c, L0x7fffffe37e] = [arr400_b, arr401_b, arr402_b, arr403_b, arr404_b, arr405_b, arr406_b, arr407_b] /\
    [L0x7fffffe380, L0x7fffffe382, L0x7fffffe384, L0x7fffffe386, L0x7fffffe388, L0x7fffffe38a, L0x7fffffe38c, L0x7fffffe38e] = [arr410_b, arr411_b, arr412_b, arr413_b, arr414_b, arr415_b, arr416_b, arr417_b] /\
    [L0x7fffffe390, L0x7fffffe392, L0x7fffffe394, L0x7fffffe396, L0x7fffffe398, L0x7fffffe39a, L0x7fffffe39c, L0x7fffffe39e] = [arr500_b, arr501_b, arr502_b, arr503_b, arr504_b, arr505_b, arr506_b, arr507_b] /\
    [L0x7fffffe3a0, L0x7fffffe3a2, L0x7fffffe3a4, L0x7fffffe3a6, L0x7fffffe3a8, L0x7fffffe3aa, L0x7fffffe3ac, L0x7fffffe3ae] = [arr510_b, arr511_b, arr512_b, arr513_b, arr514_b, arr515_b, arr516_b, arr517_b] /\
    [L0x7fffffe3b0, L0x7fffffe3b2, L0x7fffffe3b4, L0x7fffffe3b6, L0x7fffffe3b8, L0x7fffffe3ba, L0x7fffffe3bc, L0x7fffffe3be] = [arr600_b, arr601_b, arr602_b, arr603_b, arr604_b, arr605_b, arr606_b, arr607_b] /\
    [L0x7fffffe3c0, L0x7fffffe3c2, L0x7fffffe3c4, L0x7fffffe3c6, L0x7fffffe3c8, L0x7fffffe3ca, L0x7fffffe3cc, L0x7fffffe3ce] = [arr610_b, arr611_b, arr612_b, arr613_b, arr614_b, arr615_b, arr616_b, arr617_b] /\
    [L0x7fffffe3d0, L0x7fffffe3d2, L0x7fffffe3d4, L0x7fffffe3d6, L0x7fffffe3d8, L0x7fffffe3da, L0x7fffffe3dc, L0x7fffffe3de] = [arr700_b, arr701_b, arr702_b, arr703_b, arr704_b, arr705_b, arr706_b, arr707_b] /\
    [L0x7fffffe3e0, L0x7fffffe3e2, L0x7fffffe3e4, L0x7fffffe3e6, L0x7fffffe3e8, L0x7fffffe3ea, L0x7fffffe3ec, L0x7fffffe3ee] = [arr710_b, arr711_b, arr712_b, arr713_b, arr714_b, arr715_b, arr716_b, arr717_b] /\
    [L0x7fffffe3f0, L0x7fffffe3f2, L0x7fffffe3f4, L0x7fffffe3f6, L0x7fffffe3f8, L0x7fffffe3fa, L0x7fffffe3fc, L0x7fffffe3fe] = [arr800_b, arr801_b, arr802_b, arr803_b, arr804_b, arr805_b, arr806_b, arr807_b] /\
    [L0x7fffffe400, L0x7fffffe402, L0x7fffffe404, L0x7fffffe406, L0x7fffffe408, L0x7fffffe40a, L0x7fffffe40c, L0x7fffffe40e] = [arr810_b, arr811_b, arr812_b, arr813_b, arr814_b, arr815_b, arr816_b, arr817_b] /\
    [L0x7fffffe410, L0x7fffffe412, L0x7fffffe414, L0x7fffffe416, L0x7fffffe418, L0x7fffffe41a, L0x7fffffe41c, L0x7fffffe41e] = [arr900_b, arr901_b, arr902_b, arr903_b, arr904_b, arr905_b, arr906_b, arr907_b] /\
    [L0x7fffffe420, L0x7fffffe422, L0x7fffffe424, L0x7fffffe426, L0x7fffffe428, L0x7fffffe42a, L0x7fffffe42c, L0x7fffffe42e] = [arr910_b, arr911_b, arr912_b, arr913_b, arr914_b, arr915_b, arr916_b, arr917_b];


### i_iter prologue

(* ldr	q4, [x0, x3]                                #! EA = L0x7fffffe430; Value = 0x0000000000000000; PC = 0x5555551d34 *)
mov %v4 [L0x7fffffe430,L0x7fffffe432,L0x7fffffe434,L0x7fffffe436,L0x7fffffe438,L0x7fffffe43a,L0x7fffffe43c,L0x7fffffe43e];
(* ldr	q1, [x8, x3]                                #! EA = L0x7fffffe440; Value = 0x0000000000000000; PC = 0x5555551d38 *)
mov %v1 [L0x7fffffe440,L0x7fffffe442,L0x7fffffe444,L0x7fffffe446,L0x7fffffe448,L0x7fffffe44a,L0x7fffffe44c,L0x7fffffe44e];
(* ldr	q17, [x1, x3]                               #! EA = L0x7fffffe2f0; Value = 0x0000000000000000; PC = 0x5555551d3c *)
mov %v17 [L0x7fffffe2f0,L0x7fffffe2f2,L0x7fffffe2f4,L0x7fffffe2f6,L0x7fffffe2f8,L0x7fffffe2fa,L0x7fffffe2fc,L0x7fffffe2fe];
(* ldr	q18, [x7, x3]                               #! EA = L0x7fffffe300; Value = 0x0000000000000000; PC = 0x5555551d40 *)
mov %v18 [L0x7fffffe300,L0x7fffffe302,L0x7fffffe304,L0x7fffffe306,L0x7fffffe308,L0x7fffffe30a,L0x7fffffe30c,L0x7fffffe30e];

ghost %fa0_0@sint16[8], %fa1_0@sint16[8], %fb0_0@sint16[8], %fb1_0@sint16[8] :
    %fa0_0 = %v4 /\ %fa1_0 = %v1 /\ %fb0_0 = %v17 /\ %fb1_0 = %v18
  &&
    %fa0_0 = %v4 /\ %fa1_0 = %v1 /\ %fb0_0 = %v17 /\ %fb1_0 = %v18;

cut (* 1 *)
    %fa0_0 = %v4 /\ %fa1_0 = %v1 /\ %fb0_0 = %v17 /\ %fb1_0 = %v18 /\
    %fa0_0 = [arr000_a, arr001_a, arr002_a, arr003_a, arr004_a, arr005_a, arr006_a, arr007_a] /\
    %fa1_0 = [arr010_a, arr011_a, arr012_a, arr013_a, arr014_a, arr015_a, arr016_a, arr017_a] /\
    %fb0_0 = [arr000_b, arr001_b, arr002_b, arr003_b, arr004_b, arr005_b, arr006_b, arr007_b] /\
    %fb1_0 = [arr010_b, arr011_b, arr012_b, arr013_b, arr014_b, arr015_b, arr016_b, arr017_b]
    prove with [cuts[0]]
  &&
    %fa0_0 = %v4 /\ %fa1_0 = %v1 /\ %fb0_0 = %v17 /\ %fb1_0 = %v18 /\
    %fa0_0 = [arr000_a, arr001_a, arr002_a, arr003_a, arr004_a, arr005_a, arr006_a, arr007_a] /\
    %fa1_0 = [arr010_a, arr011_a, arr012_a, arr013_a, arr014_a, arr015_a, arr016_a, arr017_a] /\
    %fb0_0 = [arr000_b, arr001_b, arr002_b, arr003_b, arr004_b, arr005_b, arr006_b, arr007_b] /\
    %fb1_0 = [arr010_b, arr011_b, arr012_b, arr013_b, arr014_b, arr015_b, arr016_b, arr017_b]
    prove with [cuts[0]];

#### radix2

(* ldr	q5, [x5]                                    #! EA = L0x5555552e00; Value = 0xf2acfe2200070001; PC = 0x5555551d48 *)
mov %v5 [L0x5555552e00,L0x5555552e02,L0x5555552e04,L0x5555552e06,L0x5555552e08,L0x5555552e0a,L0x5555552e0c,L0x5555552e0e];
(* sshr	v0.8h, v4.8h, #12                          #! PC = 0x5555551d4c *)
split %v0 %dc %v4 12;
(* cmlt	v2.8h, v4.8h, #0                           #! PC = 0x5555551d50 *)
split %v2 %dc %v4 15;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551d54 *)
sub %v0 %v0 %v2;
(* mls	v4.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551d58 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v4 %v4 %mls;

assert
    %fa0_0 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v4
    prove with [algebra solver isl, precondition, cuts[0, 1]]
    && true;

assume
    %fa0_0 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v4
    && true;

(* sshr	v0.8h, v17.8h, #12                         #! PC = 0x5555551d5c *)
split %v0 %dc %v17 12;
(* cmlt	v2.8h, v17.8h, #0                          #! PC = 0x5555551d60 *)
split %v2 %dc %v17 15;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551d64 *)
sub %v0 %v0 %v2;
(* mls	v17.8h, v0.8h, v5.h[6]                      #! PC = 0x5555551d68 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v17 %v17 %mls;

assert
    %fb0_0 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v17
    prove with [algebra solver isl, precondition, cuts[0, 1]]
    && true;

assume
    %fb0_0 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v17
    && true;

(* sqrdmulh	v0.8h, v1.8h, v5.h[1]                  #! PC = 0x5555551d6c *)
broadcast %mul 8 [%v5[1]]; smulj %LO %v1 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v0 %LO11 %LO01;
(* mul	v1.8h, v1.8h, v5.h[0]                       #! PC = 0x5555551d70 *)
broadcast %mul 8 [%v5[0]]; mull %dc %v1 %v1 %mul; cast %v1@int16[8] %v1;
(* mls	v1.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551d74 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v1 %v1 %mls;

assert
    [1, 1, 1, 1, 1, 1, 1, 1] * %fa1_0
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v1
    prove with [algebra solver isl, precondition, cuts[0, 1]]
    && true;

assume
    [1, 1, 1, 1, 1, 1, 1, 1] * %fa1_0
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v1
    && true;

(* sqrdmulh	v0.8h, v18.8h, v5.h[1]                 #! PC = 0x5555551d78 *)
broadcast %mul 8 [%v5[1]]; smulj %LO %v18 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v0 %LO11 %LO01;
(* mul	v18.8h, v18.8h, v5.h[0]                     #! PC = 0x5555551d7c *)
broadcast %mul 8 [%v5[0]]; mull %dc %v18 %v18 %mul; cast %v18@int16[8] %v18;
(* mls	v18.8h, v0.8h, v5.h[6]                      #! PC = 0x5555551d80 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v18 %v18 %mls;

assert
    [1, 1, 1, 1, 1, 1, 1, 1] * %fb1_0
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v18
    prove with [algebra solver isl, precondition, cuts[0, 1]]
    && true;

assume
    [1, 1, 1, 1, 1, 1, 1, 1] * %fb1_0
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v18
    && true;

(* add	v2.8h, v4.8h, v1.8h                         #! PC = 0x5555551d84 *)
add %v2 %v4 %v1;
(* sub	v1.8h, v4.8h, v1.8h                         #! PC = 0x5555551d88 *)
sub %v1 %v4 %v1;
(* add	v7.8h, v17.8h, v18.8h                       #! PC = 0x5555551d8c *)
add %v7 %v17 %v18;
(* sub	v18.8h, v17.8h, v18.8h                      #! PC = 0x5555551d90 *)
sub %v18 %v17 %v18;

ghost %fc0_0@sint16[8], %fc1_0@sint16[8], %fd0_0@sint16[8], %fd1_0@sint16[8] :
    %fc0_0 = %v2 /\ %fc1_0 = %v1 /\ %fd0_0 = %v7 /\ %fd1_0 = %v18
  &&
    %fc0_0 = %v2 /\ %fc1_0 = %v1 /\ %fd0_0 = %v7 /\ %fd1_0 = %v18;

(* sqrdmulh	v0.8h, v7.8h, v5.h[1]                  #! PC = 0x5555551d94 *)
broadcast %mul 8 [%v5[1]]; smulj %LO %v7 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v0 %LO11 %LO01;
(* mul	v3.8h, v7.8h, v5.h[0]                       #! PC = 0x5555551d98 *)
broadcast %mul 8 [%v5[0]]; mull %dc %v3 %v7 %mul; cast %v3@int16[8] %v3;
(* mls	v3.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551d9c *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v3 %v3 %mls;

assert
    [1, 1, 1, 1, 1, 1, 1, 1] * %fd0_0
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v3
    prove with [algebra solver isl, precondition, cuts[0, 1]]
    && true;

assume
    [1, 1, 1, 1, 1, 1, 1, 1] * %fd0_0
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v3
    && true;

(* sqrdmulh	v0.8h, v18.8h, v5.h[1]                 #! PC = 0x5555551da0 *)
broadcast %mul 8 [%v5[1]]; smulj %LO %v18 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v0 %LO11 %LO01;
(* mul	v6.8h, v18.8h, v5.h[0]                      #! PC = 0x5555551da4 *)
broadcast %mul 8 [%v5[0]]; mull %dc %v6 %v18 %mul; cast %v6@int16[8] %v6;
(* mls	v6.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551da8 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v6 %v6 %mls;

assert
    [1, 1, 1, 1, 1, 1, 1, 1] * %fd1_0
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v6
    prove with [algebra solver isl, precondition, cuts[0, 1]]
    && true;

assume
    [1, 1, 1, 1, 1, 1, 1, 1] * %fd1_0
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v6
    && true;

(* neg	v6.8h, v6.8h                                #! PC = 0x5555551dac *)
broadcast %zero 8 [0@sint16]; sub %v6 %zero %v6;

ghost %gd0_0@sint16[8], %gd1_0@sint16[8] :
    %gd0_0 = %v3 /\ %gd1_0 = %v6
  &&
    %gd0_0 = %v3 /\ %gd1_0 = %v6;

cut (* 2 *)
    %fc0_0 = %v2 /\ %fc1_0 = %v1 /\ %fd0_0 = %v7 /\ %fd1_0 = %v18 /\ %gd0_0 = %v3 /\ %gd1_0 = %v6 /\

    %fc0_0 = %fa0_0 + [1, 1, 1, 1, 1, 1, 1, 1] * %fa1_0
        ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\
    %fc1_0 = %fa0_0 - [1, 1, 1, 1, 1, 1, 1, 1] * %fa1_0
        ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\

    %fd0_0 = %fb0_0 + [1, 1, 1, 1, 1, 1, 1, 1] * %fb1_0
        ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\
    %fd1_0 = %fb0_0 - [1, 1, 1, 1, 1, 1, 1, 1] * %fb1_0
        ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\

    %gd0_0 =  [1, 1, 1, 1, 1, 1, 1, 1] * %fd0_0 ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\
    %gd1_0 = -[1, 1, 1, 1, 1, 1, 1, 1] * %fd1_0 ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ),

    %fc0_0 <= [8100, 8100, 8100, 8100, 8100, 8100, 8100, 8100] /\
    %fc0_0 >= [-8100, -8100, -8100, -8100, -8100, -8100, -8100, -8100] /\

    %fc1_0 <= [8100, 8100, 8100, 8100, 8100, 8100, 8100, 8100] /\
    %fc1_0 >= [-8100, -8100, -8100, -8100, -8100, -8100, -8100, -8100] /\

    %fd0_0 <= [8100, 8100, 8100, 8100, 8100, 8100, 8100, 8100] /\
    %fd0_0 >= [-8100, -8100, -8100, -8100, -8100, -8100, -8100, -8100] /\

    %fd1_0 <= [8100, 8100, 8100, 8100, 8100, 8100, 8100, 8100] /\
    %fd1_0 >= [-8100, -8100, -8100, -8100, -8100, -8100, -8100, -8100] /\

    %gd0_0 <= [3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000] /\
    %gd0_0 >= [-3000, -3000, -3000, -3000, -3000, -3000, -3000, -3000] /\

    %gd1_0 <= [3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000] /\
    %gd1_0 >= [-3000, -3000, -3000, -3000, -3000, -3000, -3000, -3000]

    prove with [algebra solver isl, precondition, cuts[0, 1]]
  &&
    true
    prove with [precondition, cuts[0, 1]];

(* smull	v0.4s, v7.4h, v2.h[0]                     #! PC = 0x5555551db0 *)
broadcast %mull 4 [%v2[0]]; smulj %v0 [%v7[0],%v7[1],%v7[2],%v7[3]] %mull;
(* smull2	v4.4s, v7.8h, v2.h[0]                    #! PC = 0x5555551db4 *)
broadcast %mull 4 [%v2[0]]; smulj %v4 [%v7[4],%v7[5],%v7[6],%v7[7]] %mull;
(* ext	v16.16b, v3.16b, v7.16b, #14                #! PC = 0x5555551db8 *)
mov %v16 [%v3[7],%v7[0],%v7[1],%v7[2],%v7[3],%v7[4],%v7[5],%v7[6]];
(* smlal	v0.4s, v16.4h, v2.h[1]                    #! PC = 0x5555551dbc *)
broadcast %mull 4 [%v2[1]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v16.8h, v2.h[1]                   #! PC = 0x5555551dc0 *)
broadcast %mull 4 [%v2[1]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v4 %v4 %mlal;
(* ext	v16.16b, v3.16b, v7.16b, #12                #! PC = 0x5555551dc4 *)
mov %v16 [%v3[6],%v3[7],%v7[0],%v7[1],%v7[2],%v7[3],%v7[4],%v7[5]];
(* smlal	v0.4s, v16.4h, v2.h[2]                    #! PC = 0x5555551dc8 *)
broadcast %mull 4 [%v2[2]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v16.8h, v2.h[2]                   #! PC = 0x5555551dcc *)
broadcast %mull 4 [%v2[2]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v4 %v4 %mlal;
(* ext	v16.16b, v3.16b, v7.16b, #10                #! PC = 0x5555551dd0 *)
mov %v16 [%v3[5],%v3[6],%v3[7],%v7[0],%v7[1],%v7[2],%v7[3],%v7[4]];
(* smlal	v0.4s, v16.4h, v2.h[3]                    #! PC = 0x5555551dd4 *)
broadcast %mull 4 [%v2[3]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v16.8h, v2.h[3]                   #! PC = 0x5555551dd8 *)
broadcast %mull 4 [%v2[3]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v4 %v4 %mlal;
(* ext	v16.16b, v3.16b, v7.16b, #8                 #! PC = 0x5555551ddc *)
mov %v16 [%v3[4],%v3[5],%v3[6],%v3[7],%v7[0],%v7[1],%v7[2],%v7[3]];
(* smlal	v0.4s, v16.4h, v2.h[4]                    #! PC = 0x5555551de0 *)
broadcast %mull 4 [%v2[4]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v16.8h, v2.h[4]                   #! PC = 0x5555551de4 *)
broadcast %mull 4 [%v2[4]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v4 %v4 %mlal;
(* ext	v16.16b, v3.16b, v7.16b, #6                 #! PC = 0x5555551de8 *)
mov %v16 [%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v7[0],%v7[1],%v7[2]];
(* smlal	v0.4s, v16.4h, v2.h[5]                    #! PC = 0x5555551dec *)
broadcast %mull 4 [%v2[5]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v16.8h, v2.h[5]                   #! PC = 0x5555551df0 *)
broadcast %mull 4 [%v2[5]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v4 %v4 %mlal;
(* ext	v16.16b, v3.16b, v7.16b, #4                 #! PC = 0x5555551df4 *)
mov %v16 [%v3[2],%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v7[0],%v7[1]];
(* smlal	v0.4s, v16.4h, v2.h[6]                    #! PC = 0x5555551df8 *)
broadcast %mull 4 [%v2[6]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v16.8h, v2.h[6]                   #! PC = 0x5555551dfc *)
broadcast %mull 4 [%v2[6]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v4 %v4 %mlal;
(* ext	v3.16b, v3.16b, v7.16b, #2                  #! PC = 0x5555551e00 *)
mov %v3 [%v3[1],%v3[2],%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v7[0]];
(* smlal	v0.4s, v3.4h, v2.h[7]                     #! PC = 0x5555551e04 *)
broadcast %mull 4 [%v2[7]]; smulj %mlal [%v3[0],%v3[1],%v3[2],%v3[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v3.8h, v2.h[7]                    #! PC = 0x5555551e08 *)
broadcast %mull 4 [%v2[7]]; smulj %mlal [%v3[4],%v3[5],%v3[6],%v3[7]] %mull; adds %dc %v4 %v4 %mlal;
(* smull	v3.4s, v18.4h, v1.h[0]                    #! PC = 0x5555551e0c *)
broadcast %mull 4 [%v1[0]]; smulj %v3 [%v18[0],%v18[1],%v18[2],%v18[3]] %mull;
(* smull2	v2.4s, v18.8h, v1.h[0]                   #! PC = 0x5555551e10 *)
broadcast %mull 4 [%v1[0]]; smulj %v2 [%v18[4],%v18[5],%v18[6],%v18[7]] %mull;
(* ext	v7.16b, v6.16b, v18.16b, #14                #! PC = 0x5555551e14 *)
mov %v7 [%v6[7],%v18[0],%v18[1],%v18[2],%v18[3],%v18[4],%v18[5],%v18[6]];
(* smlal	v3.4s, v7.4h, v1.h[1]                     #! PC = 0x5555551e18 *)
broadcast %mull 4 [%v1[1]]; smulj %mlal [%v7[0],%v7[1],%v7[2],%v7[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v7.8h, v1.h[1]                    #! PC = 0x5555551e1c *)
broadcast %mull 4 [%v1[1]]; smulj %mlal [%v7[4],%v7[5],%v7[6],%v7[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v7.16b, v6.16b, v18.16b, #12                #! PC = 0x5555551e20 *)
mov %v7 [%v6[6],%v6[7],%v18[0],%v18[1],%v18[2],%v18[3],%v18[4],%v18[5]];
(* smlal	v3.4s, v7.4h, v1.h[2]                     #! PC = 0x5555551e24 *)
broadcast %mull 4 [%v1[2]]; smulj %mlal [%v7[0],%v7[1],%v7[2],%v7[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v7.8h, v1.h[2]                    #! PC = 0x5555551e28 *)
broadcast %mull 4 [%v1[2]]; smulj %mlal [%v7[4],%v7[5],%v7[6],%v7[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v7.16b, v6.16b, v18.16b, #10                #! PC = 0x5555551e2c *)
mov %v7 [%v6[5],%v6[6],%v6[7],%v18[0],%v18[1],%v18[2],%v18[3],%v18[4]];
(* smlal	v3.4s, v7.4h, v1.h[3]                     #! PC = 0x5555551e30 *)
broadcast %mull 4 [%v1[3]]; smulj %mlal [%v7[0],%v7[1],%v7[2],%v7[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v7.8h, v1.h[3]                    #! PC = 0x5555551e34 *)
broadcast %mull 4 [%v1[3]]; smulj %mlal [%v7[4],%v7[5],%v7[6],%v7[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v7.16b, v6.16b, v18.16b, #8                 #! PC = 0x5555551e38 *)
mov %v7 [%v6[4],%v6[5],%v6[6],%v6[7],%v18[0],%v18[1],%v18[2],%v18[3]];
(* smlal	v3.4s, v7.4h, v1.h[4]                     #! PC = 0x5555551e3c *)
broadcast %mull 4 [%v1[4]]; smulj %mlal [%v7[0],%v7[1],%v7[2],%v7[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v7.8h, v1.h[4]                    #! PC = 0x5555551e40 *)
broadcast %mull 4 [%v1[4]]; smulj %mlal [%v7[4],%v7[5],%v7[6],%v7[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v7.16b, v6.16b, v18.16b, #6                 #! PC = 0x5555551e44 *)
mov %v7 [%v6[3],%v6[4],%v6[5],%v6[6],%v6[7],%v18[0],%v18[1],%v18[2]];
(* smlal	v3.4s, v7.4h, v1.h[5]                     #! PC = 0x5555551e48 *)
broadcast %mull 4 [%v1[5]]; smulj %mlal [%v7[0],%v7[1],%v7[2],%v7[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v7.8h, v1.h[5]                    #! PC = 0x5555551e4c *)
broadcast %mull 4 [%v1[5]]; smulj %mlal [%v7[4],%v7[5],%v7[6],%v7[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v7.16b, v6.16b, v18.16b, #4                 #! PC = 0x5555551e50 *)
mov %v7 [%v6[2],%v6[3],%v6[4],%v6[5],%v6[6],%v6[7],%v18[0],%v18[1]];
(* smlal	v3.4s, v7.4h, v1.h[6]                     #! PC = 0x5555551e54 *)
broadcast %mull 4 [%v1[6]]; smulj %mlal [%v7[0],%v7[1],%v7[2],%v7[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v7.8h, v1.h[6]                    #! PC = 0x5555551e58 *)
broadcast %mull 4 [%v1[6]]; smulj %mlal [%v7[4],%v7[5],%v7[6],%v7[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v6.16b, v6.16b, v18.16b, #2                 #! PC = 0x5555551e5c *)
mov %v6 [%v6[1],%v6[2],%v6[3],%v6[4],%v6[5],%v6[6],%v6[7],%v18[0]];
(* smlal	v3.4s, v6.4h, v1.h[7]                     #! PC = 0x5555551e60 *)
broadcast %mull 4 [%v1[7]]; smulj %mlal [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v6.8h, v1.h[7]                    #! PC = 0x5555551e64 *)
broadcast %mull 4 [%v1[7]]; smulj %mlal [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; adds %dc %v2 %v2 %mlal;

ghost %conv0_0@sint32[8], %conv1_0@sint32[8] :
    %conv0_0 = [
        %fc0_0[0] * %fd0_0[0] + %fc0_0[1] * %gd0_0[7] + %fc0_0[2] * %gd0_0[6] + %fc0_0[3] * %gd0_0[5] + %fc0_0[4] * %gd0_0[4] + %fc0_0[5] * %gd0_0[3] + %fc0_0[6] * %gd0_0[2] + %fc0_0[7] * %gd0_0[1],
        %fc0_0[0] * %fd0_0[1] + %fc0_0[1] * %fd0_0[0] + %fc0_0[2] * %gd0_0[7] + %fc0_0[3] * %gd0_0[6] + %fc0_0[4] * %gd0_0[5] + %fc0_0[5] * %gd0_0[4] + %fc0_0[6] * %gd0_0[3] + %fc0_0[7] * %gd0_0[2],
        %fc0_0[0] * %fd0_0[2] + %fc0_0[1] * %fd0_0[1] + %fc0_0[2] * %fd0_0[0] + %fc0_0[3] * %gd0_0[7] + %fc0_0[4] * %gd0_0[6] + %fc0_0[5] * %gd0_0[5] + %fc0_0[6] * %gd0_0[4] + %fc0_0[7] * %gd0_0[3],
        %fc0_0[0] * %fd0_0[3] + %fc0_0[1] * %fd0_0[2] + %fc0_0[2] * %fd0_0[1] + %fc0_0[3] * %fd0_0[0] + %fc0_0[4] * %gd0_0[7] + %fc0_0[5] * %gd0_0[6] + %fc0_0[6] * %gd0_0[5] + %fc0_0[7] * %gd0_0[4],
        %fc0_0[0] * %fd0_0[4] + %fc0_0[1] * %fd0_0[3] + %fc0_0[2] * %fd0_0[2] + %fc0_0[3] * %fd0_0[1] + %fc0_0[4] * %fd0_0[0] + %fc0_0[5] * %gd0_0[7] + %fc0_0[6] * %gd0_0[6] + %fc0_0[7] * %gd0_0[5],
        %fc0_0[0] * %fd0_0[5] + %fc0_0[1] * %fd0_0[4] + %fc0_0[2] * %fd0_0[3] + %fc0_0[3] * %fd0_0[2] + %fc0_0[4] * %fd0_0[1] + %fc0_0[5] * %fd0_0[0] + %fc0_0[6] * %gd0_0[7] + %fc0_0[7] * %gd0_0[6],
        %fc0_0[0] * %fd0_0[6] + %fc0_0[1] * %fd0_0[5] + %fc0_0[2] * %fd0_0[4] + %fc0_0[3] * %fd0_0[3] + %fc0_0[4] * %fd0_0[2] + %fc0_0[5] * %fd0_0[1] + %fc0_0[6] * %fd0_0[0] + %fc0_0[7] * %gd0_0[7],
        %fc0_0[0] * %fd0_0[7] + %fc0_0[1] * %fd0_0[6] + %fc0_0[2] * %fd0_0[5] + %fc0_0[3] * %fd0_0[4] + %fc0_0[4] * %fd0_0[3] + %fc0_0[5] * %fd0_0[2] + %fc0_0[6] * %fd0_0[1] + %fc0_0[7] * %fd0_0[0]
    ] /\
    %conv1_0 = [
        %fc1_0[0] * %fd1_0[0] + %fc1_0[1] * %gd1_0[7] + %fc1_0[2] * %gd1_0[6] + %fc1_0[3] * %gd1_0[5] + %fc1_0[4] * %gd1_0[4] + %fc1_0[5] * %gd1_0[3] + %fc1_0[6] * %gd1_0[2] + %fc1_0[7] * %gd1_0[1],
        %fc1_0[0] * %fd1_0[1] + %fc1_0[1] * %fd1_0[0] + %fc1_0[2] * %gd1_0[7] + %fc1_0[3] * %gd1_0[6] + %fc1_0[4] * %gd1_0[5] + %fc1_0[5] * %gd1_0[4] + %fc1_0[6] * %gd1_0[3] + %fc1_0[7] * %gd1_0[2],
        %fc1_0[0] * %fd1_0[2] + %fc1_0[1] * %fd1_0[1] + %fc1_0[2] * %fd1_0[0] + %fc1_0[3] * %gd1_0[7] + %fc1_0[4] * %gd1_0[6] + %fc1_0[5] * %gd1_0[5] + %fc1_0[6] * %gd1_0[4] + %fc1_0[7] * %gd1_0[3],
        %fc1_0[0] * %fd1_0[3] + %fc1_0[1] * %fd1_0[2] + %fc1_0[2] * %fd1_0[1] + %fc1_0[3] * %fd1_0[0] + %fc1_0[4] * %gd1_0[7] + %fc1_0[5] * %gd1_0[6] + %fc1_0[6] * %gd1_0[5] + %fc1_0[7] * %gd1_0[4],
        %fc1_0[0] * %fd1_0[4] + %fc1_0[1] * %fd1_0[3] + %fc1_0[2] * %fd1_0[2] + %fc1_0[3] * %fd1_0[1] + %fc1_0[4] * %fd1_0[0] + %fc1_0[5] * %gd1_0[7] + %fc1_0[6] * %gd1_0[6] + %fc1_0[7] * %gd1_0[5],
        %fc1_0[0] * %fd1_0[5] + %fc1_0[1] * %fd1_0[4] + %fc1_0[2] * %fd1_0[3] + %fc1_0[3] * %fd1_0[2] + %fc1_0[4] * %fd1_0[1] + %fc1_0[5] * %fd1_0[0] + %fc1_0[6] * %gd1_0[7] + %fc1_0[7] * %gd1_0[6],
        %fc1_0[0] * %fd1_0[6] + %fc1_0[1] * %fd1_0[5] + %fc1_0[2] * %fd1_0[4] + %fc1_0[3] * %fd1_0[3] + %fc1_0[4] * %fd1_0[2] + %fc1_0[5] * %fd1_0[1] + %fc1_0[6] * %fd1_0[0] + %fc1_0[7] * %gd1_0[7],
        %fc1_0[0] * %fd1_0[7] + %fc1_0[1] * %fd1_0[6] + %fc1_0[2] * %fd1_0[5] + %fc1_0[3] * %fd1_0[4] + %fc1_0[4] * %fd1_0[3] + %fc1_0[5] * %fd1_0[2] + %fc1_0[6] * %fd1_0[1] + %fc1_0[7] * %fd1_0[0]
    ]
    && true;

assert
    %v0 ++ %v4 = %conv0_0 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] ) /\
    %v3 ++ %v2 = %conv1_0 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] )
    && true;

assume
    %v0 ++ %v4 = %conv0_0 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] ) /\
    %v3 ++ %v2 = %conv1_0 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] )
    && true;

assert
    %conv0_0 <= [524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000] /\
    %conv0_0 >= [-524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000] /\

    %conv1_0 <= [524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000] /\
    %conv1_0 >= [-524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000]
    prove with [algebra solver smt: z3]
    && true;

assume
    %conv0_0 <= [524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000] /\
    %conv0_0 >= [-524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000] /\

    %conv1_0 <= [524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000] /\
    %conv1_0 >= [-524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000]
    && true;

assert
    %v0 ++ %v4 = %conv0_0 /\ %v3 ++ %v2 = %conv1_0
    prove with [algebra solver isl]
    && true;

assume
    %v0 ++ %v4 = %conv0_0 /\ %v3 ++ %v2 = %conv1_0
    && true;

assert
    %v0 <= [524880000, 524880000, 524880000, 524880000] /\
    %v0 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v4 <= [524880000, 524880000, 524880000, 524880000] /\
    %v4 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v3 <= [524880000, 524880000, 524880000, 524880000] /\
    %v3 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v2 <= [524880000, 524880000, 524880000, 524880000] /\
    %v2 >= [-524880000, -524880000, -524880000, -524880000]

    prove with [algebra solver isl]
    && true;

assume
    %v0 <= [524880000, 524880000, 524880000, 524880000] /\
    %v0 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v4 <= [524880000, 524880000, 524880000, 524880000] /\
    %v4 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v3 <= [524880000, 524880000, 524880000, 524880000] /\
    %v3 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v2 <= [524880000, 524880000, 524880000, 524880000] /\
    %v2 >= [-524880000, -524880000, -524880000, -524880000]
  &&
    %v0 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v0 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32] /\

    %v4 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v4 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32] /\

    %v3 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v3 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32] /\

    %v2 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v2 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32];

cut (* 3 *)
    %conv0_0 = [
        %fc0_0[0] * %fd0_0[0] + %fc0_0[1] * %gd0_0[7] + %fc0_0[2] * %gd0_0[6] + %fc0_0[3] * %gd0_0[5] + %fc0_0[4] * %gd0_0[4] + %fc0_0[5] * %gd0_0[3] + %fc0_0[6] * %gd0_0[2] + %fc0_0[7] * %gd0_0[1],
        %fc0_0[0] * %fd0_0[1] + %fc0_0[1] * %fd0_0[0] + %fc0_0[2] * %gd0_0[7] + %fc0_0[3] * %gd0_0[6] + %fc0_0[4] * %gd0_0[5] + %fc0_0[5] * %gd0_0[4] + %fc0_0[6] * %gd0_0[3] + %fc0_0[7] * %gd0_0[2],
        %fc0_0[0] * %fd0_0[2] + %fc0_0[1] * %fd0_0[1] + %fc0_0[2] * %fd0_0[0] + %fc0_0[3] * %gd0_0[7] + %fc0_0[4] * %gd0_0[6] + %fc0_0[5] * %gd0_0[5] + %fc0_0[6] * %gd0_0[4] + %fc0_0[7] * %gd0_0[3],
        %fc0_0[0] * %fd0_0[3] + %fc0_0[1] * %fd0_0[2] + %fc0_0[2] * %fd0_0[1] + %fc0_0[3] * %fd0_0[0] + %fc0_0[4] * %gd0_0[7] + %fc0_0[5] * %gd0_0[6] + %fc0_0[6] * %gd0_0[5] + %fc0_0[7] * %gd0_0[4],
        %fc0_0[0] * %fd0_0[4] + %fc0_0[1] * %fd0_0[3] + %fc0_0[2] * %fd0_0[2] + %fc0_0[3] * %fd0_0[1] + %fc0_0[4] * %fd0_0[0] + %fc0_0[5] * %gd0_0[7] + %fc0_0[6] * %gd0_0[6] + %fc0_0[7] * %gd0_0[5],
        %fc0_0[0] * %fd0_0[5] + %fc0_0[1] * %fd0_0[4] + %fc0_0[2] * %fd0_0[3] + %fc0_0[3] * %fd0_0[2] + %fc0_0[4] * %fd0_0[1] + %fc0_0[5] * %fd0_0[0] + %fc0_0[6] * %gd0_0[7] + %fc0_0[7] * %gd0_0[6],
        %fc0_0[0] * %fd0_0[6] + %fc0_0[1] * %fd0_0[5] + %fc0_0[2] * %fd0_0[4] + %fc0_0[3] * %fd0_0[3] + %fc0_0[4] * %fd0_0[2] + %fc0_0[5] * %fd0_0[1] + %fc0_0[6] * %fd0_0[0] + %fc0_0[7] * %gd0_0[7],
        %fc0_0[0] * %fd0_0[7] + %fc0_0[1] * %fd0_0[6] + %fc0_0[2] * %fd0_0[5] + %fc0_0[3] * %fd0_0[4] + %fc0_0[4] * %fd0_0[3] + %fc0_0[5] * %fd0_0[2] + %fc0_0[6] * %fd0_0[1] + %fc0_0[7] * %fd0_0[0]
    ] /\
    %conv1_0 = [
        %fc1_0[0] * %fd1_0[0] + %fc1_0[1] * %gd1_0[7] + %fc1_0[2] * %gd1_0[6] + %fc1_0[3] * %gd1_0[5] + %fc1_0[4] * %gd1_0[4] + %fc1_0[5] * %gd1_0[3] + %fc1_0[6] * %gd1_0[2] + %fc1_0[7] * %gd1_0[1],
        %fc1_0[0] * %fd1_0[1] + %fc1_0[1] * %fd1_0[0] + %fc1_0[2] * %gd1_0[7] + %fc1_0[3] * %gd1_0[6] + %fc1_0[4] * %gd1_0[5] + %fc1_0[5] * %gd1_0[4] + %fc1_0[6] * %gd1_0[3] + %fc1_0[7] * %gd1_0[2],
        %fc1_0[0] * %fd1_0[2] + %fc1_0[1] * %fd1_0[1] + %fc1_0[2] * %fd1_0[0] + %fc1_0[3] * %gd1_0[7] + %fc1_0[4] * %gd1_0[6] + %fc1_0[5] * %gd1_0[5] + %fc1_0[6] * %gd1_0[4] + %fc1_0[7] * %gd1_0[3],
        %fc1_0[0] * %fd1_0[3] + %fc1_0[1] * %fd1_0[2] + %fc1_0[2] * %fd1_0[1] + %fc1_0[3] * %fd1_0[0] + %fc1_0[4] * %gd1_0[7] + %fc1_0[5] * %gd1_0[6] + %fc1_0[6] * %gd1_0[5] + %fc1_0[7] * %gd1_0[4],
        %fc1_0[0] * %fd1_0[4] + %fc1_0[1] * %fd1_0[3] + %fc1_0[2] * %fd1_0[2] + %fc1_0[3] * %fd1_0[1] + %fc1_0[4] * %fd1_0[0] + %fc1_0[5] * %gd1_0[7] + %fc1_0[6] * %gd1_0[6] + %fc1_0[7] * %gd1_0[5],
        %fc1_0[0] * %fd1_0[5] + %fc1_0[1] * %fd1_0[4] + %fc1_0[2] * %fd1_0[3] + %fc1_0[3] * %fd1_0[2] + %fc1_0[4] * %fd1_0[1] + %fc1_0[5] * %fd1_0[0] + %fc1_0[6] * %gd1_0[7] + %fc1_0[7] * %gd1_0[6],
        %fc1_0[0] * %fd1_0[6] + %fc1_0[1] * %fd1_0[5] + %fc1_0[2] * %fd1_0[4] + %fc1_0[3] * %fd1_0[3] + %fc1_0[4] * %fd1_0[2] + %fc1_0[5] * %fd1_0[1] + %fc1_0[6] * %fd1_0[0] + %fc1_0[7] * %gd1_0[7],
        %fc1_0[0] * %fd1_0[7] + %fc1_0[1] * %fd1_0[6] + %fc1_0[2] * %fd1_0[5] + %fc1_0[3] * %fd1_0[4] + %fc1_0[4] * %fd1_0[3] + %fc1_0[5] * %fd1_0[2] + %fc1_0[6] * %fd1_0[1] + %fc1_0[7] * %fd1_0[0]
    ] /\

    %v0 ++ %v4 = %conv0_0 /\ %v3 ++ %v2 = %conv1_0,

    %v0 <= [524880000, 524880000, 524880000, 524880000] /\
    %v0 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v4 <= [524880000, 524880000, 524880000, 524880000] /\
    %v4 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v3 <= [524880000, 524880000, 524880000, 524880000] /\
    %v3 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v2 <= [524880000, 524880000, 524880000, 524880000] /\
    %v2 >= [-524880000, -524880000, -524880000, -524880000]

    prove with [algebra solver isl]
  &&
    %v0 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v0 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32] /\

    %v4 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v4 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32] /\

    %v3 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v3 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32] /\

    %v2 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v2 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32];

(* add	v1.4s, v3.4s, v0.4s                         #! PC = 0x5555551e68 *)
add %v1 %v3 %v0;
(* add	v6.4s, v2.4s, v4.4s                         #! PC = 0x5555551e6c *)
add %v6 %v2 %v4;
(* sub	v0.4s, v0.4s, v3.4s                         #! PC = 0x5555551e70 *)
sub %v0 %v0 %v3;
(* sub	v4.4s, v4.4s, v2.4s                         #! PC = 0x5555551e74 *)
sub %v4 %v4 %v2;

ghost %h0_0@sint32[8], %h1_0@sint32[8] :
    %h0_0 = %v1 ++ %v6 /\ %h1_0 = %v0 ++ %v4
  &&
    %h0_0 = %v1 ++ %v6 /\ %h1_0 = %v0 ++ %v4;

(* uzp1	v2.8h, v1.8h, v6.8h                        #! PC = 0x5555551e78 *)
mov %spl_join [%v1[0], %v1[1], %v1[2], %v1[3], %v6[0], %v6[1], %v6[2], %v6[3]]; spl %splh %v2 %spl_join 16; cast %v2@int16[8] %v2;
(* mul	v2.8h, v2.8h, v5.h[7]                       #! PC = 0x5555551e7c *)
broadcast %mul 8 [%v5[7]]; mull %dc %v2 %v2 %mul; cast %v2@int16[8] %v2;

ghost %m0_0@sint16[8] : %m0_0 = %v2 && %m0_0 = %v2;

(* sqdmulh	v2.8h, v2.8h, v5.h[6]                   #! PC = 0x5555551e80 *)
broadcast %mul 8 [%v5[6]]; smulj %LO %v2 %mul;
ssplit %LO0 %dc %LO 15; vpc %v2@sint16[8] %LO0;
(* uzp2	v1.8h, v1.8h, v6.8h                        #! PC = 0x5555551e84 *)
mov %spl_join [%v1[0], %v1[1], %v1[2], %v1[3], %v6[0], %v6[1], %v6[2], %v6[3]]; spl %v1 %spll %spl_join 16;
(* sshr	v2.8h, v2.8h, #1                           #! PC = 0x5555551e88 *)
split %v2 %dc %v2 1;
(* sub	v1.8h, v1.8h, v2.8h                         #! PC = 0x5555551e8c *)
sub %v1 %v1 %v2;

ghost %hh0_0@sint16[8] : %hh0_0 = %v1 && %hh0_0 = %v1;

assert
    %h0_0 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m0_0
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh0_0
    prove with [algebra solver isl]
    && true;

assume
    %h0_0 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m0_0
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh0_0
    && true;

(* sqrdmulh	v2.8h, v1.8h, v5.h[3]                  #! PC = 0x5555551e90 *)
broadcast %mul 8 [%v5[3]]; smulj %LO %v1 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v2 %LO11 %LO01;
(* mul	v1.8h, v1.8h, v5.h[2]                       #! PC = 0x5555551e94 *)
broadcast %mul 8 [%v5[2]]; mull %dc %v1 %v1 %mul; cast %v1@int16[8] %v1;
(* mls	v1.8h, v2.8h, v5.h[6]                       #! PC = 0x5555551e98 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v2 %mul;
cast %mls@int16[8] %mls; subc %dc %v1 %v1 %mls;

assert
    [-478, -478, -478, -478, -478, -478, -478, -478] * %hh0_0
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v2
    = %v1
    prove with [algebra solver isl]
    && true;

assume
    [-478, -478, -478, -478, -478, -478, -478, -478] * %hh0_0
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v2
    = %v1
    && true;

(* uzp1	v2.8h, v0.8h, v4.8h                        #! PC = 0x5555551e9c *)
mov %spl_join [%v0[0], %v0[1], %v0[2], %v0[3], %v4[0], %v4[1], %v4[2], %v4[3]]; spl %splh %v2 %spl_join 16; cast %v2@int16[8] %v2;
(* mul	v2.8h, v2.8h, v5.h[7]                       #! PC = 0x5555551ea0 *)
broadcast %mul 8 [%v5[7]]; mull %dc %v2 %v2 %mul; cast %v2@int16[8] %v2;

ghost %m1_0@sint16[8] : %m1_0 = %v2 && %m1_0 = %v2;

(* sqdmulh	v2.8h, v2.8h, v5.h[6]                   #! PC = 0x5555551ea4 *)
broadcast %mul 8 [%v5[6]]; smulj %LO %v2 %mul;
ssplit %LO0 %dc %LO 15; vpc %v2@sint16[8] %LO0;
(* uzp2	v0.8h, v0.8h, v4.8h                        #! PC = 0x5555551ea8 *)
mov %spl_join [%v0[0], %v0[1], %v0[2], %v0[3], %v4[0], %v4[1], %v4[2], %v4[3]]; spl %v0 %spll %spl_join 16;
(* sshr	v2.8h, v2.8h, #1                           #! PC = 0x5555551eac *)
split %v2 %dc %v2 1;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551eb0 *)
sub %v0 %v0 %v2;

ghost %hh1_0@sint16[8] : %hh1_0 = %v0 && %hh1_0 = %v0;

assert
    %h1_0 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m1_0
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh1_0
    prove with [algebra solver isl]
    && true;

assume
    %h1_0 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m1_0
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh1_0
    && true;

(* sqrdmulh	v2.8h, v0.8h, v5.h[5]                  #! PC = 0x5555551eb4 *)
broadcast %mul 8 [%v5[5]]; smulj %LO %v0 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v2 %LO11 %LO01;
(* mul	v0.8h, v0.8h, v5.h[4]                       #! PC = 0x5555551eb8 *)
broadcast %mul 8 [%v5[4]]; mull %dc %v0 %v0 %mul; cast %v0@int16[8] %v0;
(* mls	v0.8h, v2.8h, v5.h[6]                       #! PC = 0x5555551ebc *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v2 %mul;
cast %mls@int16[8] %mls; subc %dc %v0 %v0 %mls;

assert
    [-478, -478, -478, -478, -478, -478, -478, -478] * %hh1_0
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v2
    = %v0
    prove with [algebra solver isl]
    && true;

assume
    [-478, -478, -478, -478, -478, -478, -478, -478] * %hh1_0
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v2
    = %v0
    && true;

(* #b	0x5555551d18 <_ZN6xpower7basemul11low_basemulEPA2_A8_sS3_S3_+504>#! PC = 0x5555551ec0 *)
#b	0x5555551d18 <_ZN6xpower7basemul11low_basemulEPA2_A8_sS3_S3_+504>#! 0x5555551ec0 = 0x5555551ec0;


### i_iter epilogue

(* str	q1, [x2, x3]                                #! EA = L0x7fffffe1b0; PC = 0x5555551d18 *)
mov [L0x7fffffe1b0,L0x7fffffe1b2,L0x7fffffe1b4,L0x7fffffe1b6,L0x7fffffe1b8,L0x7fffffe1ba,L0x7fffffe1bc,L0x7fffffe1be] %v1;
(* str	q0, [x6, x3]                                #! EA = L0x7fffffe1c0; PC = 0x5555551d1c *)
mov [L0x7fffffe1c0,L0x7fffffe1c2,L0x7fffffe1c4,L0x7fffffe1c6,L0x7fffffe1c8,L0x7fffffe1ca,L0x7fffffe1cc,L0x7fffffe1ce] %v0;
(* #b.eq	0x5555551ec4 <_ZN6xpower7basemul11low_basemulEPA2_A8_sS3_S3_+932>  // b.none#! PC = 0x5555551d30 *)
#b.eq	0x5555551ec4 <_ZN6xpower7basemul11low_basemulEPA2_A8_sS3_S3_+932>  // b.none#! 0x5555551d30 = 0x5555551d30;

assert
    %v1 <= [3700, 3700, 3700, 3700, 3700, 3700, 3700, 3700] /\
    %v1 >= [-3700, -3700, -3700, -3700, -3700, -3700, -3700, -3700] /\

    %v0 <= [3700, 3700, 3700, 3700, 3700, 3700, 3700, 3700] /\
    %v0 >= [-3700, -3700, -3700, -3700, -3700, -3700, -3700, -3700]

    prove with [algebra solver isl]
    && true;

assume
    true &&

    %v1 <=s [3700@16, 3700@16, 3700@16, 3700@16, 3700@16, 3700@16, 3700@16, 3700@16] /\
    %v1 >=s [(-3700)@16, (-3700)@16, (-3700)@16, (-3700)@16, (-3700)@16, (-3700)@16, (-3700)@16, (-3700)@16] /\

    %v0 <=s [3700@16, 3700@16, 3700@16, 3700@16, 3700@16, 3700@16, 3700@16, 3700@16] /\
    %v0 >=s [(-3700)@16, (-3700)@16, (-3700)@16, (-3700)@16, (-3700)@16, (-3700)@16, (-3700)@16, (-3700)@16];

cut (* 4 *)
    [L0x7fffffe1b0, L0x7fffffe1b2, L0x7fffffe1b4, L0x7fffffe1b6, L0x7fffffe1b8, L0x7fffffe1ba, L0x7fffffe1bc, L0x7fffffe1be] = %v1 /\
    [L0x7fffffe1c0, L0x7fffffe1c2, L0x7fffffe1c4, L0x7fffffe1c6, L0x7fffffe1c8, L0x7fffffe1ca, L0x7fffffe1cc, L0x7fffffe1ce] = %v0 /\

    %v1 ++ %v0 = [72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72] * [
        arr000_a * arr000_b + 1 * arr001_a * arr017_b + 1 * arr002_a * arr016_b + 1 * arr003_a * arr015_b + 1 * arr004_a * arr014_b + 1 * arr005_a * arr013_b + 1 * arr006_a * arr012_b + 1 * arr007_a * arr011_b + 1 * arr010_a * arr010_b + 1 * arr011_a * arr007_b + 1 * arr012_a * arr006_b + 1 * arr013_a * arr005_b + 1 * arr014_a * arr004_b + 1 * arr015_a * arr003_b + 1 * arr016_a * arr002_b + 1 * arr017_a * arr001_b,
        arr000_a * arr001_b + arr001_a * arr000_b + 1 * arr002_a * arr017_b + 1 * arr003_a * arr016_b + 1 * arr004_a * arr015_b + 1 * arr005_a * arr014_b + 1 * arr006_a * arr013_b + 1 * arr007_a * arr012_b + 1 * arr010_a * arr011_b + 1 * arr011_a * arr010_b + 1 * arr012_a * arr007_b + 1 * arr013_a * arr006_b + 1 * arr014_a * arr005_b + 1 * arr015_a * arr004_b + 1 * arr016_a * arr003_b + 1 * arr017_a * arr002_b,
        arr000_a * arr002_b + arr001_a * arr001_b + arr002_a * arr000_b + 1 * arr003_a * arr017_b + 1 * arr004_a * arr016_b + 1 * arr005_a * arr015_b + 1 * arr006_a * arr014_b + 1 * arr007_a * arr013_b + 1 * arr010_a * arr012_b + 1 * arr011_a * arr011_b + 1 * arr012_a * arr010_b + 1 * arr013_a * arr007_b + 1 * arr014_a * arr006_b + 1 * arr015_a * arr005_b + 1 * arr016_a * arr004_b + 1 * arr017_a * arr003_b,
        arr000_a * arr003_b + arr001_a * arr002_b + arr002_a * arr001_b + arr003_a * arr000_b + 1 * arr004_a * arr017_b + 1 * arr005_a * arr016_b + 1 * arr006_a * arr015_b + 1 * arr007_a * arr014_b + 1 * arr010_a * arr013_b + 1 * arr011_a * arr012_b + 1 * arr012_a * arr011_b + 1 * arr013_a * arr010_b + 1 * arr014_a * arr007_b + 1 * arr015_a * arr006_b + 1 * arr016_a * arr005_b + 1 * arr017_a * arr004_b,
        arr000_a * arr004_b + arr001_a * arr003_b + arr002_a * arr002_b + arr003_a * arr001_b + arr004_a * arr000_b + 1 * arr005_a * arr017_b + 1 * arr006_a * arr016_b + 1 * arr007_a * arr015_b + 1 * arr010_a * arr014_b + 1 * arr011_a * arr013_b + 1 * arr012_a * arr012_b + 1 * arr013_a * arr011_b + 1 * arr014_a * arr010_b + 1 * arr015_a * arr007_b + 1 * arr016_a * arr006_b + 1 * arr017_a * arr005_b,
        arr000_a * arr005_b + arr001_a * arr004_b + arr002_a * arr003_b + arr003_a * arr002_b + arr004_a * arr001_b + arr005_a * arr000_b + 1 * arr006_a * arr017_b + 1 * arr007_a * arr016_b + 1 * arr010_a * arr015_b + 1 * arr011_a * arr014_b + 1 * arr012_a * arr013_b + 1 * arr013_a * arr012_b + 1 * arr014_a * arr011_b + 1 * arr015_a * arr010_b + 1 * arr016_a * arr007_b + 1 * arr017_a * arr006_b,
        arr000_a * arr006_b + arr001_a * arr005_b + arr002_a * arr004_b + arr003_a * arr003_b + arr004_a * arr002_b + arr005_a * arr001_b + arr006_a * arr000_b + 1 * arr007_a * arr017_b + 1 * arr010_a * arr016_b + 1 * arr011_a * arr015_b + 1 * arr012_a * arr014_b + 1 * arr013_a * arr013_b + 1 * arr014_a * arr012_b + 1 * arr015_a * arr011_b + 1 * arr016_a * arr010_b + 1 * arr017_a * arr007_b,
        arr000_a * arr007_b + arr001_a * arr006_b + arr002_a * arr005_b + arr003_a * arr004_b + arr004_a * arr003_b + arr005_a * arr002_b + arr006_a * arr001_b + arr007_a * arr000_b + 1 * arr010_a * arr017_b + 1 * arr011_a * arr016_b + 1 * arr012_a * arr015_b + 1 * arr013_a * arr014_b + 1 * arr014_a * arr013_b + 1 * arr015_a * arr012_b + 1 * arr016_a * arr011_b + 1 * arr017_a * arr010_b,
        arr000_a * arr010_b + arr001_a * arr007_b + arr002_a * arr006_b + arr003_a * arr005_b + arr004_a * arr004_b + arr005_a * arr003_b + arr006_a * arr002_b + arr007_a * arr001_b + arr010_a * arr000_b + 1 * arr011_a * arr017_b + 1 * arr012_a * arr016_b + 1 * arr013_a * arr015_b + 1 * arr014_a * arr014_b + 1 * arr015_a * arr013_b + 1 * arr016_a * arr012_b + 1 * arr017_a * arr011_b,
        arr000_a * arr011_b + arr001_a * arr010_b + arr002_a * arr007_b + arr003_a * arr006_b + arr004_a * arr005_b + arr005_a * arr004_b + arr006_a * arr003_b + arr007_a * arr002_b + arr010_a * arr001_b + arr011_a * arr000_b + 1 * arr012_a * arr017_b + 1 * arr013_a * arr016_b + 1 * arr014_a * arr015_b + 1 * arr015_a * arr014_b + 1 * arr016_a * arr013_b + 1 * arr017_a * arr012_b,
        arr000_a * arr012_b + arr001_a * arr011_b + arr002_a * arr010_b + arr003_a * arr007_b + arr004_a * arr006_b + arr005_a * arr005_b + arr006_a * arr004_b + arr007_a * arr003_b + arr010_a * arr002_b + arr011_a * arr001_b + arr012_a * arr000_b + 1 * arr013_a * arr017_b + 1 * arr014_a * arr016_b + 1 * arr015_a * arr015_b + 1 * arr016_a * arr014_b + 1 * arr017_a * arr013_b,
        arr000_a * arr013_b + arr001_a * arr012_b + arr002_a * arr011_b + arr003_a * arr010_b + arr004_a * arr007_b + arr005_a * arr006_b + arr006_a * arr005_b + arr007_a * arr004_b + arr010_a * arr003_b + arr011_a * arr002_b + arr012_a * arr001_b + arr013_a * arr000_b + 1 * arr014_a * arr017_b + 1 * arr015_a * arr016_b + 1 * arr016_a * arr015_b + 1 * arr017_a * arr014_b,
        arr000_a * arr014_b + arr001_a * arr013_b + arr002_a * arr012_b + arr003_a * arr011_b + arr004_a * arr010_b + arr005_a * arr007_b + arr006_a * arr006_b + arr007_a * arr005_b + arr010_a * arr004_b + arr011_a * arr003_b + arr012_a * arr002_b + arr013_a * arr001_b + arr014_a * arr000_b + 1 * arr015_a * arr017_b + 1 * arr016_a * arr016_b + 1 * arr017_a * arr015_b,
        arr000_a * arr015_b + arr001_a * arr014_b + arr002_a * arr013_b + arr003_a * arr012_b + arr004_a * arr011_b + arr005_a * arr010_b + arr006_a * arr007_b + arr007_a * arr006_b + arr010_a * arr005_b + arr011_a * arr004_b + arr012_a * arr003_b + arr013_a * arr002_b + arr014_a * arr001_b + arr015_a * arr000_b + 1 * arr016_a * arr017_b + 1 * arr017_a * arr016_b,
        arr000_a * arr016_b + arr001_a * arr015_b + arr002_a * arr014_b + arr003_a * arr013_b + arr004_a * arr012_b + arr005_a * arr011_b + arr006_a * arr010_b + arr007_a * arr007_b + arr010_a * arr006_b + arr011_a * arr005_b + arr012_a * arr004_b + arr013_a * arr003_b + arr014_a * arr002_b + arr015_a * arr001_b + arr016_a * arr000_b + 1 * arr017_a * arr017_b,
        arr000_a * arr017_b + arr001_a * arr016_b + arr002_a * arr015_b + arr003_a * arr014_b + arr004_a * arr013_b + arr005_a * arr012_b + arr006_a * arr011_b + arr007_a * arr010_b + arr010_a * arr007_b + arr011_a * arr006_b + arr012_a * arr005_b + arr013_a * arr004_b + arr014_a * arr003_b + arr015_a * arr002_b + arr016_a * arr001_b + arr017_a * arr000_b
    ] ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] )

    prove with [cuts[0, 1, 2, 3]]
  &&
    [L0x7fffffe1b0, L0x7fffffe1b2, L0x7fffffe1b4, L0x7fffffe1b6, L0x7fffffe1b8, L0x7fffffe1ba, L0x7fffffe1bc, L0x7fffffe1be] = %v1 /\
    [L0x7fffffe1c0, L0x7fffffe1c2, L0x7fffffe1c4, L0x7fffffe1c6, L0x7fffffe1c8, L0x7fffffe1ca, L0x7fffffe1cc, L0x7fffffe1ce] = %v0 /\

    %v1 <=s [3700@16, 3700@16, 3700@16, 3700@16, 3700@16, 3700@16, 3700@16, 3700@16] /\
    %v1 >=s [(-3700)@16, (-3700)@16, (-3700)@16, (-3700)@16, (-3700)@16, (-3700)@16, (-3700)@16, (-3700)@16] /\

    %v0 <=s [3700@16, 3700@16, 3700@16, 3700@16, 3700@16, 3700@16, 3700@16, 3700@16] /\
    %v0 >=s [(-3700)@16, (-3700)@16, (-3700)@16, (-3700)@16, (-3700)@16, (-3700)@16, (-3700)@16, (-3700)@16];


### i_iter prologue

(* ldr	q4, [x0, x3]                                #! EA = L0x7fffffe450; Value = 0x0000000000000000; PC = 0x5555551d34 *)
mov %v4 [L0x7fffffe450,L0x7fffffe452,L0x7fffffe454,L0x7fffffe456,L0x7fffffe458,L0x7fffffe45a,L0x7fffffe45c,L0x7fffffe45e];
(* ldr	q1, [x8, x3]                                #! EA = L0x7fffffe460; Value = 0x0000000000000000; PC = 0x5555551d38 *)
mov %v1 [L0x7fffffe460,L0x7fffffe462,L0x7fffffe464,L0x7fffffe466,L0x7fffffe468,L0x7fffffe46a,L0x7fffffe46c,L0x7fffffe46e];
(* ldr	q17, [x1, x3]                               #! EA = L0x7fffffe310; Value = 0x0000000000000000; PC = 0x5555551d3c *)
mov %v17 [L0x7fffffe310,L0x7fffffe312,L0x7fffffe314,L0x7fffffe316,L0x7fffffe318,L0x7fffffe31a,L0x7fffffe31c,L0x7fffffe31e];
(* ldr	q18, [x7, x3]                               #! EA = L0x7fffffe320; Value = 0x0000000000000000; PC = 0x5555551d40 *)
mov %v18 [L0x7fffffe320,L0x7fffffe322,L0x7fffffe324,L0x7fffffe326,L0x7fffffe328,L0x7fffffe32a,L0x7fffffe32c,L0x7fffffe32e];

ghost %fa0_1@sint16[8], %fa1_1@sint16[8], %fb0_1@sint16[8], %fb1_1@sint16[8] :
    %fa0_1 = %v4 /\ %fa1_1 = %v1 /\ %fb0_1 = %v17 /\ %fb1_1 = %v18
  &&
    %fa0_1 = %v4 /\ %fa1_1 = %v1 /\ %fb0_1 = %v17 /\ %fb1_1 = %v18;

cut (* 5 *)
    %fa0_1 = %v4 /\ %fa1_1 = %v1 /\ %fb0_1 = %v17 /\ %fb1_1 = %v18 /\
    %fa0_1 = [arr100_a, arr101_a, arr102_a, arr103_a, arr104_a, arr105_a, arr106_a, arr107_a] /\
    %fa1_1 = [arr110_a, arr111_a, arr112_a, arr113_a, arr114_a, arr115_a, arr116_a, arr117_a] /\
    %fb0_1 = [arr100_b, arr101_b, arr102_b, arr103_b, arr104_b, arr105_b, arr106_b, arr107_b] /\
    %fb1_1 = [arr110_b, arr111_b, arr112_b, arr113_b, arr114_b, arr115_b, arr116_b, arr117_b]
    prove with [cuts[0]]
  &&
    %fa0_1 = %v4 /\ %fa1_1 = %v1 /\ %fb0_1 = %v17 /\ %fb1_1 = %v18 /\
    %fa0_1 = [arr100_a, arr101_a, arr102_a, arr103_a, arr104_a, arr105_a, arr106_a, arr107_a] /\
    %fa1_1 = [arr110_a, arr111_a, arr112_a, arr113_a, arr114_a, arr115_a, arr116_a, arr117_a] /\
    %fb0_1 = [arr100_b, arr101_b, arr102_b, arr103_b, arr104_b, arr105_b, arr106_b, arr107_b] /\
    %fb1_1 = [arr110_b, arr111_b, arr112_b, arr113_b, arr114_b, arr115_b, arr116_b, arr117_b]
    prove with [cuts[0]];

#### karatsuba

(* ldr	q5, [x5]                                    #! EA = L0x5555552e10; Value = 0x20c20497d31df9b6; PC = 0x5555551b44 *)
mov %v5 [L0x5555552e10,L0x5555552e12,L0x5555552e14,L0x5555552e16,L0x5555552e18,L0x5555552e1a,L0x5555552e1c,L0x5555552e1e];
(* sshr	v0.8h, v4.8h, #12                          #! PC = 0x5555551b48 *)
split %v0 %dc %v4 12;
(* cmlt	v2.8h, v4.8h, #0                           #! PC = 0x5555551b4c *)
split %v2 %dc %v4 15;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551b50 *)
sub %v0 %v0 %v2;
(* mls	v4.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551b54 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v4 %v4 %mls;

assert
    %fa0_1 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v4
    prove with [algebra solver isl, precondition, cuts[0, 5]]
    && true;

assume
    %fa0_1 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v4
    && true;

(* sshr	v0.8h, v1.8h, #12                          #! PC = 0x5555551b58 *)
split %v0 %dc %v1 12;
(* cmlt	v2.8h, v1.8h, #0                           #! PC = 0x5555551b5c *)
split %v2 %dc %v1 15;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551b60 *)
sub %v0 %v0 %v2;
(* mls	v1.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551b64 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v1 %v1 %mls;

assert
    %fa1_1 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v1
    prove with [algebra solver isl, precondition, cuts[0, 5]]
    && true;

assume
    %fa1_1 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v1
    && true;

(* sshr	v0.8h, v17.8h, #12                         #! PC = 0x5555551b68 *)
split %v0 %dc %v17 12;
(* cmlt	v2.8h, v17.8h, #0                          #! PC = 0x5555551b6c *)
split %v2 %dc %v17 15;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551b70 *)
sub %v0 %v0 %v2;
(* mls	v17.8h, v0.8h, v5.h[6]                      #! PC = 0x5555551b74 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v17 %v17 %mls;

assert
    %fb0_1 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v17
    prove with [algebra solver isl, precondition, cuts[0, 5]]
    && true;

assume
    %fb0_1 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v17
    && true;

(* sshr	v0.8h, v18.8h, #12                         #! PC = 0x5555551b78 *)
split %v0 %dc %v18 12;
(* cmlt	v2.8h, v18.8h, #0                          #! PC = 0x5555551b7c *)
split %v2 %dc %v18 15;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551b80 *)
sub %v0 %v0 %v2;
(* mls	v18.8h, v0.8h, v5.h[6]                      #! PC = 0x5555551b84 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v18 %v18 %mls;

assert
    %fb1_1 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v18
    prove with [algebra solver isl, precondition, cuts[0, 5]]
    && true;

assume
    %fb1_1 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v18
    && true;

ghost %fc0_1@sint16[8], %fc1_1@sint16[8], %fd0_1@sint16[8], %fd1_1@sint16[8] :
    %fc0_1 = %v4 /\ %fc1_1 = %v1 /\ %fd0_1 = %v17 /\ %fd1_1 = %v18
  &&
    %fc0_1 = %v4 /\ %fc1_1 = %v1 /\ %fd0_1 = %v17 /\ %fd1_1 = %v18;

(* sqrdmulh	v0.8h, v17.8h, v5.h[1]                 #! PC = 0x5555551b88 *)
broadcast %mul 8 [%v5[1]]; smulj %LO %v17 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v0 %LO11 %LO01;
(* mul	v6.8h, v17.8h, v5.h[0]                      #! PC = 0x5555551b8c *)
broadcast %mul 8 [%v5[0]]; mull %dc %v6 %v17 %mul; cast %v6@int16[8] %v6;
(* mov	v7.16b, v6.16b                              #! PC = 0x5555551b90 *)
mov %v7 %v6;
(* mls	v7.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551b94 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v7 %v7 %mls;

assert
    [-1610, -1610, -1610, -1610, -1610, -1610, -1610, -1610] * %fd0_1
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v7
    prove with [algebra solver isl, precondition, cuts[0, 5]]
    && true;

assume
    [-1610, -1610, -1610, -1610, -1610, -1610, -1610, -1610] * %fd0_1
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v7
    && true;

(* sqrdmulh	v0.8h, v18.8h, v5.h[1]                 #! PC = 0x5555551b98 *)
broadcast %mul 8 [%v5[1]]; smulj %LO %v18 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v0 %LO11 %LO01;
(* mul	v3.8h, v18.8h, v5.h[0]                      #! PC = 0x5555551b9c *)
broadcast %mul 8 [%v5[0]]; mull %dc %v3 %v18 %mul; cast %v3@int16[8] %v3;
(* mls	v3.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551ba0 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v3 %v3 %mls;

assert
    [-1610, -1610, -1610, -1610, -1610, -1610, -1610, -1610] * %fd1_1
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v3
    prove with [algebra solver isl, precondition, cuts[0, 5]]
    && true;

assume
    [-1610, -1610, -1610, -1610, -1610, -1610, -1610, -1610] * %fd1_1
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v3
    && true;

ghost %fe0_1@sint16[8], %fe1_1@sint16[8] :
    %fe0_1 = %v7 /\ %fe1_1 = %v3
  &&
    %fe0_1 = %v7 /\ %fe1_1 = %v3;

cut (* 6 *)
    %fc0_1 = %v4 /\ %fc1_1 = %v1 /\ %fd0_1 = %v17 /\ %fd1_1 = %v18 /\ %fe0_1 = %v7 /\ %fe1_1 = %v3 /\

    %fc0_1 = %fa0_1 ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\
    %fc1_1 = %fa1_1 ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\
    %fd0_1 = %fb0_1 ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\
    %fd1_1 = %fb1_1 ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\

    %fe0_1 = [-1610, -1610, -1610, -1610, -1610, -1610, -1610, -1610] * %fd0_1
    ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\

    %fe1_1 = [-1610, -1610, -1610, -1610, -1610, -1610, -1610, -1610] * %fd1_1
    ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ),

    %fc0_1 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %fc0_1 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %fc1_1 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %fc1_1 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %fd0_1 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %fd0_1 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %fd1_1 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %fd1_1 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %fe0_1 <= [3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000] /\
    %fe0_1 >= [-3000, -3000, -3000, -3000, -3000, -3000, -3000, -3000] /\

    %fe1_1 <= [3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000] /\
    %fe1_1 >= [-3000, -3000, -3000, -3000, -3000, -3000, -3000, -3000]

    prove with [algebra solver isl, precondition, cuts[0, 5]]
  &&
    true
    prove with [precondition, cuts[0, 5]];

assert
    %v4 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %v4 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %v1 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %v1 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %v17 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %v17 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %v18 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %v18 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %v7 <= [3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000] /\
    %v7 >= [-3000, -3000, -3000, -3000, -3000, -3000, -3000, -3000] /\

    %v3 <= [3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000] /\
    %v3 >= [-3000, -3000, -3000, -3000, -3000, -3000, -3000, -3000]

    prove with [algebra solver isl, cuts[6]]
    && true;

assume
    true &&
    %v4 <=s [4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16] /\
    %v4 >=s [(-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16] /\

    %v1 <=s [4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16] /\
    %v1 >=s [(-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16] /\

    %v17 <=s [4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16] /\
    %v17 >=s [(-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16] /\

    %v18 <=s [4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16] /\
    %v18 >=s [(-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16] /\

    %v7 <=s [3000@16, 3000@16, 3000@16, 3000@16, 3000@16, 3000@16, 3000@16, 3000@16] /\
    %v7 >=s [(-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16] /\

    %v3 <=s [3000@16, 3000@16, 3000@16, 3000@16, 3000@16, 3000@16, 3000@16, 3000@16] /\
    %v3 >=s [(-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16];

(* add	v6.8h, v4.8h, v1.8h                         #! PC = 0x5555551ba4 *)
add %v6 %v4 %v1;
(* smull	v0.4s, v17.4h, v6.h[0]                    #! PC = 0x5555551ba8 *)
broadcast %mull 4 [%v6[0]]; smulj %v0 [%v17[0],%v17[1],%v17[2],%v17[3]] %mull;
(* smull2	v2.4s, v17.8h, v6.h[0]                   #! PC = 0x5555551bac *)
broadcast %mull 4 [%v6[0]]; smulj %v2 [%v17[4],%v17[5],%v17[6],%v17[7]] %mull;
(* ext	v16.16b, v3.16b, v17.16b, #14               #! PC = 0x5555551bb0 *)
mov %v16 [%v3[7],%v17[0],%v17[1],%v17[2],%v17[3],%v17[4],%v17[5],%v17[6]];
(* smlal	v0.4s, v16.4h, v6.h[1]                    #! PC = 0x5555551bb4 *)
broadcast %mull 4 [%v6[1]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[1]                   #! PC = 0x5555551bb8 *)
broadcast %mull 4 [%v6[1]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v16.16b, v3.16b, v17.16b, #12               #! PC = 0x5555551bbc *)
mov %v16 [%v3[6],%v3[7],%v17[0],%v17[1],%v17[2],%v17[3],%v17[4],%v17[5]];
(* smlal	v0.4s, v16.4h, v6.h[2]                    #! PC = 0x5555551bc0 *)
broadcast %mull 4 [%v6[2]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[2]                   #! PC = 0x5555551bc4 *)
broadcast %mull 4 [%v6[2]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v16.16b, v3.16b, v17.16b, #10               #! PC = 0x5555551bc8 *)
mov %v16 [%v3[5],%v3[6],%v3[7],%v17[0],%v17[1],%v17[2],%v17[3],%v17[4]];
(* smlal	v0.4s, v16.4h, v6.h[3]                    #! PC = 0x5555551bcc *)
broadcast %mull 4 [%v6[3]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[3]                   #! PC = 0x5555551bd0 *)
broadcast %mull 4 [%v6[3]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v16.16b, v3.16b, v17.16b, #8                #! PC = 0x5555551bd4 *)
mov %v16 [%v3[4],%v3[5],%v3[6],%v3[7],%v17[0],%v17[1],%v17[2],%v17[3]];
(* smlal	v0.4s, v16.4h, v6.h[4]                    #! PC = 0x5555551bd8 *)
broadcast %mull 4 [%v6[4]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[4]                   #! PC = 0x5555551bdc *)
broadcast %mull 4 [%v6[4]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v16.16b, v3.16b, v17.16b, #6                #! PC = 0x5555551be0 *)
mov %v16 [%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v17[0],%v17[1],%v17[2]];
(* smlal	v0.4s, v16.4h, v6.h[5]                    #! PC = 0x5555551be4 *)
broadcast %mull 4 [%v6[5]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[5]                   #! PC = 0x5555551be8 *)
broadcast %mull 4 [%v6[5]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v16.16b, v3.16b, v17.16b, #4                #! PC = 0x5555551bec *)
mov %v16 [%v3[2],%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v17[0],%v17[1]];
(* smlal	v0.4s, v16.4h, v6.h[6]                    #! PC = 0x5555551bf0 *)
broadcast %mull 4 [%v6[6]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[6]                   #! PC = 0x5555551bf4 *)
broadcast %mull 4 [%v6[6]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v16.16b, v3.16b, v17.16b, #2                #! PC = 0x5555551bf8 *)
mov %v16 [%v3[1],%v3[2],%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v17[0]];
(* smlal	v0.4s, v16.4h, v6.h[7]                    #! PC = 0x5555551bfc *)
broadcast %mull 4 [%v6[7]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[7]                   #! PC = 0x5555551c00 *)
broadcast %mull 4 [%v6[7]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* sub	v6.8h, v7.8h, v3.8h                         #! PC = 0x5555551c04 *)
sub %v6 %v7 %v3;
(* sub	v3.8h, v3.8h, v17.8h                        #! PC = 0x5555551c08 *)
sub %v3 %v3 %v17;
(* mov	v16.16b, v0.16b                             #! PC = 0x5555551c0c *)
mov %v16 %v0;
(* smlal	v16.4s, v3.4h, v1.h[0]                    #! PC = 0x5555551c10 *)
broadcast %mull 4 [%v1[0]]; smulj %mlal [%v3[0],%v3[1],%v3[2],%v3[3]] %mull; adds %dc %v16 %v16 %mlal;
(* mov	v7.16b, v2.16b                              #! PC = 0x5555551c14 *)
mov %v7 %v2;
(* smlal2	v7.4s, v3.8h, v1.h[0]                    #! PC = 0x5555551c18 *)
broadcast %mull 4 [%v1[0]]; smulj %mlal [%v3[4],%v3[5],%v3[6],%v3[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v19.16b, v6.16b, v3.16b, #14                #! PC = 0x5555551c1c *)
mov %v19 [%v6[7],%v3[0],%v3[1],%v3[2],%v3[3],%v3[4],%v3[5],%v3[6]];
(* smlal	v16.4s, v19.4h, v1.h[1]                   #! PC = 0x5555551c20 *)
broadcast %mull 4 [%v1[1]]; smulj %mlal [%v19[0],%v19[1],%v19[2],%v19[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v19.8h, v1.h[1]                   #! PC = 0x5555551c24 *)
broadcast %mull 4 [%v1[1]]; smulj %mlal [%v19[4],%v19[5],%v19[6],%v19[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v19.16b, v6.16b, v3.16b, #12                #! PC = 0x5555551c28 *)
mov %v19 [%v6[6],%v6[7],%v3[0],%v3[1],%v3[2],%v3[3],%v3[4],%v3[5]];
(* smlal	v16.4s, v19.4h, v1.h[2]                   #! PC = 0x5555551c2c *)
broadcast %mull 4 [%v1[2]]; smulj %mlal [%v19[0],%v19[1],%v19[2],%v19[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v19.8h, v1.h[2]                   #! PC = 0x5555551c30 *)
broadcast %mull 4 [%v1[2]]; smulj %mlal [%v19[4],%v19[5],%v19[6],%v19[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v19.16b, v6.16b, v3.16b, #10                #! PC = 0x5555551c34 *)
mov %v19 [%v6[5],%v6[6],%v6[7],%v3[0],%v3[1],%v3[2],%v3[3],%v3[4]];
(* smlal	v16.4s, v19.4h, v1.h[3]                   #! PC = 0x5555551c38 *)
broadcast %mull 4 [%v1[3]]; smulj %mlal [%v19[0],%v19[1],%v19[2],%v19[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v19.8h, v1.h[3]                   #! PC = 0x5555551c3c *)
broadcast %mull 4 [%v1[3]]; smulj %mlal [%v19[4],%v19[5],%v19[6],%v19[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v19.16b, v6.16b, v3.16b, #8                 #! PC = 0x5555551c40 *)
mov %v19 [%v6[4],%v6[5],%v6[6],%v6[7],%v3[0],%v3[1],%v3[2],%v3[3]];
(* smlal	v16.4s, v19.4h, v1.h[4]                   #! PC = 0x5555551c44 *)
broadcast %mull 4 [%v1[4]]; smulj %mlal [%v19[0],%v19[1],%v19[2],%v19[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v19.8h, v1.h[4]                   #! PC = 0x5555551c48 *)
broadcast %mull 4 [%v1[4]]; smulj %mlal [%v19[4],%v19[5],%v19[6],%v19[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v19.16b, v6.16b, v3.16b, #6                 #! PC = 0x5555551c4c *)
mov %v19 [%v6[3],%v6[4],%v6[5],%v6[6],%v6[7],%v3[0],%v3[1],%v3[2]];
(* smlal	v16.4s, v19.4h, v1.h[5]                   #! PC = 0x5555551c50 *)
broadcast %mull 4 [%v1[5]]; smulj %mlal [%v19[0],%v19[1],%v19[2],%v19[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v19.8h, v1.h[5]                   #! PC = 0x5555551c54 *)
broadcast %mull 4 [%v1[5]]; smulj %mlal [%v19[4],%v19[5],%v19[6],%v19[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v19.16b, v6.16b, v3.16b, #4                 #! PC = 0x5555551c58 *)
mov %v19 [%v6[2],%v6[3],%v6[4],%v6[5],%v6[6],%v6[7],%v3[0],%v3[1]];
(* smlal	v16.4s, v19.4h, v1.h[6]                   #! PC = 0x5555551c5c *)
broadcast %mull 4 [%v1[6]]; smulj %mlal [%v19[0],%v19[1],%v19[2],%v19[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v19.8h, v1.h[6]                   #! PC = 0x5555551c60 *)
broadcast %mull 4 [%v1[6]]; smulj %mlal [%v19[4],%v19[5],%v19[6],%v19[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v6.16b, v6.16b, v3.16b, #2                  #! PC = 0x5555551c64 *)
mov %v6 [%v6[1],%v6[2],%v6[3],%v6[4],%v6[5],%v6[6],%v6[7],%v3[0]];
(* smlal	v16.4s, v6.4h, v1.h[7]                    #! PC = 0x5555551c68 *)
broadcast %mull 4 [%v1[7]]; smulj %mlal [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v6.8h, v1.h[7]                    #! PC = 0x5555551c6c *)
broadcast %mull 4 [%v1[7]]; smulj %mlal [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; adds %dc %v7 %v7 %mlal;
(* sub	v1.8h, v17.8h, v18.8h                       #! PC = 0x5555551c70 *)
sub %v1 %v17 %v18;
(* smlsl	v0.4s, v1.4h, v4.h[0]                     #! PC = 0x5555551c74 *)
broadcast %mull 4 [%v4[0]]; smulj %mlsl [%v1[0],%v1[1],%v1[2],%v1[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v1.8h, v4.h[0]                    #! PC = 0x5555551c78 *)
broadcast %mull 4 [%v4[0]]; smulj %mlsl [%v1[4],%v1[5],%v1[6],%v1[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v6.16b, v3.16b, v1.16b, #14                 #! PC = 0x5555551c7c *)
mov %v6 [%v3[7],%v1[0],%v1[1],%v1[2],%v1[3],%v1[4],%v1[5],%v1[6]];
(* smlsl	v0.4s, v6.4h, v4.h[1]                     #! PC = 0x5555551c80 *)
broadcast %mull 4 [%v4[1]]; smulj %mlsl [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v6.8h, v4.h[1]                    #! PC = 0x5555551c84 *)
broadcast %mull 4 [%v4[1]]; smulj %mlsl [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v6.16b, v3.16b, v1.16b, #12                 #! PC = 0x5555551c88 *)
mov %v6 [%v3[6],%v3[7],%v1[0],%v1[1],%v1[2],%v1[3],%v1[4],%v1[5]];
(* smlsl	v0.4s, v6.4h, v4.h[2]                     #! PC = 0x5555551c8c *)
broadcast %mull 4 [%v4[2]]; smulj %mlsl [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v6.8h, v4.h[2]                    #! PC = 0x5555551c90 *)
broadcast %mull 4 [%v4[2]]; smulj %mlsl [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v6.16b, v3.16b, v1.16b, #10                 #! PC = 0x5555551c94 *)
mov %v6 [%v3[5],%v3[6],%v3[7],%v1[0],%v1[1],%v1[2],%v1[3],%v1[4]];
(* smlsl	v0.4s, v6.4h, v4.h[3]                     #! PC = 0x5555551c98 *)
broadcast %mull 4 [%v4[3]]; smulj %mlsl [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v6.8h, v4.h[3]                    #! PC = 0x5555551c9c *)
broadcast %mull 4 [%v4[3]]; smulj %mlsl [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v6.16b, v3.16b, v1.16b, #8                  #! PC = 0x5555551ca0 *)
mov %v6 [%v3[4],%v3[5],%v3[6],%v3[7],%v1[0],%v1[1],%v1[2],%v1[3]];
(* smlsl	v0.4s, v6.4h, v4.h[4]                     #! PC = 0x5555551ca4 *)
broadcast %mull 4 [%v4[4]]; smulj %mlsl [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v6.8h, v4.h[4]                    #! PC = 0x5555551ca8 *)
broadcast %mull 4 [%v4[4]]; smulj %mlsl [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v6.16b, v3.16b, v1.16b, #6                  #! PC = 0x5555551cac *)
mov %v6 [%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v1[0],%v1[1],%v1[2]];
(* smlsl	v0.4s, v6.4h, v4.h[5]                     #! PC = 0x5555551cb0 *)
broadcast %mull 4 [%v4[5]]; smulj %mlsl [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v6.8h, v4.h[5]                    #! PC = 0x5555551cb4 *)
broadcast %mull 4 [%v4[5]]; smulj %mlsl [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v6.16b, v3.16b, v1.16b, #4                  #! PC = 0x5555551cb8 *)
mov %v6 [%v3[2],%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v1[0],%v1[1]];
(* smlsl	v0.4s, v6.4h, v4.h[6]                     #! PC = 0x5555551cbc *)
broadcast %mull 4 [%v4[6]]; smulj %mlsl [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v6.8h, v4.h[6]                    #! PC = 0x5555551cc0 *)
broadcast %mull 4 [%v4[6]]; smulj %mlsl [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v3.16b, v3.16b, v1.16b, #2                  #! PC = 0x5555551cc4 *)
mov %v3 [%v3[1],%v3[2],%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v1[0]];
(* smlsl	v0.4s, v3.4h, v4.h[7]                     #! PC = 0x5555551cc8 *)
broadcast %mull 4 [%v4[7]]; smulj %mlsl [%v3[0],%v3[1],%v3[2],%v3[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v3.8h, v4.h[7]                    #! PC = 0x5555551ccc *)
broadcast %mull 4 [%v4[7]]; smulj %mlsl [%v3[4],%v3[5],%v3[6],%v3[7]] %mull; subc %dc %v2 %v2 %mlsl;

ghost %conv0_1@sint32[8], %conv1_1@sint32[8] :
    %conv0_1 = [
        %fc0_1[0] * %fd0_1[0] + %fc0_1[1] * %fe1_1[7] + %fc0_1[2] * %fe1_1[6] + %fc0_1[3] * %fe1_1[5] + %fc0_1[4] * %fe1_1[4] + %fc0_1[5] * %fe1_1[3] + %fc0_1[6] * %fe1_1[2] + %fc0_1[7] * %fe1_1[1] +
        %fc1_1[0] * %fe1_1[0] + %fc1_1[1] * %fe0_1[7] + %fc1_1[2] * %fe0_1[6] + %fc1_1[3] * %fe0_1[5] + %fc1_1[4] * %fe0_1[4] + %fc1_1[5] * %fe0_1[3] + %fc1_1[6] * %fe0_1[2] + %fc1_1[7] * %fe0_1[1],
        %fc0_1[0] * %fd0_1[1] + %fc0_1[1] * %fd0_1[0] + %fc0_1[2] * %fe1_1[7] + %fc0_1[3] * %fe1_1[6] + %fc0_1[4] * %fe1_1[5] + %fc0_1[5] * %fe1_1[4] + %fc0_1[6] * %fe1_1[3] + %fc0_1[7] * %fe1_1[2] +
        %fc1_1[0] * %fe1_1[1] + %fc1_1[1] * %fe1_1[0] + %fc1_1[2] * %fe0_1[7] + %fc1_1[3] * %fe0_1[6] + %fc1_1[4] * %fe0_1[5] + %fc1_1[5] * %fe0_1[4] + %fc1_1[6] * %fe0_1[3] + %fc1_1[7] * %fe0_1[2],
        %fc0_1[0] * %fd0_1[2] + %fc0_1[1] * %fd0_1[1] + %fc0_1[2] * %fd0_1[0] + %fc0_1[3] * %fe1_1[7] + %fc0_1[4] * %fe1_1[6] + %fc0_1[5] * %fe1_1[5] + %fc0_1[6] * %fe1_1[4] + %fc0_1[7] * %fe1_1[3] +
        %fc1_1[0] * %fe1_1[2] + %fc1_1[1] * %fe1_1[1] + %fc1_1[2] * %fe1_1[0] + %fc1_1[3] * %fe0_1[7] + %fc1_1[4] * %fe0_1[6] + %fc1_1[5] * %fe0_1[5] + %fc1_1[6] * %fe0_1[4] + %fc1_1[7] * %fe0_1[3],
        %fc0_1[0] * %fd0_1[3] + %fc0_1[1] * %fd0_1[2] + %fc0_1[2] * %fd0_1[1] + %fc0_1[3] * %fd0_1[0] + %fc0_1[4] * %fe1_1[7] + %fc0_1[5] * %fe1_1[6] + %fc0_1[6] * %fe1_1[5] + %fc0_1[7] * %fe1_1[4] +
        %fc1_1[0] * %fe1_1[3] + %fc1_1[1] * %fe1_1[2] + %fc1_1[2] * %fe1_1[1] + %fc1_1[3] * %fe1_1[0] + %fc1_1[4] * %fe0_1[7] + %fc1_1[5] * %fe0_1[6] + %fc1_1[6] * %fe0_1[5] + %fc1_1[7] * %fe0_1[4],
        %fc0_1[0] * %fd0_1[4] + %fc0_1[1] * %fd0_1[3] + %fc0_1[2] * %fd0_1[2] + %fc0_1[3] * %fd0_1[1] + %fc0_1[4] * %fd0_1[0] + %fc0_1[5] * %fe1_1[7] + %fc0_1[6] * %fe1_1[6] + %fc0_1[7] * %fe1_1[5] +
        %fc1_1[0] * %fe1_1[4] + %fc1_1[1] * %fe1_1[3] + %fc1_1[2] * %fe1_1[2] + %fc1_1[3] * %fe1_1[1] + %fc1_1[4] * %fe1_1[0] + %fc1_1[5] * %fe0_1[7] + %fc1_1[6] * %fe0_1[6] + %fc1_1[7] * %fe0_1[5],
        %fc0_1[0] * %fd0_1[5] + %fc0_1[1] * %fd0_1[4] + %fc0_1[2] * %fd0_1[3] + %fc0_1[3] * %fd0_1[2] + %fc0_1[4] * %fd0_1[1] + %fc0_1[5] * %fd0_1[0] + %fc0_1[6] * %fe1_1[7] + %fc0_1[7] * %fe1_1[6] +
        %fc1_1[0] * %fe1_1[5] + %fc1_1[1] * %fe1_1[4] + %fc1_1[2] * %fe1_1[3] + %fc1_1[3] * %fe1_1[2] + %fc1_1[4] * %fe1_1[1] + %fc1_1[5] * %fe1_1[0] + %fc1_1[6] * %fe0_1[7] + %fc1_1[7] * %fe0_1[6],
        %fc0_1[0] * %fd0_1[6] + %fc0_1[1] * %fd0_1[5] + %fc0_1[2] * %fd0_1[4] + %fc0_1[3] * %fd0_1[3] + %fc0_1[4] * %fd0_1[2] + %fc0_1[5] * %fd0_1[1] + %fc0_1[6] * %fd0_1[0] + %fc0_1[7] * %fe1_1[7] +
        %fc1_1[0] * %fe1_1[6] + %fc1_1[1] * %fe1_1[5] + %fc1_1[2] * %fe1_1[4] + %fc1_1[3] * %fe1_1[3] + %fc1_1[4] * %fe1_1[2] + %fc1_1[5] * %fe1_1[1] + %fc1_1[6] * %fe1_1[0] + %fc1_1[7] * %fe0_1[7],
        %fc0_1[0] * %fd0_1[7] + %fc0_1[1] * %fd0_1[6] + %fc0_1[2] * %fd0_1[5] + %fc0_1[3] * %fd0_1[4] + %fc0_1[4] * %fd0_1[3] + %fc0_1[5] * %fd0_1[2] + %fc0_1[6] * %fd0_1[1] + %fc0_1[7] * %fd0_1[0] +
        %fc1_1[0] * %fe1_1[7] + %fc1_1[1] * %fe1_1[6] + %fc1_1[2] * %fe1_1[5] + %fc1_1[3] * %fe1_1[4] + %fc1_1[4] * %fe1_1[3] + %fc1_1[5] * %fe1_1[2] + %fc1_1[6] * %fe1_1[1] + %fc1_1[7] * %fe1_1[0]
    ] /\
    %conv1_1 = [
        %fc0_1[0] * %fd1_1[0] + %fc0_1[1] * %fd0_1[7] + %fc0_1[2] * %fd0_1[6] + %fc0_1[3] * %fd0_1[5] + %fc0_1[4] * %fd0_1[4] + %fc0_1[5] * %fd0_1[3] + %fc0_1[6] * %fd0_1[2] + %fc0_1[7] * %fd0_1[1] +
        %fc1_1[0] * %fd0_1[0] + %fc1_1[1] * %fe1_1[7] + %fc1_1[2] * %fe1_1[6] + %fc1_1[3] * %fe1_1[5] + %fc1_1[4] * %fe1_1[4] + %fc1_1[5] * %fe1_1[3] + %fc1_1[6] * %fe1_1[2] + %fc1_1[7] * %fe1_1[1],
        %fc0_1[0] * %fd1_1[1] + %fc0_1[1] * %fd1_1[0] + %fc0_1[2] * %fd0_1[7] + %fc0_1[3] * %fd0_1[6] + %fc0_1[4] * %fd0_1[5] + %fc0_1[5] * %fd0_1[4] + %fc0_1[6] * %fd0_1[3] + %fc0_1[7] * %fd0_1[2] +
        %fc1_1[0] * %fd0_1[1] + %fc1_1[1] * %fd0_1[0] + %fc1_1[2] * %fe1_1[7] + %fc1_1[3] * %fe1_1[6] + %fc1_1[4] * %fe1_1[5] + %fc1_1[5] * %fe1_1[4] + %fc1_1[6] * %fe1_1[3] + %fc1_1[7] * %fe1_1[2],
        %fc0_1[0] * %fd1_1[2] + %fc0_1[1] * %fd1_1[1] + %fc0_1[2] * %fd1_1[0] + %fc0_1[3] * %fd0_1[7] + %fc0_1[4] * %fd0_1[6] + %fc0_1[5] * %fd0_1[5] + %fc0_1[6] * %fd0_1[4] + %fc0_1[7] * %fd0_1[3] +
        %fc1_1[0] * %fd0_1[2] + %fc1_1[1] * %fd0_1[1] + %fc1_1[2] * %fd0_1[0] + %fc1_1[3] * %fe1_1[7] + %fc1_1[4] * %fe1_1[6] + %fc1_1[5] * %fe1_1[5] + %fc1_1[6] * %fe1_1[4] + %fc1_1[7] * %fe1_1[3],
        %fc0_1[0] * %fd1_1[3] + %fc0_1[1] * %fd1_1[2] + %fc0_1[2] * %fd1_1[1] + %fc0_1[3] * %fd1_1[0] + %fc0_1[4] * %fd0_1[7] + %fc0_1[5] * %fd0_1[6] + %fc0_1[6] * %fd0_1[5] + %fc0_1[7] * %fd0_1[4] +
        %fc1_1[0] * %fd0_1[3] + %fc1_1[1] * %fd0_1[2] + %fc1_1[2] * %fd0_1[1] + %fc1_1[3] * %fd0_1[0] + %fc1_1[4] * %fe1_1[7] + %fc1_1[5] * %fe1_1[6] + %fc1_1[6] * %fe1_1[5] + %fc1_1[7] * %fe1_1[4],
        %fc0_1[0] * %fd1_1[4] + %fc0_1[1] * %fd1_1[3] + %fc0_1[2] * %fd1_1[2] + %fc0_1[3] * %fd1_1[1] + %fc0_1[4] * %fd1_1[0] + %fc0_1[5] * %fd0_1[7] + %fc0_1[6] * %fd0_1[6] + %fc0_1[7] * %fd0_1[5] +
        %fc1_1[0] * %fd0_1[4] + %fc1_1[1] * %fd0_1[3] + %fc1_1[2] * %fd0_1[2] + %fc1_1[3] * %fd0_1[1] + %fc1_1[4] * %fd0_1[0] + %fc1_1[5] * %fe1_1[7] + %fc1_1[6] * %fe1_1[6] + %fc1_1[7] * %fe1_1[5],
        %fc0_1[0] * %fd1_1[5] + %fc0_1[1] * %fd1_1[4] + %fc0_1[2] * %fd1_1[3] + %fc0_1[3] * %fd1_1[2] + %fc0_1[4] * %fd1_1[1] + %fc0_1[5] * %fd1_1[0] + %fc0_1[6] * %fd0_1[7] + %fc0_1[7] * %fd0_1[6] +
        %fc1_1[0] * %fd0_1[5] + %fc1_1[1] * %fd0_1[4] + %fc1_1[2] * %fd0_1[3] + %fc1_1[3] * %fd0_1[2] + %fc1_1[4] * %fd0_1[1] + %fc1_1[5] * %fd0_1[0] + %fc1_1[6] * %fe1_1[7] + %fc1_1[7] * %fe1_1[6],
        %fc0_1[0] * %fd1_1[6] + %fc0_1[1] * %fd1_1[5] + %fc0_1[2] * %fd1_1[4] + %fc0_1[3] * %fd1_1[3] + %fc0_1[4] * %fd1_1[2] + %fc0_1[5] * %fd1_1[1] + %fc0_1[6] * %fd1_1[0] + %fc0_1[7] * %fd0_1[7] +
        %fc1_1[0] * %fd0_1[6] + %fc1_1[1] * %fd0_1[5] + %fc1_1[2] * %fd0_1[4] + %fc1_1[3] * %fd0_1[3] + %fc1_1[4] * %fd0_1[2] + %fc1_1[5] * %fd0_1[1] + %fc1_1[6] * %fd0_1[0] + %fc1_1[7] * %fe1_1[7],
        %fc0_1[0] * %fd1_1[7] + %fc0_1[1] * %fd1_1[6] + %fc0_1[2] * %fd1_1[5] + %fc0_1[3] * %fd1_1[4] + %fc0_1[4] * %fd1_1[3] + %fc0_1[5] * %fd1_1[2] + %fc0_1[6] * %fd1_1[1] + %fc0_1[7] * %fd1_1[0] +
        %fc1_1[0] * %fd0_1[7] + %fc1_1[1] * %fd0_1[6] + %fc1_1[2] * %fd0_1[5] + %fc1_1[3] * %fd0_1[4] + %fc1_1[4] * %fd0_1[3] + %fc1_1[5] * %fd0_1[2] + %fc1_1[6] * %fd0_1[1] + %fc1_1[7] * %fd0_1[0]
    ]
    && true;

assert
    %v16 ++ %v7 = %conv0_1 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] ) /\
    %v0 ++ %v2 = %conv1_1 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] )
    && true;

assume
    %v16 ++ %v7 = %conv0_1 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] ) /\
    %v0 ++ %v2 = %conv1_1 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] )
    && true;

assert
    %conv0_1 <= [268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456] /\
    %conv0_1 >= [-268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456] /\

    %conv1_1 <= [268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456] /\
    %conv1_1 >= [-268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456]
    prove with [algebra solver smt: z3]
    && true;

assume
    %conv0_1 <= [268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456] /\
    %conv0_1 >= [-268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456] /\

    %conv1_1 <= [268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456] /\
    %conv1_1 >= [-268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456]
    && true;

assert
    %v16 ++ %v7 = %conv0_1 /\ %v0 ++ %v2 = %conv1_1
    prove with [algebra solver isl]
    && true;

assume
    %v16 ++ %v7 = %conv0_1 /\ %v0 ++ %v2 = %conv1_1
    && true;

assert
    %v16 <= [268435456, 268435456, 268435456, 268435456] /\
    %v16 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v7 <= [268435456, 268435456, 268435456, 268435456] /\
    %v7 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v0 <= [268435456, 268435456, 268435456, 268435456] /\
    %v0 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v2 <= [268435456, 268435456, 268435456, 268435456] /\
    %v2 >= [-268435456, -268435456, -268435456, -268435456]

    prove with [algebra solver isl]
    && true;

assume
    %v16 <= [268435456, 268435456, 268435456, 268435456] /\
    %v16 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v7 <= [268435456, 268435456, 268435456, 268435456] /\
    %v7 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v0 <= [268435456, 268435456, 268435456, 268435456] /\
    %v0 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v2 <= [268435456, 268435456, 268435456, 268435456] /\
    %v2 >= [-268435456, -268435456, -268435456, -268435456]
  &&
    %v16 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v16 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32] /\

    %v7 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v7 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32] /\

    %v0 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v0 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32] /\

    %v2 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v2 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32];

cut (* 7 *)
    %conv0_1 = [
        %fc0_1[0] * %fd0_1[0] + %fc0_1[1] * %fe1_1[7] + %fc0_1[2] * %fe1_1[6] + %fc0_1[3] * %fe1_1[5] + %fc0_1[4] * %fe1_1[4] + %fc0_1[5] * %fe1_1[3] + %fc0_1[6] * %fe1_1[2] + %fc0_1[7] * %fe1_1[1] +
        %fc1_1[0] * %fe1_1[0] + %fc1_1[1] * %fe0_1[7] + %fc1_1[2] * %fe0_1[6] + %fc1_1[3] * %fe0_1[5] + %fc1_1[4] * %fe0_1[4] + %fc1_1[5] * %fe0_1[3] + %fc1_1[6] * %fe0_1[2] + %fc1_1[7] * %fe0_1[1],
        %fc0_1[0] * %fd0_1[1] + %fc0_1[1] * %fd0_1[0] + %fc0_1[2] * %fe1_1[7] + %fc0_1[3] * %fe1_1[6] + %fc0_1[4] * %fe1_1[5] + %fc0_1[5] * %fe1_1[4] + %fc0_1[6] * %fe1_1[3] + %fc0_1[7] * %fe1_1[2] +
        %fc1_1[0] * %fe1_1[1] + %fc1_1[1] * %fe1_1[0] + %fc1_1[2] * %fe0_1[7] + %fc1_1[3] * %fe0_1[6] + %fc1_1[4] * %fe0_1[5] + %fc1_1[5] * %fe0_1[4] + %fc1_1[6] * %fe0_1[3] + %fc1_1[7] * %fe0_1[2],
        %fc0_1[0] * %fd0_1[2] + %fc0_1[1] * %fd0_1[1] + %fc0_1[2] * %fd0_1[0] + %fc0_1[3] * %fe1_1[7] + %fc0_1[4] * %fe1_1[6] + %fc0_1[5] * %fe1_1[5] + %fc0_1[6] * %fe1_1[4] + %fc0_1[7] * %fe1_1[3] +
        %fc1_1[0] * %fe1_1[2] + %fc1_1[1] * %fe1_1[1] + %fc1_1[2] * %fe1_1[0] + %fc1_1[3] * %fe0_1[7] + %fc1_1[4] * %fe0_1[6] + %fc1_1[5] * %fe0_1[5] + %fc1_1[6] * %fe0_1[4] + %fc1_1[7] * %fe0_1[3],
        %fc0_1[0] * %fd0_1[3] + %fc0_1[1] * %fd0_1[2] + %fc0_1[2] * %fd0_1[1] + %fc0_1[3] * %fd0_1[0] + %fc0_1[4] * %fe1_1[7] + %fc0_1[5] * %fe1_1[6] + %fc0_1[6] * %fe1_1[5] + %fc0_1[7] * %fe1_1[4] +
        %fc1_1[0] * %fe1_1[3] + %fc1_1[1] * %fe1_1[2] + %fc1_1[2] * %fe1_1[1] + %fc1_1[3] * %fe1_1[0] + %fc1_1[4] * %fe0_1[7] + %fc1_1[5] * %fe0_1[6] + %fc1_1[6] * %fe0_1[5] + %fc1_1[7] * %fe0_1[4],
        %fc0_1[0] * %fd0_1[4] + %fc0_1[1] * %fd0_1[3] + %fc0_1[2] * %fd0_1[2] + %fc0_1[3] * %fd0_1[1] + %fc0_1[4] * %fd0_1[0] + %fc0_1[5] * %fe1_1[7] + %fc0_1[6] * %fe1_1[6] + %fc0_1[7] * %fe1_1[5] +
        %fc1_1[0] * %fe1_1[4] + %fc1_1[1] * %fe1_1[3] + %fc1_1[2] * %fe1_1[2] + %fc1_1[3] * %fe1_1[1] + %fc1_1[4] * %fe1_1[0] + %fc1_1[5] * %fe0_1[7] + %fc1_1[6] * %fe0_1[6] + %fc1_1[7] * %fe0_1[5],
        %fc0_1[0] * %fd0_1[5] + %fc0_1[1] * %fd0_1[4] + %fc0_1[2] * %fd0_1[3] + %fc0_1[3] * %fd0_1[2] + %fc0_1[4] * %fd0_1[1] + %fc0_1[5] * %fd0_1[0] + %fc0_1[6] * %fe1_1[7] + %fc0_1[7] * %fe1_1[6] +
        %fc1_1[0] * %fe1_1[5] + %fc1_1[1] * %fe1_1[4] + %fc1_1[2] * %fe1_1[3] + %fc1_1[3] * %fe1_1[2] + %fc1_1[4] * %fe1_1[1] + %fc1_1[5] * %fe1_1[0] + %fc1_1[6] * %fe0_1[7] + %fc1_1[7] * %fe0_1[6],
        %fc0_1[0] * %fd0_1[6] + %fc0_1[1] * %fd0_1[5] + %fc0_1[2] * %fd0_1[4] + %fc0_1[3] * %fd0_1[3] + %fc0_1[4] * %fd0_1[2] + %fc0_1[5] * %fd0_1[1] + %fc0_1[6] * %fd0_1[0] + %fc0_1[7] * %fe1_1[7] +
        %fc1_1[0] * %fe1_1[6] + %fc1_1[1] * %fe1_1[5] + %fc1_1[2] * %fe1_1[4] + %fc1_1[3] * %fe1_1[3] + %fc1_1[4] * %fe1_1[2] + %fc1_1[5] * %fe1_1[1] + %fc1_1[6] * %fe1_1[0] + %fc1_1[7] * %fe0_1[7],
        %fc0_1[0] * %fd0_1[7] + %fc0_1[1] * %fd0_1[6] + %fc0_1[2] * %fd0_1[5] + %fc0_1[3] * %fd0_1[4] + %fc0_1[4] * %fd0_1[3] + %fc0_1[5] * %fd0_1[2] + %fc0_1[6] * %fd0_1[1] + %fc0_1[7] * %fd0_1[0] +
        %fc1_1[0] * %fe1_1[7] + %fc1_1[1] * %fe1_1[6] + %fc1_1[2] * %fe1_1[5] + %fc1_1[3] * %fe1_1[4] + %fc1_1[4] * %fe1_1[3] + %fc1_1[5] * %fe1_1[2] + %fc1_1[6] * %fe1_1[1] + %fc1_1[7] * %fe1_1[0]
    ] /\
    %conv1_1 = [
        %fc0_1[0] * %fd1_1[0] + %fc0_1[1] * %fd0_1[7] + %fc0_1[2] * %fd0_1[6] + %fc0_1[3] * %fd0_1[5] + %fc0_1[4] * %fd0_1[4] + %fc0_1[5] * %fd0_1[3] + %fc0_1[6] * %fd0_1[2] + %fc0_1[7] * %fd0_1[1] +
        %fc1_1[0] * %fd0_1[0] + %fc1_1[1] * %fe1_1[7] + %fc1_1[2] * %fe1_1[6] + %fc1_1[3] * %fe1_1[5] + %fc1_1[4] * %fe1_1[4] + %fc1_1[5] * %fe1_1[3] + %fc1_1[6] * %fe1_1[2] + %fc1_1[7] * %fe1_1[1],
        %fc0_1[0] * %fd1_1[1] + %fc0_1[1] * %fd1_1[0] + %fc0_1[2] * %fd0_1[7] + %fc0_1[3] * %fd0_1[6] + %fc0_1[4] * %fd0_1[5] + %fc0_1[5] * %fd0_1[4] + %fc0_1[6] * %fd0_1[3] + %fc0_1[7] * %fd0_1[2] +
        %fc1_1[0] * %fd0_1[1] + %fc1_1[1] * %fd0_1[0] + %fc1_1[2] * %fe1_1[7] + %fc1_1[3] * %fe1_1[6] + %fc1_1[4] * %fe1_1[5] + %fc1_1[5] * %fe1_1[4] + %fc1_1[6] * %fe1_1[3] + %fc1_1[7] * %fe1_1[2],
        %fc0_1[0] * %fd1_1[2] + %fc0_1[1] * %fd1_1[1] + %fc0_1[2] * %fd1_1[0] + %fc0_1[3] * %fd0_1[7] + %fc0_1[4] * %fd0_1[6] + %fc0_1[5] * %fd0_1[5] + %fc0_1[6] * %fd0_1[4] + %fc0_1[7] * %fd0_1[3] +
        %fc1_1[0] * %fd0_1[2] + %fc1_1[1] * %fd0_1[1] + %fc1_1[2] * %fd0_1[0] + %fc1_1[3] * %fe1_1[7] + %fc1_1[4] * %fe1_1[6] + %fc1_1[5] * %fe1_1[5] + %fc1_1[6] * %fe1_1[4] + %fc1_1[7] * %fe1_1[3],
        %fc0_1[0] * %fd1_1[3] + %fc0_1[1] * %fd1_1[2] + %fc0_1[2] * %fd1_1[1] + %fc0_1[3] * %fd1_1[0] + %fc0_1[4] * %fd0_1[7] + %fc0_1[5] * %fd0_1[6] + %fc0_1[6] * %fd0_1[5] + %fc0_1[7] * %fd0_1[4] +
        %fc1_1[0] * %fd0_1[3] + %fc1_1[1] * %fd0_1[2] + %fc1_1[2] * %fd0_1[1] + %fc1_1[3] * %fd0_1[0] + %fc1_1[4] * %fe1_1[7] + %fc1_1[5] * %fe1_1[6] + %fc1_1[6] * %fe1_1[5] + %fc1_1[7] * %fe1_1[4],
        %fc0_1[0] * %fd1_1[4] + %fc0_1[1] * %fd1_1[3] + %fc0_1[2] * %fd1_1[2] + %fc0_1[3] * %fd1_1[1] + %fc0_1[4] * %fd1_1[0] + %fc0_1[5] * %fd0_1[7] + %fc0_1[6] * %fd0_1[6] + %fc0_1[7] * %fd0_1[5] +
        %fc1_1[0] * %fd0_1[4] + %fc1_1[1] * %fd0_1[3] + %fc1_1[2] * %fd0_1[2] + %fc1_1[3] * %fd0_1[1] + %fc1_1[4] * %fd0_1[0] + %fc1_1[5] * %fe1_1[7] + %fc1_1[6] * %fe1_1[6] + %fc1_1[7] * %fe1_1[5],
        %fc0_1[0] * %fd1_1[5] + %fc0_1[1] * %fd1_1[4] + %fc0_1[2] * %fd1_1[3] + %fc0_1[3] * %fd1_1[2] + %fc0_1[4] * %fd1_1[1] + %fc0_1[5] * %fd1_1[0] + %fc0_1[6] * %fd0_1[7] + %fc0_1[7] * %fd0_1[6] +
        %fc1_1[0] * %fd0_1[5] + %fc1_1[1] * %fd0_1[4] + %fc1_1[2] * %fd0_1[3] + %fc1_1[3] * %fd0_1[2] + %fc1_1[4] * %fd0_1[1] + %fc1_1[5] * %fd0_1[0] + %fc1_1[6] * %fe1_1[7] + %fc1_1[7] * %fe1_1[6],
        %fc0_1[0] * %fd1_1[6] + %fc0_1[1] * %fd1_1[5] + %fc0_1[2] * %fd1_1[4] + %fc0_1[3] * %fd1_1[3] + %fc0_1[4] * %fd1_1[2] + %fc0_1[5] * %fd1_1[1] + %fc0_1[6] * %fd1_1[0] + %fc0_1[7] * %fd0_1[7] +
        %fc1_1[0] * %fd0_1[6] + %fc1_1[1] * %fd0_1[5] + %fc1_1[2] * %fd0_1[4] + %fc1_1[3] * %fd0_1[3] + %fc1_1[4] * %fd0_1[2] + %fc1_1[5] * %fd0_1[1] + %fc1_1[6] * %fd0_1[0] + %fc1_1[7] * %fe1_1[7],
        %fc0_1[0] * %fd1_1[7] + %fc0_1[1] * %fd1_1[6] + %fc0_1[2] * %fd1_1[5] + %fc0_1[3] * %fd1_1[4] + %fc0_1[4] * %fd1_1[3] + %fc0_1[5] * %fd1_1[2] + %fc0_1[6] * %fd1_1[1] + %fc0_1[7] * %fd1_1[0] +
        %fc1_1[0] * %fd0_1[7] + %fc1_1[1] * %fd0_1[6] + %fc1_1[2] * %fd0_1[5] + %fc1_1[3] * %fd0_1[4] + %fc1_1[4] * %fd0_1[3] + %fc1_1[5] * %fd0_1[2] + %fc1_1[6] * %fd0_1[1] + %fc1_1[7] * %fd0_1[0]
    ] /\

    %v16 ++ %v7 = %conv0_1 /\ %v0 ++ %v2 = %conv1_1,

    %v16 <= [268435456, 268435456, 268435456, 268435456] /\
    %v16 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v7 <= [268435456, 268435456, 268435456, 268435456] /\
    %v7 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v0 <= [268435456, 268435456, 268435456, 268435456] /\
    %v0 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v2 <= [268435456, 268435456, 268435456, 268435456] /\
    %v2 >= [-268435456, -268435456, -268435456, -268435456]

    prove with [algebra solver isl]
  &&
    %v16 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v16 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32] /\

    %v7 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v7 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32] /\

    %v0 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v0 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32] /\

    %v2 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v2 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32];

ghost %h0_1@sint32[8], %h1_1@sint32[8] :
    %h0_1 = %v16 ++ %v7 /\ %h1_1 = %v0 ++ %v2
  &&
    %h0_1 = %v16 ++ %v7 /\ %h1_1 = %v0 ++ %v2;

(* uzp1	v3.8h, v16.8h, v7.8h                       #! PC = 0x5555551cd0 *)
mov %spl_join [%v16[0], %v16[1], %v16[2], %v16[3], %v7[0], %v7[1], %v7[2], %v7[3]]; spl %splh %v3 %spl_join 16; cast %v3@int16[8] %v3;
(* mul	v3.8h, v3.8h, v5.h[7]                       #! PC = 0x5555551cd4 *)
broadcast %mul 8 [%v5[7]]; mull %dc %v3 %v3 %mul; cast %v3@int16[8] %v3;

ghost %m0_1@sint16[8] : %m0_1 = %v3 && %m0_1 = %v3;

(* sqdmulh	v3.8h, v3.8h, v5.h[6]                   #! PC = 0x5555551cd8 *)
broadcast %mul 8 [%v5[6]]; smulj %LO %v3 %mul;
ssplit %LO0 %dc %LO 15; vpc %v3@sint16[8] %LO0;
(* uzp2	v1.8h, v16.8h, v7.8h                       #! PC = 0x5555551cdc *)
mov %spl_join [%v16[0], %v16[1], %v16[2], %v16[3], %v7[0], %v7[1], %v7[2], %v7[3]]; spl %v1 %spll %spl_join 16;
(* sshr	v3.8h, v3.8h, #1                           #! PC = 0x5555551ce0 *)
split %v3 %dc %v3 1;
(* sub	v1.8h, v1.8h, v3.8h                         #! PC = 0x5555551ce4 *)
sub %v1 %v1 %v3;

ghost %hh0_1@sint16[8] : %hh0_1 = %v1 && %hh0_1 = %v1;

assert
    %h0_1 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m0_1
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh0_1
    prove with [algebra solver isl]
    && true;

assume
    %h0_1 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m0_1
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh0_1
    && true;

(* sqrdmulh	v3.8h, v1.8h, v5.h[3]                  #! PC = 0x5555551ce8 *)
broadcast %mul 8 [%v5[3]]; smulj %LO %v1 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v3 %LO11 %LO01;
(* mul	v1.8h, v1.8h, v5.h[2]                       #! PC = 0x5555551cec *)
broadcast %mul 8 [%v5[2]]; mull %dc %v1 %v1 %mul; cast %v1@int16[8] %v1;
(* mls	v1.8h, v3.8h, v5.h[6]                       #! PC = 0x5555551cf0 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v3 %mul;
cast %mls@int16[8] %mls; subc %dc %v1 %v1 %mls;

assert
    [1175, 1175, 1175, 1175, 1175, 1175, 1175, 1175] * %hh0_1
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v3
    = %v1
    prove with [algebra solver isl]
    && true;

assume
    [1175, 1175, 1175, 1175, 1175, 1175, 1175, 1175] * %hh0_1
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v3
    = %v1
    && true;

(* uzp1	v3.8h, v0.8h, v2.8h                        #! PC = 0x5555551cf4 *)
mov %spl_join [%v0[0], %v0[1], %v0[2], %v0[3], %v2[0], %v2[1], %v2[2], %v2[3]]; spl %splh %v3 %spl_join 16; cast %v3@int16[8] %v3;
(* mul	v3.8h, v3.8h, v5.h[7]                       #! PC = 0x5555551cf8 *)
broadcast %mul 8 [%v5[7]]; mull %dc %v3 %v3 %mul; cast %v3@int16[8] %v3;

ghost %m1_1@sint16[8] : %m1_1 = %v3 && %m1_1 = %v3;

(* sqdmulh	v3.8h, v3.8h, v5.h[6]                   #! PC = 0x5555551cfc *)
broadcast %mul 8 [%v5[6]]; smulj %LO %v3 %mul;
ssplit %LO0 %dc %LO 15; vpc %v3@sint16[8] %LO0;
(* uzp2	v0.8h, v0.8h, v2.8h                        #! PC = 0x5555551d00 *)
mov %spl_join [%v0[0], %v0[1], %v0[2], %v0[3], %v2[0], %v2[1], %v2[2], %v2[3]]; spl %v0 %spll %spl_join 16;
(* sshr	v2.8h, v3.8h, #1                           #! PC = 0x5555551d04 *)
split %v2 %dc %v3 1;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551d08 *)
sub %v0 %v0 %v2;

ghost %hh1_1@sint16[8] : %hh1_1 = %v0 && %hh1_1 = %v0;

assert
    %h1_1 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m1_1
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh1_1
    prove with [algebra solver isl]
    && true;

assume
    %h1_1 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m1_1
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh1_1
    && true;

(* sqrdmulh	v2.8h, v0.8h, v5.h[3]                  #! PC = 0x5555551d0c *)
broadcast %mul 8 [%v5[3]]; smulj %LO %v0 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v2 %LO11 %LO01;
(* mul	v0.8h, v0.8h, v5.h[2]                       #! PC = 0x5555551d10 *)
broadcast %mul 8 [%v5[2]]; mull %dc %v0 %v0 %mul; cast %v0@int16[8] %v0;
(* mls	v0.8h, v2.8h, v5.h[6]                       #! PC = 0x5555551d14 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v2 %mul;
cast %mls@int16[8] %mls; subc %dc %v0 %v0 %mls;

assert
    [1175, 1175, 1175, 1175, 1175, 1175, 1175, 1175] * %hh1_1
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v2
    = %v0
    prove with [algebra solver isl]
    && true;

assume
    [1175, 1175, 1175, 1175, 1175, 1175, 1175, 1175] * %hh1_1
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v2
    = %v0
    && true;


### i_iter epilogue

(* str	q1, [x2, x3]                                #! EA = L0x7fffffe1d0; PC = 0x5555551d18 *)
mov [L0x7fffffe1d0,L0x7fffffe1d2,L0x7fffffe1d4,L0x7fffffe1d6,L0x7fffffe1d8,L0x7fffffe1da,L0x7fffffe1dc,L0x7fffffe1de] %v1;
(* str	q0, [x6, x3]                                #! EA = L0x7fffffe1e0; PC = 0x5555551d1c *)
mov [L0x7fffffe1e0,L0x7fffffe1e2,L0x7fffffe1e4,L0x7fffffe1e6,L0x7fffffe1e8,L0x7fffffe1ea,L0x7fffffe1ec,L0x7fffffe1ee] %v0;
(* #b.eq	0x5555551ec4 <_ZN6xpower7basemul11low_basemulEPA2_A8_sS3_S3_+932>  // b.none#! PC = 0x5555551d30 *)
#b.eq	0x5555551ec4 <_ZN6xpower7basemul11low_basemulEPA2_A8_sS3_S3_+932>  // b.none#! 0x5555551d30 = 0x5555551d30;

assert
    %v1 <= [2750, 2750, 2750, 2750, 2750, 2750, 2750, 2750] /\
    %v1 >= [-2750, -2750, -2750, -2750, -2750, -2750, -2750, -2750] /\

    %v0 <= [2750, 2750, 2750, 2750, 2750, 2750, 2750, 2750] /\
    %v0 >= [-2750, -2750, -2750, -2750, -2750, -2750, -2750, -2750]

    prove with [algebra solver isl]
    && true;

assume
    true &&

    %v1 <=s [2750@16, 2750@16, 2750@16, 2750@16, 2750@16, 2750@16, 2750@16, 2750@16] /\
    %v1 >=s [(-2750)@16, (-2750)@16, (-2750)@16, (-2750)@16, (-2750)@16, (-2750)@16, (-2750)@16, (-2750)@16] /\

    %v0 <=s [2750@16, 2750@16, 2750@16, 2750@16, 2750@16, 2750@16, 2750@16, 2750@16] /\
    %v0 >=s [(-2750)@16, (-2750)@16, (-2750)@16, (-2750)@16, (-2750)@16, (-2750)@16, (-2750)@16, (-2750)@16];

cut (* 8 *)
    [L0x7fffffe1d0, L0x7fffffe1d2, L0x7fffffe1d4, L0x7fffffe1d6, L0x7fffffe1d8, L0x7fffffe1da, L0x7fffffe1dc, L0x7fffffe1de] = %v1 /\
    [L0x7fffffe1e0, L0x7fffffe1e2, L0x7fffffe1e4, L0x7fffffe1e6, L0x7fffffe1e8, L0x7fffffe1ea, L0x7fffffe1ec, L0x7fffffe1ee] = %v0 /\

    %v1 ++ %v0 = [-1145, -1145, -1145, -1145, -1145, -1145, -1145, -1145, -1145, -1145, -1145, -1145, -1145, -1145, -1145, -1145] * [
        arr100_a * arr100_b + -1610 * arr101_a * arr117_b + -1610 * arr102_a * arr116_b + -1610 * arr103_a * arr115_b + -1610 * arr104_a * arr114_b + -1610 * arr105_a * arr113_b + -1610 * arr106_a * arr112_b + -1610 * arr107_a * arr111_b + -1610 * arr110_a * arr110_b + -1610 * arr111_a * arr107_b + -1610 * arr112_a * arr106_b + -1610 * arr113_a * arr105_b + -1610 * arr114_a * arr104_b + -1610 * arr115_a * arr103_b + -1610 * arr116_a * arr102_b + -1610 * arr117_a * arr101_b,
        arr100_a * arr101_b + arr101_a * arr100_b + -1610 * arr102_a * arr117_b + -1610 * arr103_a * arr116_b + -1610 * arr104_a * arr115_b + -1610 * arr105_a * arr114_b + -1610 * arr106_a * arr113_b + -1610 * arr107_a * arr112_b + -1610 * arr110_a * arr111_b + -1610 * arr111_a * arr110_b + -1610 * arr112_a * arr107_b + -1610 * arr113_a * arr106_b + -1610 * arr114_a * arr105_b + -1610 * arr115_a * arr104_b + -1610 * arr116_a * arr103_b + -1610 * arr117_a * arr102_b,
        arr100_a * arr102_b + arr101_a * arr101_b + arr102_a * arr100_b + -1610 * arr103_a * arr117_b + -1610 * arr104_a * arr116_b + -1610 * arr105_a * arr115_b + -1610 * arr106_a * arr114_b + -1610 * arr107_a * arr113_b + -1610 * arr110_a * arr112_b + -1610 * arr111_a * arr111_b + -1610 * arr112_a * arr110_b + -1610 * arr113_a * arr107_b + -1610 * arr114_a * arr106_b + -1610 * arr115_a * arr105_b + -1610 * arr116_a * arr104_b + -1610 * arr117_a * arr103_b,
        arr100_a * arr103_b + arr101_a * arr102_b + arr102_a * arr101_b + arr103_a * arr100_b + -1610 * arr104_a * arr117_b + -1610 * arr105_a * arr116_b + -1610 * arr106_a * arr115_b + -1610 * arr107_a * arr114_b + -1610 * arr110_a * arr113_b + -1610 * arr111_a * arr112_b + -1610 * arr112_a * arr111_b + -1610 * arr113_a * arr110_b + -1610 * arr114_a * arr107_b + -1610 * arr115_a * arr106_b + -1610 * arr116_a * arr105_b + -1610 * arr117_a * arr104_b,
        arr100_a * arr104_b + arr101_a * arr103_b + arr102_a * arr102_b + arr103_a * arr101_b + arr104_a * arr100_b + -1610 * arr105_a * arr117_b + -1610 * arr106_a * arr116_b + -1610 * arr107_a * arr115_b + -1610 * arr110_a * arr114_b + -1610 * arr111_a * arr113_b + -1610 * arr112_a * arr112_b + -1610 * arr113_a * arr111_b + -1610 * arr114_a * arr110_b + -1610 * arr115_a * arr107_b + -1610 * arr116_a * arr106_b + -1610 * arr117_a * arr105_b,
        arr100_a * arr105_b + arr101_a * arr104_b + arr102_a * arr103_b + arr103_a * arr102_b + arr104_a * arr101_b + arr105_a * arr100_b + -1610 * arr106_a * arr117_b + -1610 * arr107_a * arr116_b + -1610 * arr110_a * arr115_b + -1610 * arr111_a * arr114_b + -1610 * arr112_a * arr113_b + -1610 * arr113_a * arr112_b + -1610 * arr114_a * arr111_b + -1610 * arr115_a * arr110_b + -1610 * arr116_a * arr107_b + -1610 * arr117_a * arr106_b,
        arr100_a * arr106_b + arr101_a * arr105_b + arr102_a * arr104_b + arr103_a * arr103_b + arr104_a * arr102_b + arr105_a * arr101_b + arr106_a * arr100_b + -1610 * arr107_a * arr117_b + -1610 * arr110_a * arr116_b + -1610 * arr111_a * arr115_b + -1610 * arr112_a * arr114_b + -1610 * arr113_a * arr113_b + -1610 * arr114_a * arr112_b + -1610 * arr115_a * arr111_b + -1610 * arr116_a * arr110_b + -1610 * arr117_a * arr107_b,
        arr100_a * arr107_b + arr101_a * arr106_b + arr102_a * arr105_b + arr103_a * arr104_b + arr104_a * arr103_b + arr105_a * arr102_b + arr106_a * arr101_b + arr107_a * arr100_b + -1610 * arr110_a * arr117_b + -1610 * arr111_a * arr116_b + -1610 * arr112_a * arr115_b + -1610 * arr113_a * arr114_b + -1610 * arr114_a * arr113_b + -1610 * arr115_a * arr112_b + -1610 * arr116_a * arr111_b + -1610 * arr117_a * arr110_b,
        arr100_a * arr110_b + arr101_a * arr107_b + arr102_a * arr106_b + arr103_a * arr105_b + arr104_a * arr104_b + arr105_a * arr103_b + arr106_a * arr102_b + arr107_a * arr101_b + arr110_a * arr100_b + -1610 * arr111_a * arr117_b + -1610 * arr112_a * arr116_b + -1610 * arr113_a * arr115_b + -1610 * arr114_a * arr114_b + -1610 * arr115_a * arr113_b + -1610 * arr116_a * arr112_b + -1610 * arr117_a * arr111_b,
        arr100_a * arr111_b + arr101_a * arr110_b + arr102_a * arr107_b + arr103_a * arr106_b + arr104_a * arr105_b + arr105_a * arr104_b + arr106_a * arr103_b + arr107_a * arr102_b + arr110_a * arr101_b + arr111_a * arr100_b + -1610 * arr112_a * arr117_b + -1610 * arr113_a * arr116_b + -1610 * arr114_a * arr115_b + -1610 * arr115_a * arr114_b + -1610 * arr116_a * arr113_b + -1610 * arr117_a * arr112_b,
        arr100_a * arr112_b + arr101_a * arr111_b + arr102_a * arr110_b + arr103_a * arr107_b + arr104_a * arr106_b + arr105_a * arr105_b + arr106_a * arr104_b + arr107_a * arr103_b + arr110_a * arr102_b + arr111_a * arr101_b + arr112_a * arr100_b + -1610 * arr113_a * arr117_b + -1610 * arr114_a * arr116_b + -1610 * arr115_a * arr115_b + -1610 * arr116_a * arr114_b + -1610 * arr117_a * arr113_b,
        arr100_a * arr113_b + arr101_a * arr112_b + arr102_a * arr111_b + arr103_a * arr110_b + arr104_a * arr107_b + arr105_a * arr106_b + arr106_a * arr105_b + arr107_a * arr104_b + arr110_a * arr103_b + arr111_a * arr102_b + arr112_a * arr101_b + arr113_a * arr100_b + -1610 * arr114_a * arr117_b + -1610 * arr115_a * arr116_b + -1610 * arr116_a * arr115_b + -1610 * arr117_a * arr114_b,
        arr100_a * arr114_b + arr101_a * arr113_b + arr102_a * arr112_b + arr103_a * arr111_b + arr104_a * arr110_b + arr105_a * arr107_b + arr106_a * arr106_b + arr107_a * arr105_b + arr110_a * arr104_b + arr111_a * arr103_b + arr112_a * arr102_b + arr113_a * arr101_b + arr114_a * arr100_b + -1610 * arr115_a * arr117_b + -1610 * arr116_a * arr116_b + -1610 * arr117_a * arr115_b,
        arr100_a * arr115_b + arr101_a * arr114_b + arr102_a * arr113_b + arr103_a * arr112_b + arr104_a * arr111_b + arr105_a * arr110_b + arr106_a * arr107_b + arr107_a * arr106_b + arr110_a * arr105_b + arr111_a * arr104_b + arr112_a * arr103_b + arr113_a * arr102_b + arr114_a * arr101_b + arr115_a * arr100_b + -1610 * arr116_a * arr117_b + -1610 * arr117_a * arr116_b,
        arr100_a * arr116_b + arr101_a * arr115_b + arr102_a * arr114_b + arr103_a * arr113_b + arr104_a * arr112_b + arr105_a * arr111_b + arr106_a * arr110_b + arr107_a * arr107_b + arr110_a * arr106_b + arr111_a * arr105_b + arr112_a * arr104_b + arr113_a * arr103_b + arr114_a * arr102_b + arr115_a * arr101_b + arr116_a * arr100_b + -1610 * arr117_a * arr117_b,
        arr100_a * arr117_b + arr101_a * arr116_b + arr102_a * arr115_b + arr103_a * arr114_b + arr104_a * arr113_b + arr105_a * arr112_b + arr106_a * arr111_b + arr107_a * arr110_b + arr110_a * arr107_b + arr111_a * arr106_b + arr112_a * arr105_b + arr113_a * arr104_b + arr114_a * arr103_b + arr115_a * arr102_b + arr116_a * arr101_b + arr117_a * arr100_b
    ] ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] )

    prove with [cuts[0, 5, 6, 7]]
  &&
    [L0x7fffffe1d0, L0x7fffffe1d2, L0x7fffffe1d4, L0x7fffffe1d6, L0x7fffffe1d8, L0x7fffffe1da, L0x7fffffe1dc, L0x7fffffe1de] = %v1 /\
    [L0x7fffffe1e0, L0x7fffffe1e2, L0x7fffffe1e4, L0x7fffffe1e6, L0x7fffffe1e8, L0x7fffffe1ea, L0x7fffffe1ec, L0x7fffffe1ee] = %v0 /\

    %v1 <=s [2750@16, 2750@16, 2750@16, 2750@16, 2750@16, 2750@16, 2750@16, 2750@16] /\
    %v1 >=s [(-2750)@16, (-2750)@16, (-2750)@16, (-2750)@16, (-2750)@16, (-2750)@16, (-2750)@16, (-2750)@16] /\

    %v0 <=s [2750@16, 2750@16, 2750@16, 2750@16, 2750@16, 2750@16, 2750@16, 2750@16] /\
    %v0 >=s [(-2750)@16, (-2750)@16, (-2750)@16, (-2750)@16, (-2750)@16, (-2750)@16, (-2750)@16, (-2750)@16];


### i_iter prologue

(* ldr	q4, [x0, x3]                                #! EA = L0x7fffffe470; Value = 0x0000000000000000; PC = 0x5555551d34 *)
mov %v4 [L0x7fffffe470,L0x7fffffe472,L0x7fffffe474,L0x7fffffe476,L0x7fffffe478,L0x7fffffe47a,L0x7fffffe47c,L0x7fffffe47e];
(* ldr	q1, [x8, x3]                                #! EA = L0x7fffffe480; Value = 0x0000000000000000; PC = 0x5555551d38 *)
mov %v1 [L0x7fffffe480,L0x7fffffe482,L0x7fffffe484,L0x7fffffe486,L0x7fffffe488,L0x7fffffe48a,L0x7fffffe48c,L0x7fffffe48e];
(* ldr	q17, [x1, x3]                               #! EA = L0x7fffffe330; Value = 0x0000000000000000; PC = 0x5555551d3c *)
mov %v17 [L0x7fffffe330,L0x7fffffe332,L0x7fffffe334,L0x7fffffe336,L0x7fffffe338,L0x7fffffe33a,L0x7fffffe33c,L0x7fffffe33e];
(* ldr	q18, [x7, x3]                               #! EA = L0x7fffffe340; Value = 0x0000000000000000; PC = 0x5555551d40 *)
mov %v18 [L0x7fffffe340,L0x7fffffe342,L0x7fffffe344,L0x7fffffe346,L0x7fffffe348,L0x7fffffe34a,L0x7fffffe34c,L0x7fffffe34e];

ghost %fa0_2@sint16[8], %fa1_2@sint16[8], %fb0_2@sint16[8], %fb1_2@sint16[8] :
    %fa0_2 = %v4 /\ %fa1_2 = %v1 /\ %fb0_2 = %v17 /\ %fb1_2 = %v18
  &&
    %fa0_2 = %v4 /\ %fa1_2 = %v1 /\ %fb0_2 = %v17 /\ %fb1_2 = %v18;

cut (* 9 *)
    %fa0_2 = %v4 /\ %fa1_2 = %v1 /\ %fb0_2 = %v17 /\ %fb1_2 = %v18 /\
    %fa0_2 = [arr200_a, arr201_a, arr202_a, arr203_a, arr204_a, arr205_a, arr206_a, arr207_a] /\
    %fa1_2 = [arr210_a, arr211_a, arr212_a, arr213_a, arr214_a, arr215_a, arr216_a, arr217_a] /\
    %fb0_2 = [arr200_b, arr201_b, arr202_b, arr203_b, arr204_b, arr205_b, arr206_b, arr207_b] /\
    %fb1_2 = [arr210_b, arr211_b, arr212_b, arr213_b, arr214_b, arr215_b, arr216_b, arr217_b]
    prove with [cuts[0]]
  &&
    %fa0_2 = %v4 /\ %fa1_2 = %v1 /\ %fb0_2 = %v17 /\ %fb1_2 = %v18 /\
    %fa0_2 = [arr200_a, arr201_a, arr202_a, arr203_a, arr204_a, arr205_a, arr206_a, arr207_a] /\
    %fa1_2 = [arr210_a, arr211_a, arr212_a, arr213_a, arr214_a, arr215_a, arr216_a, arr217_a] /\
    %fb0_2 = [arr200_b, arr201_b, arr202_b, arr203_b, arr204_b, arr205_b, arr206_b, arr207_b] /\
    %fb1_2 = [arr210_b, arr211_b, arr212_b, arr213_b, arr214_b, arr215_b, arr216_b, arr217_b]
    prove with [cuts[0]];

#### radix2

(* ldr	q5, [x5]                                    #! EA = L0x5555552e20; Value = 0xfc67ff7f2ce3064a; PC = 0x5555551d48 *)
mov %v5 [L0x5555552e20,L0x5555552e22,L0x5555552e24,L0x5555552e26,L0x5555552e28,L0x5555552e2a,L0x5555552e2c,L0x5555552e2e];
(* sshr	v0.8h, v4.8h, #12                          #! PC = 0x5555551d4c *)
split %v0 %dc %v4 12;
(* cmlt	v2.8h, v4.8h, #0                           #! PC = 0x5555551d50 *)
split %v2 %dc %v4 15;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551d54 *)
sub %v0 %v0 %v2;
(* mls	v4.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551d58 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v4 %v4 %mls;

assert
    %fa0_2 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v4
    prove with [algebra solver isl, precondition, cuts[0, 9]]
    && true;

assume
    %fa0_2 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v4
    && true;

(* sshr	v0.8h, v17.8h, #12                         #! PC = 0x5555551d5c *)
split %v0 %dc %v17 12;
(* cmlt	v2.8h, v17.8h, #0                          #! PC = 0x5555551d60 *)
split %v2 %dc %v17 15;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551d64 *)
sub %v0 %v0 %v2;
(* mls	v17.8h, v0.8h, v5.h[6]                      #! PC = 0x5555551d68 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v17 %v17 %mls;

assert
    %fb0_2 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v17
    prove with [algebra solver isl, precondition, cuts[0, 9]]
    && true;

assume
    %fb0_2 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v17
    && true;

(* sqrdmulh	v0.8h, v1.8h, v5.h[1]                  #! PC = 0x5555551d6c *)
broadcast %mul 8 [%v5[1]]; smulj %LO %v1 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v0 %LO11 %LO01;
(* mul	v1.8h, v1.8h, v5.h[0]                       #! PC = 0x5555551d70 *)
broadcast %mul 8 [%v5[0]]; mull %dc %v1 %v1 %mul; cast %v1@int16[8] %v1;
(* mls	v1.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551d74 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v1 %v1 %mls;

assert
    [1610, 1610, 1610, 1610, 1610, 1610, 1610, 1610] * %fa1_2
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v1
    prove with [algebra solver isl, precondition, cuts[0, 9]]
    && true;

assume
    [1610, 1610, 1610, 1610, 1610, 1610, 1610, 1610] * %fa1_2
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v1
    && true;

(* sqrdmulh	v0.8h, v18.8h, v5.h[1]                 #! PC = 0x5555551d78 *)
broadcast %mul 8 [%v5[1]]; smulj %LO %v18 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v0 %LO11 %LO01;
(* mul	v18.8h, v18.8h, v5.h[0]                     #! PC = 0x5555551d7c *)
broadcast %mul 8 [%v5[0]]; mull %dc %v18 %v18 %mul; cast %v18@int16[8] %v18;
(* mls	v18.8h, v0.8h, v5.h[6]                      #! PC = 0x5555551d80 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v18 %v18 %mls;

assert
    [1610, 1610, 1610, 1610, 1610, 1610, 1610, 1610] * %fb1_2
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v18
    prove with [algebra solver isl, precondition, cuts[0, 9]]
    && true;

assume
    [1610, 1610, 1610, 1610, 1610, 1610, 1610, 1610] * %fb1_2
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v18
    && true;

(* add	v2.8h, v4.8h, v1.8h                         #! PC = 0x5555551d84 *)
add %v2 %v4 %v1;
(* sub	v1.8h, v4.8h, v1.8h                         #! PC = 0x5555551d88 *)
sub %v1 %v4 %v1;
(* add	v7.8h, v17.8h, v18.8h                       #! PC = 0x5555551d8c *)
add %v7 %v17 %v18;
(* sub	v18.8h, v17.8h, v18.8h                      #! PC = 0x5555551d90 *)
sub %v18 %v17 %v18;

ghost %fc0_2@sint16[8], %fc1_2@sint16[8], %fd0_2@sint16[8], %fd1_2@sint16[8] :
    %fc0_2 = %v2 /\ %fc1_2 = %v1 /\ %fd0_2 = %v7 /\ %fd1_2 = %v18
  &&
    %fc0_2 = %v2 /\ %fc1_2 = %v1 /\ %fd0_2 = %v7 /\ %fd1_2 = %v18;

(* sqrdmulh	v0.8h, v7.8h, v5.h[1]                  #! PC = 0x5555551d94 *)
broadcast %mul 8 [%v5[1]]; smulj %LO %v7 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v0 %LO11 %LO01;
(* mul	v3.8h, v7.8h, v5.h[0]                       #! PC = 0x5555551d98 *)
broadcast %mul 8 [%v5[0]]; mull %dc %v3 %v7 %mul; cast %v3@int16[8] %v3;
(* mls	v3.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551d9c *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v3 %v3 %mls;

assert
    [1610, 1610, 1610, 1610, 1610, 1610, 1610, 1610] * %fd0_2
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v3
    prove with [algebra solver isl, precondition, cuts[0, 9]]
    && true;

assume
    [1610, 1610, 1610, 1610, 1610, 1610, 1610, 1610] * %fd0_2
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v3
    && true;

(* sqrdmulh	v0.8h, v18.8h, v5.h[1]                 #! PC = 0x5555551da0 *)
broadcast %mul 8 [%v5[1]]; smulj %LO %v18 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v0 %LO11 %LO01;
(* mul	v6.8h, v18.8h, v5.h[0]                      #! PC = 0x5555551da4 *)
broadcast %mul 8 [%v5[0]]; mull %dc %v6 %v18 %mul; cast %v6@int16[8] %v6;
(* mls	v6.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551da8 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v6 %v6 %mls;

assert
    [1610, 1610, 1610, 1610, 1610, 1610, 1610, 1610] * %fd1_2
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v6
    prove with [algebra solver isl, precondition, cuts[0, 9]]
    && true;

assume
    [1610, 1610, 1610, 1610, 1610, 1610, 1610, 1610] * %fd1_2
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v6
    && true;

(* neg	v6.8h, v6.8h                                #! PC = 0x5555551dac *)
broadcast %zero 8 [0@sint16]; sub %v6 %zero %v6;

ghost %gd0_2@sint16[8], %gd1_2@sint16[8] :
    %gd0_2 = %v3 /\ %gd1_2 = %v6
  &&
    %gd0_2 = %v3 /\ %gd1_2 = %v6;

cut (* 10 *)
    %fc0_2 = %v2 /\ %fc1_2 = %v1 /\ %fd0_2 = %v7 /\ %fd1_2 = %v18 /\ %gd0_2 = %v3 /\ %gd1_2 = %v6 /\

    %fc0_2 = %fa0_2 + [1610, 1610, 1610, 1610, 1610, 1610, 1610, 1610] * %fa1_2
        ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\
    %fc1_2 = %fa0_2 - [1610, 1610, 1610, 1610, 1610, 1610, 1610, 1610] * %fa1_2
        ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\

    %fd0_2 = %fb0_2 + [1610, 1610, 1610, 1610, 1610, 1610, 1610, 1610] * %fb1_2
        ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\
    %fd1_2 = %fb0_2 - [1610, 1610, 1610, 1610, 1610, 1610, 1610, 1610] * %fb1_2
        ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\

    %gd0_2 =  [1610, 1610, 1610, 1610, 1610, 1610, 1610, 1610] * %fd0_2 ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\
    %gd1_2 = -[1610, 1610, 1610, 1610, 1610, 1610, 1610, 1610] * %fd1_2 ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ),

    %fc0_2 <= [8100, 8100, 8100, 8100, 8100, 8100, 8100, 8100] /\
    %fc0_2 >= [-8100, -8100, -8100, -8100, -8100, -8100, -8100, -8100] /\

    %fc1_2 <= [8100, 8100, 8100, 8100, 8100, 8100, 8100, 8100] /\
    %fc1_2 >= [-8100, -8100, -8100, -8100, -8100, -8100, -8100, -8100] /\

    %fd0_2 <= [8100, 8100, 8100, 8100, 8100, 8100, 8100, 8100] /\
    %fd0_2 >= [-8100, -8100, -8100, -8100, -8100, -8100, -8100, -8100] /\

    %fd1_2 <= [8100, 8100, 8100, 8100, 8100, 8100, 8100, 8100] /\
    %fd1_2 >= [-8100, -8100, -8100, -8100, -8100, -8100, -8100, -8100] /\

    %gd0_2 <= [3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000] /\
    %gd0_2 >= [-3000, -3000, -3000, -3000, -3000, -3000, -3000, -3000] /\

    %gd1_2 <= [3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000] /\
    %gd1_2 >= [-3000, -3000, -3000, -3000, -3000, -3000, -3000, -3000]

    prove with [algebra solver isl, precondition, cuts[0, 9]]
  &&
    true
    prove with [precondition, cuts[0, 9]];

(* smull	v0.4s, v7.4h, v2.h[0]                     #! PC = 0x5555551db0 *)
broadcast %mull 4 [%v2[0]]; smulj %v0 [%v7[0],%v7[1],%v7[2],%v7[3]] %mull;
(* smull2	v4.4s, v7.8h, v2.h[0]                    #! PC = 0x5555551db4 *)
broadcast %mull 4 [%v2[0]]; smulj %v4 [%v7[4],%v7[5],%v7[6],%v7[7]] %mull;
(* ext	v16.16b, v3.16b, v7.16b, #14                #! PC = 0x5555551db8 *)
mov %v16 [%v3[7],%v7[0],%v7[1],%v7[2],%v7[3],%v7[4],%v7[5],%v7[6]];
(* smlal	v0.4s, v16.4h, v2.h[1]                    #! PC = 0x5555551dbc *)
broadcast %mull 4 [%v2[1]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v16.8h, v2.h[1]                   #! PC = 0x5555551dc0 *)
broadcast %mull 4 [%v2[1]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v4 %v4 %mlal;
(* ext	v16.16b, v3.16b, v7.16b, #12                #! PC = 0x5555551dc4 *)
mov %v16 [%v3[6],%v3[7],%v7[0],%v7[1],%v7[2],%v7[3],%v7[4],%v7[5]];
(* smlal	v0.4s, v16.4h, v2.h[2]                    #! PC = 0x5555551dc8 *)
broadcast %mull 4 [%v2[2]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v16.8h, v2.h[2]                   #! PC = 0x5555551dcc *)
broadcast %mull 4 [%v2[2]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v4 %v4 %mlal;
(* ext	v16.16b, v3.16b, v7.16b, #10                #! PC = 0x5555551dd0 *)
mov %v16 [%v3[5],%v3[6],%v3[7],%v7[0],%v7[1],%v7[2],%v7[3],%v7[4]];
(* smlal	v0.4s, v16.4h, v2.h[3]                    #! PC = 0x5555551dd4 *)
broadcast %mull 4 [%v2[3]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v16.8h, v2.h[3]                   #! PC = 0x5555551dd8 *)
broadcast %mull 4 [%v2[3]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v4 %v4 %mlal;
(* ext	v16.16b, v3.16b, v7.16b, #8                 #! PC = 0x5555551ddc *)
mov %v16 [%v3[4],%v3[5],%v3[6],%v3[7],%v7[0],%v7[1],%v7[2],%v7[3]];
(* smlal	v0.4s, v16.4h, v2.h[4]                    #! PC = 0x5555551de0 *)
broadcast %mull 4 [%v2[4]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v16.8h, v2.h[4]                   #! PC = 0x5555551de4 *)
broadcast %mull 4 [%v2[4]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v4 %v4 %mlal;
(* ext	v16.16b, v3.16b, v7.16b, #6                 #! PC = 0x5555551de8 *)
mov %v16 [%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v7[0],%v7[1],%v7[2]];
(* smlal	v0.4s, v16.4h, v2.h[5]                    #! PC = 0x5555551dec *)
broadcast %mull 4 [%v2[5]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v16.8h, v2.h[5]                   #! PC = 0x5555551df0 *)
broadcast %mull 4 [%v2[5]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v4 %v4 %mlal;
(* ext	v16.16b, v3.16b, v7.16b, #4                 #! PC = 0x5555551df4 *)
mov %v16 [%v3[2],%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v7[0],%v7[1]];
(* smlal	v0.4s, v16.4h, v2.h[6]                    #! PC = 0x5555551df8 *)
broadcast %mull 4 [%v2[6]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v16.8h, v2.h[6]                   #! PC = 0x5555551dfc *)
broadcast %mull 4 [%v2[6]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v4 %v4 %mlal;
(* ext	v3.16b, v3.16b, v7.16b, #2                  #! PC = 0x5555551e00 *)
mov %v3 [%v3[1],%v3[2],%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v7[0]];
(* smlal	v0.4s, v3.4h, v2.h[7]                     #! PC = 0x5555551e04 *)
broadcast %mull 4 [%v2[7]]; smulj %mlal [%v3[0],%v3[1],%v3[2],%v3[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v3.8h, v2.h[7]                    #! PC = 0x5555551e08 *)
broadcast %mull 4 [%v2[7]]; smulj %mlal [%v3[4],%v3[5],%v3[6],%v3[7]] %mull; adds %dc %v4 %v4 %mlal;
(* smull	v3.4s, v18.4h, v1.h[0]                    #! PC = 0x5555551e0c *)
broadcast %mull 4 [%v1[0]]; smulj %v3 [%v18[0],%v18[1],%v18[2],%v18[3]] %mull;
(* smull2	v2.4s, v18.8h, v1.h[0]                   #! PC = 0x5555551e10 *)
broadcast %mull 4 [%v1[0]]; smulj %v2 [%v18[4],%v18[5],%v18[6],%v18[7]] %mull;
(* ext	v7.16b, v6.16b, v18.16b, #14                #! PC = 0x5555551e14 *)
mov %v7 [%v6[7],%v18[0],%v18[1],%v18[2],%v18[3],%v18[4],%v18[5],%v18[6]];
(* smlal	v3.4s, v7.4h, v1.h[1]                     #! PC = 0x5555551e18 *)
broadcast %mull 4 [%v1[1]]; smulj %mlal [%v7[0],%v7[1],%v7[2],%v7[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v7.8h, v1.h[1]                    #! PC = 0x5555551e1c *)
broadcast %mull 4 [%v1[1]]; smulj %mlal [%v7[4],%v7[5],%v7[6],%v7[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v7.16b, v6.16b, v18.16b, #12                #! PC = 0x5555551e20 *)
mov %v7 [%v6[6],%v6[7],%v18[0],%v18[1],%v18[2],%v18[3],%v18[4],%v18[5]];
(* smlal	v3.4s, v7.4h, v1.h[2]                     #! PC = 0x5555551e24 *)
broadcast %mull 4 [%v1[2]]; smulj %mlal [%v7[0],%v7[1],%v7[2],%v7[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v7.8h, v1.h[2]                    #! PC = 0x5555551e28 *)
broadcast %mull 4 [%v1[2]]; smulj %mlal [%v7[4],%v7[5],%v7[6],%v7[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v7.16b, v6.16b, v18.16b, #10                #! PC = 0x5555551e2c *)
mov %v7 [%v6[5],%v6[6],%v6[7],%v18[0],%v18[1],%v18[2],%v18[3],%v18[4]];
(* smlal	v3.4s, v7.4h, v1.h[3]                     #! PC = 0x5555551e30 *)
broadcast %mull 4 [%v1[3]]; smulj %mlal [%v7[0],%v7[1],%v7[2],%v7[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v7.8h, v1.h[3]                    #! PC = 0x5555551e34 *)
broadcast %mull 4 [%v1[3]]; smulj %mlal [%v7[4],%v7[5],%v7[6],%v7[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v7.16b, v6.16b, v18.16b, #8                 #! PC = 0x5555551e38 *)
mov %v7 [%v6[4],%v6[5],%v6[6],%v6[7],%v18[0],%v18[1],%v18[2],%v18[3]];
(* smlal	v3.4s, v7.4h, v1.h[4]                     #! PC = 0x5555551e3c *)
broadcast %mull 4 [%v1[4]]; smulj %mlal [%v7[0],%v7[1],%v7[2],%v7[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v7.8h, v1.h[4]                    #! PC = 0x5555551e40 *)
broadcast %mull 4 [%v1[4]]; smulj %mlal [%v7[4],%v7[5],%v7[6],%v7[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v7.16b, v6.16b, v18.16b, #6                 #! PC = 0x5555551e44 *)
mov %v7 [%v6[3],%v6[4],%v6[5],%v6[6],%v6[7],%v18[0],%v18[1],%v18[2]];
(* smlal	v3.4s, v7.4h, v1.h[5]                     #! PC = 0x5555551e48 *)
broadcast %mull 4 [%v1[5]]; smulj %mlal [%v7[0],%v7[1],%v7[2],%v7[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v7.8h, v1.h[5]                    #! PC = 0x5555551e4c *)
broadcast %mull 4 [%v1[5]]; smulj %mlal [%v7[4],%v7[5],%v7[6],%v7[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v7.16b, v6.16b, v18.16b, #4                 #! PC = 0x5555551e50 *)
mov %v7 [%v6[2],%v6[3],%v6[4],%v6[5],%v6[6],%v6[7],%v18[0],%v18[1]];
(* smlal	v3.4s, v7.4h, v1.h[6]                     #! PC = 0x5555551e54 *)
broadcast %mull 4 [%v1[6]]; smulj %mlal [%v7[0],%v7[1],%v7[2],%v7[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v7.8h, v1.h[6]                    #! PC = 0x5555551e58 *)
broadcast %mull 4 [%v1[6]]; smulj %mlal [%v7[4],%v7[5],%v7[6],%v7[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v6.16b, v6.16b, v18.16b, #2                 #! PC = 0x5555551e5c *)
mov %v6 [%v6[1],%v6[2],%v6[3],%v6[4],%v6[5],%v6[6],%v6[7],%v18[0]];
(* smlal	v3.4s, v6.4h, v1.h[7]                     #! PC = 0x5555551e60 *)
broadcast %mull 4 [%v1[7]]; smulj %mlal [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v6.8h, v1.h[7]                    #! PC = 0x5555551e64 *)
broadcast %mull 4 [%v1[7]]; smulj %mlal [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; adds %dc %v2 %v2 %mlal;

ghost %conv0_2@sint32[8], %conv1_2@sint32[8] :
    %conv0_2 = [
        %fc0_2[0] * %fd0_2[0] + %fc0_2[1] * %gd0_2[7] + %fc0_2[2] * %gd0_2[6] + %fc0_2[3] * %gd0_2[5] + %fc0_2[4] * %gd0_2[4] + %fc0_2[5] * %gd0_2[3] + %fc0_2[6] * %gd0_2[2] + %fc0_2[7] * %gd0_2[1],
        %fc0_2[0] * %fd0_2[1] + %fc0_2[1] * %fd0_2[0] + %fc0_2[2] * %gd0_2[7] + %fc0_2[3] * %gd0_2[6] + %fc0_2[4] * %gd0_2[5] + %fc0_2[5] * %gd0_2[4] + %fc0_2[6] * %gd0_2[3] + %fc0_2[7] * %gd0_2[2],
        %fc0_2[0] * %fd0_2[2] + %fc0_2[1] * %fd0_2[1] + %fc0_2[2] * %fd0_2[0] + %fc0_2[3] * %gd0_2[7] + %fc0_2[4] * %gd0_2[6] + %fc0_2[5] * %gd0_2[5] + %fc0_2[6] * %gd0_2[4] + %fc0_2[7] * %gd0_2[3],
        %fc0_2[0] * %fd0_2[3] + %fc0_2[1] * %fd0_2[2] + %fc0_2[2] * %fd0_2[1] + %fc0_2[3] * %fd0_2[0] + %fc0_2[4] * %gd0_2[7] + %fc0_2[5] * %gd0_2[6] + %fc0_2[6] * %gd0_2[5] + %fc0_2[7] * %gd0_2[4],
        %fc0_2[0] * %fd0_2[4] + %fc0_2[1] * %fd0_2[3] + %fc0_2[2] * %fd0_2[2] + %fc0_2[3] * %fd0_2[1] + %fc0_2[4] * %fd0_2[0] + %fc0_2[5] * %gd0_2[7] + %fc0_2[6] * %gd0_2[6] + %fc0_2[7] * %gd0_2[5],
        %fc0_2[0] * %fd0_2[5] + %fc0_2[1] * %fd0_2[4] + %fc0_2[2] * %fd0_2[3] + %fc0_2[3] * %fd0_2[2] + %fc0_2[4] * %fd0_2[1] + %fc0_2[5] * %fd0_2[0] + %fc0_2[6] * %gd0_2[7] + %fc0_2[7] * %gd0_2[6],
        %fc0_2[0] * %fd0_2[6] + %fc0_2[1] * %fd0_2[5] + %fc0_2[2] * %fd0_2[4] + %fc0_2[3] * %fd0_2[3] + %fc0_2[4] * %fd0_2[2] + %fc0_2[5] * %fd0_2[1] + %fc0_2[6] * %fd0_2[0] + %fc0_2[7] * %gd0_2[7],
        %fc0_2[0] * %fd0_2[7] + %fc0_2[1] * %fd0_2[6] + %fc0_2[2] * %fd0_2[5] + %fc0_2[3] * %fd0_2[4] + %fc0_2[4] * %fd0_2[3] + %fc0_2[5] * %fd0_2[2] + %fc0_2[6] * %fd0_2[1] + %fc0_2[7] * %fd0_2[0]
    ] /\
    %conv1_2 = [
        %fc1_2[0] * %fd1_2[0] + %fc1_2[1] * %gd1_2[7] + %fc1_2[2] * %gd1_2[6] + %fc1_2[3] * %gd1_2[5] + %fc1_2[4] * %gd1_2[4] + %fc1_2[5] * %gd1_2[3] + %fc1_2[6] * %gd1_2[2] + %fc1_2[7] * %gd1_2[1],
        %fc1_2[0] * %fd1_2[1] + %fc1_2[1] * %fd1_2[0] + %fc1_2[2] * %gd1_2[7] + %fc1_2[3] * %gd1_2[6] + %fc1_2[4] * %gd1_2[5] + %fc1_2[5] * %gd1_2[4] + %fc1_2[6] * %gd1_2[3] + %fc1_2[7] * %gd1_2[2],
        %fc1_2[0] * %fd1_2[2] + %fc1_2[1] * %fd1_2[1] + %fc1_2[2] * %fd1_2[0] + %fc1_2[3] * %gd1_2[7] + %fc1_2[4] * %gd1_2[6] + %fc1_2[5] * %gd1_2[5] + %fc1_2[6] * %gd1_2[4] + %fc1_2[7] * %gd1_2[3],
        %fc1_2[0] * %fd1_2[3] + %fc1_2[1] * %fd1_2[2] + %fc1_2[2] * %fd1_2[1] + %fc1_2[3] * %fd1_2[0] + %fc1_2[4] * %gd1_2[7] + %fc1_2[5] * %gd1_2[6] + %fc1_2[6] * %gd1_2[5] + %fc1_2[7] * %gd1_2[4],
        %fc1_2[0] * %fd1_2[4] + %fc1_2[1] * %fd1_2[3] + %fc1_2[2] * %fd1_2[2] + %fc1_2[3] * %fd1_2[1] + %fc1_2[4] * %fd1_2[0] + %fc1_2[5] * %gd1_2[7] + %fc1_2[6] * %gd1_2[6] + %fc1_2[7] * %gd1_2[5],
        %fc1_2[0] * %fd1_2[5] + %fc1_2[1] * %fd1_2[4] + %fc1_2[2] * %fd1_2[3] + %fc1_2[3] * %fd1_2[2] + %fc1_2[4] * %fd1_2[1] + %fc1_2[5] * %fd1_2[0] + %fc1_2[6] * %gd1_2[7] + %fc1_2[7] * %gd1_2[6],
        %fc1_2[0] * %fd1_2[6] + %fc1_2[1] * %fd1_2[5] + %fc1_2[2] * %fd1_2[4] + %fc1_2[3] * %fd1_2[3] + %fc1_2[4] * %fd1_2[2] + %fc1_2[5] * %fd1_2[1] + %fc1_2[6] * %fd1_2[0] + %fc1_2[7] * %gd1_2[7],
        %fc1_2[0] * %fd1_2[7] + %fc1_2[1] * %fd1_2[6] + %fc1_2[2] * %fd1_2[5] + %fc1_2[3] * %fd1_2[4] + %fc1_2[4] * %fd1_2[3] + %fc1_2[5] * %fd1_2[2] + %fc1_2[6] * %fd1_2[1] + %fc1_2[7] * %fd1_2[0]
    ]
    && true;

assert
    %v0 ++ %v4 = %conv0_2 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] ) /\
    %v3 ++ %v2 = %conv1_2 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] )
    && true;

assume
    %v0 ++ %v4 = %conv0_2 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] ) /\
    %v3 ++ %v2 = %conv1_2 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] )
    && true;

assert
    %conv0_2 <= [524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000] /\
    %conv0_2 >= [-524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000] /\

    %conv1_2 <= [524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000] /\
    %conv1_2 >= [-524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000]
    prove with [algebra solver smt: z3]
    && true;

assume
    %conv0_2 <= [524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000] /\
    %conv0_2 >= [-524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000] /\

    %conv1_2 <= [524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000] /\
    %conv1_2 >= [-524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000]
    && true;

assert
    %v0 ++ %v4 = %conv0_2 /\ %v3 ++ %v2 = %conv1_2
    prove with [algebra solver isl]
    && true;

assume
    %v0 ++ %v4 = %conv0_2 /\ %v3 ++ %v2 = %conv1_2
    && true;

assert
    %v0 <= [524880000, 524880000, 524880000, 524880000] /\
    %v0 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v4 <= [524880000, 524880000, 524880000, 524880000] /\
    %v4 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v3 <= [524880000, 524880000, 524880000, 524880000] /\
    %v3 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v2 <= [524880000, 524880000, 524880000, 524880000] /\
    %v2 >= [-524880000, -524880000, -524880000, -524880000]

    prove with [algebra solver isl]
    && true;

assume
    %v0 <= [524880000, 524880000, 524880000, 524880000] /\
    %v0 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v4 <= [524880000, 524880000, 524880000, 524880000] /\
    %v4 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v3 <= [524880000, 524880000, 524880000, 524880000] /\
    %v3 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v2 <= [524880000, 524880000, 524880000, 524880000] /\
    %v2 >= [-524880000, -524880000, -524880000, -524880000]
  &&
    %v0 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v0 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32] /\

    %v4 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v4 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32] /\

    %v3 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v3 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32] /\

    %v2 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v2 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32];

cut (* 11 *)
    %conv0_2 = [
        %fc0_2[0] * %fd0_2[0] + %fc0_2[1] * %gd0_2[7] + %fc0_2[2] * %gd0_2[6] + %fc0_2[3] * %gd0_2[5] + %fc0_2[4] * %gd0_2[4] + %fc0_2[5] * %gd0_2[3] + %fc0_2[6] * %gd0_2[2] + %fc0_2[7] * %gd0_2[1],
        %fc0_2[0] * %fd0_2[1] + %fc0_2[1] * %fd0_2[0] + %fc0_2[2] * %gd0_2[7] + %fc0_2[3] * %gd0_2[6] + %fc0_2[4] * %gd0_2[5] + %fc0_2[5] * %gd0_2[4] + %fc0_2[6] * %gd0_2[3] + %fc0_2[7] * %gd0_2[2],
        %fc0_2[0] * %fd0_2[2] + %fc0_2[1] * %fd0_2[1] + %fc0_2[2] * %fd0_2[0] + %fc0_2[3] * %gd0_2[7] + %fc0_2[4] * %gd0_2[6] + %fc0_2[5] * %gd0_2[5] + %fc0_2[6] * %gd0_2[4] + %fc0_2[7] * %gd0_2[3],
        %fc0_2[0] * %fd0_2[3] + %fc0_2[1] * %fd0_2[2] + %fc0_2[2] * %fd0_2[1] + %fc0_2[3] * %fd0_2[0] + %fc0_2[4] * %gd0_2[7] + %fc0_2[5] * %gd0_2[6] + %fc0_2[6] * %gd0_2[5] + %fc0_2[7] * %gd0_2[4],
        %fc0_2[0] * %fd0_2[4] + %fc0_2[1] * %fd0_2[3] + %fc0_2[2] * %fd0_2[2] + %fc0_2[3] * %fd0_2[1] + %fc0_2[4] * %fd0_2[0] + %fc0_2[5] * %gd0_2[7] + %fc0_2[6] * %gd0_2[6] + %fc0_2[7] * %gd0_2[5],
        %fc0_2[0] * %fd0_2[5] + %fc0_2[1] * %fd0_2[4] + %fc0_2[2] * %fd0_2[3] + %fc0_2[3] * %fd0_2[2] + %fc0_2[4] * %fd0_2[1] + %fc0_2[5] * %fd0_2[0] + %fc0_2[6] * %gd0_2[7] + %fc0_2[7] * %gd0_2[6],
        %fc0_2[0] * %fd0_2[6] + %fc0_2[1] * %fd0_2[5] + %fc0_2[2] * %fd0_2[4] + %fc0_2[3] * %fd0_2[3] + %fc0_2[4] * %fd0_2[2] + %fc0_2[5] * %fd0_2[1] + %fc0_2[6] * %fd0_2[0] + %fc0_2[7] * %gd0_2[7],
        %fc0_2[0] * %fd0_2[7] + %fc0_2[1] * %fd0_2[6] + %fc0_2[2] * %fd0_2[5] + %fc0_2[3] * %fd0_2[4] + %fc0_2[4] * %fd0_2[3] + %fc0_2[5] * %fd0_2[2] + %fc0_2[6] * %fd0_2[1] + %fc0_2[7] * %fd0_2[0]
    ] /\
    %conv1_2 = [
        %fc1_2[0] * %fd1_2[0] + %fc1_2[1] * %gd1_2[7] + %fc1_2[2] * %gd1_2[6] + %fc1_2[3] * %gd1_2[5] + %fc1_2[4] * %gd1_2[4] + %fc1_2[5] * %gd1_2[3] + %fc1_2[6] * %gd1_2[2] + %fc1_2[7] * %gd1_2[1],
        %fc1_2[0] * %fd1_2[1] + %fc1_2[1] * %fd1_2[0] + %fc1_2[2] * %gd1_2[7] + %fc1_2[3] * %gd1_2[6] + %fc1_2[4] * %gd1_2[5] + %fc1_2[5] * %gd1_2[4] + %fc1_2[6] * %gd1_2[3] + %fc1_2[7] * %gd1_2[2],
        %fc1_2[0] * %fd1_2[2] + %fc1_2[1] * %fd1_2[1] + %fc1_2[2] * %fd1_2[0] + %fc1_2[3] * %gd1_2[7] + %fc1_2[4] * %gd1_2[6] + %fc1_2[5] * %gd1_2[5] + %fc1_2[6] * %gd1_2[4] + %fc1_2[7] * %gd1_2[3],
        %fc1_2[0] * %fd1_2[3] + %fc1_2[1] * %fd1_2[2] + %fc1_2[2] * %fd1_2[1] + %fc1_2[3] * %fd1_2[0] + %fc1_2[4] * %gd1_2[7] + %fc1_2[5] * %gd1_2[6] + %fc1_2[6] * %gd1_2[5] + %fc1_2[7] * %gd1_2[4],
        %fc1_2[0] * %fd1_2[4] + %fc1_2[1] * %fd1_2[3] + %fc1_2[2] * %fd1_2[2] + %fc1_2[3] * %fd1_2[1] + %fc1_2[4] * %fd1_2[0] + %fc1_2[5] * %gd1_2[7] + %fc1_2[6] * %gd1_2[6] + %fc1_2[7] * %gd1_2[5],
        %fc1_2[0] * %fd1_2[5] + %fc1_2[1] * %fd1_2[4] + %fc1_2[2] * %fd1_2[3] + %fc1_2[3] * %fd1_2[2] + %fc1_2[4] * %fd1_2[1] + %fc1_2[5] * %fd1_2[0] + %fc1_2[6] * %gd1_2[7] + %fc1_2[7] * %gd1_2[6],
        %fc1_2[0] * %fd1_2[6] + %fc1_2[1] * %fd1_2[5] + %fc1_2[2] * %fd1_2[4] + %fc1_2[3] * %fd1_2[3] + %fc1_2[4] * %fd1_2[2] + %fc1_2[5] * %fd1_2[1] + %fc1_2[6] * %fd1_2[0] + %fc1_2[7] * %gd1_2[7],
        %fc1_2[0] * %fd1_2[7] + %fc1_2[1] * %fd1_2[6] + %fc1_2[2] * %fd1_2[5] + %fc1_2[3] * %fd1_2[4] + %fc1_2[4] * %fd1_2[3] + %fc1_2[5] * %fd1_2[2] + %fc1_2[6] * %fd1_2[1] + %fc1_2[7] * %fd1_2[0]
    ] /\

    %v0 ++ %v4 = %conv0_2 /\ %v3 ++ %v2 = %conv1_2,

    %v0 <= [524880000, 524880000, 524880000, 524880000] /\
    %v0 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v4 <= [524880000, 524880000, 524880000, 524880000] /\
    %v4 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v3 <= [524880000, 524880000, 524880000, 524880000] /\
    %v3 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v2 <= [524880000, 524880000, 524880000, 524880000] /\
    %v2 >= [-524880000, -524880000, -524880000, -524880000]

    prove with [algebra solver isl]
  &&
    %v0 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v0 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32] /\

    %v4 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v4 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32] /\

    %v3 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v3 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32] /\

    %v2 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v2 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32];

(* add	v1.4s, v3.4s, v0.4s                         #! PC = 0x5555551e68 *)
add %v1 %v3 %v0;
(* add	v6.4s, v2.4s, v4.4s                         #! PC = 0x5555551e6c *)
add %v6 %v2 %v4;
(* sub	v0.4s, v0.4s, v3.4s                         #! PC = 0x5555551e70 *)
sub %v0 %v0 %v3;
(* sub	v4.4s, v4.4s, v2.4s                         #! PC = 0x5555551e74 *)
sub %v4 %v4 %v2;

ghost %h0_2@sint32[8], %h1_2@sint32[8] :
    %h0_2 = %v1 ++ %v6 /\ %h1_2 = %v0 ++ %v4
  &&
    %h0_2 = %v1 ++ %v6 /\ %h1_2 = %v0 ++ %v4;

(* uzp1	v2.8h, v1.8h, v6.8h                        #! PC = 0x5555551e78 *)
mov %spl_join [%v1[0], %v1[1], %v1[2], %v1[3], %v6[0], %v6[1], %v6[2], %v6[3]]; spl %splh %v2 %spl_join 16; cast %v2@int16[8] %v2;
(* mul	v2.8h, v2.8h, v5.h[7]                       #! PC = 0x5555551e7c *)
broadcast %mul 8 [%v5[7]]; mull %dc %v2 %v2 %mul; cast %v2@int16[8] %v2;

ghost %m0_2@sint16[8] : %m0_2 = %v2 && %m0_2 = %v2;

(* sqdmulh	v2.8h, v2.8h, v5.h[6]                   #! PC = 0x5555551e80 *)
broadcast %mul 8 [%v5[6]]; smulj %LO %v2 %mul;
ssplit %LO0 %dc %LO 15; vpc %v2@sint16[8] %LO0;
(* uzp2	v1.8h, v1.8h, v6.8h                        #! PC = 0x5555551e84 *)
mov %spl_join [%v1[0], %v1[1], %v1[2], %v1[3], %v6[0], %v6[1], %v6[2], %v6[3]]; spl %v1 %spll %spl_join 16;
(* sshr	v2.8h, v2.8h, #1                           #! PC = 0x5555551e88 *)
split %v2 %dc %v2 1;
(* sub	v1.8h, v1.8h, v2.8h                         #! PC = 0x5555551e8c *)
sub %v1 %v1 %v2;

ghost %hh0_2@sint16[8] : %hh0_2 = %v1 && %hh0_2 = %v1;

assert
    %h0_2 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m0_2
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh0_2
    prove with [algebra solver isl]
    && true;

assume
    %h0_2 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m0_2
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh0_2
    && true;

(* sqrdmulh	v2.8h, v1.8h, v5.h[3]                  #! PC = 0x5555551e90 *)
broadcast %mul 8 [%v5[3]]; smulj %LO %v1 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v2 %LO11 %LO01;
(* mul	v1.8h, v1.8h, v5.h[2]                       #! PC = 0x5555551e94 *)
broadcast %mul 8 [%v5[2]]; mull %dc %v1 %v1 %mul; cast %v1@int16[8] %v1;
(* mls	v1.8h, v2.8h, v5.h[6]                       #! PC = 0x5555551e98 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v2 %mul;
cast %mls@int16[8] %mls; subc %dc %v1 %v1 %mls;

assert
    [-129, -129, -129, -129, -129, -129, -129, -129] * %hh0_2
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v2
    = %v1
    prove with [algebra solver isl]
    && true;

assume
    [-129, -129, -129, -129, -129, -129, -129, -129] * %hh0_2
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v2
    = %v1
    && true;

(* uzp1	v2.8h, v0.8h, v4.8h                        #! PC = 0x5555551e9c *)
mov %spl_join [%v0[0], %v0[1], %v0[2], %v0[3], %v4[0], %v4[1], %v4[2], %v4[3]]; spl %splh %v2 %spl_join 16; cast %v2@int16[8] %v2;
(* mul	v2.8h, v2.8h, v5.h[7]                       #! PC = 0x5555551ea0 *)
broadcast %mul 8 [%v5[7]]; mull %dc %v2 %v2 %mul; cast %v2@int16[8] %v2;

ghost %m1_2@sint16[8] : %m1_2 = %v2 && %m1_2 = %v2;

(* sqdmulh	v2.8h, v2.8h, v5.h[6]                   #! PC = 0x5555551ea4 *)
broadcast %mul 8 [%v5[6]]; smulj %LO %v2 %mul;
ssplit %LO0 %dc %LO 15; vpc %v2@sint16[8] %LO0;
(* uzp2	v0.8h, v0.8h, v4.8h                        #! PC = 0x5555551ea8 *)
mov %spl_join [%v0[0], %v0[1], %v0[2], %v0[3], %v4[0], %v4[1], %v4[2], %v4[3]]; spl %v0 %spll %spl_join 16;
(* sshr	v2.8h, v2.8h, #1                           #! PC = 0x5555551eac *)
split %v2 %dc %v2 1;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551eb0 *)
sub %v0 %v0 %v2;

ghost %hh1_2@sint16[8] : %hh1_2 = %v0 && %hh1_2 = %v0;

assert
    %h1_2 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m1_2
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh1_2
    prove with [algebra solver isl]
    && true;

assume
    %h1_2 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m1_2
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh1_2
    && true;

(* sqrdmulh	v2.8h, v0.8h, v5.h[5]                  #! PC = 0x5555551eb4 *)
broadcast %mul 8 [%v5[5]]; smulj %LO %v0 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v2 %LO11 %LO01;
(* mul	v0.8h, v0.8h, v5.h[4]                       #! PC = 0x5555551eb8 *)
broadcast %mul 8 [%v5[4]]; mull %dc %v0 %v0 %mul; cast %v0@int16[8] %v0;
(* mls	v0.8h, v2.8h, v5.h[6]                       #! PC = 0x5555551ebc *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v2 %mul;
cast %mls@int16[8] %mls; subc %dc %v0 %v0 %mls;

assert
    [1708, 1708, 1708, 1708, 1708, 1708, 1708, 1708] * %hh1_2
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v2
    = %v0
    prove with [algebra solver isl]
    && true;

assume
    [1708, 1708, 1708, 1708, 1708, 1708, 1708, 1708] * %hh1_2
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v2
    = %v0
    && true;

(* #b	0x5555551d18 <_ZN6xpower7basemul11low_basemulEPA2_A8_sS3_S3_+504>#! PC = 0x5555551ec0 *)
#b	0x5555551d18 <_ZN6xpower7basemul11low_basemulEPA2_A8_sS3_S3_+504>#! 0x5555551ec0 = 0x5555551ec0;


### i_iter epilogue

(* str	q1, [x2, x3]                                #! EA = L0x7fffffe1f0; PC = 0x5555551d18 *)
mov [L0x7fffffe1f0,L0x7fffffe1f2,L0x7fffffe1f4,L0x7fffffe1f6,L0x7fffffe1f8,L0x7fffffe1fa,L0x7fffffe1fc,L0x7fffffe1fe] %v1;
(* str	q0, [x6, x3]                                #! EA = L0x7fffffe200; PC = 0x5555551d1c *)
mov [L0x7fffffe200,L0x7fffffe202,L0x7fffffe204,L0x7fffffe206,L0x7fffffe208,L0x7fffffe20a,L0x7fffffe20c,L0x7fffffe20e] %v0;
(* #b.eq	0x5555551ec4 <_ZN6xpower7basemul11low_basemulEPA2_A8_sS3_S3_+932>  // b.none#! PC = 0x5555551d30 *)
#b.eq	0x5555551ec4 <_ZN6xpower7basemul11low_basemulEPA2_A8_sS3_S3_+932>  // b.none#! 0x5555551d30 = 0x5555551d30;

assert
    %v1 <= [3550, 3550, 3550, 3550, 3550, 3550, 3550, 3550] /\
    %v1 >= [-3550, -3550, -3550, -3550, -3550, -3550, -3550, -3550] /\

    %v0 <= [3450, 3450, 3450, 3450, 3450, 3450, 3450, 3450] /\
    %v0 >= [-3450, -3450, -3450, -3450, -3450, -3450, -3450, -3450]

    prove with [algebra solver isl]
    && true;

assume
    true &&

    %v1 <=s [3550@16, 3550@16, 3550@16, 3550@16, 3550@16, 3550@16, 3550@16, 3550@16] /\
    %v1 >=s [(-3550)@16, (-3550)@16, (-3550)@16, (-3550)@16, (-3550)@16, (-3550)@16, (-3550)@16, (-3550)@16] /\

    %v0 <=s [3450@16, 3450@16, 3450@16, 3450@16, 3450@16, 3450@16, 3450@16, 3450@16] /\
    %v0 >=s [(-3450)@16, (-3450)@16, (-3450)@16, (-3450)@16, (-3450)@16, (-3450)@16, (-3450)@16, (-3450)@16];

cut (* 12 *)
    [L0x7fffffe1f0, L0x7fffffe1f2, L0x7fffffe1f4, L0x7fffffe1f6, L0x7fffffe1f8, L0x7fffffe1fa, L0x7fffffe1fc, L0x7fffffe1fe] = %v1 /\
    [L0x7fffffe200, L0x7fffffe202, L0x7fffffe204, L0x7fffffe206, L0x7fffffe208, L0x7fffffe20a, L0x7fffffe20c, L0x7fffffe20e] = %v0 /\

    %v1 ++ %v0 = [-2132, -2132, -2132, -2132, -2132, -2132, -2132, -2132, -2132, -2132, -2132, -2132, -2132, -2132, -2132, -2132] * [
        arr200_a * arr200_b + -1815 * arr201_a * arr217_b + -1815 * arr202_a * arr216_b + -1815 * arr203_a * arr215_b + -1815 * arr204_a * arr214_b + -1815 * arr205_a * arr213_b + -1815 * arr206_a * arr212_b + -1815 * arr207_a * arr211_b + -1815 * arr210_a * arr210_b + -1815 * arr211_a * arr207_b + -1815 * arr212_a * arr206_b + -1815 * arr213_a * arr205_b + -1815 * arr214_a * arr204_b + -1815 * arr215_a * arr203_b + -1815 * arr216_a * arr202_b + -1815 * arr217_a * arr201_b,
        arr200_a * arr201_b + arr201_a * arr200_b + -1815 * arr202_a * arr217_b + -1815 * arr203_a * arr216_b + -1815 * arr204_a * arr215_b + -1815 * arr205_a * arr214_b + -1815 * arr206_a * arr213_b + -1815 * arr207_a * arr212_b + -1815 * arr210_a * arr211_b + -1815 * arr211_a * arr210_b + -1815 * arr212_a * arr207_b + -1815 * arr213_a * arr206_b + -1815 * arr214_a * arr205_b + -1815 * arr215_a * arr204_b + -1815 * arr216_a * arr203_b + -1815 * arr217_a * arr202_b,
        arr200_a * arr202_b + arr201_a * arr201_b + arr202_a * arr200_b + -1815 * arr203_a * arr217_b + -1815 * arr204_a * arr216_b + -1815 * arr205_a * arr215_b + -1815 * arr206_a * arr214_b + -1815 * arr207_a * arr213_b + -1815 * arr210_a * arr212_b + -1815 * arr211_a * arr211_b + -1815 * arr212_a * arr210_b + -1815 * arr213_a * arr207_b + -1815 * arr214_a * arr206_b + -1815 * arr215_a * arr205_b + -1815 * arr216_a * arr204_b + -1815 * arr217_a * arr203_b,
        arr200_a * arr203_b + arr201_a * arr202_b + arr202_a * arr201_b + arr203_a * arr200_b + -1815 * arr204_a * arr217_b + -1815 * arr205_a * arr216_b + -1815 * arr206_a * arr215_b + -1815 * arr207_a * arr214_b + -1815 * arr210_a * arr213_b + -1815 * arr211_a * arr212_b + -1815 * arr212_a * arr211_b + -1815 * arr213_a * arr210_b + -1815 * arr214_a * arr207_b + -1815 * arr215_a * arr206_b + -1815 * arr216_a * arr205_b + -1815 * arr217_a * arr204_b,
        arr200_a * arr204_b + arr201_a * arr203_b + arr202_a * arr202_b + arr203_a * arr201_b + arr204_a * arr200_b + -1815 * arr205_a * arr217_b + -1815 * arr206_a * arr216_b + -1815 * arr207_a * arr215_b + -1815 * arr210_a * arr214_b + -1815 * arr211_a * arr213_b + -1815 * arr212_a * arr212_b + -1815 * arr213_a * arr211_b + -1815 * arr214_a * arr210_b + -1815 * arr215_a * arr207_b + -1815 * arr216_a * arr206_b + -1815 * arr217_a * arr205_b,
        arr200_a * arr205_b + arr201_a * arr204_b + arr202_a * arr203_b + arr203_a * arr202_b + arr204_a * arr201_b + arr205_a * arr200_b + -1815 * arr206_a * arr217_b + -1815 * arr207_a * arr216_b + -1815 * arr210_a * arr215_b + -1815 * arr211_a * arr214_b + -1815 * arr212_a * arr213_b + -1815 * arr213_a * arr212_b + -1815 * arr214_a * arr211_b + -1815 * arr215_a * arr210_b + -1815 * arr216_a * arr207_b + -1815 * arr217_a * arr206_b,
        arr200_a * arr206_b + arr201_a * arr205_b + arr202_a * arr204_b + arr203_a * arr203_b + arr204_a * arr202_b + arr205_a * arr201_b + arr206_a * arr200_b + -1815 * arr207_a * arr217_b + -1815 * arr210_a * arr216_b + -1815 * arr211_a * arr215_b + -1815 * arr212_a * arr214_b + -1815 * arr213_a * arr213_b + -1815 * arr214_a * arr212_b + -1815 * arr215_a * arr211_b + -1815 * arr216_a * arr210_b + -1815 * arr217_a * arr207_b,
        arr200_a * arr207_b + arr201_a * arr206_b + arr202_a * arr205_b + arr203_a * arr204_b + arr204_a * arr203_b + arr205_a * arr202_b + arr206_a * arr201_b + arr207_a * arr200_b + -1815 * arr210_a * arr217_b + -1815 * arr211_a * arr216_b + -1815 * arr212_a * arr215_b + -1815 * arr213_a * arr214_b + -1815 * arr214_a * arr213_b + -1815 * arr215_a * arr212_b + -1815 * arr216_a * arr211_b + -1815 * arr217_a * arr210_b,
        arr200_a * arr210_b + arr201_a * arr207_b + arr202_a * arr206_b + arr203_a * arr205_b + arr204_a * arr204_b + arr205_a * arr203_b + arr206_a * arr202_b + arr207_a * arr201_b + arr210_a * arr200_b + -1815 * arr211_a * arr217_b + -1815 * arr212_a * arr216_b + -1815 * arr213_a * arr215_b + -1815 * arr214_a * arr214_b + -1815 * arr215_a * arr213_b + -1815 * arr216_a * arr212_b + -1815 * arr217_a * arr211_b,
        arr200_a * arr211_b + arr201_a * arr210_b + arr202_a * arr207_b + arr203_a * arr206_b + arr204_a * arr205_b + arr205_a * arr204_b + arr206_a * arr203_b + arr207_a * arr202_b + arr210_a * arr201_b + arr211_a * arr200_b + -1815 * arr212_a * arr217_b + -1815 * arr213_a * arr216_b + -1815 * arr214_a * arr215_b + -1815 * arr215_a * arr214_b + -1815 * arr216_a * arr213_b + -1815 * arr217_a * arr212_b,
        arr200_a * arr212_b + arr201_a * arr211_b + arr202_a * arr210_b + arr203_a * arr207_b + arr204_a * arr206_b + arr205_a * arr205_b + arr206_a * arr204_b + arr207_a * arr203_b + arr210_a * arr202_b + arr211_a * arr201_b + arr212_a * arr200_b + -1815 * arr213_a * arr217_b + -1815 * arr214_a * arr216_b + -1815 * arr215_a * arr215_b + -1815 * arr216_a * arr214_b + -1815 * arr217_a * arr213_b,
        arr200_a * arr213_b + arr201_a * arr212_b + arr202_a * arr211_b + arr203_a * arr210_b + arr204_a * arr207_b + arr205_a * arr206_b + arr206_a * arr205_b + arr207_a * arr204_b + arr210_a * arr203_b + arr211_a * arr202_b + arr212_a * arr201_b + arr213_a * arr200_b + -1815 * arr214_a * arr217_b + -1815 * arr215_a * arr216_b + -1815 * arr216_a * arr215_b + -1815 * arr217_a * arr214_b,
        arr200_a * arr214_b + arr201_a * arr213_b + arr202_a * arr212_b + arr203_a * arr211_b + arr204_a * arr210_b + arr205_a * arr207_b + arr206_a * arr206_b + arr207_a * arr205_b + arr210_a * arr204_b + arr211_a * arr203_b + arr212_a * arr202_b + arr213_a * arr201_b + arr214_a * arr200_b + -1815 * arr215_a * arr217_b + -1815 * arr216_a * arr216_b + -1815 * arr217_a * arr215_b,
        arr200_a * arr215_b + arr201_a * arr214_b + arr202_a * arr213_b + arr203_a * arr212_b + arr204_a * arr211_b + arr205_a * arr210_b + arr206_a * arr207_b + arr207_a * arr206_b + arr210_a * arr205_b + arr211_a * arr204_b + arr212_a * arr203_b + arr213_a * arr202_b + arr214_a * arr201_b + arr215_a * arr200_b + -1815 * arr216_a * arr217_b + -1815 * arr217_a * arr216_b,
        arr200_a * arr216_b + arr201_a * arr215_b + arr202_a * arr214_b + arr203_a * arr213_b + arr204_a * arr212_b + arr205_a * arr211_b + arr206_a * arr210_b + arr207_a * arr207_b + arr210_a * arr206_b + arr211_a * arr205_b + arr212_a * arr204_b + arr213_a * arr203_b + arr214_a * arr202_b + arr215_a * arr201_b + arr216_a * arr200_b + -1815 * arr217_a * arr217_b,
        arr200_a * arr217_b + arr201_a * arr216_b + arr202_a * arr215_b + arr203_a * arr214_b + arr204_a * arr213_b + arr205_a * arr212_b + arr206_a * arr211_b + arr207_a * arr210_b + arr210_a * arr207_b + arr211_a * arr206_b + arr212_a * arr205_b + arr213_a * arr204_b + arr214_a * arr203_b + arr215_a * arr202_b + arr216_a * arr201_b + arr217_a * arr200_b
    ] ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] )

    prove with [cuts[0, 9, 10, 11]]
  &&
    [L0x7fffffe1f0, L0x7fffffe1f2, L0x7fffffe1f4, L0x7fffffe1f6, L0x7fffffe1f8, L0x7fffffe1fa, L0x7fffffe1fc, L0x7fffffe1fe] = %v1 /\
    [L0x7fffffe200, L0x7fffffe202, L0x7fffffe204, L0x7fffffe206, L0x7fffffe208, L0x7fffffe20a, L0x7fffffe20c, L0x7fffffe20e] = %v0 /\

    %v1 <=s [3550@16, 3550@16, 3550@16, 3550@16, 3550@16, 3550@16, 3550@16, 3550@16] /\
    %v1 >=s [(-3550)@16, (-3550)@16, (-3550)@16, (-3550)@16, (-3550)@16, (-3550)@16, (-3550)@16, (-3550)@16] /\

    %v0 <=s [3450@16, 3450@16, 3450@16, 3450@16, 3450@16, 3450@16, 3450@16, 3450@16] /\
    %v0 >=s [(-3450)@16, (-3450)@16, (-3450)@16, (-3450)@16, (-3450)@16, (-3450)@16, (-3450)@16, (-3450)@16];


### i_iter prologue

(* ldr	q4, [x0, x3]                                #! EA = L0x7fffffe490; Value = 0x0000000000000000; PC = 0x5555551d34 *)
mov %v4 [L0x7fffffe490,L0x7fffffe492,L0x7fffffe494,L0x7fffffe496,L0x7fffffe498,L0x7fffffe49a,L0x7fffffe49c,L0x7fffffe49e];
(* ldr	q1, [x8, x3]                                #! EA = L0x7fffffe4a0; Value = 0x0000000000000000; PC = 0x5555551d38 *)
mov %v1 [L0x7fffffe4a0,L0x7fffffe4a2,L0x7fffffe4a4,L0x7fffffe4a6,L0x7fffffe4a8,L0x7fffffe4aa,L0x7fffffe4ac,L0x7fffffe4ae];
(* ldr	q17, [x1, x3]                               #! EA = L0x7fffffe350; Value = 0x0000000000000000; PC = 0x5555551d3c *)
mov %v17 [L0x7fffffe350,L0x7fffffe352,L0x7fffffe354,L0x7fffffe356,L0x7fffffe358,L0x7fffffe35a,L0x7fffffe35c,L0x7fffffe35e];
(* ldr	q18, [x7, x3]                               #! EA = L0x7fffffe360; Value = 0x0000000000000000; PC = 0x5555551d40 *)
mov %v18 [L0x7fffffe360,L0x7fffffe362,L0x7fffffe364,L0x7fffffe366,L0x7fffffe368,L0x7fffffe36a,L0x7fffffe36c,L0x7fffffe36e];

ghost %fa0_3@sint16[8], %fa1_3@sint16[8], %fb0_3@sint16[8], %fb1_3@sint16[8] :
    %fa0_3 = %v4 /\ %fa1_3 = %v1 /\ %fb0_3 = %v17 /\ %fb1_3 = %v18
  &&
    %fa0_3 = %v4 /\ %fa1_3 = %v1 /\ %fb0_3 = %v17 /\ %fb1_3 = %v18;

cut (* 13 *)
    %fa0_3 = %v4 /\ %fa1_3 = %v1 /\ %fb0_3 = %v17 /\ %fb1_3 = %v18 /\
    %fa0_3 = [arr300_a, arr301_a, arr302_a, arr303_a, arr304_a, arr305_a, arr306_a, arr307_a] /\
    %fa1_3 = [arr310_a, arr311_a, arr312_a, arr313_a, arr314_a, arr315_a, arr316_a, arr317_a] /\
    %fb0_3 = [arr300_b, arr301_b, arr302_b, arr303_b, arr304_b, arr305_b, arr306_b, arr307_b] /\
    %fb1_3 = [arr310_b, arr311_b, arr312_b, arr313_b, arr314_b, arr315_b, arr316_b, arr317_b]
    prove with [cuts[0]]
  &&
    %fa0_3 = %v4 /\ %fa1_3 = %v1 /\ %fb0_3 = %v17 /\ %fb1_3 = %v18 /\
    %fa0_3 = [arr300_a, arr301_a, arr302_a, arr303_a, arr304_a, arr305_a, arr306_a, arr307_a] /\
    %fa1_3 = [arr310_a, arr311_a, arr312_a, arr313_a, arr314_a, arr315_a, arr316_a, arr317_a] /\
    %fb0_3 = [arr300_b, arr301_b, arr302_b, arr303_b, arr304_b, arr305_b, arr306_b, arr307_b] /\
    %fb1_3 = [arr310_b, arr311_b, arr312_b, arr313_b, arr314_b, arr315_b, arr316_b, arr317_b]
    prove with [cuts[0]];

#### karatsuba

(* ldr	q5, [x5]                                    #! EA = L0x5555552e30; Value = 0x3d0f088e3f6708e2; PC = 0x5555551b44 *)
mov %v5 [L0x5555552e30,L0x5555552e32,L0x5555552e34,L0x5555552e36,L0x5555552e38,L0x5555552e3a,L0x5555552e3c,L0x5555552e3e];
(* sshr	v0.8h, v4.8h, #12                          #! PC = 0x5555551b48 *)
split %v0 %dc %v4 12;
(* cmlt	v2.8h, v4.8h, #0                           #! PC = 0x5555551b4c *)
split %v2 %dc %v4 15;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551b50 *)
sub %v0 %v0 %v2;
(* mls	v4.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551b54 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v4 %v4 %mls;

assert
    %fa0_3 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v4
    prove with [algebra solver isl, precondition, cuts[0, 13]]
    && true;

assume
    %fa0_3 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v4
    && true;

(* sshr	v0.8h, v1.8h, #12                          #! PC = 0x5555551b58 *)
split %v0 %dc %v1 12;
(* cmlt	v2.8h, v1.8h, #0                           #! PC = 0x5555551b5c *)
split %v2 %dc %v1 15;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551b60 *)
sub %v0 %v0 %v2;
(* mls	v1.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551b64 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v1 %v1 %mls;

assert
    %fa1_3 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v1
    prove with [algebra solver isl, precondition, cuts[0, 13]]
    && true;

assume
    %fa1_3 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v1
    && true;

(* sshr	v0.8h, v17.8h, #12                         #! PC = 0x5555551b68 *)
split %v0 %dc %v17 12;
(* cmlt	v2.8h, v17.8h, #0                          #! PC = 0x5555551b6c *)
split %v2 %dc %v17 15;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551b70 *)
sub %v0 %v0 %v2;
(* mls	v17.8h, v0.8h, v5.h[6]                      #! PC = 0x5555551b74 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v17 %v17 %mls;

assert
    %fb0_3 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v17
    prove with [algebra solver isl, precondition, cuts[0, 13]]
    && true;

assume
    %fb0_3 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v17
    && true;

(* sshr	v0.8h, v18.8h, #12                         #! PC = 0x5555551b78 *)
split %v0 %dc %v18 12;
(* cmlt	v2.8h, v18.8h, #0                          #! PC = 0x5555551b7c *)
split %v2 %dc %v18 15;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551b80 *)
sub %v0 %v0 %v2;
(* mls	v18.8h, v0.8h, v5.h[6]                      #! PC = 0x5555551b84 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v18 %v18 %mls;

assert
    %fb1_3 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v18
    prove with [algebra solver isl, precondition, cuts[0, 13]]
    && true;

assume
    %fb1_3 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v18
    && true;

ghost %fc0_3@sint16[8], %fc1_3@sint16[8], %fd0_3@sint16[8], %fd1_3@sint16[8] :
    %fc0_3 = %v4 /\ %fc1_3 = %v1 /\ %fd0_3 = %v17 /\ %fd1_3 = %v18
  &&
    %fc0_3 = %v4 /\ %fc1_3 = %v1 /\ %fd0_3 = %v17 /\ %fd1_3 = %v18;

(* sqrdmulh	v0.8h, v17.8h, v5.h[1]                 #! PC = 0x5555551b88 *)
broadcast %mul 8 [%v5[1]]; smulj %LO %v17 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v0 %LO11 %LO01;
(* mul	v6.8h, v17.8h, v5.h[0]                      #! PC = 0x5555551b8c *)
broadcast %mul 8 [%v5[0]]; mull %dc %v6 %v17 %mul; cast %v6@int16[8] %v6;
(* mov	v7.16b, v6.16b                              #! PC = 0x5555551b90 *)
mov %v7 %v6;
(* mls	v7.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551b94 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v7 %v7 %mls;

assert
    [2274, 2274, 2274, 2274, 2274, 2274, 2274, 2274] * %fd0_3
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v7
    prove with [algebra solver isl, precondition, cuts[0, 13]]
    && true;

assume
    [2274, 2274, 2274, 2274, 2274, 2274, 2274, 2274] * %fd0_3
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v7
    && true;

(* sqrdmulh	v0.8h, v18.8h, v5.h[1]                 #! PC = 0x5555551b98 *)
broadcast %mul 8 [%v5[1]]; smulj %LO %v18 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v0 %LO11 %LO01;
(* mul	v3.8h, v18.8h, v5.h[0]                      #! PC = 0x5555551b9c *)
broadcast %mul 8 [%v5[0]]; mull %dc %v3 %v18 %mul; cast %v3@int16[8] %v3;
(* mls	v3.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551ba0 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v3 %v3 %mls;

assert
    [2274, 2274, 2274, 2274, 2274, 2274, 2274, 2274] * %fd1_3
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v3
    prove with [algebra solver isl, precondition, cuts[0, 13]]
    && true;

assume
    [2274, 2274, 2274, 2274, 2274, 2274, 2274, 2274] * %fd1_3
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v3
    && true;

ghost %fe0_3@sint16[8], %fe1_3@sint16[8] :
    %fe0_3 = %v7 /\ %fe1_3 = %v3
  &&
    %fe0_3 = %v7 /\ %fe1_3 = %v3;

cut (* 14 *)
    %fc0_3 = %v4 /\ %fc1_3 = %v1 /\ %fd0_3 = %v17 /\ %fd1_3 = %v18 /\ %fe0_3 = %v7 /\ %fe1_3 = %v3 /\

    %fc0_3 = %fa0_3 ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\
    %fc1_3 = %fa1_3 ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\
    %fd0_3 = %fb0_3 ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\
    %fd1_3 = %fb1_3 ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\

    %fe0_3 = [2274, 2274, 2274, 2274, 2274, 2274, 2274, 2274] * %fd0_3
    ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\

    %fe1_3 = [2274, 2274, 2274, 2274, 2274, 2274, 2274, 2274] * %fd1_3
    ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ),

    %fc0_3 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %fc0_3 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %fc1_3 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %fc1_3 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %fd0_3 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %fd0_3 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %fd1_3 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %fd1_3 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %fe0_3 <= [3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000] /\
    %fe0_3 >= [-3000, -3000, -3000, -3000, -3000, -3000, -3000, -3000] /\

    %fe1_3 <= [3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000] /\
    %fe1_3 >= [-3000, -3000, -3000, -3000, -3000, -3000, -3000, -3000]

    prove with [algebra solver isl, precondition, cuts[0, 13]]
  &&
    true
    prove with [precondition, cuts[0, 13]];

assert
    %v4 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %v4 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %v1 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %v1 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %v17 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %v17 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %v18 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %v18 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %v7 <= [3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000] /\
    %v7 >= [-3000, -3000, -3000, -3000, -3000, -3000, -3000, -3000] /\

    %v3 <= [3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000] /\
    %v3 >= [-3000, -3000, -3000, -3000, -3000, -3000, -3000, -3000]

    prove with [algebra solver isl, cuts[14]]
    && true;

assume
    true &&
    %v4 <=s [4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16] /\
    %v4 >=s [(-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16] /\

    %v1 <=s [4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16] /\
    %v1 >=s [(-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16] /\

    %v17 <=s [4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16] /\
    %v17 >=s [(-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16] /\

    %v18 <=s [4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16] /\
    %v18 >=s [(-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16] /\

    %v7 <=s [3000@16, 3000@16, 3000@16, 3000@16, 3000@16, 3000@16, 3000@16, 3000@16] /\
    %v7 >=s [(-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16] /\

    %v3 <=s [3000@16, 3000@16, 3000@16, 3000@16, 3000@16, 3000@16, 3000@16, 3000@16] /\
    %v3 >=s [(-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16];

(* add	v6.8h, v4.8h, v1.8h                         #! PC = 0x5555551ba4 *)
add %v6 %v4 %v1;
(* smull	v0.4s, v17.4h, v6.h[0]                    #! PC = 0x5555551ba8 *)
broadcast %mull 4 [%v6[0]]; smulj %v0 [%v17[0],%v17[1],%v17[2],%v17[3]] %mull;
(* smull2	v2.4s, v17.8h, v6.h[0]                   #! PC = 0x5555551bac *)
broadcast %mull 4 [%v6[0]]; smulj %v2 [%v17[4],%v17[5],%v17[6],%v17[7]] %mull;
(* ext	v16.16b, v3.16b, v17.16b, #14               #! PC = 0x5555551bb0 *)
mov %v16 [%v3[7],%v17[0],%v17[1],%v17[2],%v17[3],%v17[4],%v17[5],%v17[6]];
(* smlal	v0.4s, v16.4h, v6.h[1]                    #! PC = 0x5555551bb4 *)
broadcast %mull 4 [%v6[1]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[1]                   #! PC = 0x5555551bb8 *)
broadcast %mull 4 [%v6[1]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v16.16b, v3.16b, v17.16b, #12               #! PC = 0x5555551bbc *)
mov %v16 [%v3[6],%v3[7],%v17[0],%v17[1],%v17[2],%v17[3],%v17[4],%v17[5]];
(* smlal	v0.4s, v16.4h, v6.h[2]                    #! PC = 0x5555551bc0 *)
broadcast %mull 4 [%v6[2]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[2]                   #! PC = 0x5555551bc4 *)
broadcast %mull 4 [%v6[2]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v16.16b, v3.16b, v17.16b, #10               #! PC = 0x5555551bc8 *)
mov %v16 [%v3[5],%v3[6],%v3[7],%v17[0],%v17[1],%v17[2],%v17[3],%v17[4]];
(* smlal	v0.4s, v16.4h, v6.h[3]                    #! PC = 0x5555551bcc *)
broadcast %mull 4 [%v6[3]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[3]                   #! PC = 0x5555551bd0 *)
broadcast %mull 4 [%v6[3]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v16.16b, v3.16b, v17.16b, #8                #! PC = 0x5555551bd4 *)
mov %v16 [%v3[4],%v3[5],%v3[6],%v3[7],%v17[0],%v17[1],%v17[2],%v17[3]];
(* smlal	v0.4s, v16.4h, v6.h[4]                    #! PC = 0x5555551bd8 *)
broadcast %mull 4 [%v6[4]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[4]                   #! PC = 0x5555551bdc *)
broadcast %mull 4 [%v6[4]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v16.16b, v3.16b, v17.16b, #6                #! PC = 0x5555551be0 *)
mov %v16 [%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v17[0],%v17[1],%v17[2]];
(* smlal	v0.4s, v16.4h, v6.h[5]                    #! PC = 0x5555551be4 *)
broadcast %mull 4 [%v6[5]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[5]                   #! PC = 0x5555551be8 *)
broadcast %mull 4 [%v6[5]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v16.16b, v3.16b, v17.16b, #4                #! PC = 0x5555551bec *)
mov %v16 [%v3[2],%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v17[0],%v17[1]];
(* smlal	v0.4s, v16.4h, v6.h[6]                    #! PC = 0x5555551bf0 *)
broadcast %mull 4 [%v6[6]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[6]                   #! PC = 0x5555551bf4 *)
broadcast %mull 4 [%v6[6]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v16.16b, v3.16b, v17.16b, #2                #! PC = 0x5555551bf8 *)
mov %v16 [%v3[1],%v3[2],%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v17[0]];
(* smlal	v0.4s, v16.4h, v6.h[7]                    #! PC = 0x5555551bfc *)
broadcast %mull 4 [%v6[7]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[7]                   #! PC = 0x5555551c00 *)
broadcast %mull 4 [%v6[7]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* sub	v6.8h, v7.8h, v3.8h                         #! PC = 0x5555551c04 *)
sub %v6 %v7 %v3;
(* sub	v3.8h, v3.8h, v17.8h                        #! PC = 0x5555551c08 *)
sub %v3 %v3 %v17;
(* mov	v16.16b, v0.16b                             #! PC = 0x5555551c0c *)
mov %v16 %v0;
(* smlal	v16.4s, v3.4h, v1.h[0]                    #! PC = 0x5555551c10 *)
broadcast %mull 4 [%v1[0]]; smulj %mlal [%v3[0],%v3[1],%v3[2],%v3[3]] %mull; adds %dc %v16 %v16 %mlal;
(* mov	v7.16b, v2.16b                              #! PC = 0x5555551c14 *)
mov %v7 %v2;
(* smlal2	v7.4s, v3.8h, v1.h[0]                    #! PC = 0x5555551c18 *)
broadcast %mull 4 [%v1[0]]; smulj %mlal [%v3[4],%v3[5],%v3[6],%v3[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v19.16b, v6.16b, v3.16b, #14                #! PC = 0x5555551c1c *)
mov %v19 [%v6[7],%v3[0],%v3[1],%v3[2],%v3[3],%v3[4],%v3[5],%v3[6]];
(* smlal	v16.4s, v19.4h, v1.h[1]                   #! PC = 0x5555551c20 *)
broadcast %mull 4 [%v1[1]]; smulj %mlal [%v19[0],%v19[1],%v19[2],%v19[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v19.8h, v1.h[1]                   #! PC = 0x5555551c24 *)
broadcast %mull 4 [%v1[1]]; smulj %mlal [%v19[4],%v19[5],%v19[6],%v19[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v19.16b, v6.16b, v3.16b, #12                #! PC = 0x5555551c28 *)
mov %v19 [%v6[6],%v6[7],%v3[0],%v3[1],%v3[2],%v3[3],%v3[4],%v3[5]];
(* smlal	v16.4s, v19.4h, v1.h[2]                   #! PC = 0x5555551c2c *)
broadcast %mull 4 [%v1[2]]; smulj %mlal [%v19[0],%v19[1],%v19[2],%v19[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v19.8h, v1.h[2]                   #! PC = 0x5555551c30 *)
broadcast %mull 4 [%v1[2]]; smulj %mlal [%v19[4],%v19[5],%v19[6],%v19[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v19.16b, v6.16b, v3.16b, #10                #! PC = 0x5555551c34 *)
mov %v19 [%v6[5],%v6[6],%v6[7],%v3[0],%v3[1],%v3[2],%v3[3],%v3[4]];
(* smlal	v16.4s, v19.4h, v1.h[3]                   #! PC = 0x5555551c38 *)
broadcast %mull 4 [%v1[3]]; smulj %mlal [%v19[0],%v19[1],%v19[2],%v19[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v19.8h, v1.h[3]                   #! PC = 0x5555551c3c *)
broadcast %mull 4 [%v1[3]]; smulj %mlal [%v19[4],%v19[5],%v19[6],%v19[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v19.16b, v6.16b, v3.16b, #8                 #! PC = 0x5555551c40 *)
mov %v19 [%v6[4],%v6[5],%v6[6],%v6[7],%v3[0],%v3[1],%v3[2],%v3[3]];
(* smlal	v16.4s, v19.4h, v1.h[4]                   #! PC = 0x5555551c44 *)
broadcast %mull 4 [%v1[4]]; smulj %mlal [%v19[0],%v19[1],%v19[2],%v19[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v19.8h, v1.h[4]                   #! PC = 0x5555551c48 *)
broadcast %mull 4 [%v1[4]]; smulj %mlal [%v19[4],%v19[5],%v19[6],%v19[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v19.16b, v6.16b, v3.16b, #6                 #! PC = 0x5555551c4c *)
mov %v19 [%v6[3],%v6[4],%v6[5],%v6[6],%v6[7],%v3[0],%v3[1],%v3[2]];
(* smlal	v16.4s, v19.4h, v1.h[5]                   #! PC = 0x5555551c50 *)
broadcast %mull 4 [%v1[5]]; smulj %mlal [%v19[0],%v19[1],%v19[2],%v19[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v19.8h, v1.h[5]                   #! PC = 0x5555551c54 *)
broadcast %mull 4 [%v1[5]]; smulj %mlal [%v19[4],%v19[5],%v19[6],%v19[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v19.16b, v6.16b, v3.16b, #4                 #! PC = 0x5555551c58 *)
mov %v19 [%v6[2],%v6[3],%v6[4],%v6[5],%v6[6],%v6[7],%v3[0],%v3[1]];
(* smlal	v16.4s, v19.4h, v1.h[6]                   #! PC = 0x5555551c5c *)
broadcast %mull 4 [%v1[6]]; smulj %mlal [%v19[0],%v19[1],%v19[2],%v19[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v19.8h, v1.h[6]                   #! PC = 0x5555551c60 *)
broadcast %mull 4 [%v1[6]]; smulj %mlal [%v19[4],%v19[5],%v19[6],%v19[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v6.16b, v6.16b, v3.16b, #2                  #! PC = 0x5555551c64 *)
mov %v6 [%v6[1],%v6[2],%v6[3],%v6[4],%v6[5],%v6[6],%v6[7],%v3[0]];
(* smlal	v16.4s, v6.4h, v1.h[7]                    #! PC = 0x5555551c68 *)
broadcast %mull 4 [%v1[7]]; smulj %mlal [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v6.8h, v1.h[7]                    #! PC = 0x5555551c6c *)
broadcast %mull 4 [%v1[7]]; smulj %mlal [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; adds %dc %v7 %v7 %mlal;
(* sub	v1.8h, v17.8h, v18.8h                       #! PC = 0x5555551c70 *)
sub %v1 %v17 %v18;
(* smlsl	v0.4s, v1.4h, v4.h[0]                     #! PC = 0x5555551c74 *)
broadcast %mull 4 [%v4[0]]; smulj %mlsl [%v1[0],%v1[1],%v1[2],%v1[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v1.8h, v4.h[0]                    #! PC = 0x5555551c78 *)
broadcast %mull 4 [%v4[0]]; smulj %mlsl [%v1[4],%v1[5],%v1[6],%v1[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v6.16b, v3.16b, v1.16b, #14                 #! PC = 0x5555551c7c *)
mov %v6 [%v3[7],%v1[0],%v1[1],%v1[2],%v1[3],%v1[4],%v1[5],%v1[6]];
(* smlsl	v0.4s, v6.4h, v4.h[1]                     #! PC = 0x5555551c80 *)
broadcast %mull 4 [%v4[1]]; smulj %mlsl [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v6.8h, v4.h[1]                    #! PC = 0x5555551c84 *)
broadcast %mull 4 [%v4[1]]; smulj %mlsl [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v6.16b, v3.16b, v1.16b, #12                 #! PC = 0x5555551c88 *)
mov %v6 [%v3[6],%v3[7],%v1[0],%v1[1],%v1[2],%v1[3],%v1[4],%v1[5]];
(* smlsl	v0.4s, v6.4h, v4.h[2]                     #! PC = 0x5555551c8c *)
broadcast %mull 4 [%v4[2]]; smulj %mlsl [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v6.8h, v4.h[2]                    #! PC = 0x5555551c90 *)
broadcast %mull 4 [%v4[2]]; smulj %mlsl [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v6.16b, v3.16b, v1.16b, #10                 #! PC = 0x5555551c94 *)
mov %v6 [%v3[5],%v3[6],%v3[7],%v1[0],%v1[1],%v1[2],%v1[3],%v1[4]];
(* smlsl	v0.4s, v6.4h, v4.h[3]                     #! PC = 0x5555551c98 *)
broadcast %mull 4 [%v4[3]]; smulj %mlsl [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v6.8h, v4.h[3]                    #! PC = 0x5555551c9c *)
broadcast %mull 4 [%v4[3]]; smulj %mlsl [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v6.16b, v3.16b, v1.16b, #8                  #! PC = 0x5555551ca0 *)
mov %v6 [%v3[4],%v3[5],%v3[6],%v3[7],%v1[0],%v1[1],%v1[2],%v1[3]];
(* smlsl	v0.4s, v6.4h, v4.h[4]                     #! PC = 0x5555551ca4 *)
broadcast %mull 4 [%v4[4]]; smulj %mlsl [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v6.8h, v4.h[4]                    #! PC = 0x5555551ca8 *)
broadcast %mull 4 [%v4[4]]; smulj %mlsl [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v6.16b, v3.16b, v1.16b, #6                  #! PC = 0x5555551cac *)
mov %v6 [%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v1[0],%v1[1],%v1[2]];
(* smlsl	v0.4s, v6.4h, v4.h[5]                     #! PC = 0x5555551cb0 *)
broadcast %mull 4 [%v4[5]]; smulj %mlsl [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v6.8h, v4.h[5]                    #! PC = 0x5555551cb4 *)
broadcast %mull 4 [%v4[5]]; smulj %mlsl [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v6.16b, v3.16b, v1.16b, #4                  #! PC = 0x5555551cb8 *)
mov %v6 [%v3[2],%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v1[0],%v1[1]];
(* smlsl	v0.4s, v6.4h, v4.h[6]                     #! PC = 0x5555551cbc *)
broadcast %mull 4 [%v4[6]]; smulj %mlsl [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v6.8h, v4.h[6]                    #! PC = 0x5555551cc0 *)
broadcast %mull 4 [%v4[6]]; smulj %mlsl [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v3.16b, v3.16b, v1.16b, #2                  #! PC = 0x5555551cc4 *)
mov %v3 [%v3[1],%v3[2],%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v1[0]];
(* smlsl	v0.4s, v3.4h, v4.h[7]                     #! PC = 0x5555551cc8 *)
broadcast %mull 4 [%v4[7]]; smulj %mlsl [%v3[0],%v3[1],%v3[2],%v3[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v3.8h, v4.h[7]                    #! PC = 0x5555551ccc *)
broadcast %mull 4 [%v4[7]]; smulj %mlsl [%v3[4],%v3[5],%v3[6],%v3[7]] %mull; subc %dc %v2 %v2 %mlsl;

ghost %conv0_3@sint32[8], %conv1_3@sint32[8] :
    %conv0_3 = [
        %fc0_3[0] * %fd0_3[0] + %fc0_3[1] * %fe1_3[7] + %fc0_3[2] * %fe1_3[6] + %fc0_3[3] * %fe1_3[5] + %fc0_3[4] * %fe1_3[4] + %fc0_3[5] * %fe1_3[3] + %fc0_3[6] * %fe1_3[2] + %fc0_3[7] * %fe1_3[1] +
        %fc1_3[0] * %fe1_3[0] + %fc1_3[1] * %fe0_3[7] + %fc1_3[2] * %fe0_3[6] + %fc1_3[3] * %fe0_3[5] + %fc1_3[4] * %fe0_3[4] + %fc1_3[5] * %fe0_3[3] + %fc1_3[6] * %fe0_3[2] + %fc1_3[7] * %fe0_3[1],
        %fc0_3[0] * %fd0_3[1] + %fc0_3[1] * %fd0_3[0] + %fc0_3[2] * %fe1_3[7] + %fc0_3[3] * %fe1_3[6] + %fc0_3[4] * %fe1_3[5] + %fc0_3[5] * %fe1_3[4] + %fc0_3[6] * %fe1_3[3] + %fc0_3[7] * %fe1_3[2] +
        %fc1_3[0] * %fe1_3[1] + %fc1_3[1] * %fe1_3[0] + %fc1_3[2] * %fe0_3[7] + %fc1_3[3] * %fe0_3[6] + %fc1_3[4] * %fe0_3[5] + %fc1_3[5] * %fe0_3[4] + %fc1_3[6] * %fe0_3[3] + %fc1_3[7] * %fe0_3[2],
        %fc0_3[0] * %fd0_3[2] + %fc0_3[1] * %fd0_3[1] + %fc0_3[2] * %fd0_3[0] + %fc0_3[3] * %fe1_3[7] + %fc0_3[4] * %fe1_3[6] + %fc0_3[5] * %fe1_3[5] + %fc0_3[6] * %fe1_3[4] + %fc0_3[7] * %fe1_3[3] +
        %fc1_3[0] * %fe1_3[2] + %fc1_3[1] * %fe1_3[1] + %fc1_3[2] * %fe1_3[0] + %fc1_3[3] * %fe0_3[7] + %fc1_3[4] * %fe0_3[6] + %fc1_3[5] * %fe0_3[5] + %fc1_3[6] * %fe0_3[4] + %fc1_3[7] * %fe0_3[3],
        %fc0_3[0] * %fd0_3[3] + %fc0_3[1] * %fd0_3[2] + %fc0_3[2] * %fd0_3[1] + %fc0_3[3] * %fd0_3[0] + %fc0_3[4] * %fe1_3[7] + %fc0_3[5] * %fe1_3[6] + %fc0_3[6] * %fe1_3[5] + %fc0_3[7] * %fe1_3[4] +
        %fc1_3[0] * %fe1_3[3] + %fc1_3[1] * %fe1_3[2] + %fc1_3[2] * %fe1_3[1] + %fc1_3[3] * %fe1_3[0] + %fc1_3[4] * %fe0_3[7] + %fc1_3[5] * %fe0_3[6] + %fc1_3[6] * %fe0_3[5] + %fc1_3[7] * %fe0_3[4],
        %fc0_3[0] * %fd0_3[4] + %fc0_3[1] * %fd0_3[3] + %fc0_3[2] * %fd0_3[2] + %fc0_3[3] * %fd0_3[1] + %fc0_3[4] * %fd0_3[0] + %fc0_3[5] * %fe1_3[7] + %fc0_3[6] * %fe1_3[6] + %fc0_3[7] * %fe1_3[5] +
        %fc1_3[0] * %fe1_3[4] + %fc1_3[1] * %fe1_3[3] + %fc1_3[2] * %fe1_3[2] + %fc1_3[3] * %fe1_3[1] + %fc1_3[4] * %fe1_3[0] + %fc1_3[5] * %fe0_3[7] + %fc1_3[6] * %fe0_3[6] + %fc1_3[7] * %fe0_3[5],
        %fc0_3[0] * %fd0_3[5] + %fc0_3[1] * %fd0_3[4] + %fc0_3[2] * %fd0_3[3] + %fc0_3[3] * %fd0_3[2] + %fc0_3[4] * %fd0_3[1] + %fc0_3[5] * %fd0_3[0] + %fc0_3[6] * %fe1_3[7] + %fc0_3[7] * %fe1_3[6] +
        %fc1_3[0] * %fe1_3[5] + %fc1_3[1] * %fe1_3[4] + %fc1_3[2] * %fe1_3[3] + %fc1_3[3] * %fe1_3[2] + %fc1_3[4] * %fe1_3[1] + %fc1_3[5] * %fe1_3[0] + %fc1_3[6] * %fe0_3[7] + %fc1_3[7] * %fe0_3[6],
        %fc0_3[0] * %fd0_3[6] + %fc0_3[1] * %fd0_3[5] + %fc0_3[2] * %fd0_3[4] + %fc0_3[3] * %fd0_3[3] + %fc0_3[4] * %fd0_3[2] + %fc0_3[5] * %fd0_3[1] + %fc0_3[6] * %fd0_3[0] + %fc0_3[7] * %fe1_3[7] +
        %fc1_3[0] * %fe1_3[6] + %fc1_3[1] * %fe1_3[5] + %fc1_3[2] * %fe1_3[4] + %fc1_3[3] * %fe1_3[3] + %fc1_3[4] * %fe1_3[2] + %fc1_3[5] * %fe1_3[1] + %fc1_3[6] * %fe1_3[0] + %fc1_3[7] * %fe0_3[7],
        %fc0_3[0] * %fd0_3[7] + %fc0_3[1] * %fd0_3[6] + %fc0_3[2] * %fd0_3[5] + %fc0_3[3] * %fd0_3[4] + %fc0_3[4] * %fd0_3[3] + %fc0_3[5] * %fd0_3[2] + %fc0_3[6] * %fd0_3[1] + %fc0_3[7] * %fd0_3[0] +
        %fc1_3[0] * %fe1_3[7] + %fc1_3[1] * %fe1_3[6] + %fc1_3[2] * %fe1_3[5] + %fc1_3[3] * %fe1_3[4] + %fc1_3[4] * %fe1_3[3] + %fc1_3[5] * %fe1_3[2] + %fc1_3[6] * %fe1_3[1] + %fc1_3[7] * %fe1_3[0]
    ] /\
    %conv1_3 = [
        %fc0_3[0] * %fd1_3[0] + %fc0_3[1] * %fd0_3[7] + %fc0_3[2] * %fd0_3[6] + %fc0_3[3] * %fd0_3[5] + %fc0_3[4] * %fd0_3[4] + %fc0_3[5] * %fd0_3[3] + %fc0_3[6] * %fd0_3[2] + %fc0_3[7] * %fd0_3[1] +
        %fc1_3[0] * %fd0_3[0] + %fc1_3[1] * %fe1_3[7] + %fc1_3[2] * %fe1_3[6] + %fc1_3[3] * %fe1_3[5] + %fc1_3[4] * %fe1_3[4] + %fc1_3[5] * %fe1_3[3] + %fc1_3[6] * %fe1_3[2] + %fc1_3[7] * %fe1_3[1],
        %fc0_3[0] * %fd1_3[1] + %fc0_3[1] * %fd1_3[0] + %fc0_3[2] * %fd0_3[7] + %fc0_3[3] * %fd0_3[6] + %fc0_3[4] * %fd0_3[5] + %fc0_3[5] * %fd0_3[4] + %fc0_3[6] * %fd0_3[3] + %fc0_3[7] * %fd0_3[2] +
        %fc1_3[0] * %fd0_3[1] + %fc1_3[1] * %fd0_3[0] + %fc1_3[2] * %fe1_3[7] + %fc1_3[3] * %fe1_3[6] + %fc1_3[4] * %fe1_3[5] + %fc1_3[5] * %fe1_3[4] + %fc1_3[6] * %fe1_3[3] + %fc1_3[7] * %fe1_3[2],
        %fc0_3[0] * %fd1_3[2] + %fc0_3[1] * %fd1_3[1] + %fc0_3[2] * %fd1_3[0] + %fc0_3[3] * %fd0_3[7] + %fc0_3[4] * %fd0_3[6] + %fc0_3[5] * %fd0_3[5] + %fc0_3[6] * %fd0_3[4] + %fc0_3[7] * %fd0_3[3] +
        %fc1_3[0] * %fd0_3[2] + %fc1_3[1] * %fd0_3[1] + %fc1_3[2] * %fd0_3[0] + %fc1_3[3] * %fe1_3[7] + %fc1_3[4] * %fe1_3[6] + %fc1_3[5] * %fe1_3[5] + %fc1_3[6] * %fe1_3[4] + %fc1_3[7] * %fe1_3[3],
        %fc0_3[0] * %fd1_3[3] + %fc0_3[1] * %fd1_3[2] + %fc0_3[2] * %fd1_3[1] + %fc0_3[3] * %fd1_3[0] + %fc0_3[4] * %fd0_3[7] + %fc0_3[5] * %fd0_3[6] + %fc0_3[6] * %fd0_3[5] + %fc0_3[7] * %fd0_3[4] +
        %fc1_3[0] * %fd0_3[3] + %fc1_3[1] * %fd0_3[2] + %fc1_3[2] * %fd0_3[1] + %fc1_3[3] * %fd0_3[0] + %fc1_3[4] * %fe1_3[7] + %fc1_3[5] * %fe1_3[6] + %fc1_3[6] * %fe1_3[5] + %fc1_3[7] * %fe1_3[4],
        %fc0_3[0] * %fd1_3[4] + %fc0_3[1] * %fd1_3[3] + %fc0_3[2] * %fd1_3[2] + %fc0_3[3] * %fd1_3[1] + %fc0_3[4] * %fd1_3[0] + %fc0_3[5] * %fd0_3[7] + %fc0_3[6] * %fd0_3[6] + %fc0_3[7] * %fd0_3[5] +
        %fc1_3[0] * %fd0_3[4] + %fc1_3[1] * %fd0_3[3] + %fc1_3[2] * %fd0_3[2] + %fc1_3[3] * %fd0_3[1] + %fc1_3[4] * %fd0_3[0] + %fc1_3[5] * %fe1_3[7] + %fc1_3[6] * %fe1_3[6] + %fc1_3[7] * %fe1_3[5],
        %fc0_3[0] * %fd1_3[5] + %fc0_3[1] * %fd1_3[4] + %fc0_3[2] * %fd1_3[3] + %fc0_3[3] * %fd1_3[2] + %fc0_3[4] * %fd1_3[1] + %fc0_3[5] * %fd1_3[0] + %fc0_3[6] * %fd0_3[7] + %fc0_3[7] * %fd0_3[6] +
        %fc1_3[0] * %fd0_3[5] + %fc1_3[1] * %fd0_3[4] + %fc1_3[2] * %fd0_3[3] + %fc1_3[3] * %fd0_3[2] + %fc1_3[4] * %fd0_3[1] + %fc1_3[5] * %fd0_3[0] + %fc1_3[6] * %fe1_3[7] + %fc1_3[7] * %fe1_3[6],
        %fc0_3[0] * %fd1_3[6] + %fc0_3[1] * %fd1_3[5] + %fc0_3[2] * %fd1_3[4] + %fc0_3[3] * %fd1_3[3] + %fc0_3[4] * %fd1_3[2] + %fc0_3[5] * %fd1_3[1] + %fc0_3[6] * %fd1_3[0] + %fc0_3[7] * %fd0_3[7] +
        %fc1_3[0] * %fd0_3[6] + %fc1_3[1] * %fd0_3[5] + %fc1_3[2] * %fd0_3[4] + %fc1_3[3] * %fd0_3[3] + %fc1_3[4] * %fd0_3[2] + %fc1_3[5] * %fd0_3[1] + %fc1_3[6] * %fd0_3[0] + %fc1_3[7] * %fe1_3[7],
        %fc0_3[0] * %fd1_3[7] + %fc0_3[1] * %fd1_3[6] + %fc0_3[2] * %fd1_3[5] + %fc0_3[3] * %fd1_3[4] + %fc0_3[4] * %fd1_3[3] + %fc0_3[5] * %fd1_3[2] + %fc0_3[6] * %fd1_3[1] + %fc0_3[7] * %fd1_3[0] +
        %fc1_3[0] * %fd0_3[7] + %fc1_3[1] * %fd0_3[6] + %fc1_3[2] * %fd0_3[5] + %fc1_3[3] * %fd0_3[4] + %fc1_3[4] * %fd0_3[3] + %fc1_3[5] * %fd0_3[2] + %fc1_3[6] * %fd0_3[1] + %fc1_3[7] * %fd0_3[0]
    ]
    && true;

assert
    %v16 ++ %v7 = %conv0_3 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] ) /\
    %v0 ++ %v2 = %conv1_3 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] )
    && true;

assume
    %v16 ++ %v7 = %conv0_3 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] ) /\
    %v0 ++ %v2 = %conv1_3 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] )
    && true;

assert
    %conv0_3 <= [268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456] /\
    %conv0_3 >= [-268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456] /\

    %conv1_3 <= [268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456] /\
    %conv1_3 >= [-268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456]
    prove with [algebra solver smt: z3]
    && true;

assume
    %conv0_3 <= [268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456] /\
    %conv0_3 >= [-268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456] /\

    %conv1_3 <= [268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456] /\
    %conv1_3 >= [-268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456]
    && true;

assert
    %v16 ++ %v7 = %conv0_3 /\ %v0 ++ %v2 = %conv1_3
    prove with [algebra solver isl]
    && true;

assume
    %v16 ++ %v7 = %conv0_3 /\ %v0 ++ %v2 = %conv1_3
    && true;

assert
    %v16 <= [268435456, 268435456, 268435456, 268435456] /\
    %v16 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v7 <= [268435456, 268435456, 268435456, 268435456] /\
    %v7 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v0 <= [268435456, 268435456, 268435456, 268435456] /\
    %v0 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v2 <= [268435456, 268435456, 268435456, 268435456] /\
    %v2 >= [-268435456, -268435456, -268435456, -268435456]

    prove with [algebra solver isl]
    && true;

assume
    %v16 <= [268435456, 268435456, 268435456, 268435456] /\
    %v16 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v7 <= [268435456, 268435456, 268435456, 268435456] /\
    %v7 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v0 <= [268435456, 268435456, 268435456, 268435456] /\
    %v0 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v2 <= [268435456, 268435456, 268435456, 268435456] /\
    %v2 >= [-268435456, -268435456, -268435456, -268435456]
  &&
    %v16 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v16 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32] /\

    %v7 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v7 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32] /\

    %v0 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v0 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32] /\

    %v2 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v2 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32];

cut (* 15 *)
    %conv0_3 = [
        %fc0_3[0] * %fd0_3[0] + %fc0_3[1] * %fe1_3[7] + %fc0_3[2] * %fe1_3[6] + %fc0_3[3] * %fe1_3[5] + %fc0_3[4] * %fe1_3[4] + %fc0_3[5] * %fe1_3[3] + %fc0_3[6] * %fe1_3[2] + %fc0_3[7] * %fe1_3[1] +
        %fc1_3[0] * %fe1_3[0] + %fc1_3[1] * %fe0_3[7] + %fc1_3[2] * %fe0_3[6] + %fc1_3[3] * %fe0_3[5] + %fc1_3[4] * %fe0_3[4] + %fc1_3[5] * %fe0_3[3] + %fc1_3[6] * %fe0_3[2] + %fc1_3[7] * %fe0_3[1],
        %fc0_3[0] * %fd0_3[1] + %fc0_3[1] * %fd0_3[0] + %fc0_3[2] * %fe1_3[7] + %fc0_3[3] * %fe1_3[6] + %fc0_3[4] * %fe1_3[5] + %fc0_3[5] * %fe1_3[4] + %fc0_3[6] * %fe1_3[3] + %fc0_3[7] * %fe1_3[2] +
        %fc1_3[0] * %fe1_3[1] + %fc1_3[1] * %fe1_3[0] + %fc1_3[2] * %fe0_3[7] + %fc1_3[3] * %fe0_3[6] + %fc1_3[4] * %fe0_3[5] + %fc1_3[5] * %fe0_3[4] + %fc1_3[6] * %fe0_3[3] + %fc1_3[7] * %fe0_3[2],
        %fc0_3[0] * %fd0_3[2] + %fc0_3[1] * %fd0_3[1] + %fc0_3[2] * %fd0_3[0] + %fc0_3[3] * %fe1_3[7] + %fc0_3[4] * %fe1_3[6] + %fc0_3[5] * %fe1_3[5] + %fc0_3[6] * %fe1_3[4] + %fc0_3[7] * %fe1_3[3] +
        %fc1_3[0] * %fe1_3[2] + %fc1_3[1] * %fe1_3[1] + %fc1_3[2] * %fe1_3[0] + %fc1_3[3] * %fe0_3[7] + %fc1_3[4] * %fe0_3[6] + %fc1_3[5] * %fe0_3[5] + %fc1_3[6] * %fe0_3[4] + %fc1_3[7] * %fe0_3[3],
        %fc0_3[0] * %fd0_3[3] + %fc0_3[1] * %fd0_3[2] + %fc0_3[2] * %fd0_3[1] + %fc0_3[3] * %fd0_3[0] + %fc0_3[4] * %fe1_3[7] + %fc0_3[5] * %fe1_3[6] + %fc0_3[6] * %fe1_3[5] + %fc0_3[7] * %fe1_3[4] +
        %fc1_3[0] * %fe1_3[3] + %fc1_3[1] * %fe1_3[2] + %fc1_3[2] * %fe1_3[1] + %fc1_3[3] * %fe1_3[0] + %fc1_3[4] * %fe0_3[7] + %fc1_3[5] * %fe0_3[6] + %fc1_3[6] * %fe0_3[5] + %fc1_3[7] * %fe0_3[4],
        %fc0_3[0] * %fd0_3[4] + %fc0_3[1] * %fd0_3[3] + %fc0_3[2] * %fd0_3[2] + %fc0_3[3] * %fd0_3[1] + %fc0_3[4] * %fd0_3[0] + %fc0_3[5] * %fe1_3[7] + %fc0_3[6] * %fe1_3[6] + %fc0_3[7] * %fe1_3[5] +
        %fc1_3[0] * %fe1_3[4] + %fc1_3[1] * %fe1_3[3] + %fc1_3[2] * %fe1_3[2] + %fc1_3[3] * %fe1_3[1] + %fc1_3[4] * %fe1_3[0] + %fc1_3[5] * %fe0_3[7] + %fc1_3[6] * %fe0_3[6] + %fc1_3[7] * %fe0_3[5],
        %fc0_3[0] * %fd0_3[5] + %fc0_3[1] * %fd0_3[4] + %fc0_3[2] * %fd0_3[3] + %fc0_3[3] * %fd0_3[2] + %fc0_3[4] * %fd0_3[1] + %fc0_3[5] * %fd0_3[0] + %fc0_3[6] * %fe1_3[7] + %fc0_3[7] * %fe1_3[6] +
        %fc1_3[0] * %fe1_3[5] + %fc1_3[1] * %fe1_3[4] + %fc1_3[2] * %fe1_3[3] + %fc1_3[3] * %fe1_3[2] + %fc1_3[4] * %fe1_3[1] + %fc1_3[5] * %fe1_3[0] + %fc1_3[6] * %fe0_3[7] + %fc1_3[7] * %fe0_3[6],
        %fc0_3[0] * %fd0_3[6] + %fc0_3[1] * %fd0_3[5] + %fc0_3[2] * %fd0_3[4] + %fc0_3[3] * %fd0_3[3] + %fc0_3[4] * %fd0_3[2] + %fc0_3[5] * %fd0_3[1] + %fc0_3[6] * %fd0_3[0] + %fc0_3[7] * %fe1_3[7] +
        %fc1_3[0] * %fe1_3[6] + %fc1_3[1] * %fe1_3[5] + %fc1_3[2] * %fe1_3[4] + %fc1_3[3] * %fe1_3[3] + %fc1_3[4] * %fe1_3[2] + %fc1_3[5] * %fe1_3[1] + %fc1_3[6] * %fe1_3[0] + %fc1_3[7] * %fe0_3[7],
        %fc0_3[0] * %fd0_3[7] + %fc0_3[1] * %fd0_3[6] + %fc0_3[2] * %fd0_3[5] + %fc0_3[3] * %fd0_3[4] + %fc0_3[4] * %fd0_3[3] + %fc0_3[5] * %fd0_3[2] + %fc0_3[6] * %fd0_3[1] + %fc0_3[7] * %fd0_3[0] +
        %fc1_3[0] * %fe1_3[7] + %fc1_3[1] * %fe1_3[6] + %fc1_3[2] * %fe1_3[5] + %fc1_3[3] * %fe1_3[4] + %fc1_3[4] * %fe1_3[3] + %fc1_3[5] * %fe1_3[2] + %fc1_3[6] * %fe1_3[1] + %fc1_3[7] * %fe1_3[0]
    ] /\
    %conv1_3 = [
        %fc0_3[0] * %fd1_3[0] + %fc0_3[1] * %fd0_3[7] + %fc0_3[2] * %fd0_3[6] + %fc0_3[3] * %fd0_3[5] + %fc0_3[4] * %fd0_3[4] + %fc0_3[5] * %fd0_3[3] + %fc0_3[6] * %fd0_3[2] + %fc0_3[7] * %fd0_3[1] +
        %fc1_3[0] * %fd0_3[0] + %fc1_3[1] * %fe1_3[7] + %fc1_3[2] * %fe1_3[6] + %fc1_3[3] * %fe1_3[5] + %fc1_3[4] * %fe1_3[4] + %fc1_3[5] * %fe1_3[3] + %fc1_3[6] * %fe1_3[2] + %fc1_3[7] * %fe1_3[1],
        %fc0_3[0] * %fd1_3[1] + %fc0_3[1] * %fd1_3[0] + %fc0_3[2] * %fd0_3[7] + %fc0_3[3] * %fd0_3[6] + %fc0_3[4] * %fd0_3[5] + %fc0_3[5] * %fd0_3[4] + %fc0_3[6] * %fd0_3[3] + %fc0_3[7] * %fd0_3[2] +
        %fc1_3[0] * %fd0_3[1] + %fc1_3[1] * %fd0_3[0] + %fc1_3[2] * %fe1_3[7] + %fc1_3[3] * %fe1_3[6] + %fc1_3[4] * %fe1_3[5] + %fc1_3[5] * %fe1_3[4] + %fc1_3[6] * %fe1_3[3] + %fc1_3[7] * %fe1_3[2],
        %fc0_3[0] * %fd1_3[2] + %fc0_3[1] * %fd1_3[1] + %fc0_3[2] * %fd1_3[0] + %fc0_3[3] * %fd0_3[7] + %fc0_3[4] * %fd0_3[6] + %fc0_3[5] * %fd0_3[5] + %fc0_3[6] * %fd0_3[4] + %fc0_3[7] * %fd0_3[3] +
        %fc1_3[0] * %fd0_3[2] + %fc1_3[1] * %fd0_3[1] + %fc1_3[2] * %fd0_3[0] + %fc1_3[3] * %fe1_3[7] + %fc1_3[4] * %fe1_3[6] + %fc1_3[5] * %fe1_3[5] + %fc1_3[6] * %fe1_3[4] + %fc1_3[7] * %fe1_3[3],
        %fc0_3[0] * %fd1_3[3] + %fc0_3[1] * %fd1_3[2] + %fc0_3[2] * %fd1_3[1] + %fc0_3[3] * %fd1_3[0] + %fc0_3[4] * %fd0_3[7] + %fc0_3[5] * %fd0_3[6] + %fc0_3[6] * %fd0_3[5] + %fc0_3[7] * %fd0_3[4] +
        %fc1_3[0] * %fd0_3[3] + %fc1_3[1] * %fd0_3[2] + %fc1_3[2] * %fd0_3[1] + %fc1_3[3] * %fd0_3[0] + %fc1_3[4] * %fe1_3[7] + %fc1_3[5] * %fe1_3[6] + %fc1_3[6] * %fe1_3[5] + %fc1_3[7] * %fe1_3[4],
        %fc0_3[0] * %fd1_3[4] + %fc0_3[1] * %fd1_3[3] + %fc0_3[2] * %fd1_3[2] + %fc0_3[3] * %fd1_3[1] + %fc0_3[4] * %fd1_3[0] + %fc0_3[5] * %fd0_3[7] + %fc0_3[6] * %fd0_3[6] + %fc0_3[7] * %fd0_3[5] +
        %fc1_3[0] * %fd0_3[4] + %fc1_3[1] * %fd0_3[3] + %fc1_3[2] * %fd0_3[2] + %fc1_3[3] * %fd0_3[1] + %fc1_3[4] * %fd0_3[0] + %fc1_3[5] * %fe1_3[7] + %fc1_3[6] * %fe1_3[6] + %fc1_3[7] * %fe1_3[5],
        %fc0_3[0] * %fd1_3[5] + %fc0_3[1] * %fd1_3[4] + %fc0_3[2] * %fd1_3[3] + %fc0_3[3] * %fd1_3[2] + %fc0_3[4] * %fd1_3[1] + %fc0_3[5] * %fd1_3[0] + %fc0_3[6] * %fd0_3[7] + %fc0_3[7] * %fd0_3[6] +
        %fc1_3[0] * %fd0_3[5] + %fc1_3[1] * %fd0_3[4] + %fc1_3[2] * %fd0_3[3] + %fc1_3[3] * %fd0_3[2] + %fc1_3[4] * %fd0_3[1] + %fc1_3[5] * %fd0_3[0] + %fc1_3[6] * %fe1_3[7] + %fc1_3[7] * %fe1_3[6],
        %fc0_3[0] * %fd1_3[6] + %fc0_3[1] * %fd1_3[5] + %fc0_3[2] * %fd1_3[4] + %fc0_3[3] * %fd1_3[3] + %fc0_3[4] * %fd1_3[2] + %fc0_3[5] * %fd1_3[1] + %fc0_3[6] * %fd1_3[0] + %fc0_3[7] * %fd0_3[7] +
        %fc1_3[0] * %fd0_3[6] + %fc1_3[1] * %fd0_3[5] + %fc1_3[2] * %fd0_3[4] + %fc1_3[3] * %fd0_3[3] + %fc1_3[4] * %fd0_3[2] + %fc1_3[5] * %fd0_3[1] + %fc1_3[6] * %fd0_3[0] + %fc1_3[7] * %fe1_3[7],
        %fc0_3[0] * %fd1_3[7] + %fc0_3[1] * %fd1_3[6] + %fc0_3[2] * %fd1_3[5] + %fc0_3[3] * %fd1_3[4] + %fc0_3[4] * %fd1_3[3] + %fc0_3[5] * %fd1_3[2] + %fc0_3[6] * %fd1_3[1] + %fc0_3[7] * %fd1_3[0] +
        %fc1_3[0] * %fd0_3[7] + %fc1_3[1] * %fd0_3[6] + %fc1_3[2] * %fd0_3[5] + %fc1_3[3] * %fd0_3[4] + %fc1_3[4] * %fd0_3[3] + %fc1_3[5] * %fd0_3[2] + %fc1_3[6] * %fd0_3[1] + %fc1_3[7] * %fd0_3[0]
    ] /\

    %v16 ++ %v7 = %conv0_3 /\ %v0 ++ %v2 = %conv1_3,

    %v16 <= [268435456, 268435456, 268435456, 268435456] /\
    %v16 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v7 <= [268435456, 268435456, 268435456, 268435456] /\
    %v7 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v0 <= [268435456, 268435456, 268435456, 268435456] /\
    %v0 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v2 <= [268435456, 268435456, 268435456, 268435456] /\
    %v2 >= [-268435456, -268435456, -268435456, -268435456]

    prove with [algebra solver isl]
  &&
    %v16 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v16 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32] /\

    %v7 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v7 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32] /\

    %v0 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v0 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32] /\

    %v2 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v2 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32];

ghost %h0_3@sint32[8], %h1_3@sint32[8] :
    %h0_3 = %v16 ++ %v7 /\ %h1_3 = %v0 ++ %v2
  &&
    %h0_3 = %v16 ++ %v7 /\ %h1_3 = %v0 ++ %v2;

(* uzp1	v3.8h, v16.8h, v7.8h                       #! PC = 0x5555551cd0 *)
mov %spl_join [%v16[0], %v16[1], %v16[2], %v16[3], %v7[0], %v7[1], %v7[2], %v7[3]]; spl %splh %v3 %spl_join 16; cast %v3@int16[8] %v3;
(* mul	v3.8h, v3.8h, v5.h[7]                       #! PC = 0x5555551cd4 *)
broadcast %mul 8 [%v5[7]]; mull %dc %v3 %v3 %mul; cast %v3@int16[8] %v3;

ghost %m0_3@sint16[8] : %m0_3 = %v3 && %m0_3 = %v3;

(* sqdmulh	v3.8h, v3.8h, v5.h[6]                   #! PC = 0x5555551cd8 *)
broadcast %mul 8 [%v5[6]]; smulj %LO %v3 %mul;
ssplit %LO0 %dc %LO 15; vpc %v3@sint16[8] %LO0;
(* uzp2	v1.8h, v16.8h, v7.8h                       #! PC = 0x5555551cdc *)
mov %spl_join [%v16[0], %v16[1], %v16[2], %v16[3], %v7[0], %v7[1], %v7[2], %v7[3]]; spl %v1 %spll %spl_join 16;
(* sshr	v3.8h, v3.8h, #1                           #! PC = 0x5555551ce0 *)
split %v3 %dc %v3 1;
(* sub	v1.8h, v1.8h, v3.8h                         #! PC = 0x5555551ce4 *)
sub %v1 %v1 %v3;

ghost %hh0_3@sint16[8] : %hh0_3 = %v1 && %hh0_3 = %v1;

assert
    %h0_3 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m0_3
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh0_3
    prove with [algebra solver isl]
    && true;

assume
    %h0_3 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m0_3
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh0_3
    && true;

(* sqrdmulh	v3.8h, v1.8h, v5.h[3]                  #! PC = 0x5555551ce8 *)
broadcast %mul 8 [%v5[3]]; smulj %LO %v1 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v3 %LO11 %LO01;
(* mul	v1.8h, v1.8h, v5.h[2]                       #! PC = 0x5555551cec *)
broadcast %mul 8 [%v5[2]]; mull %dc %v1 %v1 %mul; cast %v1@int16[8] %v1;
(* mls	v1.8h, v3.8h, v5.h[6]                       #! PC = 0x5555551cf0 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v3 %mul;
cast %mls@int16[8] %mls; subc %dc %v1 %v1 %mls;

assert
    [2190, 2190, 2190, 2190, 2190, 2190, 2190, 2190] * %hh0_3
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v3
    = %v1
    prove with [algebra solver isl]
    && true;

assume
    [2190, 2190, 2190, 2190, 2190, 2190, 2190, 2190] * %hh0_3
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v3
    = %v1
    && true;

(* uzp1	v3.8h, v0.8h, v2.8h                        #! PC = 0x5555551cf4 *)
mov %spl_join [%v0[0], %v0[1], %v0[2], %v0[3], %v2[0], %v2[1], %v2[2], %v2[3]]; spl %splh %v3 %spl_join 16; cast %v3@int16[8] %v3;
(* mul	v3.8h, v3.8h, v5.h[7]                       #! PC = 0x5555551cf8 *)
broadcast %mul 8 [%v5[7]]; mull %dc %v3 %v3 %mul; cast %v3@int16[8] %v3;

ghost %m1_3@sint16[8] : %m1_3 = %v3 && %m1_3 = %v3;

(* sqdmulh	v3.8h, v3.8h, v5.h[6]                   #! PC = 0x5555551cfc *)
broadcast %mul 8 [%v5[6]]; smulj %LO %v3 %mul;
ssplit %LO0 %dc %LO 15; vpc %v3@sint16[8] %LO0;
(* uzp2	v0.8h, v0.8h, v2.8h                        #! PC = 0x5555551d00 *)
mov %spl_join [%v0[0], %v0[1], %v0[2], %v0[3], %v2[0], %v2[1], %v2[2], %v2[3]]; spl %v0 %spll %spl_join 16;
(* sshr	v2.8h, v3.8h, #1                           #! PC = 0x5555551d04 *)
split %v2 %dc %v3 1;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551d08 *)
sub %v0 %v0 %v2;

ghost %hh1_3@sint16[8] : %hh1_3 = %v0 && %hh1_3 = %v0;

assert
    %h1_3 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m1_3
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh1_3
    prove with [algebra solver isl]
    && true;

assume
    %h1_3 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m1_3
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh1_3
    && true;

(* sqrdmulh	v2.8h, v0.8h, v5.h[3]                  #! PC = 0x5555551d0c *)
broadcast %mul 8 [%v5[3]]; smulj %LO %v0 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v2 %LO11 %LO01;
(* mul	v0.8h, v0.8h, v5.h[2]                       #! PC = 0x5555551d10 *)
broadcast %mul 8 [%v5[2]]; mull %dc %v0 %v0 %mul; cast %v0@int16[8] %v0;
(* mls	v0.8h, v2.8h, v5.h[6]                       #! PC = 0x5555551d14 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v2 %mul;
cast %mls@int16[8] %mls; subc %dc %v0 %v0 %mls;

assert
    [2190, 2190, 2190, 2190, 2190, 2190, 2190, 2190] * %hh1_3
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v2
    = %v0
    prove with [algebra solver isl]
    && true;

assume
    [2190, 2190, 2190, 2190, 2190, 2190, 2190, 2190] * %hh1_3
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v2
    = %v0
    && true;


### i_iter epilogue

(* str	q1, [x2, x3]                                #! EA = L0x7fffffe210; PC = 0x5555551d18 *)
mov [L0x7fffffe210,L0x7fffffe212,L0x7fffffe214,L0x7fffffe216,L0x7fffffe218,L0x7fffffe21a,L0x7fffffe21c,L0x7fffffe21e] %v1;
(* str	q0, [x6, x3]                                #! EA = L0x7fffffe220; PC = 0x5555551d1c *)
mov [L0x7fffffe220,L0x7fffffe222,L0x7fffffe224,L0x7fffffe226,L0x7fffffe228,L0x7fffffe22a,L0x7fffffe22c,L0x7fffffe22e] %v0;
(* #b.eq	0x5555551ec4 <_ZN6xpower7basemul11low_basemulEPA2_A8_sS3_S3_+932>  // b.none#! PC = 0x5555551d30 *)
#b.eq	0x5555551ec4 <_ZN6xpower7basemul11low_basemulEPA2_A8_sS3_S3_+932>  // b.none#! 0x5555551d30 = 0x5555551d30;

assert
    %v1 <= [2300, 2300, 2300, 2300, 2300, 2300, 2300, 2300] /\
    %v1 >= [-2300, -2300, -2300, -2300, -2300, -2300, -2300, -2300] /\

    %v0 <= [2300, 2300, 2300, 2300, 2300, 2300, 2300, 2300] /\
    %v0 >= [-2300, -2300, -2300, -2300, -2300, -2300, -2300, -2300]

    prove with [algebra solver isl]
    && true;

assume
    true &&

    %v1 <=s [2300@16, 2300@16, 2300@16, 2300@16, 2300@16, 2300@16, 2300@16, 2300@16] /\
    %v1 >=s [(-2300)@16, (-2300)@16, (-2300)@16, (-2300)@16, (-2300)@16, (-2300)@16, (-2300)@16, (-2300)@16] /\

    %v0 <=s [2300@16, 2300@16, 2300@16, 2300@16, 2300@16, 2300@16, 2300@16, 2300@16] /\
    %v0 >=s [(-2300)@16, (-2300)@16, (-2300)@16, (-2300)@16, (-2300)@16, (-2300)@16, (-2300)@16, (-2300)@16];

cut (* 16 *)
    [L0x7fffffe210, L0x7fffffe212, L0x7fffffe214, L0x7fffffe216, L0x7fffffe218, L0x7fffffe21a, L0x7fffffe21c, L0x7fffffe21e] = %v1 /\
    [L0x7fffffe220, L0x7fffffe222, L0x7fffffe224, L0x7fffffe226, L0x7fffffe228, L0x7fffffe22a, L0x7fffffe22c, L0x7fffffe22e] = %v0 /\

    %v1 ++ %v0 = [-1548, -1548, -1548, -1548, -1548, -1548, -1548, -1548, -1548, -1548, -1548, -1548, -1548, -1548, -1548, -1548] * [
        arr300_a * arr300_b + 2274 * arr301_a * arr317_b + 2274 * arr302_a * arr316_b + 2274 * arr303_a * arr315_b + 2274 * arr304_a * arr314_b + 2274 * arr305_a * arr313_b + 2274 * arr306_a * arr312_b + 2274 * arr307_a * arr311_b + 2274 * arr310_a * arr310_b + 2274 * arr311_a * arr307_b + 2274 * arr312_a * arr306_b + 2274 * arr313_a * arr305_b + 2274 * arr314_a * arr304_b + 2274 * arr315_a * arr303_b + 2274 * arr316_a * arr302_b + 2274 * arr317_a * arr301_b,
        arr300_a * arr301_b + arr301_a * arr300_b + 2274 * arr302_a * arr317_b + 2274 * arr303_a * arr316_b + 2274 * arr304_a * arr315_b + 2274 * arr305_a * arr314_b + 2274 * arr306_a * arr313_b + 2274 * arr307_a * arr312_b + 2274 * arr310_a * arr311_b + 2274 * arr311_a * arr310_b + 2274 * arr312_a * arr307_b + 2274 * arr313_a * arr306_b + 2274 * arr314_a * arr305_b + 2274 * arr315_a * arr304_b + 2274 * arr316_a * arr303_b + 2274 * arr317_a * arr302_b,
        arr300_a * arr302_b + arr301_a * arr301_b + arr302_a * arr300_b + 2274 * arr303_a * arr317_b + 2274 * arr304_a * arr316_b + 2274 * arr305_a * arr315_b + 2274 * arr306_a * arr314_b + 2274 * arr307_a * arr313_b + 2274 * arr310_a * arr312_b + 2274 * arr311_a * arr311_b + 2274 * arr312_a * arr310_b + 2274 * arr313_a * arr307_b + 2274 * arr314_a * arr306_b + 2274 * arr315_a * arr305_b + 2274 * arr316_a * arr304_b + 2274 * arr317_a * arr303_b,
        arr300_a * arr303_b + arr301_a * arr302_b + arr302_a * arr301_b + arr303_a * arr300_b + 2274 * arr304_a * arr317_b + 2274 * arr305_a * arr316_b + 2274 * arr306_a * arr315_b + 2274 * arr307_a * arr314_b + 2274 * arr310_a * arr313_b + 2274 * arr311_a * arr312_b + 2274 * arr312_a * arr311_b + 2274 * arr313_a * arr310_b + 2274 * arr314_a * arr307_b + 2274 * arr315_a * arr306_b + 2274 * arr316_a * arr305_b + 2274 * arr317_a * arr304_b,
        arr300_a * arr304_b + arr301_a * arr303_b + arr302_a * arr302_b + arr303_a * arr301_b + arr304_a * arr300_b + 2274 * arr305_a * arr317_b + 2274 * arr306_a * arr316_b + 2274 * arr307_a * arr315_b + 2274 * arr310_a * arr314_b + 2274 * arr311_a * arr313_b + 2274 * arr312_a * arr312_b + 2274 * arr313_a * arr311_b + 2274 * arr314_a * arr310_b + 2274 * arr315_a * arr307_b + 2274 * arr316_a * arr306_b + 2274 * arr317_a * arr305_b,
        arr300_a * arr305_b + arr301_a * arr304_b + arr302_a * arr303_b + arr303_a * arr302_b + arr304_a * arr301_b + arr305_a * arr300_b + 2274 * arr306_a * arr317_b + 2274 * arr307_a * arr316_b + 2274 * arr310_a * arr315_b + 2274 * arr311_a * arr314_b + 2274 * arr312_a * arr313_b + 2274 * arr313_a * arr312_b + 2274 * arr314_a * arr311_b + 2274 * arr315_a * arr310_b + 2274 * arr316_a * arr307_b + 2274 * arr317_a * arr306_b,
        arr300_a * arr306_b + arr301_a * arr305_b + arr302_a * arr304_b + arr303_a * arr303_b + arr304_a * arr302_b + arr305_a * arr301_b + arr306_a * arr300_b + 2274 * arr307_a * arr317_b + 2274 * arr310_a * arr316_b + 2274 * arr311_a * arr315_b + 2274 * arr312_a * arr314_b + 2274 * arr313_a * arr313_b + 2274 * arr314_a * arr312_b + 2274 * arr315_a * arr311_b + 2274 * arr316_a * arr310_b + 2274 * arr317_a * arr307_b,
        arr300_a * arr307_b + arr301_a * arr306_b + arr302_a * arr305_b + arr303_a * arr304_b + arr304_a * arr303_b + arr305_a * arr302_b + arr306_a * arr301_b + arr307_a * arr300_b + 2274 * arr310_a * arr317_b + 2274 * arr311_a * arr316_b + 2274 * arr312_a * arr315_b + 2274 * arr313_a * arr314_b + 2274 * arr314_a * arr313_b + 2274 * arr315_a * arr312_b + 2274 * arr316_a * arr311_b + 2274 * arr317_a * arr310_b,
        arr300_a * arr310_b + arr301_a * arr307_b + arr302_a * arr306_b + arr303_a * arr305_b + arr304_a * arr304_b + arr305_a * arr303_b + arr306_a * arr302_b + arr307_a * arr301_b + arr310_a * arr300_b + 2274 * arr311_a * arr317_b + 2274 * arr312_a * arr316_b + 2274 * arr313_a * arr315_b + 2274 * arr314_a * arr314_b + 2274 * arr315_a * arr313_b + 2274 * arr316_a * arr312_b + 2274 * arr317_a * arr311_b,
        arr300_a * arr311_b + arr301_a * arr310_b + arr302_a * arr307_b + arr303_a * arr306_b + arr304_a * arr305_b + arr305_a * arr304_b + arr306_a * arr303_b + arr307_a * arr302_b + arr310_a * arr301_b + arr311_a * arr300_b + 2274 * arr312_a * arr317_b + 2274 * arr313_a * arr316_b + 2274 * arr314_a * arr315_b + 2274 * arr315_a * arr314_b + 2274 * arr316_a * arr313_b + 2274 * arr317_a * arr312_b,
        arr300_a * arr312_b + arr301_a * arr311_b + arr302_a * arr310_b + arr303_a * arr307_b + arr304_a * arr306_b + arr305_a * arr305_b + arr306_a * arr304_b + arr307_a * arr303_b + arr310_a * arr302_b + arr311_a * arr301_b + arr312_a * arr300_b + 2274 * arr313_a * arr317_b + 2274 * arr314_a * arr316_b + 2274 * arr315_a * arr315_b + 2274 * arr316_a * arr314_b + 2274 * arr317_a * arr313_b,
        arr300_a * arr313_b + arr301_a * arr312_b + arr302_a * arr311_b + arr303_a * arr310_b + arr304_a * arr307_b + arr305_a * arr306_b + arr306_a * arr305_b + arr307_a * arr304_b + arr310_a * arr303_b + arr311_a * arr302_b + arr312_a * arr301_b + arr313_a * arr300_b + 2274 * arr314_a * arr317_b + 2274 * arr315_a * arr316_b + 2274 * arr316_a * arr315_b + 2274 * arr317_a * arr314_b,
        arr300_a * arr314_b + arr301_a * arr313_b + arr302_a * arr312_b + arr303_a * arr311_b + arr304_a * arr310_b + arr305_a * arr307_b + arr306_a * arr306_b + arr307_a * arr305_b + arr310_a * arr304_b + arr311_a * arr303_b + arr312_a * arr302_b + arr313_a * arr301_b + arr314_a * arr300_b + 2274 * arr315_a * arr317_b + 2274 * arr316_a * arr316_b + 2274 * arr317_a * arr315_b,
        arr300_a * arr315_b + arr301_a * arr314_b + arr302_a * arr313_b + arr303_a * arr312_b + arr304_a * arr311_b + arr305_a * arr310_b + arr306_a * arr307_b + arr307_a * arr306_b + arr310_a * arr305_b + arr311_a * arr304_b + arr312_a * arr303_b + arr313_a * arr302_b + arr314_a * arr301_b + arr315_a * arr300_b + 2274 * arr316_a * arr317_b + 2274 * arr317_a * arr316_b,
        arr300_a * arr316_b + arr301_a * arr315_b + arr302_a * arr314_b + arr303_a * arr313_b + arr304_a * arr312_b + arr305_a * arr311_b + arr306_a * arr310_b + arr307_a * arr307_b + arr310_a * arr306_b + arr311_a * arr305_b + arr312_a * arr304_b + arr313_a * arr303_b + arr314_a * arr302_b + arr315_a * arr301_b + arr316_a * arr300_b + 2274 * arr317_a * arr317_b,
        arr300_a * arr317_b + arr301_a * arr316_b + arr302_a * arr315_b + arr303_a * arr314_b + arr304_a * arr313_b + arr305_a * arr312_b + arr306_a * arr311_b + arr307_a * arr310_b + arr310_a * arr307_b + arr311_a * arr306_b + arr312_a * arr305_b + arr313_a * arr304_b + arr314_a * arr303_b + arr315_a * arr302_b + arr316_a * arr301_b + arr317_a * arr300_b
    ] ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] )

    prove with [cuts[0, 13, 14, 15]]
  &&
    [L0x7fffffe210, L0x7fffffe212, L0x7fffffe214, L0x7fffffe216, L0x7fffffe218, L0x7fffffe21a, L0x7fffffe21c, L0x7fffffe21e] = %v1 /\
    [L0x7fffffe220, L0x7fffffe222, L0x7fffffe224, L0x7fffffe226, L0x7fffffe228, L0x7fffffe22a, L0x7fffffe22c, L0x7fffffe22e] = %v0 /\

    %v1 <=s [2300@16, 2300@16, 2300@16, 2300@16, 2300@16, 2300@16, 2300@16, 2300@16] /\
    %v1 >=s [(-2300)@16, (-2300)@16, (-2300)@16, (-2300)@16, (-2300)@16, (-2300)@16, (-2300)@16, (-2300)@16] /\

    %v0 <=s [2300@16, 2300@16, 2300@16, 2300@16, 2300@16, 2300@16, 2300@16, 2300@16] /\
    %v0 >=s [(-2300)@16, (-2300)@16, (-2300)@16, (-2300)@16, (-2300)@16, (-2300)@16, (-2300)@16, (-2300)@16];


### i_iter prologue

(* ldr	q4, [x0, x3]                                #! EA = L0x7fffffe4b0; Value = 0x0000000000000000; PC = 0x5555551d34 *)
mov %v4 [L0x7fffffe4b0,L0x7fffffe4b2,L0x7fffffe4b4,L0x7fffffe4b6,L0x7fffffe4b8,L0x7fffffe4ba,L0x7fffffe4bc,L0x7fffffe4be];
(* ldr	q1, [x8, x3]                                #! EA = L0x7fffffe4c0; Value = 0x0000000000000000; PC = 0x5555551d38 *)
mov %v1 [L0x7fffffe4c0,L0x7fffffe4c2,L0x7fffffe4c4,L0x7fffffe4c6,L0x7fffffe4c8,L0x7fffffe4ca,L0x7fffffe4cc,L0x7fffffe4ce];
(* ldr	q17, [x1, x3]                               #! EA = L0x7fffffe370; Value = 0x0000000000000000; PC = 0x5555551d3c *)
mov %v17 [L0x7fffffe370,L0x7fffffe372,L0x7fffffe374,L0x7fffffe376,L0x7fffffe378,L0x7fffffe37a,L0x7fffffe37c,L0x7fffffe37e];
(* ldr	q18, [x7, x3]                               #! EA = L0x7fffffe380; Value = 0x0000000000000000; PC = 0x5555551d40 *)
mov %v18 [L0x7fffffe380,L0x7fffffe382,L0x7fffffe384,L0x7fffffe386,L0x7fffffe388,L0x7fffffe38a,L0x7fffffe38c,L0x7fffffe38e];

ghost %fa0_4@sint16[8], %fa1_4@sint16[8], %fb0_4@sint16[8], %fb1_4@sint16[8] :
    %fa0_4 = %v4 /\ %fa1_4 = %v1 /\ %fb0_4 = %v17 /\ %fb1_4 = %v18
  &&
    %fa0_4 = %v4 /\ %fa1_4 = %v1 /\ %fb0_4 = %v17 /\ %fb1_4 = %v18;

cut (* 17 *)
    %fa0_4 = %v4 /\ %fa1_4 = %v1 /\ %fb0_4 = %v17 /\ %fb1_4 = %v18 /\
    %fa0_4 = [arr400_a, arr401_a, arr402_a, arr403_a, arr404_a, arr405_a, arr406_a, arr407_a] /\
    %fa1_4 = [arr410_a, arr411_a, arr412_a, arr413_a, arr414_a, arr415_a, arr416_a, arr417_a] /\
    %fb0_4 = [arr400_b, arr401_b, arr402_b, arr403_b, arr404_b, arr405_b, arr406_b, arr407_b] /\
    %fb1_4 = [arr410_b, arr411_b, arr412_b, arr413_b, arr414_b, arr415_b, arr416_b, arr417_b]
    prove with [cuts[0]]
  &&
    %fa0_4 = %v4 /\ %fa1_4 = %v1 /\ %fb0_4 = %v17 /\ %fb1_4 = %v18 /\
    %fa0_4 = [arr400_a, arr401_a, arr402_a, arr403_a, arr404_a, arr405_a, arr406_a, arr407_a] /\
    %fa1_4 = [arr410_a, arr411_a, arr412_a, arr413_a, arr414_a, arr415_a, arr416_a, arr417_a] /\
    %fb0_4 = [arr400_b, arr401_b, arr402_b, arr403_b, arr404_b, arr405_b, arr406_b, arr407_b] /\
    %fb1_4 = [arr410_b, arr411_b, arr412_b, arr413_b, arr414_b, arr415_b, arr416_b, arr417_b]
    prove with [cuts[0]];

#### radix2

(* ldr	q5, [x5]                                    #! EA = L0x5555552e40; Value = 0xffd5fffacd66f8e9; PC = 0x5555551d48 *)
mov %v5 [L0x5555552e40,L0x5555552e42,L0x5555552e44,L0x5555552e46,L0x5555552e48,L0x5555552e4a,L0x5555552e4c,L0x5555552e4e];
(* sshr	v0.8h, v4.8h, #12                          #! PC = 0x5555551d4c *)
split %v0 %dc %v4 12;
(* cmlt	v2.8h, v4.8h, #0                           #! PC = 0x5555551d50 *)
split %v2 %dc %v4 15;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551d54 *)
sub %v0 %v0 %v2;
(* mls	v4.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551d58 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v4 %v4 %mls;

assert
    %fa0_4 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v4
    prove with [algebra solver isl, precondition, cuts[0, 17]]
    && true;

assume
    %fa0_4 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v4
    && true;

(* sshr	v0.8h, v17.8h, #12                         #! PC = 0x5555551d5c *)
split %v0 %dc %v17 12;
(* cmlt	v2.8h, v17.8h, #0                          #! PC = 0x5555551d60 *)
split %v2 %dc %v17 15;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551d64 *)
sub %v0 %v0 %v2;
(* mls	v17.8h, v0.8h, v5.h[6]                      #! PC = 0x5555551d68 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v17 %v17 %mls;

assert
    %fb0_4 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v17
    prove with [algebra solver isl, precondition, cuts[0, 17]]
    && true;

assume
    %fb0_4 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v17
    && true;

(* sqrdmulh	v0.8h, v1.8h, v5.h[1]                  #! PC = 0x5555551d6c *)
broadcast %mul 8 [%v5[1]]; smulj %LO %v1 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v0 %LO11 %LO01;
(* mul	v1.8h, v1.8h, v5.h[0]                       #! PC = 0x5555551d70 *)
broadcast %mul 8 [%v5[0]]; mull %dc %v1 %v1 %mul; cast %v1@int16[8] %v1;
(* mls	v1.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551d74 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v1 %v1 %mls;

assert
    [-1815, -1815, -1815, -1815, -1815, -1815, -1815, -1815] * %fa1_4
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v1
    prove with [algebra solver isl, precondition, cuts[0, 17]]
    && true;

assume
    [-1815, -1815, -1815, -1815, -1815, -1815, -1815, -1815] * %fa1_4
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v1
    && true;

(* sqrdmulh	v0.8h, v18.8h, v5.h[1]                 #! PC = 0x5555551d78 *)
broadcast %mul 8 [%v5[1]]; smulj %LO %v18 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v0 %LO11 %LO01;
(* mul	v18.8h, v18.8h, v5.h[0]                     #! PC = 0x5555551d7c *)
broadcast %mul 8 [%v5[0]]; mull %dc %v18 %v18 %mul; cast %v18@int16[8] %v18;
(* mls	v18.8h, v0.8h, v5.h[6]                      #! PC = 0x5555551d80 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v18 %v18 %mls;

assert
    [-1815, -1815, -1815, -1815, -1815, -1815, -1815, -1815] * %fb1_4
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v18
    prove with [algebra solver isl, precondition, cuts[0, 17]]
    && true;

assume
    [-1815, -1815, -1815, -1815, -1815, -1815, -1815, -1815] * %fb1_4
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v18
    && true;

(* add	v2.8h, v4.8h, v1.8h                         #! PC = 0x5555551d84 *)
add %v2 %v4 %v1;
(* sub	v1.8h, v4.8h, v1.8h                         #! PC = 0x5555551d88 *)
sub %v1 %v4 %v1;
(* add	v7.8h, v17.8h, v18.8h                       #! PC = 0x5555551d8c *)
add %v7 %v17 %v18;
(* sub	v18.8h, v17.8h, v18.8h                      #! PC = 0x5555551d90 *)
sub %v18 %v17 %v18;

ghost %fc0_4@sint16[8], %fc1_4@sint16[8], %fd0_4@sint16[8], %fd1_4@sint16[8] :
    %fc0_4 = %v2 /\ %fc1_4 = %v1 /\ %fd0_4 = %v7 /\ %fd1_4 = %v18
  &&
    %fc0_4 = %v2 /\ %fc1_4 = %v1 /\ %fd0_4 = %v7 /\ %fd1_4 = %v18;

(* sqrdmulh	v0.8h, v7.8h, v5.h[1]                  #! PC = 0x5555551d94 *)
broadcast %mul 8 [%v5[1]]; smulj %LO %v7 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v0 %LO11 %LO01;
(* mul	v3.8h, v7.8h, v5.h[0]                       #! PC = 0x5555551d98 *)
broadcast %mul 8 [%v5[0]]; mull %dc %v3 %v7 %mul; cast %v3@int16[8] %v3;
(* mls	v3.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551d9c *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v3 %v3 %mls;

assert
    [-1815, -1815, -1815, -1815, -1815, -1815, -1815, -1815] * %fd0_4
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v3
    prove with [algebra solver isl, precondition, cuts[0, 17]]
    && true;

assume
    [-1815, -1815, -1815, -1815, -1815, -1815, -1815, -1815] * %fd0_4
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v3
    && true;

(* sqrdmulh	v0.8h, v18.8h, v5.h[1]                 #! PC = 0x5555551da0 *)
broadcast %mul 8 [%v5[1]]; smulj %LO %v18 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v0 %LO11 %LO01;
(* mul	v6.8h, v18.8h, v5.h[0]                      #! PC = 0x5555551da4 *)
broadcast %mul 8 [%v5[0]]; mull %dc %v6 %v18 %mul; cast %v6@int16[8] %v6;
(* mls	v6.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551da8 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v6 %v6 %mls;

assert
    [-1815, -1815, -1815, -1815, -1815, -1815, -1815, -1815] * %fd1_4
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v6
    prove with [algebra solver isl, precondition, cuts[0, 17]]
    && true;

assume
    [-1815, -1815, -1815, -1815, -1815, -1815, -1815, -1815] * %fd1_4
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v6
    && true;

(* neg	v6.8h, v6.8h                                #! PC = 0x5555551dac *)
broadcast %zero 8 [0@sint16]; sub %v6 %zero %v6;

ghost %gd0_4@sint16[8], %gd1_4@sint16[8] :
    %gd0_4 = %v3 /\ %gd1_4 = %v6
  &&
    %gd0_4 = %v3 /\ %gd1_4 = %v6;

cut (* 18 *)
    %fc0_4 = %v2 /\ %fc1_4 = %v1 /\ %fd0_4 = %v7 /\ %fd1_4 = %v18 /\ %gd0_4 = %v3 /\ %gd1_4 = %v6 /\

    %fc0_4 = %fa0_4 + [-1815, -1815, -1815, -1815, -1815, -1815, -1815, -1815] * %fa1_4
        ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\
    %fc1_4 = %fa0_4 - [-1815, -1815, -1815, -1815, -1815, -1815, -1815, -1815] * %fa1_4
        ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\

    %fd0_4 = %fb0_4 + [-1815, -1815, -1815, -1815, -1815, -1815, -1815, -1815] * %fb1_4
        ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\
    %fd1_4 = %fb0_4 - [-1815, -1815, -1815, -1815, -1815, -1815, -1815, -1815] * %fb1_4
        ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\

    %gd0_4 =  [-1815, -1815, -1815, -1815, -1815, -1815, -1815, -1815] * %fd0_4 ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\
    %gd1_4 = -[-1815, -1815, -1815, -1815, -1815, -1815, -1815, -1815] * %fd1_4 ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ),

    %fc0_4 <= [8100, 8100, 8100, 8100, 8100, 8100, 8100, 8100] /\
    %fc0_4 >= [-8100, -8100, -8100, -8100, -8100, -8100, -8100, -8100] /\

    %fc1_4 <= [8100, 8100, 8100, 8100, 8100, 8100, 8100, 8100] /\
    %fc1_4 >= [-8100, -8100, -8100, -8100, -8100, -8100, -8100, -8100] /\

    %fd0_4 <= [8100, 8100, 8100, 8100, 8100, 8100, 8100, 8100] /\
    %fd0_4 >= [-8100, -8100, -8100, -8100, -8100, -8100, -8100, -8100] /\

    %fd1_4 <= [8100, 8100, 8100, 8100, 8100, 8100, 8100, 8100] /\
    %fd1_4 >= [-8100, -8100, -8100, -8100, -8100, -8100, -8100, -8100] /\

    %gd0_4 <= [3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000] /\
    %gd0_4 >= [-3000, -3000, -3000, -3000, -3000, -3000, -3000, -3000] /\

    %gd1_4 <= [3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000] /\
    %gd1_4 >= [-3000, -3000, -3000, -3000, -3000, -3000, -3000, -3000]

    prove with [algebra solver isl, precondition, cuts[0, 17]]
  &&
    true
    prove with [precondition, cuts[0, 17]];

(* smull	v0.4s, v7.4h, v2.h[0]                     #! PC = 0x5555551db0 *)
broadcast %mull 4 [%v2[0]]; smulj %v0 [%v7[0],%v7[1],%v7[2],%v7[3]] %mull;
(* smull2	v4.4s, v7.8h, v2.h[0]                    #! PC = 0x5555551db4 *)
broadcast %mull 4 [%v2[0]]; smulj %v4 [%v7[4],%v7[5],%v7[6],%v7[7]] %mull;
(* ext	v16.16b, v3.16b, v7.16b, #14                #! PC = 0x5555551db8 *)
mov %v16 [%v3[7],%v7[0],%v7[1],%v7[2],%v7[3],%v7[4],%v7[5],%v7[6]];
(* smlal	v0.4s, v16.4h, v2.h[1]                    #! PC = 0x5555551dbc *)
broadcast %mull 4 [%v2[1]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v16.8h, v2.h[1]                   #! PC = 0x5555551dc0 *)
broadcast %mull 4 [%v2[1]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v4 %v4 %mlal;
(* ext	v16.16b, v3.16b, v7.16b, #12                #! PC = 0x5555551dc4 *)
mov %v16 [%v3[6],%v3[7],%v7[0],%v7[1],%v7[2],%v7[3],%v7[4],%v7[5]];
(* smlal	v0.4s, v16.4h, v2.h[2]                    #! PC = 0x5555551dc8 *)
broadcast %mull 4 [%v2[2]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v16.8h, v2.h[2]                   #! PC = 0x5555551dcc *)
broadcast %mull 4 [%v2[2]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v4 %v4 %mlal;
(* ext	v16.16b, v3.16b, v7.16b, #10                #! PC = 0x5555551dd0 *)
mov %v16 [%v3[5],%v3[6],%v3[7],%v7[0],%v7[1],%v7[2],%v7[3],%v7[4]];
(* smlal	v0.4s, v16.4h, v2.h[3]                    #! PC = 0x5555551dd4 *)
broadcast %mull 4 [%v2[3]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v16.8h, v2.h[3]                   #! PC = 0x5555551dd8 *)
broadcast %mull 4 [%v2[3]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v4 %v4 %mlal;
(* ext	v16.16b, v3.16b, v7.16b, #8                 #! PC = 0x5555551ddc *)
mov %v16 [%v3[4],%v3[5],%v3[6],%v3[7],%v7[0],%v7[1],%v7[2],%v7[3]];
(* smlal	v0.4s, v16.4h, v2.h[4]                    #! PC = 0x5555551de0 *)
broadcast %mull 4 [%v2[4]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v16.8h, v2.h[4]                   #! PC = 0x5555551de4 *)
broadcast %mull 4 [%v2[4]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v4 %v4 %mlal;
(* ext	v16.16b, v3.16b, v7.16b, #6                 #! PC = 0x5555551de8 *)
mov %v16 [%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v7[0],%v7[1],%v7[2]];
(* smlal	v0.4s, v16.4h, v2.h[5]                    #! PC = 0x5555551dec *)
broadcast %mull 4 [%v2[5]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v16.8h, v2.h[5]                   #! PC = 0x5555551df0 *)
broadcast %mull 4 [%v2[5]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v4 %v4 %mlal;
(* ext	v16.16b, v3.16b, v7.16b, #4                 #! PC = 0x5555551df4 *)
mov %v16 [%v3[2],%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v7[0],%v7[1]];
(* smlal	v0.4s, v16.4h, v2.h[6]                    #! PC = 0x5555551df8 *)
broadcast %mull 4 [%v2[6]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v16.8h, v2.h[6]                   #! PC = 0x5555551dfc *)
broadcast %mull 4 [%v2[6]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v4 %v4 %mlal;
(* ext	v3.16b, v3.16b, v7.16b, #2                  #! PC = 0x5555551e00 *)
mov %v3 [%v3[1],%v3[2],%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v7[0]];
(* smlal	v0.4s, v3.4h, v2.h[7]                     #! PC = 0x5555551e04 *)
broadcast %mull 4 [%v2[7]]; smulj %mlal [%v3[0],%v3[1],%v3[2],%v3[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v3.8h, v2.h[7]                    #! PC = 0x5555551e08 *)
broadcast %mull 4 [%v2[7]]; smulj %mlal [%v3[4],%v3[5],%v3[6],%v3[7]] %mull; adds %dc %v4 %v4 %mlal;
(* smull	v3.4s, v18.4h, v1.h[0]                    #! PC = 0x5555551e0c *)
broadcast %mull 4 [%v1[0]]; smulj %v3 [%v18[0],%v18[1],%v18[2],%v18[3]] %mull;
(* smull2	v2.4s, v18.8h, v1.h[0]                   #! PC = 0x5555551e10 *)
broadcast %mull 4 [%v1[0]]; smulj %v2 [%v18[4],%v18[5],%v18[6],%v18[7]] %mull;
(* ext	v7.16b, v6.16b, v18.16b, #14                #! PC = 0x5555551e14 *)
mov %v7 [%v6[7],%v18[0],%v18[1],%v18[2],%v18[3],%v18[4],%v18[5],%v18[6]];
(* smlal	v3.4s, v7.4h, v1.h[1]                     #! PC = 0x5555551e18 *)
broadcast %mull 4 [%v1[1]]; smulj %mlal [%v7[0],%v7[1],%v7[2],%v7[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v7.8h, v1.h[1]                    #! PC = 0x5555551e1c *)
broadcast %mull 4 [%v1[1]]; smulj %mlal [%v7[4],%v7[5],%v7[6],%v7[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v7.16b, v6.16b, v18.16b, #12                #! PC = 0x5555551e20 *)
mov %v7 [%v6[6],%v6[7],%v18[0],%v18[1],%v18[2],%v18[3],%v18[4],%v18[5]];
(* smlal	v3.4s, v7.4h, v1.h[2]                     #! PC = 0x5555551e24 *)
broadcast %mull 4 [%v1[2]]; smulj %mlal [%v7[0],%v7[1],%v7[2],%v7[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v7.8h, v1.h[2]                    #! PC = 0x5555551e28 *)
broadcast %mull 4 [%v1[2]]; smulj %mlal [%v7[4],%v7[5],%v7[6],%v7[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v7.16b, v6.16b, v18.16b, #10                #! PC = 0x5555551e2c *)
mov %v7 [%v6[5],%v6[6],%v6[7],%v18[0],%v18[1],%v18[2],%v18[3],%v18[4]];
(* smlal	v3.4s, v7.4h, v1.h[3]                     #! PC = 0x5555551e30 *)
broadcast %mull 4 [%v1[3]]; smulj %mlal [%v7[0],%v7[1],%v7[2],%v7[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v7.8h, v1.h[3]                    #! PC = 0x5555551e34 *)
broadcast %mull 4 [%v1[3]]; smulj %mlal [%v7[4],%v7[5],%v7[6],%v7[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v7.16b, v6.16b, v18.16b, #8                 #! PC = 0x5555551e38 *)
mov %v7 [%v6[4],%v6[5],%v6[6],%v6[7],%v18[0],%v18[1],%v18[2],%v18[3]];
(* smlal	v3.4s, v7.4h, v1.h[4]                     #! PC = 0x5555551e3c *)
broadcast %mull 4 [%v1[4]]; smulj %mlal [%v7[0],%v7[1],%v7[2],%v7[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v7.8h, v1.h[4]                    #! PC = 0x5555551e40 *)
broadcast %mull 4 [%v1[4]]; smulj %mlal [%v7[4],%v7[5],%v7[6],%v7[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v7.16b, v6.16b, v18.16b, #6                 #! PC = 0x5555551e44 *)
mov %v7 [%v6[3],%v6[4],%v6[5],%v6[6],%v6[7],%v18[0],%v18[1],%v18[2]];
(* smlal	v3.4s, v7.4h, v1.h[5]                     #! PC = 0x5555551e48 *)
broadcast %mull 4 [%v1[5]]; smulj %mlal [%v7[0],%v7[1],%v7[2],%v7[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v7.8h, v1.h[5]                    #! PC = 0x5555551e4c *)
broadcast %mull 4 [%v1[5]]; smulj %mlal [%v7[4],%v7[5],%v7[6],%v7[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v7.16b, v6.16b, v18.16b, #4                 #! PC = 0x5555551e50 *)
mov %v7 [%v6[2],%v6[3],%v6[4],%v6[5],%v6[6],%v6[7],%v18[0],%v18[1]];
(* smlal	v3.4s, v7.4h, v1.h[6]                     #! PC = 0x5555551e54 *)
broadcast %mull 4 [%v1[6]]; smulj %mlal [%v7[0],%v7[1],%v7[2],%v7[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v7.8h, v1.h[6]                    #! PC = 0x5555551e58 *)
broadcast %mull 4 [%v1[6]]; smulj %mlal [%v7[4],%v7[5],%v7[6],%v7[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v6.16b, v6.16b, v18.16b, #2                 #! PC = 0x5555551e5c *)
mov %v6 [%v6[1],%v6[2],%v6[3],%v6[4],%v6[5],%v6[6],%v6[7],%v18[0]];
(* smlal	v3.4s, v6.4h, v1.h[7]                     #! PC = 0x5555551e60 *)
broadcast %mull 4 [%v1[7]]; smulj %mlal [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v6.8h, v1.h[7]                    #! PC = 0x5555551e64 *)
broadcast %mull 4 [%v1[7]]; smulj %mlal [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; adds %dc %v2 %v2 %mlal;

ghost %conv0_4@sint32[8], %conv1_4@sint32[8] :
    %conv0_4 = [
        %fc0_4[0] * %fd0_4[0] + %fc0_4[1] * %gd0_4[7] + %fc0_4[2] * %gd0_4[6] + %fc0_4[3] * %gd0_4[5] + %fc0_4[4] * %gd0_4[4] + %fc0_4[5] * %gd0_4[3] + %fc0_4[6] * %gd0_4[2] + %fc0_4[7] * %gd0_4[1],
        %fc0_4[0] * %fd0_4[1] + %fc0_4[1] * %fd0_4[0] + %fc0_4[2] * %gd0_4[7] + %fc0_4[3] * %gd0_4[6] + %fc0_4[4] * %gd0_4[5] + %fc0_4[5] * %gd0_4[4] + %fc0_4[6] * %gd0_4[3] + %fc0_4[7] * %gd0_4[2],
        %fc0_4[0] * %fd0_4[2] + %fc0_4[1] * %fd0_4[1] + %fc0_4[2] * %fd0_4[0] + %fc0_4[3] * %gd0_4[7] + %fc0_4[4] * %gd0_4[6] + %fc0_4[5] * %gd0_4[5] + %fc0_4[6] * %gd0_4[4] + %fc0_4[7] * %gd0_4[3],
        %fc0_4[0] * %fd0_4[3] + %fc0_4[1] * %fd0_4[2] + %fc0_4[2] * %fd0_4[1] + %fc0_4[3] * %fd0_4[0] + %fc0_4[4] * %gd0_4[7] + %fc0_4[5] * %gd0_4[6] + %fc0_4[6] * %gd0_4[5] + %fc0_4[7] * %gd0_4[4],
        %fc0_4[0] * %fd0_4[4] + %fc0_4[1] * %fd0_4[3] + %fc0_4[2] * %fd0_4[2] + %fc0_4[3] * %fd0_4[1] + %fc0_4[4] * %fd0_4[0] + %fc0_4[5] * %gd0_4[7] + %fc0_4[6] * %gd0_4[6] + %fc0_4[7] * %gd0_4[5],
        %fc0_4[0] * %fd0_4[5] + %fc0_4[1] * %fd0_4[4] + %fc0_4[2] * %fd0_4[3] + %fc0_4[3] * %fd0_4[2] + %fc0_4[4] * %fd0_4[1] + %fc0_4[5] * %fd0_4[0] + %fc0_4[6] * %gd0_4[7] + %fc0_4[7] * %gd0_4[6],
        %fc0_4[0] * %fd0_4[6] + %fc0_4[1] * %fd0_4[5] + %fc0_4[2] * %fd0_4[4] + %fc0_4[3] * %fd0_4[3] + %fc0_4[4] * %fd0_4[2] + %fc0_4[5] * %fd0_4[1] + %fc0_4[6] * %fd0_4[0] + %fc0_4[7] * %gd0_4[7],
        %fc0_4[0] * %fd0_4[7] + %fc0_4[1] * %fd0_4[6] + %fc0_4[2] * %fd0_4[5] + %fc0_4[3] * %fd0_4[4] + %fc0_4[4] * %fd0_4[3] + %fc0_4[5] * %fd0_4[2] + %fc0_4[6] * %fd0_4[1] + %fc0_4[7] * %fd0_4[0]
    ] /\
    %conv1_4 = [
        %fc1_4[0] * %fd1_4[0] + %fc1_4[1] * %gd1_4[7] + %fc1_4[2] * %gd1_4[6] + %fc1_4[3] * %gd1_4[5] + %fc1_4[4] * %gd1_4[4] + %fc1_4[5] * %gd1_4[3] + %fc1_4[6] * %gd1_4[2] + %fc1_4[7] * %gd1_4[1],
        %fc1_4[0] * %fd1_4[1] + %fc1_4[1] * %fd1_4[0] + %fc1_4[2] * %gd1_4[7] + %fc1_4[3] * %gd1_4[6] + %fc1_4[4] * %gd1_4[5] + %fc1_4[5] * %gd1_4[4] + %fc1_4[6] * %gd1_4[3] + %fc1_4[7] * %gd1_4[2],
        %fc1_4[0] * %fd1_4[2] + %fc1_4[1] * %fd1_4[1] + %fc1_4[2] * %fd1_4[0] + %fc1_4[3] * %gd1_4[7] + %fc1_4[4] * %gd1_4[6] + %fc1_4[5] * %gd1_4[5] + %fc1_4[6] * %gd1_4[4] + %fc1_4[7] * %gd1_4[3],
        %fc1_4[0] * %fd1_4[3] + %fc1_4[1] * %fd1_4[2] + %fc1_4[2] * %fd1_4[1] + %fc1_4[3] * %fd1_4[0] + %fc1_4[4] * %gd1_4[7] + %fc1_4[5] * %gd1_4[6] + %fc1_4[6] * %gd1_4[5] + %fc1_4[7] * %gd1_4[4],
        %fc1_4[0] * %fd1_4[4] + %fc1_4[1] * %fd1_4[3] + %fc1_4[2] * %fd1_4[2] + %fc1_4[3] * %fd1_4[1] + %fc1_4[4] * %fd1_4[0] + %fc1_4[5] * %gd1_4[7] + %fc1_4[6] * %gd1_4[6] + %fc1_4[7] * %gd1_4[5],
        %fc1_4[0] * %fd1_4[5] + %fc1_4[1] * %fd1_4[4] + %fc1_4[2] * %fd1_4[3] + %fc1_4[3] * %fd1_4[2] + %fc1_4[4] * %fd1_4[1] + %fc1_4[5] * %fd1_4[0] + %fc1_4[6] * %gd1_4[7] + %fc1_4[7] * %gd1_4[6],
        %fc1_4[0] * %fd1_4[6] + %fc1_4[1] * %fd1_4[5] + %fc1_4[2] * %fd1_4[4] + %fc1_4[3] * %fd1_4[3] + %fc1_4[4] * %fd1_4[2] + %fc1_4[5] * %fd1_4[1] + %fc1_4[6] * %fd1_4[0] + %fc1_4[7] * %gd1_4[7],
        %fc1_4[0] * %fd1_4[7] + %fc1_4[1] * %fd1_4[6] + %fc1_4[2] * %fd1_4[5] + %fc1_4[3] * %fd1_4[4] + %fc1_4[4] * %fd1_4[3] + %fc1_4[5] * %fd1_4[2] + %fc1_4[6] * %fd1_4[1] + %fc1_4[7] * %fd1_4[0]
    ]
    && true;

assert
    %v0 ++ %v4 = %conv0_4 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] ) /\
    %v3 ++ %v2 = %conv1_4 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] )
    && true;

assume
    %v0 ++ %v4 = %conv0_4 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] ) /\
    %v3 ++ %v2 = %conv1_4 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] )
    && true;

assert
    %conv0_4 <= [524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000] /\
    %conv0_4 >= [-524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000] /\

    %conv1_4 <= [524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000] /\
    %conv1_4 >= [-524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000]
    prove with [algebra solver smt: z3]
    && true;

assume
    %conv0_4 <= [524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000] /\
    %conv0_4 >= [-524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000] /\

    %conv1_4 <= [524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000] /\
    %conv1_4 >= [-524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000]
    && true;

assert
    %v0 ++ %v4 = %conv0_4 /\ %v3 ++ %v2 = %conv1_4
    prove with [algebra solver isl]
    && true;

assume
    %v0 ++ %v4 = %conv0_4 /\ %v3 ++ %v2 = %conv1_4
    && true;

assert
    %v0 <= [524880000, 524880000, 524880000, 524880000] /\
    %v0 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v4 <= [524880000, 524880000, 524880000, 524880000] /\
    %v4 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v3 <= [524880000, 524880000, 524880000, 524880000] /\
    %v3 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v2 <= [524880000, 524880000, 524880000, 524880000] /\
    %v2 >= [-524880000, -524880000, -524880000, -524880000]

    prove with [algebra solver isl]
    && true;

assume
    %v0 <= [524880000, 524880000, 524880000, 524880000] /\
    %v0 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v4 <= [524880000, 524880000, 524880000, 524880000] /\
    %v4 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v3 <= [524880000, 524880000, 524880000, 524880000] /\
    %v3 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v2 <= [524880000, 524880000, 524880000, 524880000] /\
    %v2 >= [-524880000, -524880000, -524880000, -524880000]
  &&
    %v0 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v0 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32] /\

    %v4 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v4 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32] /\

    %v3 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v3 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32] /\

    %v2 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v2 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32];

cut (* 19 *)
    %conv0_4 = [
        %fc0_4[0] * %fd0_4[0] + %fc0_4[1] * %gd0_4[7] + %fc0_4[2] * %gd0_4[6] + %fc0_4[3] * %gd0_4[5] + %fc0_4[4] * %gd0_4[4] + %fc0_4[5] * %gd0_4[3] + %fc0_4[6] * %gd0_4[2] + %fc0_4[7] * %gd0_4[1],
        %fc0_4[0] * %fd0_4[1] + %fc0_4[1] * %fd0_4[0] + %fc0_4[2] * %gd0_4[7] + %fc0_4[3] * %gd0_4[6] + %fc0_4[4] * %gd0_4[5] + %fc0_4[5] * %gd0_4[4] + %fc0_4[6] * %gd0_4[3] + %fc0_4[7] * %gd0_4[2],
        %fc0_4[0] * %fd0_4[2] + %fc0_4[1] * %fd0_4[1] + %fc0_4[2] * %fd0_4[0] + %fc0_4[3] * %gd0_4[7] + %fc0_4[4] * %gd0_4[6] + %fc0_4[5] * %gd0_4[5] + %fc0_4[6] * %gd0_4[4] + %fc0_4[7] * %gd0_4[3],
        %fc0_4[0] * %fd0_4[3] + %fc0_4[1] * %fd0_4[2] + %fc0_4[2] * %fd0_4[1] + %fc0_4[3] * %fd0_4[0] + %fc0_4[4] * %gd0_4[7] + %fc0_4[5] * %gd0_4[6] + %fc0_4[6] * %gd0_4[5] + %fc0_4[7] * %gd0_4[4],
        %fc0_4[0] * %fd0_4[4] + %fc0_4[1] * %fd0_4[3] + %fc0_4[2] * %fd0_4[2] + %fc0_4[3] * %fd0_4[1] + %fc0_4[4] * %fd0_4[0] + %fc0_4[5] * %gd0_4[7] + %fc0_4[6] * %gd0_4[6] + %fc0_4[7] * %gd0_4[5],
        %fc0_4[0] * %fd0_4[5] + %fc0_4[1] * %fd0_4[4] + %fc0_4[2] * %fd0_4[3] + %fc0_4[3] * %fd0_4[2] + %fc0_4[4] * %fd0_4[1] + %fc0_4[5] * %fd0_4[0] + %fc0_4[6] * %gd0_4[7] + %fc0_4[7] * %gd0_4[6],
        %fc0_4[0] * %fd0_4[6] + %fc0_4[1] * %fd0_4[5] + %fc0_4[2] * %fd0_4[4] + %fc0_4[3] * %fd0_4[3] + %fc0_4[4] * %fd0_4[2] + %fc0_4[5] * %fd0_4[1] + %fc0_4[6] * %fd0_4[0] + %fc0_4[7] * %gd0_4[7],
        %fc0_4[0] * %fd0_4[7] + %fc0_4[1] * %fd0_4[6] + %fc0_4[2] * %fd0_4[5] + %fc0_4[3] * %fd0_4[4] + %fc0_4[4] * %fd0_4[3] + %fc0_4[5] * %fd0_4[2] + %fc0_4[6] * %fd0_4[1] + %fc0_4[7] * %fd0_4[0]
    ] /\
    %conv1_4 = [
        %fc1_4[0] * %fd1_4[0] + %fc1_4[1] * %gd1_4[7] + %fc1_4[2] * %gd1_4[6] + %fc1_4[3] * %gd1_4[5] + %fc1_4[4] * %gd1_4[4] + %fc1_4[5] * %gd1_4[3] + %fc1_4[6] * %gd1_4[2] + %fc1_4[7] * %gd1_4[1],
        %fc1_4[0] * %fd1_4[1] + %fc1_4[1] * %fd1_4[0] + %fc1_4[2] * %gd1_4[7] + %fc1_4[3] * %gd1_4[6] + %fc1_4[4] * %gd1_4[5] + %fc1_4[5] * %gd1_4[4] + %fc1_4[6] * %gd1_4[3] + %fc1_4[7] * %gd1_4[2],
        %fc1_4[0] * %fd1_4[2] + %fc1_4[1] * %fd1_4[1] + %fc1_4[2] * %fd1_4[0] + %fc1_4[3] * %gd1_4[7] + %fc1_4[4] * %gd1_4[6] + %fc1_4[5] * %gd1_4[5] + %fc1_4[6] * %gd1_4[4] + %fc1_4[7] * %gd1_4[3],
        %fc1_4[0] * %fd1_4[3] + %fc1_4[1] * %fd1_4[2] + %fc1_4[2] * %fd1_4[1] + %fc1_4[3] * %fd1_4[0] + %fc1_4[4] * %gd1_4[7] + %fc1_4[5] * %gd1_4[6] + %fc1_4[6] * %gd1_4[5] + %fc1_4[7] * %gd1_4[4],
        %fc1_4[0] * %fd1_4[4] + %fc1_4[1] * %fd1_4[3] + %fc1_4[2] * %fd1_4[2] + %fc1_4[3] * %fd1_4[1] + %fc1_4[4] * %fd1_4[0] + %fc1_4[5] * %gd1_4[7] + %fc1_4[6] * %gd1_4[6] + %fc1_4[7] * %gd1_4[5],
        %fc1_4[0] * %fd1_4[5] + %fc1_4[1] * %fd1_4[4] + %fc1_4[2] * %fd1_4[3] + %fc1_4[3] * %fd1_4[2] + %fc1_4[4] * %fd1_4[1] + %fc1_4[5] * %fd1_4[0] + %fc1_4[6] * %gd1_4[7] + %fc1_4[7] * %gd1_4[6],
        %fc1_4[0] * %fd1_4[6] + %fc1_4[1] * %fd1_4[5] + %fc1_4[2] * %fd1_4[4] + %fc1_4[3] * %fd1_4[3] + %fc1_4[4] * %fd1_4[2] + %fc1_4[5] * %fd1_4[1] + %fc1_4[6] * %fd1_4[0] + %fc1_4[7] * %gd1_4[7],
        %fc1_4[0] * %fd1_4[7] + %fc1_4[1] * %fd1_4[6] + %fc1_4[2] * %fd1_4[5] + %fc1_4[3] * %fd1_4[4] + %fc1_4[4] * %fd1_4[3] + %fc1_4[5] * %fd1_4[2] + %fc1_4[6] * %fd1_4[1] + %fc1_4[7] * %fd1_4[0]
    ] /\

    %v0 ++ %v4 = %conv0_4 /\ %v3 ++ %v2 = %conv1_4,

    %v0 <= [524880000, 524880000, 524880000, 524880000] /\
    %v0 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v4 <= [524880000, 524880000, 524880000, 524880000] /\
    %v4 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v3 <= [524880000, 524880000, 524880000, 524880000] /\
    %v3 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v2 <= [524880000, 524880000, 524880000, 524880000] /\
    %v2 >= [-524880000, -524880000, -524880000, -524880000]

    prove with [algebra solver isl]
  &&
    %v0 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v0 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32] /\

    %v4 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v4 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32] /\

    %v3 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v3 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32] /\

    %v2 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v2 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32];

(* add	v1.4s, v3.4s, v0.4s                         #! PC = 0x5555551e68 *)
add %v1 %v3 %v0;
(* add	v6.4s, v2.4s, v4.4s                         #! PC = 0x5555551e6c *)
add %v6 %v2 %v4;
(* sub	v0.4s, v0.4s, v3.4s                         #! PC = 0x5555551e70 *)
sub %v0 %v0 %v3;
(* sub	v4.4s, v4.4s, v2.4s                         #! PC = 0x5555551e74 *)
sub %v4 %v4 %v2;

ghost %h0_4@sint32[8], %h1_4@sint32[8] :
    %h0_4 = %v1 ++ %v6 /\ %h1_4 = %v0 ++ %v4
  &&
    %h0_4 = %v1 ++ %v6 /\ %h1_4 = %v0 ++ %v4;

(* uzp1	v2.8h, v1.8h, v6.8h                        #! PC = 0x5555551e78 *)
mov %spl_join [%v1[0], %v1[1], %v1[2], %v1[3], %v6[0], %v6[1], %v6[2], %v6[3]]; spl %splh %v2 %spl_join 16; cast %v2@int16[8] %v2;
(* mul	v2.8h, v2.8h, v5.h[7]                       #! PC = 0x5555551e7c *)
broadcast %mul 8 [%v5[7]]; mull %dc %v2 %v2 %mul; cast %v2@int16[8] %v2;

ghost %m0_4@sint16[8] : %m0_4 = %v2 && %m0_4 = %v2;

(* sqdmulh	v2.8h, v2.8h, v5.h[6]                   #! PC = 0x5555551e80 *)
broadcast %mul 8 [%v5[6]]; smulj %LO %v2 %mul;
ssplit %LO0 %dc %LO 15; vpc %v2@sint16[8] %LO0;
(* uzp2	v1.8h, v1.8h, v6.8h                        #! PC = 0x5555551e84 *)
mov %spl_join [%v1[0], %v1[1], %v1[2], %v1[3], %v6[0], %v6[1], %v6[2], %v6[3]]; spl %v1 %spll %spl_join 16;
(* sshr	v2.8h, v2.8h, #1                           #! PC = 0x5555551e88 *)
split %v2 %dc %v2 1;
(* sub	v1.8h, v1.8h, v2.8h                         #! PC = 0x5555551e8c *)
sub %v1 %v1 %v2;

ghost %hh0_4@sint16[8] : %hh0_4 = %v1 && %hh0_4 = %v1;

assert
    %h0_4 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m0_4
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh0_4
    prove with [algebra solver isl]
    && true;

assume
    %h0_4 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m0_4
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh0_4
    && true;

(* sqrdmulh	v2.8h, v1.8h, v5.h[3]                  #! PC = 0x5555551e90 *)
broadcast %mul 8 [%v5[3]]; smulj %LO %v1 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v2 %LO11 %LO01;
(* mul	v1.8h, v1.8h, v5.h[2]                       #! PC = 0x5555551e94 *)
broadcast %mul 8 [%v5[2]]; mull %dc %v1 %v1 %mul; cast %v1@int16[8] %v1;
(* mls	v1.8h, v2.8h, v5.h[6]                       #! PC = 0x5555551e98 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v2 %mul;
cast %mls@int16[8] %mls; subc %dc %v1 %v1 %mls;

assert
    [-6, -6, -6, -6, -6, -6, -6, -6] * %hh0_4
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v2
    = %v1
    prove with [algebra solver isl]
    && true;

assume
    [-6, -6, -6, -6, -6, -6, -6, -6] * %hh0_4
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v2
    = %v1
    && true;

(* uzp1	v2.8h, v0.8h, v4.8h                        #! PC = 0x5555551e9c *)
mov %spl_join [%v0[0], %v0[1], %v0[2], %v0[3], %v4[0], %v4[1], %v4[2], %v4[3]]; spl %splh %v2 %spl_join 16; cast %v2@int16[8] %v2;
(* mul	v2.8h, v2.8h, v5.h[7]                       #! PC = 0x5555551ea0 *)
broadcast %mul 8 [%v5[7]]; mull %dc %v2 %v2 %mul; cast %v2@int16[8] %v2;

ghost %m1_4@sint16[8] : %m1_4 = %v2 && %m1_4 = %v2;

(* sqdmulh	v2.8h, v2.8h, v5.h[6]                   #! PC = 0x5555551ea4 *)
broadcast %mul 8 [%v5[6]]; smulj %LO %v2 %mul;
ssplit %LO0 %dc %LO 15; vpc %v2@sint16[8] %LO0;
(* uzp2	v0.8h, v0.8h, v4.8h                        #! PC = 0x5555551ea8 *)
mov %spl_join [%v0[0], %v0[1], %v0[2], %v0[3], %v4[0], %v4[1], %v4[2], %v4[3]]; spl %v0 %spll %spl_join 16;
(* sshr	v2.8h, v2.8h, #1                           #! PC = 0x5555551eac *)
split %v2 %dc %v2 1;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551eb0 *)
sub %v0 %v0 %v2;

ghost %hh1_4@sint16[8] : %hh1_4 = %v0 && %hh1_4 = %v0;

assert
    %h1_4 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m1_4
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh1_4
    prove with [algebra solver isl]
    && true;

assume
    %h1_4 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m1_4
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh1_4
    && true;

(* sqrdmulh	v2.8h, v0.8h, v5.h[5]                  #! PC = 0x5555551eb4 *)
broadcast %mul 8 [%v5[5]]; smulj %LO %v0 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v2 %LO11 %LO01;
(* mul	v0.8h, v0.8h, v5.h[4]                       #! PC = 0x5555551eb8 *)
broadcast %mul 8 [%v5[4]]; mull %dc %v0 %v0 %mul; cast %v0@int16[8] %v0;
(* mls	v0.8h, v2.8h, v5.h[6]                       #! PC = 0x5555551ebc *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v2 %mul;
cast %mls@int16[8] %mls; subc %dc %v0 %v0 %mls;

assert
    [-129, -129, -129, -129, -129, -129, -129, -129] * %hh1_4
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v2
    = %v0
    prove with [algebra solver isl]
    && true;

assume
    [-129, -129, -129, -129, -129, -129, -129, -129] * %hh1_4
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v2
    = %v0
    && true;

(* #b	0x5555551d18 <_ZN6xpower7basemul11low_basemulEPA2_A8_sS3_S3_+504>#! PC = 0x5555551ec0 *)
#b	0x5555551d18 <_ZN6xpower7basemul11low_basemulEPA2_A8_sS3_S3_+504>#! 0x5555551ec0 = 0x5555551ec0;


### i_iter epilogue

(* str	q1, [x2, x3]                                #! EA = L0x7fffffe230; PC = 0x5555551d18 *)
mov [L0x7fffffe230,L0x7fffffe232,L0x7fffffe234,L0x7fffffe236,L0x7fffffe238,L0x7fffffe23a,L0x7fffffe23c,L0x7fffffe23e] %v1;
(* str	q0, [x6, x3]                                #! EA = L0x7fffffe240; PC = 0x5555551d1c *)
mov [L0x7fffffe240,L0x7fffffe242,L0x7fffffe244,L0x7fffffe246,L0x7fffffe248,L0x7fffffe24a,L0x7fffffe24c,L0x7fffffe24e] %v0;
(* #b.eq	0x5555551ec4 <_ZN6xpower7basemul11low_basemulEPA2_A8_sS3_S3_+932>  // b.none#! PC = 0x5555551d30 *)
#b.eq	0x5555551ec4 <_ZN6xpower7basemul11low_basemulEPA2_A8_sS3_S3_+932>  // b.none#! 0x5555551d30 = 0x5555551d30;

assert
    %v1 <= [3100, 3100, 3100, 3100, 3100, 3100, 3100, 3100] /\
    %v1 >= [-3100, -3100, -3100, -3100, -3100, -3100, -3100, -3100] /\

    %v0 <= [3550, 3550, 3550, 3550, 3550, 3550, 3550, 3550] /\
    %v0 >= [-3550, -3550, -3550, -3550, -3550, -3550, -3550, -3550]

    prove with [algebra solver isl]
    && true;

assume
    true &&

    %v1 <=s [3100@16, 3100@16, 3100@16, 3100@16, 3100@16, 3100@16, 3100@16, 3100@16] /\
    %v1 >=s [(-3100)@16, (-3100)@16, (-3100)@16, (-3100)@16, (-3100)@16, (-3100)@16, (-3100)@16, (-3100)@16] /\

    %v0 <=s [3550@16, 3550@16, 3550@16, 3550@16, 3550@16, 3550@16, 3550@16, 3550@16] /\
    %v0 >=s [(-3550)@16, (-3550)@16, (-3550)@16, (-3550)@16, (-3550)@16, (-3550)@16, (-3550)@16, (-3550)@16];

cut (* 20 *)
    [L0x7fffffe230, L0x7fffffe232, L0x7fffffe234, L0x7fffffe236, L0x7fffffe238, L0x7fffffe23a, L0x7fffffe23c, L0x7fffffe23e] = %v1 /\
    [L0x7fffffe240, L0x7fffffe242, L0x7fffffe244, L0x7fffffe246, L0x7fffffe248, L0x7fffffe24a, L0x7fffffe24c, L0x7fffffe24e] = %v0 /\

    %v1 ++ %v0 = [-633, -633, -633, -633, -633, -633, -633, -633, -633, -633, -633, -633, -633, -633, -633, -633] * [
        arr400_a * arr400_b + -2113 * arr401_a * arr417_b + -2113 * arr402_a * arr416_b + -2113 * arr403_a * arr415_b + -2113 * arr404_a * arr414_b + -2113 * arr405_a * arr413_b + -2113 * arr406_a * arr412_b + -2113 * arr407_a * arr411_b + -2113 * arr410_a * arr410_b + -2113 * arr411_a * arr407_b + -2113 * arr412_a * arr406_b + -2113 * arr413_a * arr405_b + -2113 * arr414_a * arr404_b + -2113 * arr415_a * arr403_b + -2113 * arr416_a * arr402_b + -2113 * arr417_a * arr401_b,
        arr400_a * arr401_b + arr401_a * arr400_b + -2113 * arr402_a * arr417_b + -2113 * arr403_a * arr416_b + -2113 * arr404_a * arr415_b + -2113 * arr405_a * arr414_b + -2113 * arr406_a * arr413_b + -2113 * arr407_a * arr412_b + -2113 * arr410_a * arr411_b + -2113 * arr411_a * arr410_b + -2113 * arr412_a * arr407_b + -2113 * arr413_a * arr406_b + -2113 * arr414_a * arr405_b + -2113 * arr415_a * arr404_b + -2113 * arr416_a * arr403_b + -2113 * arr417_a * arr402_b,
        arr400_a * arr402_b + arr401_a * arr401_b + arr402_a * arr400_b + -2113 * arr403_a * arr417_b + -2113 * arr404_a * arr416_b + -2113 * arr405_a * arr415_b + -2113 * arr406_a * arr414_b + -2113 * arr407_a * arr413_b + -2113 * arr410_a * arr412_b + -2113 * arr411_a * arr411_b + -2113 * arr412_a * arr410_b + -2113 * arr413_a * arr407_b + -2113 * arr414_a * arr406_b + -2113 * arr415_a * arr405_b + -2113 * arr416_a * arr404_b + -2113 * arr417_a * arr403_b,
        arr400_a * arr403_b + arr401_a * arr402_b + arr402_a * arr401_b + arr403_a * arr400_b + -2113 * arr404_a * arr417_b + -2113 * arr405_a * arr416_b + -2113 * arr406_a * arr415_b + -2113 * arr407_a * arr414_b + -2113 * arr410_a * arr413_b + -2113 * arr411_a * arr412_b + -2113 * arr412_a * arr411_b + -2113 * arr413_a * arr410_b + -2113 * arr414_a * arr407_b + -2113 * arr415_a * arr406_b + -2113 * arr416_a * arr405_b + -2113 * arr417_a * arr404_b,
        arr400_a * arr404_b + arr401_a * arr403_b + arr402_a * arr402_b + arr403_a * arr401_b + arr404_a * arr400_b + -2113 * arr405_a * arr417_b + -2113 * arr406_a * arr416_b + -2113 * arr407_a * arr415_b + -2113 * arr410_a * arr414_b + -2113 * arr411_a * arr413_b + -2113 * arr412_a * arr412_b + -2113 * arr413_a * arr411_b + -2113 * arr414_a * arr410_b + -2113 * arr415_a * arr407_b + -2113 * arr416_a * arr406_b + -2113 * arr417_a * arr405_b,
        arr400_a * arr405_b + arr401_a * arr404_b + arr402_a * arr403_b + arr403_a * arr402_b + arr404_a * arr401_b + arr405_a * arr400_b + -2113 * arr406_a * arr417_b + -2113 * arr407_a * arr416_b + -2113 * arr410_a * arr415_b + -2113 * arr411_a * arr414_b + -2113 * arr412_a * arr413_b + -2113 * arr413_a * arr412_b + -2113 * arr414_a * arr411_b + -2113 * arr415_a * arr410_b + -2113 * arr416_a * arr407_b + -2113 * arr417_a * arr406_b,
        arr400_a * arr406_b + arr401_a * arr405_b + arr402_a * arr404_b + arr403_a * arr403_b + arr404_a * arr402_b + arr405_a * arr401_b + arr406_a * arr400_b + -2113 * arr407_a * arr417_b + -2113 * arr410_a * arr416_b + -2113 * arr411_a * arr415_b + -2113 * arr412_a * arr414_b + -2113 * arr413_a * arr413_b + -2113 * arr414_a * arr412_b + -2113 * arr415_a * arr411_b + -2113 * arr416_a * arr410_b + -2113 * arr417_a * arr407_b,
        arr400_a * arr407_b + arr401_a * arr406_b + arr402_a * arr405_b + arr403_a * arr404_b + arr404_a * arr403_b + arr405_a * arr402_b + arr406_a * arr401_b + arr407_a * arr400_b + -2113 * arr410_a * arr417_b + -2113 * arr411_a * arr416_b + -2113 * arr412_a * arr415_b + -2113 * arr413_a * arr414_b + -2113 * arr414_a * arr413_b + -2113 * arr415_a * arr412_b + -2113 * arr416_a * arr411_b + -2113 * arr417_a * arr410_b,
        arr400_a * arr410_b + arr401_a * arr407_b + arr402_a * arr406_b + arr403_a * arr405_b + arr404_a * arr404_b + arr405_a * arr403_b + arr406_a * arr402_b + arr407_a * arr401_b + arr410_a * arr400_b + -2113 * arr411_a * arr417_b + -2113 * arr412_a * arr416_b + -2113 * arr413_a * arr415_b + -2113 * arr414_a * arr414_b + -2113 * arr415_a * arr413_b + -2113 * arr416_a * arr412_b + -2113 * arr417_a * arr411_b,
        arr400_a * arr411_b + arr401_a * arr410_b + arr402_a * arr407_b + arr403_a * arr406_b + arr404_a * arr405_b + arr405_a * arr404_b + arr406_a * arr403_b + arr407_a * arr402_b + arr410_a * arr401_b + arr411_a * arr400_b + -2113 * arr412_a * arr417_b + -2113 * arr413_a * arr416_b + -2113 * arr414_a * arr415_b + -2113 * arr415_a * arr414_b + -2113 * arr416_a * arr413_b + -2113 * arr417_a * arr412_b,
        arr400_a * arr412_b + arr401_a * arr411_b + arr402_a * arr410_b + arr403_a * arr407_b + arr404_a * arr406_b + arr405_a * arr405_b + arr406_a * arr404_b + arr407_a * arr403_b + arr410_a * arr402_b + arr411_a * arr401_b + arr412_a * arr400_b + -2113 * arr413_a * arr417_b + -2113 * arr414_a * arr416_b + -2113 * arr415_a * arr415_b + -2113 * arr416_a * arr414_b + -2113 * arr417_a * arr413_b,
        arr400_a * arr413_b + arr401_a * arr412_b + arr402_a * arr411_b + arr403_a * arr410_b + arr404_a * arr407_b + arr405_a * arr406_b + arr406_a * arr405_b + arr407_a * arr404_b + arr410_a * arr403_b + arr411_a * arr402_b + arr412_a * arr401_b + arr413_a * arr400_b + -2113 * arr414_a * arr417_b + -2113 * arr415_a * arr416_b + -2113 * arr416_a * arr415_b + -2113 * arr417_a * arr414_b,
        arr400_a * arr414_b + arr401_a * arr413_b + arr402_a * arr412_b + arr403_a * arr411_b + arr404_a * arr410_b + arr405_a * arr407_b + arr406_a * arr406_b + arr407_a * arr405_b + arr410_a * arr404_b + arr411_a * arr403_b + arr412_a * arr402_b + arr413_a * arr401_b + arr414_a * arr400_b + -2113 * arr415_a * arr417_b + -2113 * arr416_a * arr416_b + -2113 * arr417_a * arr415_b,
        arr400_a * arr415_b + arr401_a * arr414_b + arr402_a * arr413_b + arr403_a * arr412_b + arr404_a * arr411_b + arr405_a * arr410_b + arr406_a * arr407_b + arr407_a * arr406_b + arr410_a * arr405_b + arr411_a * arr404_b + arr412_a * arr403_b + arr413_a * arr402_b + arr414_a * arr401_b + arr415_a * arr400_b + -2113 * arr416_a * arr417_b + -2113 * arr417_a * arr416_b,
        arr400_a * arr416_b + arr401_a * arr415_b + arr402_a * arr414_b + arr403_a * arr413_b + arr404_a * arr412_b + arr405_a * arr411_b + arr406_a * arr410_b + arr407_a * arr407_b + arr410_a * arr406_b + arr411_a * arr405_b + arr412_a * arr404_b + arr413_a * arr403_b + arr414_a * arr402_b + arr415_a * arr401_b + arr416_a * arr400_b + -2113 * arr417_a * arr417_b,
        arr400_a * arr417_b + arr401_a * arr416_b + arr402_a * arr415_b + arr403_a * arr414_b + arr404_a * arr413_b + arr405_a * arr412_b + arr406_a * arr411_b + arr407_a * arr410_b + arr410_a * arr407_b + arr411_a * arr406_b + arr412_a * arr405_b + arr413_a * arr404_b + arr414_a * arr403_b + arr415_a * arr402_b + arr416_a * arr401_b + arr417_a * arr400_b
    ] ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] )

    prove with [cuts[0, 17, 18, 19]]
  &&
    [L0x7fffffe230, L0x7fffffe232, L0x7fffffe234, L0x7fffffe236, L0x7fffffe238, L0x7fffffe23a, L0x7fffffe23c, L0x7fffffe23e] = %v1 /\
    [L0x7fffffe240, L0x7fffffe242, L0x7fffffe244, L0x7fffffe246, L0x7fffffe248, L0x7fffffe24a, L0x7fffffe24c, L0x7fffffe24e] = %v0 /\

    %v1 <=s [3100@16, 3100@16, 3100@16, 3100@16, 3100@16, 3100@16, 3100@16, 3100@16] /\
    %v1 >=s [(-3100)@16, (-3100)@16, (-3100)@16, (-3100)@16, (-3100)@16, (-3100)@16, (-3100)@16, (-3100)@16] /\

    %v0 <=s [3550@16, 3550@16, 3550@16, 3550@16, 3550@16, 3550@16, 3550@16, 3550@16] /\
    %v0 >=s [(-3550)@16, (-3550)@16, (-3550)@16, (-3550)@16, (-3550)@16, (-3550)@16, (-3550)@16, (-3550)@16];


### i_iter prologue

(* ldr	q4, [x0, x3]                                #! EA = L0x7fffffe4d0; Value = 0x0000000000000000; PC = 0x5555551d34 *)
mov %v4 [L0x7fffffe4d0,L0x7fffffe4d2,L0x7fffffe4d4,L0x7fffffe4d6,L0x7fffffe4d8,L0x7fffffe4da,L0x7fffffe4dc,L0x7fffffe4de];
(* ldr	q1, [x8, x3]                                #! EA = L0x7fffffe4e0; Value = 0x0000000000000000; PC = 0x5555551d38 *)
mov %v1 [L0x7fffffe4e0,L0x7fffffe4e2,L0x7fffffe4e4,L0x7fffffe4e6,L0x7fffffe4e8,L0x7fffffe4ea,L0x7fffffe4ec,L0x7fffffe4ee];
(* ldr	q17, [x1, x3]                               #! EA = L0x7fffffe390; Value = 0x0000000000000000; PC = 0x5555551d3c *)
mov %v17 [L0x7fffffe390,L0x7fffffe392,L0x7fffffe394,L0x7fffffe396,L0x7fffffe398,L0x7fffffe39a,L0x7fffffe39c,L0x7fffffe39e];
(* ldr	q18, [x7, x3]                               #! EA = L0x7fffffe3a0; Value = 0x0000000000000000; PC = 0x5555551d40 *)
mov %v18 [L0x7fffffe3a0,L0x7fffffe3a2,L0x7fffffe3a4,L0x7fffffe3a6,L0x7fffffe3a8,L0x7fffffe3aa,L0x7fffffe3ac,L0x7fffffe3ae];

ghost %fa0_5@sint16[8], %fa1_5@sint16[8], %fb0_5@sint16[8], %fb1_5@sint16[8] :
    %fa0_5 = %v4 /\ %fa1_5 = %v1 /\ %fb0_5 = %v17 /\ %fb1_5 = %v18
  &&
    %fa0_5 = %v4 /\ %fa1_5 = %v1 /\ %fb0_5 = %v17 /\ %fb1_5 = %v18;

cut (* 21 *)
    %fa0_5 = %v4 /\ %fa1_5 = %v1 /\ %fb0_5 = %v17 /\ %fb1_5 = %v18 /\
    %fa0_5 = [arr500_a, arr501_a, arr502_a, arr503_a, arr504_a, arr505_a, arr506_a, arr507_a] /\
    %fa1_5 = [arr510_a, arr511_a, arr512_a, arr513_a, arr514_a, arr515_a, arr516_a, arr517_a] /\
    %fb0_5 = [arr500_b, arr501_b, arr502_b, arr503_b, arr504_b, arr505_b, arr506_b, arr507_b] /\
    %fb1_5 = [arr510_b, arr511_b, arr512_b, arr513_b, arr514_b, arr515_b, arr516_b, arr517_b]
    prove with [cuts[0]]
  &&
    %fa0_5 = %v4 /\ %fa1_5 = %v1 /\ %fb0_5 = %v17 /\ %fb1_5 = %v18 /\
    %fa0_5 = [arr500_a, arr501_a, arr502_a, arr503_a, arr504_a, arr505_a, arr506_a, arr507_a] /\
    %fa1_5 = [arr510_a, arr511_a, arr512_a, arr513_a, arr514_a, arr515_a, arr516_a, arr517_a] /\
    %fb0_5 = [arr500_b, arr501_b, arr502_b, arr503_b, arr504_b, arr505_b, arr506_b, arr507_b] /\
    %fb1_5 = [arr510_b, arr511_b, arr512_b, arr513_b, arr514_b, arr515_b, arr516_b, arr517_b]
    prove with [cuts[0]];

#### karatsuba

(* ldr	q5, [x5]                                    #! EA = L0x5555552e50; Value = 0x1aa703bcfff9ffff; PC = 0x5555551b44 *)
mov %v5 [L0x5555552e50,L0x5555552e52,L0x5555552e54,L0x5555552e56,L0x5555552e58,L0x5555552e5a,L0x5555552e5c,L0x5555552e5e];
(* sshr	v0.8h, v4.8h, #12                          #! PC = 0x5555551b48 *)
split %v0 %dc %v4 12;
(* cmlt	v2.8h, v4.8h, #0                           #! PC = 0x5555551b4c *)
split %v2 %dc %v4 15;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551b50 *)
sub %v0 %v0 %v2;
(* mls	v4.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551b54 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v4 %v4 %mls;

assert
    %fa0_5 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v4
    prove with [algebra solver isl, precondition, cuts[0, 21]]
    && true;

assume
    %fa0_5 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v4
    && true;

(* sshr	v0.8h, v1.8h, #12                          #! PC = 0x5555551b58 *)
split %v0 %dc %v1 12;
(* cmlt	v2.8h, v1.8h, #0                           #! PC = 0x5555551b5c *)
split %v2 %dc %v1 15;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551b60 *)
sub %v0 %v0 %v2;
(* mls	v1.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551b64 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v1 %v1 %mls;

assert
    %fa1_5 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v1
    prove with [algebra solver isl, precondition, cuts[0, 21]]
    && true;

assume
    %fa1_5 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v1
    && true;

(* sshr	v0.8h, v17.8h, #12                         #! PC = 0x5555551b68 *)
split %v0 %dc %v17 12;
(* cmlt	v2.8h, v17.8h, #0                          #! PC = 0x5555551b6c *)
split %v2 %dc %v17 15;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551b70 *)
sub %v0 %v0 %v2;
(* mls	v17.8h, v0.8h, v5.h[6]                      #! PC = 0x5555551b74 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v17 %v17 %mls;

assert
    %fb0_5 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v17
    prove with [algebra solver isl, precondition, cuts[0, 21]]
    && true;

assume
    %fb0_5 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v17
    && true;

(* sshr	v0.8h, v18.8h, #12                         #! PC = 0x5555551b78 *)
split %v0 %dc %v18 12;
(* cmlt	v2.8h, v18.8h, #0                          #! PC = 0x5555551b7c *)
split %v2 %dc %v18 15;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551b80 *)
sub %v0 %v0 %v2;
(* mls	v18.8h, v0.8h, v5.h[6]                      #! PC = 0x5555551b84 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v18 %v18 %mls;

assert
    %fb1_5 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v18
    prove with [algebra solver isl, precondition, cuts[0, 21]]
    && true;

assume
    %fb1_5 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v18
    && true;

ghost %fc0_5@sint16[8], %fc1_5@sint16[8], %fd0_5@sint16[8], %fd1_5@sint16[8] :
    %fc0_5 = %v4 /\ %fc1_5 = %v1 /\ %fd0_5 = %v17 /\ %fd1_5 = %v18
  &&
    %fc0_5 = %v4 /\ %fc1_5 = %v1 /\ %fd0_5 = %v17 /\ %fd1_5 = %v18;

(* sqrdmulh	v0.8h, v17.8h, v5.h[1]                 #! PC = 0x5555551b88 *)
broadcast %mul 8 [%v5[1]]; smulj %LO %v17 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v0 %LO11 %LO01;
(* mul	v6.8h, v17.8h, v5.h[0]                      #! PC = 0x5555551b8c *)
broadcast %mul 8 [%v5[0]]; mull %dc %v6 %v17 %mul; cast %v6@int16[8] %v6;
(* mov	v7.16b, v6.16b                              #! PC = 0x5555551b90 *)
mov %v7 %v6;
(* mls	v7.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551b94 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v7 %v7 %mls;

assert
    [-1, -1, -1, -1, -1, -1, -1, -1] * %fd0_5
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v7
    prove with [algebra solver isl, precondition, cuts[0, 21]]
    && true;

assume
    [-1, -1, -1, -1, -1, -1, -1, -1] * %fd0_5
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v7
    && true;

(* sqrdmulh	v0.8h, v18.8h, v5.h[1]                 #! PC = 0x5555551b98 *)
broadcast %mul 8 [%v5[1]]; smulj %LO %v18 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v0 %LO11 %LO01;
(* mul	v3.8h, v18.8h, v5.h[0]                      #! PC = 0x5555551b9c *)
broadcast %mul 8 [%v5[0]]; mull %dc %v3 %v18 %mul; cast %v3@int16[8] %v3;
(* mls	v3.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551ba0 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v3 %v3 %mls;

assert
    [-1, -1, -1, -1, -1, -1, -1, -1] * %fd1_5
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v3
    prove with [algebra solver isl, precondition, cuts[0, 21]]
    && true;

assume
    [-1, -1, -1, -1, -1, -1, -1, -1] * %fd1_5
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v3
    && true;

ghost %fe0_5@sint16[8], %fe1_5@sint16[8] :
    %fe0_5 = %v7 /\ %fe1_5 = %v3
  &&
    %fe0_5 = %v7 /\ %fe1_5 = %v3;

cut (* 22 *)
    %fc0_5 = %v4 /\ %fc1_5 = %v1 /\ %fd0_5 = %v17 /\ %fd1_5 = %v18 /\ %fe0_5 = %v7 /\ %fe1_5 = %v3 /\

    %fc0_5 = %fa0_5 ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\
    %fc1_5 = %fa1_5 ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\
    %fd0_5 = %fb0_5 ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\
    %fd1_5 = %fb1_5 ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\

    %fe0_5 = [-1, -1, -1, -1, -1, -1, -1, -1] * %fd0_5
    ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\

    %fe1_5 = [-1, -1, -1, -1, -1, -1, -1, -1] * %fd1_5
    ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ),

    %fc0_5 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %fc0_5 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %fc1_5 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %fc1_5 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %fd0_5 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %fd0_5 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %fd1_5 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %fd1_5 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %fe0_5 <= [3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000] /\
    %fe0_5 >= [-3000, -3000, -3000, -3000, -3000, -3000, -3000, -3000] /\

    %fe1_5 <= [3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000] /\
    %fe1_5 >= [-3000, -3000, -3000, -3000, -3000, -3000, -3000, -3000]

    prove with [algebra solver isl, precondition, cuts[0, 21]]
  &&
    true
    prove with [precondition, cuts[0, 21]];

assert
    %v4 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %v4 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %v1 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %v1 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %v17 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %v17 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %v18 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %v18 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %v7 <= [3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000] /\
    %v7 >= [-3000, -3000, -3000, -3000, -3000, -3000, -3000, -3000] /\

    %v3 <= [3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000] /\
    %v3 >= [-3000, -3000, -3000, -3000, -3000, -3000, -3000, -3000]

    prove with [algebra solver isl, cuts[22]]
    && true;

assume
    true &&
    %v4 <=s [4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16] /\
    %v4 >=s [(-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16] /\

    %v1 <=s [4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16] /\
    %v1 >=s [(-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16] /\

    %v17 <=s [4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16] /\
    %v17 >=s [(-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16] /\

    %v18 <=s [4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16] /\
    %v18 >=s [(-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16] /\

    %v7 <=s [3000@16, 3000@16, 3000@16, 3000@16, 3000@16, 3000@16, 3000@16, 3000@16] /\
    %v7 >=s [(-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16] /\

    %v3 <=s [3000@16, 3000@16, 3000@16, 3000@16, 3000@16, 3000@16, 3000@16, 3000@16] /\
    %v3 >=s [(-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16];

(* add	v6.8h, v4.8h, v1.8h                         #! PC = 0x5555551ba4 *)
add %v6 %v4 %v1;
(* smull	v0.4s, v17.4h, v6.h[0]                    #! PC = 0x5555551ba8 *)
broadcast %mull 4 [%v6[0]]; smulj %v0 [%v17[0],%v17[1],%v17[2],%v17[3]] %mull;
(* smull2	v2.4s, v17.8h, v6.h[0]                   #! PC = 0x5555551bac *)
broadcast %mull 4 [%v6[0]]; smulj %v2 [%v17[4],%v17[5],%v17[6],%v17[7]] %mull;
(* ext	v16.16b, v3.16b, v17.16b, #14               #! PC = 0x5555551bb0 *)
mov %v16 [%v3[7],%v17[0],%v17[1],%v17[2],%v17[3],%v17[4],%v17[5],%v17[6]];
(* smlal	v0.4s, v16.4h, v6.h[1]                    #! PC = 0x5555551bb4 *)
broadcast %mull 4 [%v6[1]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[1]                   #! PC = 0x5555551bb8 *)
broadcast %mull 4 [%v6[1]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v16.16b, v3.16b, v17.16b, #12               #! PC = 0x5555551bbc *)
mov %v16 [%v3[6],%v3[7],%v17[0],%v17[1],%v17[2],%v17[3],%v17[4],%v17[5]];
(* smlal	v0.4s, v16.4h, v6.h[2]                    #! PC = 0x5555551bc0 *)
broadcast %mull 4 [%v6[2]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[2]                   #! PC = 0x5555551bc4 *)
broadcast %mull 4 [%v6[2]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v16.16b, v3.16b, v17.16b, #10               #! PC = 0x5555551bc8 *)
mov %v16 [%v3[5],%v3[6],%v3[7],%v17[0],%v17[1],%v17[2],%v17[3],%v17[4]];
(* smlal	v0.4s, v16.4h, v6.h[3]                    #! PC = 0x5555551bcc *)
broadcast %mull 4 [%v6[3]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[3]                   #! PC = 0x5555551bd0 *)
broadcast %mull 4 [%v6[3]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v16.16b, v3.16b, v17.16b, #8                #! PC = 0x5555551bd4 *)
mov %v16 [%v3[4],%v3[5],%v3[6],%v3[7],%v17[0],%v17[1],%v17[2],%v17[3]];
(* smlal	v0.4s, v16.4h, v6.h[4]                    #! PC = 0x5555551bd8 *)
broadcast %mull 4 [%v6[4]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[4]                   #! PC = 0x5555551bdc *)
broadcast %mull 4 [%v6[4]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v16.16b, v3.16b, v17.16b, #6                #! PC = 0x5555551be0 *)
mov %v16 [%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v17[0],%v17[1],%v17[2]];
(* smlal	v0.4s, v16.4h, v6.h[5]                    #! PC = 0x5555551be4 *)
broadcast %mull 4 [%v6[5]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[5]                   #! PC = 0x5555551be8 *)
broadcast %mull 4 [%v6[5]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v16.16b, v3.16b, v17.16b, #4                #! PC = 0x5555551bec *)
mov %v16 [%v3[2],%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v17[0],%v17[1]];
(* smlal	v0.4s, v16.4h, v6.h[6]                    #! PC = 0x5555551bf0 *)
broadcast %mull 4 [%v6[6]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[6]                   #! PC = 0x5555551bf4 *)
broadcast %mull 4 [%v6[6]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v16.16b, v3.16b, v17.16b, #2                #! PC = 0x5555551bf8 *)
mov %v16 [%v3[1],%v3[2],%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v17[0]];
(* smlal	v0.4s, v16.4h, v6.h[7]                    #! PC = 0x5555551bfc *)
broadcast %mull 4 [%v6[7]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[7]                   #! PC = 0x5555551c00 *)
broadcast %mull 4 [%v6[7]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* sub	v6.8h, v7.8h, v3.8h                         #! PC = 0x5555551c04 *)
sub %v6 %v7 %v3;
(* sub	v3.8h, v3.8h, v17.8h                        #! PC = 0x5555551c08 *)
sub %v3 %v3 %v17;
(* mov	v16.16b, v0.16b                             #! PC = 0x5555551c0c *)
mov %v16 %v0;
(* smlal	v16.4s, v3.4h, v1.h[0]                    #! PC = 0x5555551c10 *)
broadcast %mull 4 [%v1[0]]; smulj %mlal [%v3[0],%v3[1],%v3[2],%v3[3]] %mull; adds %dc %v16 %v16 %mlal;
(* mov	v7.16b, v2.16b                              #! PC = 0x5555551c14 *)
mov %v7 %v2;
(* smlal2	v7.4s, v3.8h, v1.h[0]                    #! PC = 0x5555551c18 *)
broadcast %mull 4 [%v1[0]]; smulj %mlal [%v3[4],%v3[5],%v3[6],%v3[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v19.16b, v6.16b, v3.16b, #14                #! PC = 0x5555551c1c *)
mov %v19 [%v6[7],%v3[0],%v3[1],%v3[2],%v3[3],%v3[4],%v3[5],%v3[6]];
(* smlal	v16.4s, v19.4h, v1.h[1]                   #! PC = 0x5555551c20 *)
broadcast %mull 4 [%v1[1]]; smulj %mlal [%v19[0],%v19[1],%v19[2],%v19[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v19.8h, v1.h[1]                   #! PC = 0x5555551c24 *)
broadcast %mull 4 [%v1[1]]; smulj %mlal [%v19[4],%v19[5],%v19[6],%v19[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v19.16b, v6.16b, v3.16b, #12                #! PC = 0x5555551c28 *)
mov %v19 [%v6[6],%v6[7],%v3[0],%v3[1],%v3[2],%v3[3],%v3[4],%v3[5]];
(* smlal	v16.4s, v19.4h, v1.h[2]                   #! PC = 0x5555551c2c *)
broadcast %mull 4 [%v1[2]]; smulj %mlal [%v19[0],%v19[1],%v19[2],%v19[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v19.8h, v1.h[2]                   #! PC = 0x5555551c30 *)
broadcast %mull 4 [%v1[2]]; smulj %mlal [%v19[4],%v19[5],%v19[6],%v19[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v19.16b, v6.16b, v3.16b, #10                #! PC = 0x5555551c34 *)
mov %v19 [%v6[5],%v6[6],%v6[7],%v3[0],%v3[1],%v3[2],%v3[3],%v3[4]];
(* smlal	v16.4s, v19.4h, v1.h[3]                   #! PC = 0x5555551c38 *)
broadcast %mull 4 [%v1[3]]; smulj %mlal [%v19[0],%v19[1],%v19[2],%v19[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v19.8h, v1.h[3]                   #! PC = 0x5555551c3c *)
broadcast %mull 4 [%v1[3]]; smulj %mlal [%v19[4],%v19[5],%v19[6],%v19[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v19.16b, v6.16b, v3.16b, #8                 #! PC = 0x5555551c40 *)
mov %v19 [%v6[4],%v6[5],%v6[6],%v6[7],%v3[0],%v3[1],%v3[2],%v3[3]];
(* smlal	v16.4s, v19.4h, v1.h[4]                   #! PC = 0x5555551c44 *)
broadcast %mull 4 [%v1[4]]; smulj %mlal [%v19[0],%v19[1],%v19[2],%v19[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v19.8h, v1.h[4]                   #! PC = 0x5555551c48 *)
broadcast %mull 4 [%v1[4]]; smulj %mlal [%v19[4],%v19[5],%v19[6],%v19[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v19.16b, v6.16b, v3.16b, #6                 #! PC = 0x5555551c4c *)
mov %v19 [%v6[3],%v6[4],%v6[5],%v6[6],%v6[7],%v3[0],%v3[1],%v3[2]];
(* smlal	v16.4s, v19.4h, v1.h[5]                   #! PC = 0x5555551c50 *)
broadcast %mull 4 [%v1[5]]; smulj %mlal [%v19[0],%v19[1],%v19[2],%v19[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v19.8h, v1.h[5]                   #! PC = 0x5555551c54 *)
broadcast %mull 4 [%v1[5]]; smulj %mlal [%v19[4],%v19[5],%v19[6],%v19[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v19.16b, v6.16b, v3.16b, #4                 #! PC = 0x5555551c58 *)
mov %v19 [%v6[2],%v6[3],%v6[4],%v6[5],%v6[6],%v6[7],%v3[0],%v3[1]];
(* smlal	v16.4s, v19.4h, v1.h[6]                   #! PC = 0x5555551c5c *)
broadcast %mull 4 [%v1[6]]; smulj %mlal [%v19[0],%v19[1],%v19[2],%v19[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v19.8h, v1.h[6]                   #! PC = 0x5555551c60 *)
broadcast %mull 4 [%v1[6]]; smulj %mlal [%v19[4],%v19[5],%v19[6],%v19[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v6.16b, v6.16b, v3.16b, #2                  #! PC = 0x5555551c64 *)
mov %v6 [%v6[1],%v6[2],%v6[3],%v6[4],%v6[5],%v6[6],%v6[7],%v3[0]];
(* smlal	v16.4s, v6.4h, v1.h[7]                    #! PC = 0x5555551c68 *)
broadcast %mull 4 [%v1[7]]; smulj %mlal [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v6.8h, v1.h[7]                    #! PC = 0x5555551c6c *)
broadcast %mull 4 [%v1[7]]; smulj %mlal [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; adds %dc %v7 %v7 %mlal;
(* sub	v1.8h, v17.8h, v18.8h                       #! PC = 0x5555551c70 *)
sub %v1 %v17 %v18;
(* smlsl	v0.4s, v1.4h, v4.h[0]                     #! PC = 0x5555551c74 *)
broadcast %mull 4 [%v4[0]]; smulj %mlsl [%v1[0],%v1[1],%v1[2],%v1[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v1.8h, v4.h[0]                    #! PC = 0x5555551c78 *)
broadcast %mull 4 [%v4[0]]; smulj %mlsl [%v1[4],%v1[5],%v1[6],%v1[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v6.16b, v3.16b, v1.16b, #14                 #! PC = 0x5555551c7c *)
mov %v6 [%v3[7],%v1[0],%v1[1],%v1[2],%v1[3],%v1[4],%v1[5],%v1[6]];
(* smlsl	v0.4s, v6.4h, v4.h[1]                     #! PC = 0x5555551c80 *)
broadcast %mull 4 [%v4[1]]; smulj %mlsl [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v6.8h, v4.h[1]                    #! PC = 0x5555551c84 *)
broadcast %mull 4 [%v4[1]]; smulj %mlsl [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v6.16b, v3.16b, v1.16b, #12                 #! PC = 0x5555551c88 *)
mov %v6 [%v3[6],%v3[7],%v1[0],%v1[1],%v1[2],%v1[3],%v1[4],%v1[5]];
(* smlsl	v0.4s, v6.4h, v4.h[2]                     #! PC = 0x5555551c8c *)
broadcast %mull 4 [%v4[2]]; smulj %mlsl [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v6.8h, v4.h[2]                    #! PC = 0x5555551c90 *)
broadcast %mull 4 [%v4[2]]; smulj %mlsl [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v6.16b, v3.16b, v1.16b, #10                 #! PC = 0x5555551c94 *)
mov %v6 [%v3[5],%v3[6],%v3[7],%v1[0],%v1[1],%v1[2],%v1[3],%v1[4]];
(* smlsl	v0.4s, v6.4h, v4.h[3]                     #! PC = 0x5555551c98 *)
broadcast %mull 4 [%v4[3]]; smulj %mlsl [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v6.8h, v4.h[3]                    #! PC = 0x5555551c9c *)
broadcast %mull 4 [%v4[3]]; smulj %mlsl [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v6.16b, v3.16b, v1.16b, #8                  #! PC = 0x5555551ca0 *)
mov %v6 [%v3[4],%v3[5],%v3[6],%v3[7],%v1[0],%v1[1],%v1[2],%v1[3]];
(* smlsl	v0.4s, v6.4h, v4.h[4]                     #! PC = 0x5555551ca4 *)
broadcast %mull 4 [%v4[4]]; smulj %mlsl [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v6.8h, v4.h[4]                    #! PC = 0x5555551ca8 *)
broadcast %mull 4 [%v4[4]]; smulj %mlsl [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v6.16b, v3.16b, v1.16b, #6                  #! PC = 0x5555551cac *)
mov %v6 [%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v1[0],%v1[1],%v1[2]];
(* smlsl	v0.4s, v6.4h, v4.h[5]                     #! PC = 0x5555551cb0 *)
broadcast %mull 4 [%v4[5]]; smulj %mlsl [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v6.8h, v4.h[5]                    #! PC = 0x5555551cb4 *)
broadcast %mull 4 [%v4[5]]; smulj %mlsl [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v6.16b, v3.16b, v1.16b, #4                  #! PC = 0x5555551cb8 *)
mov %v6 [%v3[2],%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v1[0],%v1[1]];
(* smlsl	v0.4s, v6.4h, v4.h[6]                     #! PC = 0x5555551cbc *)
broadcast %mull 4 [%v4[6]]; smulj %mlsl [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v6.8h, v4.h[6]                    #! PC = 0x5555551cc0 *)
broadcast %mull 4 [%v4[6]]; smulj %mlsl [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v3.16b, v3.16b, v1.16b, #2                  #! PC = 0x5555551cc4 *)
mov %v3 [%v3[1],%v3[2],%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v1[0]];
(* smlsl	v0.4s, v3.4h, v4.h[7]                     #! PC = 0x5555551cc8 *)
broadcast %mull 4 [%v4[7]]; smulj %mlsl [%v3[0],%v3[1],%v3[2],%v3[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v3.8h, v4.h[7]                    #! PC = 0x5555551ccc *)
broadcast %mull 4 [%v4[7]]; smulj %mlsl [%v3[4],%v3[5],%v3[6],%v3[7]] %mull; subc %dc %v2 %v2 %mlsl;

ghost %conv0_5@sint32[8], %conv1_5@sint32[8] :
    %conv0_5 = [
        %fc0_5[0] * %fd0_5[0] + %fc0_5[1] * %fe1_5[7] + %fc0_5[2] * %fe1_5[6] + %fc0_5[3] * %fe1_5[5] + %fc0_5[4] * %fe1_5[4] + %fc0_5[5] * %fe1_5[3] + %fc0_5[6] * %fe1_5[2] + %fc0_5[7] * %fe1_5[1] +
        %fc1_5[0] * %fe1_5[0] + %fc1_5[1] * %fe0_5[7] + %fc1_5[2] * %fe0_5[6] + %fc1_5[3] * %fe0_5[5] + %fc1_5[4] * %fe0_5[4] + %fc1_5[5] * %fe0_5[3] + %fc1_5[6] * %fe0_5[2] + %fc1_5[7] * %fe0_5[1],
        %fc0_5[0] * %fd0_5[1] + %fc0_5[1] * %fd0_5[0] + %fc0_5[2] * %fe1_5[7] + %fc0_5[3] * %fe1_5[6] + %fc0_5[4] * %fe1_5[5] + %fc0_5[5] * %fe1_5[4] + %fc0_5[6] * %fe1_5[3] + %fc0_5[7] * %fe1_5[2] +
        %fc1_5[0] * %fe1_5[1] + %fc1_5[1] * %fe1_5[0] + %fc1_5[2] * %fe0_5[7] + %fc1_5[3] * %fe0_5[6] + %fc1_5[4] * %fe0_5[5] + %fc1_5[5] * %fe0_5[4] + %fc1_5[6] * %fe0_5[3] + %fc1_5[7] * %fe0_5[2],
        %fc0_5[0] * %fd0_5[2] + %fc0_5[1] * %fd0_5[1] + %fc0_5[2] * %fd0_5[0] + %fc0_5[3] * %fe1_5[7] + %fc0_5[4] * %fe1_5[6] + %fc0_5[5] * %fe1_5[5] + %fc0_5[6] * %fe1_5[4] + %fc0_5[7] * %fe1_5[3] +
        %fc1_5[0] * %fe1_5[2] + %fc1_5[1] * %fe1_5[1] + %fc1_5[2] * %fe1_5[0] + %fc1_5[3] * %fe0_5[7] + %fc1_5[4] * %fe0_5[6] + %fc1_5[5] * %fe0_5[5] + %fc1_5[6] * %fe0_5[4] + %fc1_5[7] * %fe0_5[3],
        %fc0_5[0] * %fd0_5[3] + %fc0_5[1] * %fd0_5[2] + %fc0_5[2] * %fd0_5[1] + %fc0_5[3] * %fd0_5[0] + %fc0_5[4] * %fe1_5[7] + %fc0_5[5] * %fe1_5[6] + %fc0_5[6] * %fe1_5[5] + %fc0_5[7] * %fe1_5[4] +
        %fc1_5[0] * %fe1_5[3] + %fc1_5[1] * %fe1_5[2] + %fc1_5[2] * %fe1_5[1] + %fc1_5[3] * %fe1_5[0] + %fc1_5[4] * %fe0_5[7] + %fc1_5[5] * %fe0_5[6] + %fc1_5[6] * %fe0_5[5] + %fc1_5[7] * %fe0_5[4],
        %fc0_5[0] * %fd0_5[4] + %fc0_5[1] * %fd0_5[3] + %fc0_5[2] * %fd0_5[2] + %fc0_5[3] * %fd0_5[1] + %fc0_5[4] * %fd0_5[0] + %fc0_5[5] * %fe1_5[7] + %fc0_5[6] * %fe1_5[6] + %fc0_5[7] * %fe1_5[5] +
        %fc1_5[0] * %fe1_5[4] + %fc1_5[1] * %fe1_5[3] + %fc1_5[2] * %fe1_5[2] + %fc1_5[3] * %fe1_5[1] + %fc1_5[4] * %fe1_5[0] + %fc1_5[5] * %fe0_5[7] + %fc1_5[6] * %fe0_5[6] + %fc1_5[7] * %fe0_5[5],
        %fc0_5[0] * %fd0_5[5] + %fc0_5[1] * %fd0_5[4] + %fc0_5[2] * %fd0_5[3] + %fc0_5[3] * %fd0_5[2] + %fc0_5[4] * %fd0_5[1] + %fc0_5[5] * %fd0_5[0] + %fc0_5[6] * %fe1_5[7] + %fc0_5[7] * %fe1_5[6] +
        %fc1_5[0] * %fe1_5[5] + %fc1_5[1] * %fe1_5[4] + %fc1_5[2] * %fe1_5[3] + %fc1_5[3] * %fe1_5[2] + %fc1_5[4] * %fe1_5[1] + %fc1_5[5] * %fe1_5[0] + %fc1_5[6] * %fe0_5[7] + %fc1_5[7] * %fe0_5[6],
        %fc0_5[0] * %fd0_5[6] + %fc0_5[1] * %fd0_5[5] + %fc0_5[2] * %fd0_5[4] + %fc0_5[3] * %fd0_5[3] + %fc0_5[4] * %fd0_5[2] + %fc0_5[5] * %fd0_5[1] + %fc0_5[6] * %fd0_5[0] + %fc0_5[7] * %fe1_5[7] +
        %fc1_5[0] * %fe1_5[6] + %fc1_5[1] * %fe1_5[5] + %fc1_5[2] * %fe1_5[4] + %fc1_5[3] * %fe1_5[3] + %fc1_5[4] * %fe1_5[2] + %fc1_5[5] * %fe1_5[1] + %fc1_5[6] * %fe1_5[0] + %fc1_5[7] * %fe0_5[7],
        %fc0_5[0] * %fd0_5[7] + %fc0_5[1] * %fd0_5[6] + %fc0_5[2] * %fd0_5[5] + %fc0_5[3] * %fd0_5[4] + %fc0_5[4] * %fd0_5[3] + %fc0_5[5] * %fd0_5[2] + %fc0_5[6] * %fd0_5[1] + %fc0_5[7] * %fd0_5[0] +
        %fc1_5[0] * %fe1_5[7] + %fc1_5[1] * %fe1_5[6] + %fc1_5[2] * %fe1_5[5] + %fc1_5[3] * %fe1_5[4] + %fc1_5[4] * %fe1_5[3] + %fc1_5[5] * %fe1_5[2] + %fc1_5[6] * %fe1_5[1] + %fc1_5[7] * %fe1_5[0]
    ] /\
    %conv1_5 = [
        %fc0_5[0] * %fd1_5[0] + %fc0_5[1] * %fd0_5[7] + %fc0_5[2] * %fd0_5[6] + %fc0_5[3] * %fd0_5[5] + %fc0_5[4] * %fd0_5[4] + %fc0_5[5] * %fd0_5[3] + %fc0_5[6] * %fd0_5[2] + %fc0_5[7] * %fd0_5[1] +
        %fc1_5[0] * %fd0_5[0] + %fc1_5[1] * %fe1_5[7] + %fc1_5[2] * %fe1_5[6] + %fc1_5[3] * %fe1_5[5] + %fc1_5[4] * %fe1_5[4] + %fc1_5[5] * %fe1_5[3] + %fc1_5[6] * %fe1_5[2] + %fc1_5[7] * %fe1_5[1],
        %fc0_5[0] * %fd1_5[1] + %fc0_5[1] * %fd1_5[0] + %fc0_5[2] * %fd0_5[7] + %fc0_5[3] * %fd0_5[6] + %fc0_5[4] * %fd0_5[5] + %fc0_5[5] * %fd0_5[4] + %fc0_5[6] * %fd0_5[3] + %fc0_5[7] * %fd0_5[2] +
        %fc1_5[0] * %fd0_5[1] + %fc1_5[1] * %fd0_5[0] + %fc1_5[2] * %fe1_5[7] + %fc1_5[3] * %fe1_5[6] + %fc1_5[4] * %fe1_5[5] + %fc1_5[5] * %fe1_5[4] + %fc1_5[6] * %fe1_5[3] + %fc1_5[7] * %fe1_5[2],
        %fc0_5[0] * %fd1_5[2] + %fc0_5[1] * %fd1_5[1] + %fc0_5[2] * %fd1_5[0] + %fc0_5[3] * %fd0_5[7] + %fc0_5[4] * %fd0_5[6] + %fc0_5[5] * %fd0_5[5] + %fc0_5[6] * %fd0_5[4] + %fc0_5[7] * %fd0_5[3] +
        %fc1_5[0] * %fd0_5[2] + %fc1_5[1] * %fd0_5[1] + %fc1_5[2] * %fd0_5[0] + %fc1_5[3] * %fe1_5[7] + %fc1_5[4] * %fe1_5[6] + %fc1_5[5] * %fe1_5[5] + %fc1_5[6] * %fe1_5[4] + %fc1_5[7] * %fe1_5[3],
        %fc0_5[0] * %fd1_5[3] + %fc0_5[1] * %fd1_5[2] + %fc0_5[2] * %fd1_5[1] + %fc0_5[3] * %fd1_5[0] + %fc0_5[4] * %fd0_5[7] + %fc0_5[5] * %fd0_5[6] + %fc0_5[6] * %fd0_5[5] + %fc0_5[7] * %fd0_5[4] +
        %fc1_5[0] * %fd0_5[3] + %fc1_5[1] * %fd0_5[2] + %fc1_5[2] * %fd0_5[1] + %fc1_5[3] * %fd0_5[0] + %fc1_5[4] * %fe1_5[7] + %fc1_5[5] * %fe1_5[6] + %fc1_5[6] * %fe1_5[5] + %fc1_5[7] * %fe1_5[4],
        %fc0_5[0] * %fd1_5[4] + %fc0_5[1] * %fd1_5[3] + %fc0_5[2] * %fd1_5[2] + %fc0_5[3] * %fd1_5[1] + %fc0_5[4] * %fd1_5[0] + %fc0_5[5] * %fd0_5[7] + %fc0_5[6] * %fd0_5[6] + %fc0_5[7] * %fd0_5[5] +
        %fc1_5[0] * %fd0_5[4] + %fc1_5[1] * %fd0_5[3] + %fc1_5[2] * %fd0_5[2] + %fc1_5[3] * %fd0_5[1] + %fc1_5[4] * %fd0_5[0] + %fc1_5[5] * %fe1_5[7] + %fc1_5[6] * %fe1_5[6] + %fc1_5[7] * %fe1_5[5],
        %fc0_5[0] * %fd1_5[5] + %fc0_5[1] * %fd1_5[4] + %fc0_5[2] * %fd1_5[3] + %fc0_5[3] * %fd1_5[2] + %fc0_5[4] * %fd1_5[1] + %fc0_5[5] * %fd1_5[0] + %fc0_5[6] * %fd0_5[7] + %fc0_5[7] * %fd0_5[6] +
        %fc1_5[0] * %fd0_5[5] + %fc1_5[1] * %fd0_5[4] + %fc1_5[2] * %fd0_5[3] + %fc1_5[3] * %fd0_5[2] + %fc1_5[4] * %fd0_5[1] + %fc1_5[5] * %fd0_5[0] + %fc1_5[6] * %fe1_5[7] + %fc1_5[7] * %fe1_5[6],
        %fc0_5[0] * %fd1_5[6] + %fc0_5[1] * %fd1_5[5] + %fc0_5[2] * %fd1_5[4] + %fc0_5[3] * %fd1_5[3] + %fc0_5[4] * %fd1_5[2] + %fc0_5[5] * %fd1_5[1] + %fc0_5[6] * %fd1_5[0] + %fc0_5[7] * %fd0_5[7] +
        %fc1_5[0] * %fd0_5[6] + %fc1_5[1] * %fd0_5[5] + %fc1_5[2] * %fd0_5[4] + %fc1_5[3] * %fd0_5[3] + %fc1_5[4] * %fd0_5[2] + %fc1_5[5] * %fd0_5[1] + %fc1_5[6] * %fd0_5[0] + %fc1_5[7] * %fe1_5[7],
        %fc0_5[0] * %fd1_5[7] + %fc0_5[1] * %fd1_5[6] + %fc0_5[2] * %fd1_5[5] + %fc0_5[3] * %fd1_5[4] + %fc0_5[4] * %fd1_5[3] + %fc0_5[5] * %fd1_5[2] + %fc0_5[6] * %fd1_5[1] + %fc0_5[7] * %fd1_5[0] +
        %fc1_5[0] * %fd0_5[7] + %fc1_5[1] * %fd0_5[6] + %fc1_5[2] * %fd0_5[5] + %fc1_5[3] * %fd0_5[4] + %fc1_5[4] * %fd0_5[3] + %fc1_5[5] * %fd0_5[2] + %fc1_5[6] * %fd0_5[1] + %fc1_5[7] * %fd0_5[0]
    ]
    && true;

assert
    %v16 ++ %v7 = %conv0_5 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] ) /\
    %v0 ++ %v2 = %conv1_5 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] )
    && true;

assume
    %v16 ++ %v7 = %conv0_5 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] ) /\
    %v0 ++ %v2 = %conv1_5 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] )
    && true;

assert
    %conv0_5 <= [268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456] /\
    %conv0_5 >= [-268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456] /\

    %conv1_5 <= [268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456] /\
    %conv1_5 >= [-268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456]
    prove with [algebra solver smt: z3]
    && true;

assume
    %conv0_5 <= [268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456] /\
    %conv0_5 >= [-268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456] /\

    %conv1_5 <= [268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456] /\
    %conv1_5 >= [-268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456]
    && true;

assert
    %v16 ++ %v7 = %conv0_5 /\ %v0 ++ %v2 = %conv1_5
    prove with [algebra solver isl]
    && true;

assume
    %v16 ++ %v7 = %conv0_5 /\ %v0 ++ %v2 = %conv1_5
    && true;

assert
    %v16 <= [268435456, 268435456, 268435456, 268435456] /\
    %v16 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v7 <= [268435456, 268435456, 268435456, 268435456] /\
    %v7 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v0 <= [268435456, 268435456, 268435456, 268435456] /\
    %v0 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v2 <= [268435456, 268435456, 268435456, 268435456] /\
    %v2 >= [-268435456, -268435456, -268435456, -268435456]

    prove with [algebra solver isl]
    && true;

assume
    %v16 <= [268435456, 268435456, 268435456, 268435456] /\
    %v16 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v7 <= [268435456, 268435456, 268435456, 268435456] /\
    %v7 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v0 <= [268435456, 268435456, 268435456, 268435456] /\
    %v0 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v2 <= [268435456, 268435456, 268435456, 268435456] /\
    %v2 >= [-268435456, -268435456, -268435456, -268435456]
  &&
    %v16 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v16 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32] /\

    %v7 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v7 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32] /\

    %v0 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v0 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32] /\

    %v2 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v2 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32];

cut (* 23 *)
    %conv0_5 = [
        %fc0_5[0] * %fd0_5[0] + %fc0_5[1] * %fe1_5[7] + %fc0_5[2] * %fe1_5[6] + %fc0_5[3] * %fe1_5[5] + %fc0_5[4] * %fe1_5[4] + %fc0_5[5] * %fe1_5[3] + %fc0_5[6] * %fe1_5[2] + %fc0_5[7] * %fe1_5[1] +
        %fc1_5[0] * %fe1_5[0] + %fc1_5[1] * %fe0_5[7] + %fc1_5[2] * %fe0_5[6] + %fc1_5[3] * %fe0_5[5] + %fc1_5[4] * %fe0_5[4] + %fc1_5[5] * %fe0_5[3] + %fc1_5[6] * %fe0_5[2] + %fc1_5[7] * %fe0_5[1],
        %fc0_5[0] * %fd0_5[1] + %fc0_5[1] * %fd0_5[0] + %fc0_5[2] * %fe1_5[7] + %fc0_5[3] * %fe1_5[6] + %fc0_5[4] * %fe1_5[5] + %fc0_5[5] * %fe1_5[4] + %fc0_5[6] * %fe1_5[3] + %fc0_5[7] * %fe1_5[2] +
        %fc1_5[0] * %fe1_5[1] + %fc1_5[1] * %fe1_5[0] + %fc1_5[2] * %fe0_5[7] + %fc1_5[3] * %fe0_5[6] + %fc1_5[4] * %fe0_5[5] + %fc1_5[5] * %fe0_5[4] + %fc1_5[6] * %fe0_5[3] + %fc1_5[7] * %fe0_5[2],
        %fc0_5[0] * %fd0_5[2] + %fc0_5[1] * %fd0_5[1] + %fc0_5[2] * %fd0_5[0] + %fc0_5[3] * %fe1_5[7] + %fc0_5[4] * %fe1_5[6] + %fc0_5[5] * %fe1_5[5] + %fc0_5[6] * %fe1_5[4] + %fc0_5[7] * %fe1_5[3] +
        %fc1_5[0] * %fe1_5[2] + %fc1_5[1] * %fe1_5[1] + %fc1_5[2] * %fe1_5[0] + %fc1_5[3] * %fe0_5[7] + %fc1_5[4] * %fe0_5[6] + %fc1_5[5] * %fe0_5[5] + %fc1_5[6] * %fe0_5[4] + %fc1_5[7] * %fe0_5[3],
        %fc0_5[0] * %fd0_5[3] + %fc0_5[1] * %fd0_5[2] + %fc0_5[2] * %fd0_5[1] + %fc0_5[3] * %fd0_5[0] + %fc0_5[4] * %fe1_5[7] + %fc0_5[5] * %fe1_5[6] + %fc0_5[6] * %fe1_5[5] + %fc0_5[7] * %fe1_5[4] +
        %fc1_5[0] * %fe1_5[3] + %fc1_5[1] * %fe1_5[2] + %fc1_5[2] * %fe1_5[1] + %fc1_5[3] * %fe1_5[0] + %fc1_5[4] * %fe0_5[7] + %fc1_5[5] * %fe0_5[6] + %fc1_5[6] * %fe0_5[5] + %fc1_5[7] * %fe0_5[4],
        %fc0_5[0] * %fd0_5[4] + %fc0_5[1] * %fd0_5[3] + %fc0_5[2] * %fd0_5[2] + %fc0_5[3] * %fd0_5[1] + %fc0_5[4] * %fd0_5[0] + %fc0_5[5] * %fe1_5[7] + %fc0_5[6] * %fe1_5[6] + %fc0_5[7] * %fe1_5[5] +
        %fc1_5[0] * %fe1_5[4] + %fc1_5[1] * %fe1_5[3] + %fc1_5[2] * %fe1_5[2] + %fc1_5[3] * %fe1_5[1] + %fc1_5[4] * %fe1_5[0] + %fc1_5[5] * %fe0_5[7] + %fc1_5[6] * %fe0_5[6] + %fc1_5[7] * %fe0_5[5],
        %fc0_5[0] * %fd0_5[5] + %fc0_5[1] * %fd0_5[4] + %fc0_5[2] * %fd0_5[3] + %fc0_5[3] * %fd0_5[2] + %fc0_5[4] * %fd0_5[1] + %fc0_5[5] * %fd0_5[0] + %fc0_5[6] * %fe1_5[7] + %fc0_5[7] * %fe1_5[6] +
        %fc1_5[0] * %fe1_5[5] + %fc1_5[1] * %fe1_5[4] + %fc1_5[2] * %fe1_5[3] + %fc1_5[3] * %fe1_5[2] + %fc1_5[4] * %fe1_5[1] + %fc1_5[5] * %fe1_5[0] + %fc1_5[6] * %fe0_5[7] + %fc1_5[7] * %fe0_5[6],
        %fc0_5[0] * %fd0_5[6] + %fc0_5[1] * %fd0_5[5] + %fc0_5[2] * %fd0_5[4] + %fc0_5[3] * %fd0_5[3] + %fc0_5[4] * %fd0_5[2] + %fc0_5[5] * %fd0_5[1] + %fc0_5[6] * %fd0_5[0] + %fc0_5[7] * %fe1_5[7] +
        %fc1_5[0] * %fe1_5[6] + %fc1_5[1] * %fe1_5[5] + %fc1_5[2] * %fe1_5[4] + %fc1_5[3] * %fe1_5[3] + %fc1_5[4] * %fe1_5[2] + %fc1_5[5] * %fe1_5[1] + %fc1_5[6] * %fe1_5[0] + %fc1_5[7] * %fe0_5[7],
        %fc0_5[0] * %fd0_5[7] + %fc0_5[1] * %fd0_5[6] + %fc0_5[2] * %fd0_5[5] + %fc0_5[3] * %fd0_5[4] + %fc0_5[4] * %fd0_5[3] + %fc0_5[5] * %fd0_5[2] + %fc0_5[6] * %fd0_5[1] + %fc0_5[7] * %fd0_5[0] +
        %fc1_5[0] * %fe1_5[7] + %fc1_5[1] * %fe1_5[6] + %fc1_5[2] * %fe1_5[5] + %fc1_5[3] * %fe1_5[4] + %fc1_5[4] * %fe1_5[3] + %fc1_5[5] * %fe1_5[2] + %fc1_5[6] * %fe1_5[1] + %fc1_5[7] * %fe1_5[0]
    ] /\
    %conv1_5 = [
        %fc0_5[0] * %fd1_5[0] + %fc0_5[1] * %fd0_5[7] + %fc0_5[2] * %fd0_5[6] + %fc0_5[3] * %fd0_5[5] + %fc0_5[4] * %fd0_5[4] + %fc0_5[5] * %fd0_5[3] + %fc0_5[6] * %fd0_5[2] + %fc0_5[7] * %fd0_5[1] +
        %fc1_5[0] * %fd0_5[0] + %fc1_5[1] * %fe1_5[7] + %fc1_5[2] * %fe1_5[6] + %fc1_5[3] * %fe1_5[5] + %fc1_5[4] * %fe1_5[4] + %fc1_5[5] * %fe1_5[3] + %fc1_5[6] * %fe1_5[2] + %fc1_5[7] * %fe1_5[1],
        %fc0_5[0] * %fd1_5[1] + %fc0_5[1] * %fd1_5[0] + %fc0_5[2] * %fd0_5[7] + %fc0_5[3] * %fd0_5[6] + %fc0_5[4] * %fd0_5[5] + %fc0_5[5] * %fd0_5[4] + %fc0_5[6] * %fd0_5[3] + %fc0_5[7] * %fd0_5[2] +
        %fc1_5[0] * %fd0_5[1] + %fc1_5[1] * %fd0_5[0] + %fc1_5[2] * %fe1_5[7] + %fc1_5[3] * %fe1_5[6] + %fc1_5[4] * %fe1_5[5] + %fc1_5[5] * %fe1_5[4] + %fc1_5[6] * %fe1_5[3] + %fc1_5[7] * %fe1_5[2],
        %fc0_5[0] * %fd1_5[2] + %fc0_5[1] * %fd1_5[1] + %fc0_5[2] * %fd1_5[0] + %fc0_5[3] * %fd0_5[7] + %fc0_5[4] * %fd0_5[6] + %fc0_5[5] * %fd0_5[5] + %fc0_5[6] * %fd0_5[4] + %fc0_5[7] * %fd0_5[3] +
        %fc1_5[0] * %fd0_5[2] + %fc1_5[1] * %fd0_5[1] + %fc1_5[2] * %fd0_5[0] + %fc1_5[3] * %fe1_5[7] + %fc1_5[4] * %fe1_5[6] + %fc1_5[5] * %fe1_5[5] + %fc1_5[6] * %fe1_5[4] + %fc1_5[7] * %fe1_5[3],
        %fc0_5[0] * %fd1_5[3] + %fc0_5[1] * %fd1_5[2] + %fc0_5[2] * %fd1_5[1] + %fc0_5[3] * %fd1_5[0] + %fc0_5[4] * %fd0_5[7] + %fc0_5[5] * %fd0_5[6] + %fc0_5[6] * %fd0_5[5] + %fc0_5[7] * %fd0_5[4] +
        %fc1_5[0] * %fd0_5[3] + %fc1_5[1] * %fd0_5[2] + %fc1_5[2] * %fd0_5[1] + %fc1_5[3] * %fd0_5[0] + %fc1_5[4] * %fe1_5[7] + %fc1_5[5] * %fe1_5[6] + %fc1_5[6] * %fe1_5[5] + %fc1_5[7] * %fe1_5[4],
        %fc0_5[0] * %fd1_5[4] + %fc0_5[1] * %fd1_5[3] + %fc0_5[2] * %fd1_5[2] + %fc0_5[3] * %fd1_5[1] + %fc0_5[4] * %fd1_5[0] + %fc0_5[5] * %fd0_5[7] + %fc0_5[6] * %fd0_5[6] + %fc0_5[7] * %fd0_5[5] +
        %fc1_5[0] * %fd0_5[4] + %fc1_5[1] * %fd0_5[3] + %fc1_5[2] * %fd0_5[2] + %fc1_5[3] * %fd0_5[1] + %fc1_5[4] * %fd0_5[0] + %fc1_5[5] * %fe1_5[7] + %fc1_5[6] * %fe1_5[6] + %fc1_5[7] * %fe1_5[5],
        %fc0_5[0] * %fd1_5[5] + %fc0_5[1] * %fd1_5[4] + %fc0_5[2] * %fd1_5[3] + %fc0_5[3] * %fd1_5[2] + %fc0_5[4] * %fd1_5[1] + %fc0_5[5] * %fd1_5[0] + %fc0_5[6] * %fd0_5[7] + %fc0_5[7] * %fd0_5[6] +
        %fc1_5[0] * %fd0_5[5] + %fc1_5[1] * %fd0_5[4] + %fc1_5[2] * %fd0_5[3] + %fc1_5[3] * %fd0_5[2] + %fc1_5[4] * %fd0_5[1] + %fc1_5[5] * %fd0_5[0] + %fc1_5[6] * %fe1_5[7] + %fc1_5[7] * %fe1_5[6],
        %fc0_5[0] * %fd1_5[6] + %fc0_5[1] * %fd1_5[5] + %fc0_5[2] * %fd1_5[4] + %fc0_5[3] * %fd1_5[3] + %fc0_5[4] * %fd1_5[2] + %fc0_5[5] * %fd1_5[1] + %fc0_5[6] * %fd1_5[0] + %fc0_5[7] * %fd0_5[7] +
        %fc1_5[0] * %fd0_5[6] + %fc1_5[1] * %fd0_5[5] + %fc1_5[2] * %fd0_5[4] + %fc1_5[3] * %fd0_5[3] + %fc1_5[4] * %fd0_5[2] + %fc1_5[5] * %fd0_5[1] + %fc1_5[6] * %fd0_5[0] + %fc1_5[7] * %fe1_5[7],
        %fc0_5[0] * %fd1_5[7] + %fc0_5[1] * %fd1_5[6] + %fc0_5[2] * %fd1_5[5] + %fc0_5[3] * %fd1_5[4] + %fc0_5[4] * %fd1_5[3] + %fc0_5[5] * %fd1_5[2] + %fc0_5[6] * %fd1_5[1] + %fc0_5[7] * %fd1_5[0] +
        %fc1_5[0] * %fd0_5[7] + %fc1_5[1] * %fd0_5[6] + %fc1_5[2] * %fd0_5[5] + %fc1_5[3] * %fd0_5[4] + %fc1_5[4] * %fd0_5[3] + %fc1_5[5] * %fd0_5[2] + %fc1_5[6] * %fd0_5[1] + %fc1_5[7] * %fd0_5[0]
    ] /\

    %v16 ++ %v7 = %conv0_5 /\ %v0 ++ %v2 = %conv1_5,

    %v16 <= [268435456, 268435456, 268435456, 268435456] /\
    %v16 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v7 <= [268435456, 268435456, 268435456, 268435456] /\
    %v7 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v0 <= [268435456, 268435456, 268435456, 268435456] /\
    %v0 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v2 <= [268435456, 268435456, 268435456, 268435456] /\
    %v2 >= [-268435456, -268435456, -268435456, -268435456]

    prove with [algebra solver isl]
  &&
    %v16 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v16 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32] /\

    %v7 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v7 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32] /\

    %v0 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v0 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32] /\

    %v2 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v2 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32];

ghost %h0_5@sint32[8], %h1_5@sint32[8] :
    %h0_5 = %v16 ++ %v7 /\ %h1_5 = %v0 ++ %v2
  &&
    %h0_5 = %v16 ++ %v7 /\ %h1_5 = %v0 ++ %v2;

(* uzp1	v3.8h, v16.8h, v7.8h                       #! PC = 0x5555551cd0 *)
mov %spl_join [%v16[0], %v16[1], %v16[2], %v16[3], %v7[0], %v7[1], %v7[2], %v7[3]]; spl %splh %v3 %spl_join 16; cast %v3@int16[8] %v3;
(* mul	v3.8h, v3.8h, v5.h[7]                       #! PC = 0x5555551cd4 *)
broadcast %mul 8 [%v5[7]]; mull %dc %v3 %v3 %mul; cast %v3@int16[8] %v3;

ghost %m0_5@sint16[8] : %m0_5 = %v3 && %m0_5 = %v3;

(* sqdmulh	v3.8h, v3.8h, v5.h[6]                   #! PC = 0x5555551cd8 *)
broadcast %mul 8 [%v5[6]]; smulj %LO %v3 %mul;
ssplit %LO0 %dc %LO 15; vpc %v3@sint16[8] %LO0;
(* uzp2	v1.8h, v16.8h, v7.8h                       #! PC = 0x5555551cdc *)
mov %spl_join [%v16[0], %v16[1], %v16[2], %v16[3], %v7[0], %v7[1], %v7[2], %v7[3]]; spl %v1 %spll %spl_join 16;
(* sshr	v3.8h, v3.8h, #1                           #! PC = 0x5555551ce0 *)
split %v3 %dc %v3 1;
(* sub	v1.8h, v1.8h, v3.8h                         #! PC = 0x5555551ce4 *)
sub %v1 %v1 %v3;

ghost %hh0_5@sint16[8] : %hh0_5 = %v1 && %hh0_5 = %v1;

assert
    %h0_5 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m0_5
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh0_5
    prove with [algebra solver isl]
    && true;

assume
    %h0_5 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m0_5
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh0_5
    && true;

(* sqrdmulh	v3.8h, v1.8h, v5.h[3]                  #! PC = 0x5555551ce8 *)
broadcast %mul 8 [%v5[3]]; smulj %LO %v1 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v3 %LO11 %LO01;
(* mul	v1.8h, v1.8h, v5.h[2]                       #! PC = 0x5555551cec *)
broadcast %mul 8 [%v5[2]]; mull %dc %v1 %v1 %mul; cast %v1@int16[8] %v1;
(* mls	v1.8h, v3.8h, v5.h[6]                       #! PC = 0x5555551cf0 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v3 %mul;
cast %mls@int16[8] %mls; subc %dc %v1 %v1 %mls;

assert
    [956, 956, 956, 956, 956, 956, 956, 956] * %hh0_5
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v3
    = %v1
    prove with [algebra solver isl]
    && true;

assume
    [956, 956, 956, 956, 956, 956, 956, 956] * %hh0_5
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v3
    = %v1
    && true;

(* uzp1	v3.8h, v0.8h, v2.8h                        #! PC = 0x5555551cf4 *)
mov %spl_join [%v0[0], %v0[1], %v0[2], %v0[3], %v2[0], %v2[1], %v2[2], %v2[3]]; spl %splh %v3 %spl_join 16; cast %v3@int16[8] %v3;
(* mul	v3.8h, v3.8h, v5.h[7]                       #! PC = 0x5555551cf8 *)
broadcast %mul 8 [%v5[7]]; mull %dc %v3 %v3 %mul; cast %v3@int16[8] %v3;

ghost %m1_5@sint16[8] : %m1_5 = %v3 && %m1_5 = %v3;

(* sqdmulh	v3.8h, v3.8h, v5.h[6]                   #! PC = 0x5555551cfc *)
broadcast %mul 8 [%v5[6]]; smulj %LO %v3 %mul;
ssplit %LO0 %dc %LO 15; vpc %v3@sint16[8] %LO0;
(* uzp2	v0.8h, v0.8h, v2.8h                        #! PC = 0x5555551d00 *)
mov %spl_join [%v0[0], %v0[1], %v0[2], %v0[3], %v2[0], %v2[1], %v2[2], %v2[3]]; spl %v0 %spll %spl_join 16;
(* sshr	v2.8h, v3.8h, #1                           #! PC = 0x5555551d04 *)
split %v2 %dc %v3 1;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551d08 *)
sub %v0 %v0 %v2;

ghost %hh1_5@sint16[8] : %hh1_5 = %v0 && %hh1_5 = %v0;

assert
    %h1_5 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m1_5
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh1_5
    prove with [algebra solver isl]
    && true;

assume
    %h1_5 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m1_5
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh1_5
    && true;

(* sqrdmulh	v2.8h, v0.8h, v5.h[3]                  #! PC = 0x5555551d0c *)
broadcast %mul 8 [%v5[3]]; smulj %LO %v0 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v2 %LO11 %LO01;
(* mul	v0.8h, v0.8h, v5.h[2]                       #! PC = 0x5555551d10 *)
broadcast %mul 8 [%v5[2]]; mull %dc %v0 %v0 %mul; cast %v0@int16[8] %v0;
(* mls	v0.8h, v2.8h, v5.h[6]                       #! PC = 0x5555551d14 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v2 %mul;
cast %mls@int16[8] %mls; subc %dc %v0 %v0 %mls;

assert
    [956, 956, 956, 956, 956, 956, 956, 956] * %hh1_5
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v2
    = %v0
    prove with [algebra solver isl]
    && true;

assume
    [956, 956, 956, 956, 956, 956, 956, 956] * %hh1_5
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v2
    = %v0
    && true;


### i_iter epilogue

(* str	q1, [x2, x3]                                #! EA = L0x7fffffe250; PC = 0x5555551d18 *)
mov [L0x7fffffe250,L0x7fffffe252,L0x7fffffe254,L0x7fffffe256,L0x7fffffe258,L0x7fffffe25a,L0x7fffffe25c,L0x7fffffe25e] %v1;
(* str	q0, [x6, x3]                                #! EA = L0x7fffffe260; PC = 0x5555551d1c *)
mov [L0x7fffffe260,L0x7fffffe262,L0x7fffffe264,L0x7fffffe266,L0x7fffffe268,L0x7fffffe26a,L0x7fffffe26c,L0x7fffffe26e] %v0;
(* #b.eq	0x5555551ec4 <_ZN6xpower7basemul11low_basemulEPA2_A8_sS3_S3_+932>  // b.none#! PC = 0x5555551d30 *)
#b.eq	0x5555551ec4 <_ZN6xpower7basemul11low_basemulEPA2_A8_sS3_S3_+932>  // b.none#! 0x5555551d30 = 0x5555551d30;

assert
    %v1 <= [2650, 2650, 2650, 2650, 2650, 2650, 2650, 2650] /\
    %v1 >= [-2650, -2650, -2650, -2650, -2650, -2650, -2650, -2650] /\

    %v0 <= [2650, 2650, 2650, 2650, 2650, 2650, 2650, 2650] /\
    %v0 >= [-2650, -2650, -2650, -2650, -2650, -2650, -2650, -2650]

    prove with [algebra solver isl]
    && true;

assume
    true &&

    %v1 <=s [2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16] /\
    %v1 >=s [(-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16] /\

    %v0 <=s [2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16] /\
    %v0 >=s [(-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16];

cut (* 24 *)
    [L0x7fffffe250, L0x7fffffe252, L0x7fffffe254, L0x7fffffe256, L0x7fffffe258, L0x7fffffe25a, L0x7fffffe25c, L0x7fffffe25e] = %v1 /\
    [L0x7fffffe260, L0x7fffffe262, L0x7fffffe264, L0x7fffffe266, L0x7fffffe268, L0x7fffffe26a, L0x7fffffe26c, L0x7fffffe26e] = %v0 /\

    %v1 ++ %v0 = [-72, -72, -72, -72, -72, -72, -72, -72, -72, -72, -72, -72, -72, -72, -72, -72] * [
        arr500_a * arr500_b + -1 * arr501_a * arr517_b + -1 * arr502_a * arr516_b + -1 * arr503_a * arr515_b + -1 * arr504_a * arr514_b + -1 * arr505_a * arr513_b + -1 * arr506_a * arr512_b + -1 * arr507_a * arr511_b + -1 * arr510_a * arr510_b + -1 * arr511_a * arr507_b + -1 * arr512_a * arr506_b + -1 * arr513_a * arr505_b + -1 * arr514_a * arr504_b + -1 * arr515_a * arr503_b + -1 * arr516_a * arr502_b + -1 * arr517_a * arr501_b,
        arr500_a * arr501_b + arr501_a * arr500_b + -1 * arr502_a * arr517_b + -1 * arr503_a * arr516_b + -1 * arr504_a * arr515_b + -1 * arr505_a * arr514_b + -1 * arr506_a * arr513_b + -1 * arr507_a * arr512_b + -1 * arr510_a * arr511_b + -1 * arr511_a * arr510_b + -1 * arr512_a * arr507_b + -1 * arr513_a * arr506_b + -1 * arr514_a * arr505_b + -1 * arr515_a * arr504_b + -1 * arr516_a * arr503_b + -1 * arr517_a * arr502_b,
        arr500_a * arr502_b + arr501_a * arr501_b + arr502_a * arr500_b + -1 * arr503_a * arr517_b + -1 * arr504_a * arr516_b + -1 * arr505_a * arr515_b + -1 * arr506_a * arr514_b + -1 * arr507_a * arr513_b + -1 * arr510_a * arr512_b + -1 * arr511_a * arr511_b + -1 * arr512_a * arr510_b + -1 * arr513_a * arr507_b + -1 * arr514_a * arr506_b + -1 * arr515_a * arr505_b + -1 * arr516_a * arr504_b + -1 * arr517_a * arr503_b,
        arr500_a * arr503_b + arr501_a * arr502_b + arr502_a * arr501_b + arr503_a * arr500_b + -1 * arr504_a * arr517_b + -1 * arr505_a * arr516_b + -1 * arr506_a * arr515_b + -1 * arr507_a * arr514_b + -1 * arr510_a * arr513_b + -1 * arr511_a * arr512_b + -1 * arr512_a * arr511_b + -1 * arr513_a * arr510_b + -1 * arr514_a * arr507_b + -1 * arr515_a * arr506_b + -1 * arr516_a * arr505_b + -1 * arr517_a * arr504_b,
        arr500_a * arr504_b + arr501_a * arr503_b + arr502_a * arr502_b + arr503_a * arr501_b + arr504_a * arr500_b + -1 * arr505_a * arr517_b + -1 * arr506_a * arr516_b + -1 * arr507_a * arr515_b + -1 * arr510_a * arr514_b + -1 * arr511_a * arr513_b + -1 * arr512_a * arr512_b + -1 * arr513_a * arr511_b + -1 * arr514_a * arr510_b + -1 * arr515_a * arr507_b + -1 * arr516_a * arr506_b + -1 * arr517_a * arr505_b,
        arr500_a * arr505_b + arr501_a * arr504_b + arr502_a * arr503_b + arr503_a * arr502_b + arr504_a * arr501_b + arr505_a * arr500_b + -1 * arr506_a * arr517_b + -1 * arr507_a * arr516_b + -1 * arr510_a * arr515_b + -1 * arr511_a * arr514_b + -1 * arr512_a * arr513_b + -1 * arr513_a * arr512_b + -1 * arr514_a * arr511_b + -1 * arr515_a * arr510_b + -1 * arr516_a * arr507_b + -1 * arr517_a * arr506_b,
        arr500_a * arr506_b + arr501_a * arr505_b + arr502_a * arr504_b + arr503_a * arr503_b + arr504_a * arr502_b + arr505_a * arr501_b + arr506_a * arr500_b + -1 * arr507_a * arr517_b + -1 * arr510_a * arr516_b + -1 * arr511_a * arr515_b + -1 * arr512_a * arr514_b + -1 * arr513_a * arr513_b + -1 * arr514_a * arr512_b + -1 * arr515_a * arr511_b + -1 * arr516_a * arr510_b + -1 * arr517_a * arr507_b,
        arr500_a * arr507_b + arr501_a * arr506_b + arr502_a * arr505_b + arr503_a * arr504_b + arr504_a * arr503_b + arr505_a * arr502_b + arr506_a * arr501_b + arr507_a * arr500_b + -1 * arr510_a * arr517_b + -1 * arr511_a * arr516_b + -1 * arr512_a * arr515_b + -1 * arr513_a * arr514_b + -1 * arr514_a * arr513_b + -1 * arr515_a * arr512_b + -1 * arr516_a * arr511_b + -1 * arr517_a * arr510_b,
        arr500_a * arr510_b + arr501_a * arr507_b + arr502_a * arr506_b + arr503_a * arr505_b + arr504_a * arr504_b + arr505_a * arr503_b + arr506_a * arr502_b + arr507_a * arr501_b + arr510_a * arr500_b + -1 * arr511_a * arr517_b + -1 * arr512_a * arr516_b + -1 * arr513_a * arr515_b + -1 * arr514_a * arr514_b + -1 * arr515_a * arr513_b + -1 * arr516_a * arr512_b + -1 * arr517_a * arr511_b,
        arr500_a * arr511_b + arr501_a * arr510_b + arr502_a * arr507_b + arr503_a * arr506_b + arr504_a * arr505_b + arr505_a * arr504_b + arr506_a * arr503_b + arr507_a * arr502_b + arr510_a * arr501_b + arr511_a * arr500_b + -1 * arr512_a * arr517_b + -1 * arr513_a * arr516_b + -1 * arr514_a * arr515_b + -1 * arr515_a * arr514_b + -1 * arr516_a * arr513_b + -1 * arr517_a * arr512_b,
        arr500_a * arr512_b + arr501_a * arr511_b + arr502_a * arr510_b + arr503_a * arr507_b + arr504_a * arr506_b + arr505_a * arr505_b + arr506_a * arr504_b + arr507_a * arr503_b + arr510_a * arr502_b + arr511_a * arr501_b + arr512_a * arr500_b + -1 * arr513_a * arr517_b + -1 * arr514_a * arr516_b + -1 * arr515_a * arr515_b + -1 * arr516_a * arr514_b + -1 * arr517_a * arr513_b,
        arr500_a * arr513_b + arr501_a * arr512_b + arr502_a * arr511_b + arr503_a * arr510_b + arr504_a * arr507_b + arr505_a * arr506_b + arr506_a * arr505_b + arr507_a * arr504_b + arr510_a * arr503_b + arr511_a * arr502_b + arr512_a * arr501_b + arr513_a * arr500_b + -1 * arr514_a * arr517_b + -1 * arr515_a * arr516_b + -1 * arr516_a * arr515_b + -1 * arr517_a * arr514_b,
        arr500_a * arr514_b + arr501_a * arr513_b + arr502_a * arr512_b + arr503_a * arr511_b + arr504_a * arr510_b + arr505_a * arr507_b + arr506_a * arr506_b + arr507_a * arr505_b + arr510_a * arr504_b + arr511_a * arr503_b + arr512_a * arr502_b + arr513_a * arr501_b + arr514_a * arr500_b + -1 * arr515_a * arr517_b + -1 * arr516_a * arr516_b + -1 * arr517_a * arr515_b,
        arr500_a * arr515_b + arr501_a * arr514_b + arr502_a * arr513_b + arr503_a * arr512_b + arr504_a * arr511_b + arr505_a * arr510_b + arr506_a * arr507_b + arr507_a * arr506_b + arr510_a * arr505_b + arr511_a * arr504_b + arr512_a * arr503_b + arr513_a * arr502_b + arr514_a * arr501_b + arr515_a * arr500_b + -1 * arr516_a * arr517_b + -1 * arr517_a * arr516_b,
        arr500_a * arr516_b + arr501_a * arr515_b + arr502_a * arr514_b + arr503_a * arr513_b + arr504_a * arr512_b + arr505_a * arr511_b + arr506_a * arr510_b + arr507_a * arr507_b + arr510_a * arr506_b + arr511_a * arr505_b + arr512_a * arr504_b + arr513_a * arr503_b + arr514_a * arr502_b + arr515_a * arr501_b + arr516_a * arr500_b + -1 * arr517_a * arr517_b,
        arr500_a * arr517_b + arr501_a * arr516_b + arr502_a * arr515_b + arr503_a * arr514_b + arr504_a * arr513_b + arr505_a * arr512_b + arr506_a * arr511_b + arr507_a * arr510_b + arr510_a * arr507_b + arr511_a * arr506_b + arr512_a * arr505_b + arr513_a * arr504_b + arr514_a * arr503_b + arr515_a * arr502_b + arr516_a * arr501_b + arr517_a * arr500_b
    ] ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] )

    prove with [cuts[0, 21, 22, 23]]
  &&
    [L0x7fffffe250, L0x7fffffe252, L0x7fffffe254, L0x7fffffe256, L0x7fffffe258, L0x7fffffe25a, L0x7fffffe25c, L0x7fffffe25e] = %v1 /\
    [L0x7fffffe260, L0x7fffffe262, L0x7fffffe264, L0x7fffffe266, L0x7fffffe268, L0x7fffffe26a, L0x7fffffe26c, L0x7fffffe26e] = %v0 /\

    %v1 <=s [2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16] /\
    %v1 >=s [(-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16] /\

    %v0 <=s [2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16] /\
    %v0 >=s [(-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16];


### i_iter prologue

(* ldr	q4, [x0, x3]                                #! EA = L0x7fffffe4f0; Value = 0x0000000000000000; PC = 0x5555551d34 *)
mov %v4 [L0x7fffffe4f0,L0x7fffffe4f2,L0x7fffffe4f4,L0x7fffffe4f6,L0x7fffffe4f8,L0x7fffffe4fa,L0x7fffffe4fc,L0x7fffffe4fe];
(* ldr	q1, [x8, x3]                                #! EA = L0x7fffffe500; Value = 0x0000000000000000; PC = 0x5555551d38 *)
mov %v1 [L0x7fffffe500,L0x7fffffe502,L0x7fffffe504,L0x7fffffe506,L0x7fffffe508,L0x7fffffe50a,L0x7fffffe50c,L0x7fffffe50e];
(* ldr	q17, [x1, x3]                               #! EA = L0x7fffffe3b0; Value = 0x0000000000000000; PC = 0x5555551d3c *)
mov %v17 [L0x7fffffe3b0,L0x7fffffe3b2,L0x7fffffe3b4,L0x7fffffe3b6,L0x7fffffe3b8,L0x7fffffe3ba,L0x7fffffe3bc,L0x7fffffe3be];
(* ldr	q18, [x7, x3]                               #! EA = L0x7fffffe3c0; Value = 0x0000000000000000; PC = 0x5555551d40 *)
mov %v18 [L0x7fffffe3c0,L0x7fffffe3c2,L0x7fffffe3c4,L0x7fffffe3c6,L0x7fffffe3c8,L0x7fffffe3ca,L0x7fffffe3cc,L0x7fffffe3ce];

ghost %fa0_6@sint16[8], %fa1_6@sint16[8], %fb0_6@sint16[8], %fb1_6@sint16[8] :
    %fa0_6 = %v4 /\ %fa1_6 = %v1 /\ %fb0_6 = %v17 /\ %fb1_6 = %v18
  &&
    %fa0_6 = %v4 /\ %fa1_6 = %v1 /\ %fb0_6 = %v17 /\ %fb1_6 = %v18;

cut (* 25 *)
    %fa0_6 = %v4 /\ %fa1_6 = %v1 /\ %fb0_6 = %v17 /\ %fb1_6 = %v18 /\
    %fa0_6 = [arr600_a, arr601_a, arr602_a, arr603_a, arr604_a, arr605_a, arr606_a, arr607_a] /\
    %fa1_6 = [arr610_a, arr611_a, arr612_a, arr613_a, arr614_a, arr615_a, arr616_a, arr617_a] /\
    %fb0_6 = [arr600_b, arr601_b, arr602_b, arr603_b, arr604_b, arr605_b, arr606_b, arr607_b] /\
    %fb1_6 = [arr610_b, arr611_b, arr612_b, arr613_b, arr614_b, arr615_b, arr616_b, arr617_b]
    prove with [cuts[0]]
  &&
    %fa0_6 = %v4 /\ %fa1_6 = %v1 /\ %fb0_6 = %v17 /\ %fb1_6 = %v18 /\
    %fa0_6 = [arr600_a, arr601_a, arr602_a, arr603_a, arr604_a, arr605_a, arr606_a, arr607_a] /\
    %fa1_6 = [arr610_a, arr611_a, arr612_a, arr613_a, arr614_a, arr615_a, arr616_a, arr617_a] /\
    %fb0_6 = [arr600_b, arr601_b, arr602_b, arr603_b, arr604_b, arr605_b, arr606_b, arr607_b] /\
    %fb1_6 = [arr610_b, arr611_b, arr612_b, arr613_b, arr614_b, arr615_b, arr616_b, arr617_b]
    prove with [cuts[0]];

#### radix2

(* ldr	q5, [x5]                                    #! EA = L0x5555552e60; Value = 0x2f9f06acc099f71e; PC = 0x5555551d48 *)
mov %v5 [L0x5555552e60,L0x5555552e62,L0x5555552e64,L0x5555552e66,L0x5555552e68,L0x5555552e6a,L0x5555552e6c,L0x5555552e6e];
(* sshr	v0.8h, v4.8h, #12                          #! PC = 0x5555551d4c *)
split %v0 %dc %v4 12;
(* cmlt	v2.8h, v4.8h, #0                           #! PC = 0x5555551d50 *)
split %v2 %dc %v4 15;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551d54 *)
sub %v0 %v0 %v2;
(* mls	v4.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551d58 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v4 %v4 %mls;

assert
    %fa0_6 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v4
    prove with [algebra solver isl, precondition, cuts[0, 25]]
    && true;

assume
    %fa0_6 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v4
    && true;

(* sshr	v0.8h, v17.8h, #12                         #! PC = 0x5555551d5c *)
split %v0 %dc %v17 12;
(* cmlt	v2.8h, v17.8h, #0                          #! PC = 0x5555551d60 *)
split %v2 %dc %v17 15;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551d64 *)
sub %v0 %v0 %v2;
(* mls	v17.8h, v0.8h, v5.h[6]                      #! PC = 0x5555551d68 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v17 %v17 %mls;

assert
    %fb0_6 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v17
    prove with [algebra solver isl, precondition, cuts[0, 25]]
    && true;

assume
    %fb0_6 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v17
    && true;

(* sqrdmulh	v0.8h, v1.8h, v5.h[1]                  #! PC = 0x5555551d6c *)
broadcast %mul 8 [%v5[1]]; smulj %LO %v1 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v0 %LO11 %LO01;
(* mul	v1.8h, v1.8h, v5.h[0]                       #! PC = 0x5555551d70 *)
broadcast %mul 8 [%v5[0]]; mull %dc %v1 %v1 %mul; cast %v1@int16[8] %v1;
(* mls	v1.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551d74 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v1 %v1 %mls;

assert
    [-2274, -2274, -2274, -2274, -2274, -2274, -2274, -2274] * %fa1_6
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v1
    prove with [algebra solver isl, precondition, cuts[0, 25]]
    && true;

assume
    [-2274, -2274, -2274, -2274, -2274, -2274, -2274, -2274] * %fa1_6
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v1
    && true;

(* sqrdmulh	v0.8h, v18.8h, v5.h[1]                 #! PC = 0x5555551d78 *)
broadcast %mul 8 [%v5[1]]; smulj %LO %v18 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v0 %LO11 %LO01;
(* mul	v18.8h, v18.8h, v5.h[0]                     #! PC = 0x5555551d7c *)
broadcast %mul 8 [%v5[0]]; mull %dc %v18 %v18 %mul; cast %v18@int16[8] %v18;
(* mls	v18.8h, v0.8h, v5.h[6]                      #! PC = 0x5555551d80 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v18 %v18 %mls;

assert
    [-2274, -2274, -2274, -2274, -2274, -2274, -2274, -2274] * %fb1_6
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v18
    prove with [algebra solver isl, precondition, cuts[0, 25]]
    && true;

assume
    [-2274, -2274, -2274, -2274, -2274, -2274, -2274, -2274] * %fb1_6
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v18
    && true;

(* add	v2.8h, v4.8h, v1.8h                         #! PC = 0x5555551d84 *)
add %v2 %v4 %v1;
(* sub	v1.8h, v4.8h, v1.8h                         #! PC = 0x5555551d88 *)
sub %v1 %v4 %v1;
(* add	v7.8h, v17.8h, v18.8h                       #! PC = 0x5555551d8c *)
add %v7 %v17 %v18;
(* sub	v18.8h, v17.8h, v18.8h                      #! PC = 0x5555551d90 *)
sub %v18 %v17 %v18;

ghost %fc0_6@sint16[8], %fc1_6@sint16[8], %fd0_6@sint16[8], %fd1_6@sint16[8] :
    %fc0_6 = %v2 /\ %fc1_6 = %v1 /\ %fd0_6 = %v7 /\ %fd1_6 = %v18
  &&
    %fc0_6 = %v2 /\ %fc1_6 = %v1 /\ %fd0_6 = %v7 /\ %fd1_6 = %v18;

(* sqrdmulh	v0.8h, v7.8h, v5.h[1]                  #! PC = 0x5555551d94 *)
broadcast %mul 8 [%v5[1]]; smulj %LO %v7 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v0 %LO11 %LO01;
(* mul	v3.8h, v7.8h, v5.h[0]                       #! PC = 0x5555551d98 *)
broadcast %mul 8 [%v5[0]]; mull %dc %v3 %v7 %mul; cast %v3@int16[8] %v3;
(* mls	v3.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551d9c *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v3 %v3 %mls;

assert
    [-2274, -2274, -2274, -2274, -2274, -2274, -2274, -2274] * %fd0_6
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v3
    prove with [algebra solver isl, precondition, cuts[0, 25]]
    && true;

assume
    [-2274, -2274, -2274, -2274, -2274, -2274, -2274, -2274] * %fd0_6
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v3
    && true;

(* sqrdmulh	v0.8h, v18.8h, v5.h[1]                 #! PC = 0x5555551da0 *)
broadcast %mul 8 [%v5[1]]; smulj %LO %v18 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v0 %LO11 %LO01;
(* mul	v6.8h, v18.8h, v5.h[0]                      #! PC = 0x5555551da4 *)
broadcast %mul 8 [%v5[0]]; mull %dc %v6 %v18 %mul; cast %v6@int16[8] %v6;
(* mls	v6.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551da8 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v6 %v6 %mls;

assert
    [-2274, -2274, -2274, -2274, -2274, -2274, -2274, -2274] * %fd1_6
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v6
    prove with [algebra solver isl, precondition, cuts[0, 25]]
    && true;

assume
    [-2274, -2274, -2274, -2274, -2274, -2274, -2274, -2274] * %fd1_6
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v6
    && true;

(* neg	v6.8h, v6.8h                                #! PC = 0x5555551dac *)
broadcast %zero 8 [0@sint16]; sub %v6 %zero %v6;

ghost %gd0_6@sint16[8], %gd1_6@sint16[8] :
    %gd0_6 = %v3 /\ %gd1_6 = %v6
  &&
    %gd0_6 = %v3 /\ %gd1_6 = %v6;

cut (* 26 *)
    %fc0_6 = %v2 /\ %fc1_6 = %v1 /\ %fd0_6 = %v7 /\ %fd1_6 = %v18 /\ %gd0_6 = %v3 /\ %gd1_6 = %v6 /\

    %fc0_6 = %fa0_6 + [-2274, -2274, -2274, -2274, -2274, -2274, -2274, -2274] * %fa1_6
        ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\
    %fc1_6 = %fa0_6 - [-2274, -2274, -2274, -2274, -2274, -2274, -2274, -2274] * %fa1_6
        ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\

    %fd0_6 = %fb0_6 + [-2274, -2274, -2274, -2274, -2274, -2274, -2274, -2274] * %fb1_6
        ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\
    %fd1_6 = %fb0_6 - [-2274, -2274, -2274, -2274, -2274, -2274, -2274, -2274] * %fb1_6
        ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\

    %gd0_6 =  [-2274, -2274, -2274, -2274, -2274, -2274, -2274, -2274] * %fd0_6 ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\
    %gd1_6 = -[-2274, -2274, -2274, -2274, -2274, -2274, -2274, -2274] * %fd1_6 ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ),

    %fc0_6 <= [8100, 8100, 8100, 8100, 8100, 8100, 8100, 8100] /\
    %fc0_6 >= [-8100, -8100, -8100, -8100, -8100, -8100, -8100, -8100] /\

    %fc1_6 <= [8100, 8100, 8100, 8100, 8100, 8100, 8100, 8100] /\
    %fc1_6 >= [-8100, -8100, -8100, -8100, -8100, -8100, -8100, -8100] /\

    %fd0_6 <= [8100, 8100, 8100, 8100, 8100, 8100, 8100, 8100] /\
    %fd0_6 >= [-8100, -8100, -8100, -8100, -8100, -8100, -8100, -8100] /\

    %fd1_6 <= [8100, 8100, 8100, 8100, 8100, 8100, 8100, 8100] /\
    %fd1_6 >= [-8100, -8100, -8100, -8100, -8100, -8100, -8100, -8100] /\

    %gd0_6 <= [3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000] /\
    %gd0_6 >= [-3000, -3000, -3000, -3000, -3000, -3000, -3000, -3000] /\

    %gd1_6 <= [3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000] /\
    %gd1_6 >= [-3000, -3000, -3000, -3000, -3000, -3000, -3000, -3000]

    prove with [algebra solver isl, precondition, cuts[0, 25]]
  &&
    true
    prove with [precondition, cuts[0, 25]];

(* smull	v0.4s, v7.4h, v2.h[0]                     #! PC = 0x5555551db0 *)
broadcast %mull 4 [%v2[0]]; smulj %v0 [%v7[0],%v7[1],%v7[2],%v7[3]] %mull;
(* smull2	v4.4s, v7.8h, v2.h[0]                    #! PC = 0x5555551db4 *)
broadcast %mull 4 [%v2[0]]; smulj %v4 [%v7[4],%v7[5],%v7[6],%v7[7]] %mull;
(* ext	v16.16b, v3.16b, v7.16b, #14                #! PC = 0x5555551db8 *)
mov %v16 [%v3[7],%v7[0],%v7[1],%v7[2],%v7[3],%v7[4],%v7[5],%v7[6]];
(* smlal	v0.4s, v16.4h, v2.h[1]                    #! PC = 0x5555551dbc *)
broadcast %mull 4 [%v2[1]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v16.8h, v2.h[1]                   #! PC = 0x5555551dc0 *)
broadcast %mull 4 [%v2[1]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v4 %v4 %mlal;
(* ext	v16.16b, v3.16b, v7.16b, #12                #! PC = 0x5555551dc4 *)
mov %v16 [%v3[6],%v3[7],%v7[0],%v7[1],%v7[2],%v7[3],%v7[4],%v7[5]];
(* smlal	v0.4s, v16.4h, v2.h[2]                    #! PC = 0x5555551dc8 *)
broadcast %mull 4 [%v2[2]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v16.8h, v2.h[2]                   #! PC = 0x5555551dcc *)
broadcast %mull 4 [%v2[2]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v4 %v4 %mlal;
(* ext	v16.16b, v3.16b, v7.16b, #10                #! PC = 0x5555551dd0 *)
mov %v16 [%v3[5],%v3[6],%v3[7],%v7[0],%v7[1],%v7[2],%v7[3],%v7[4]];
(* smlal	v0.4s, v16.4h, v2.h[3]                    #! PC = 0x5555551dd4 *)
broadcast %mull 4 [%v2[3]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v16.8h, v2.h[3]                   #! PC = 0x5555551dd8 *)
broadcast %mull 4 [%v2[3]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v4 %v4 %mlal;
(* ext	v16.16b, v3.16b, v7.16b, #8                 #! PC = 0x5555551ddc *)
mov %v16 [%v3[4],%v3[5],%v3[6],%v3[7],%v7[0],%v7[1],%v7[2],%v7[3]];
(* smlal	v0.4s, v16.4h, v2.h[4]                    #! PC = 0x5555551de0 *)
broadcast %mull 4 [%v2[4]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v16.8h, v2.h[4]                   #! PC = 0x5555551de4 *)
broadcast %mull 4 [%v2[4]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v4 %v4 %mlal;
(* ext	v16.16b, v3.16b, v7.16b, #6                 #! PC = 0x5555551de8 *)
mov %v16 [%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v7[0],%v7[1],%v7[2]];
(* smlal	v0.4s, v16.4h, v2.h[5]                    #! PC = 0x5555551dec *)
broadcast %mull 4 [%v2[5]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v16.8h, v2.h[5]                   #! PC = 0x5555551df0 *)
broadcast %mull 4 [%v2[5]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v4 %v4 %mlal;
(* ext	v16.16b, v3.16b, v7.16b, #4                 #! PC = 0x5555551df4 *)
mov %v16 [%v3[2],%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v7[0],%v7[1]];
(* smlal	v0.4s, v16.4h, v2.h[6]                    #! PC = 0x5555551df8 *)
broadcast %mull 4 [%v2[6]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v16.8h, v2.h[6]                   #! PC = 0x5555551dfc *)
broadcast %mull 4 [%v2[6]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v4 %v4 %mlal;
(* ext	v3.16b, v3.16b, v7.16b, #2                  #! PC = 0x5555551e00 *)
mov %v3 [%v3[1],%v3[2],%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v7[0]];
(* smlal	v0.4s, v3.4h, v2.h[7]                     #! PC = 0x5555551e04 *)
broadcast %mull 4 [%v2[7]]; smulj %mlal [%v3[0],%v3[1],%v3[2],%v3[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v3.8h, v2.h[7]                    #! PC = 0x5555551e08 *)
broadcast %mull 4 [%v2[7]]; smulj %mlal [%v3[4],%v3[5],%v3[6],%v3[7]] %mull; adds %dc %v4 %v4 %mlal;
(* smull	v3.4s, v18.4h, v1.h[0]                    #! PC = 0x5555551e0c *)
broadcast %mull 4 [%v1[0]]; smulj %v3 [%v18[0],%v18[1],%v18[2],%v18[3]] %mull;
(* smull2	v2.4s, v18.8h, v1.h[0]                   #! PC = 0x5555551e10 *)
broadcast %mull 4 [%v1[0]]; smulj %v2 [%v18[4],%v18[5],%v18[6],%v18[7]] %mull;
(* ext	v7.16b, v6.16b, v18.16b, #14                #! PC = 0x5555551e14 *)
mov %v7 [%v6[7],%v18[0],%v18[1],%v18[2],%v18[3],%v18[4],%v18[5],%v18[6]];
(* smlal	v3.4s, v7.4h, v1.h[1]                     #! PC = 0x5555551e18 *)
broadcast %mull 4 [%v1[1]]; smulj %mlal [%v7[0],%v7[1],%v7[2],%v7[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v7.8h, v1.h[1]                    #! PC = 0x5555551e1c *)
broadcast %mull 4 [%v1[1]]; smulj %mlal [%v7[4],%v7[5],%v7[6],%v7[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v7.16b, v6.16b, v18.16b, #12                #! PC = 0x5555551e20 *)
mov %v7 [%v6[6],%v6[7],%v18[0],%v18[1],%v18[2],%v18[3],%v18[4],%v18[5]];
(* smlal	v3.4s, v7.4h, v1.h[2]                     #! PC = 0x5555551e24 *)
broadcast %mull 4 [%v1[2]]; smulj %mlal [%v7[0],%v7[1],%v7[2],%v7[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v7.8h, v1.h[2]                    #! PC = 0x5555551e28 *)
broadcast %mull 4 [%v1[2]]; smulj %mlal [%v7[4],%v7[5],%v7[6],%v7[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v7.16b, v6.16b, v18.16b, #10                #! PC = 0x5555551e2c *)
mov %v7 [%v6[5],%v6[6],%v6[7],%v18[0],%v18[1],%v18[2],%v18[3],%v18[4]];
(* smlal	v3.4s, v7.4h, v1.h[3]                     #! PC = 0x5555551e30 *)
broadcast %mull 4 [%v1[3]]; smulj %mlal [%v7[0],%v7[1],%v7[2],%v7[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v7.8h, v1.h[3]                    #! PC = 0x5555551e34 *)
broadcast %mull 4 [%v1[3]]; smulj %mlal [%v7[4],%v7[5],%v7[6],%v7[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v7.16b, v6.16b, v18.16b, #8                 #! PC = 0x5555551e38 *)
mov %v7 [%v6[4],%v6[5],%v6[6],%v6[7],%v18[0],%v18[1],%v18[2],%v18[3]];
(* smlal	v3.4s, v7.4h, v1.h[4]                     #! PC = 0x5555551e3c *)
broadcast %mull 4 [%v1[4]]; smulj %mlal [%v7[0],%v7[1],%v7[2],%v7[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v7.8h, v1.h[4]                    #! PC = 0x5555551e40 *)
broadcast %mull 4 [%v1[4]]; smulj %mlal [%v7[4],%v7[5],%v7[6],%v7[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v7.16b, v6.16b, v18.16b, #6                 #! PC = 0x5555551e44 *)
mov %v7 [%v6[3],%v6[4],%v6[5],%v6[6],%v6[7],%v18[0],%v18[1],%v18[2]];
(* smlal	v3.4s, v7.4h, v1.h[5]                     #! PC = 0x5555551e48 *)
broadcast %mull 4 [%v1[5]]; smulj %mlal [%v7[0],%v7[1],%v7[2],%v7[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v7.8h, v1.h[5]                    #! PC = 0x5555551e4c *)
broadcast %mull 4 [%v1[5]]; smulj %mlal [%v7[4],%v7[5],%v7[6],%v7[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v7.16b, v6.16b, v18.16b, #4                 #! PC = 0x5555551e50 *)
mov %v7 [%v6[2],%v6[3],%v6[4],%v6[5],%v6[6],%v6[7],%v18[0],%v18[1]];
(* smlal	v3.4s, v7.4h, v1.h[6]                     #! PC = 0x5555551e54 *)
broadcast %mull 4 [%v1[6]]; smulj %mlal [%v7[0],%v7[1],%v7[2],%v7[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v7.8h, v1.h[6]                    #! PC = 0x5555551e58 *)
broadcast %mull 4 [%v1[6]]; smulj %mlal [%v7[4],%v7[5],%v7[6],%v7[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v6.16b, v6.16b, v18.16b, #2                 #! PC = 0x5555551e5c *)
mov %v6 [%v6[1],%v6[2],%v6[3],%v6[4],%v6[5],%v6[6],%v6[7],%v18[0]];
(* smlal	v3.4s, v6.4h, v1.h[7]                     #! PC = 0x5555551e60 *)
broadcast %mull 4 [%v1[7]]; smulj %mlal [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v6.8h, v1.h[7]                    #! PC = 0x5555551e64 *)
broadcast %mull 4 [%v1[7]]; smulj %mlal [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; adds %dc %v2 %v2 %mlal;

ghost %conv0_6@sint32[8], %conv1_6@sint32[8] :
    %conv0_6 = [
        %fc0_6[0] * %fd0_6[0] + %fc0_6[1] * %gd0_6[7] + %fc0_6[2] * %gd0_6[6] + %fc0_6[3] * %gd0_6[5] + %fc0_6[4] * %gd0_6[4] + %fc0_6[5] * %gd0_6[3] + %fc0_6[6] * %gd0_6[2] + %fc0_6[7] * %gd0_6[1],
        %fc0_6[0] * %fd0_6[1] + %fc0_6[1] * %fd0_6[0] + %fc0_6[2] * %gd0_6[7] + %fc0_6[3] * %gd0_6[6] + %fc0_6[4] * %gd0_6[5] + %fc0_6[5] * %gd0_6[4] + %fc0_6[6] * %gd0_6[3] + %fc0_6[7] * %gd0_6[2],
        %fc0_6[0] * %fd0_6[2] + %fc0_6[1] * %fd0_6[1] + %fc0_6[2] * %fd0_6[0] + %fc0_6[3] * %gd0_6[7] + %fc0_6[4] * %gd0_6[6] + %fc0_6[5] * %gd0_6[5] + %fc0_6[6] * %gd0_6[4] + %fc0_6[7] * %gd0_6[3],
        %fc0_6[0] * %fd0_6[3] + %fc0_6[1] * %fd0_6[2] + %fc0_6[2] * %fd0_6[1] + %fc0_6[3] * %fd0_6[0] + %fc0_6[4] * %gd0_6[7] + %fc0_6[5] * %gd0_6[6] + %fc0_6[6] * %gd0_6[5] + %fc0_6[7] * %gd0_6[4],
        %fc0_6[0] * %fd0_6[4] + %fc0_6[1] * %fd0_6[3] + %fc0_6[2] * %fd0_6[2] + %fc0_6[3] * %fd0_6[1] + %fc0_6[4] * %fd0_6[0] + %fc0_6[5] * %gd0_6[7] + %fc0_6[6] * %gd0_6[6] + %fc0_6[7] * %gd0_6[5],
        %fc0_6[0] * %fd0_6[5] + %fc0_6[1] * %fd0_6[4] + %fc0_6[2] * %fd0_6[3] + %fc0_6[3] * %fd0_6[2] + %fc0_6[4] * %fd0_6[1] + %fc0_6[5] * %fd0_6[0] + %fc0_6[6] * %gd0_6[7] + %fc0_6[7] * %gd0_6[6],
        %fc0_6[0] * %fd0_6[6] + %fc0_6[1] * %fd0_6[5] + %fc0_6[2] * %fd0_6[4] + %fc0_6[3] * %fd0_6[3] + %fc0_6[4] * %fd0_6[2] + %fc0_6[5] * %fd0_6[1] + %fc0_6[6] * %fd0_6[0] + %fc0_6[7] * %gd0_6[7],
        %fc0_6[0] * %fd0_6[7] + %fc0_6[1] * %fd0_6[6] + %fc0_6[2] * %fd0_6[5] + %fc0_6[3] * %fd0_6[4] + %fc0_6[4] * %fd0_6[3] + %fc0_6[5] * %fd0_6[2] + %fc0_6[6] * %fd0_6[1] + %fc0_6[7] * %fd0_6[0]
    ] /\
    %conv1_6 = [
        %fc1_6[0] * %fd1_6[0] + %fc1_6[1] * %gd1_6[7] + %fc1_6[2] * %gd1_6[6] + %fc1_6[3] * %gd1_6[5] + %fc1_6[4] * %gd1_6[4] + %fc1_6[5] * %gd1_6[3] + %fc1_6[6] * %gd1_6[2] + %fc1_6[7] * %gd1_6[1],
        %fc1_6[0] * %fd1_6[1] + %fc1_6[1] * %fd1_6[0] + %fc1_6[2] * %gd1_6[7] + %fc1_6[3] * %gd1_6[6] + %fc1_6[4] * %gd1_6[5] + %fc1_6[5] * %gd1_6[4] + %fc1_6[6] * %gd1_6[3] + %fc1_6[7] * %gd1_6[2],
        %fc1_6[0] * %fd1_6[2] + %fc1_6[1] * %fd1_6[1] + %fc1_6[2] * %fd1_6[0] + %fc1_6[3] * %gd1_6[7] + %fc1_6[4] * %gd1_6[6] + %fc1_6[5] * %gd1_6[5] + %fc1_6[6] * %gd1_6[4] + %fc1_6[7] * %gd1_6[3],
        %fc1_6[0] * %fd1_6[3] + %fc1_6[1] * %fd1_6[2] + %fc1_6[2] * %fd1_6[1] + %fc1_6[3] * %fd1_6[0] + %fc1_6[4] * %gd1_6[7] + %fc1_6[5] * %gd1_6[6] + %fc1_6[6] * %gd1_6[5] + %fc1_6[7] * %gd1_6[4],
        %fc1_6[0] * %fd1_6[4] + %fc1_6[1] * %fd1_6[3] + %fc1_6[2] * %fd1_6[2] + %fc1_6[3] * %fd1_6[1] + %fc1_6[4] * %fd1_6[0] + %fc1_6[5] * %gd1_6[7] + %fc1_6[6] * %gd1_6[6] + %fc1_6[7] * %gd1_6[5],
        %fc1_6[0] * %fd1_6[5] + %fc1_6[1] * %fd1_6[4] + %fc1_6[2] * %fd1_6[3] + %fc1_6[3] * %fd1_6[2] + %fc1_6[4] * %fd1_6[1] + %fc1_6[5] * %fd1_6[0] + %fc1_6[6] * %gd1_6[7] + %fc1_6[7] * %gd1_6[6],
        %fc1_6[0] * %fd1_6[6] + %fc1_6[1] * %fd1_6[5] + %fc1_6[2] * %fd1_6[4] + %fc1_6[3] * %fd1_6[3] + %fc1_6[4] * %fd1_6[2] + %fc1_6[5] * %fd1_6[1] + %fc1_6[6] * %fd1_6[0] + %fc1_6[7] * %gd1_6[7],
        %fc1_6[0] * %fd1_6[7] + %fc1_6[1] * %fd1_6[6] + %fc1_6[2] * %fd1_6[5] + %fc1_6[3] * %fd1_6[4] + %fc1_6[4] * %fd1_6[3] + %fc1_6[5] * %fd1_6[2] + %fc1_6[6] * %fd1_6[1] + %fc1_6[7] * %fd1_6[0]
    ]
    && true;

assert
    %v0 ++ %v4 = %conv0_6 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] ) /\
    %v3 ++ %v2 = %conv1_6 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] )
    && true;

assume
    %v0 ++ %v4 = %conv0_6 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] ) /\
    %v3 ++ %v2 = %conv1_6 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] )
    && true;

assert
    %conv0_6 <= [524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000] /\
    %conv0_6 >= [-524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000] /\

    %conv1_6 <= [524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000] /\
    %conv1_6 >= [-524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000]
    prove with [algebra solver smt: z3]
    && true;

assume
    %conv0_6 <= [524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000] /\
    %conv0_6 >= [-524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000] /\

    %conv1_6 <= [524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000] /\
    %conv1_6 >= [-524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000]
    && true;

assert
    %v0 ++ %v4 = %conv0_6 /\ %v3 ++ %v2 = %conv1_6
    prove with [algebra solver isl]
    && true;

assume
    %v0 ++ %v4 = %conv0_6 /\ %v3 ++ %v2 = %conv1_6
    && true;

assert
    %v0 <= [524880000, 524880000, 524880000, 524880000] /\
    %v0 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v4 <= [524880000, 524880000, 524880000, 524880000] /\
    %v4 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v3 <= [524880000, 524880000, 524880000, 524880000] /\
    %v3 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v2 <= [524880000, 524880000, 524880000, 524880000] /\
    %v2 >= [-524880000, -524880000, -524880000, -524880000]

    prove with [algebra solver isl]
    && true;

assume
    %v0 <= [524880000, 524880000, 524880000, 524880000] /\
    %v0 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v4 <= [524880000, 524880000, 524880000, 524880000] /\
    %v4 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v3 <= [524880000, 524880000, 524880000, 524880000] /\
    %v3 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v2 <= [524880000, 524880000, 524880000, 524880000] /\
    %v2 >= [-524880000, -524880000, -524880000, -524880000]
  &&
    %v0 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v0 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32] /\

    %v4 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v4 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32] /\

    %v3 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v3 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32] /\

    %v2 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v2 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32];

cut (* 27 *)
    %conv0_6 = [
        %fc0_6[0] * %fd0_6[0] + %fc0_6[1] * %gd0_6[7] + %fc0_6[2] * %gd0_6[6] + %fc0_6[3] * %gd0_6[5] + %fc0_6[4] * %gd0_6[4] + %fc0_6[5] * %gd0_6[3] + %fc0_6[6] * %gd0_6[2] + %fc0_6[7] * %gd0_6[1],
        %fc0_6[0] * %fd0_6[1] + %fc0_6[1] * %fd0_6[0] + %fc0_6[2] * %gd0_6[7] + %fc0_6[3] * %gd0_6[6] + %fc0_6[4] * %gd0_6[5] + %fc0_6[5] * %gd0_6[4] + %fc0_6[6] * %gd0_6[3] + %fc0_6[7] * %gd0_6[2],
        %fc0_6[0] * %fd0_6[2] + %fc0_6[1] * %fd0_6[1] + %fc0_6[2] * %fd0_6[0] + %fc0_6[3] * %gd0_6[7] + %fc0_6[4] * %gd0_6[6] + %fc0_6[5] * %gd0_6[5] + %fc0_6[6] * %gd0_6[4] + %fc0_6[7] * %gd0_6[3],
        %fc0_6[0] * %fd0_6[3] + %fc0_6[1] * %fd0_6[2] + %fc0_6[2] * %fd0_6[1] + %fc0_6[3] * %fd0_6[0] + %fc0_6[4] * %gd0_6[7] + %fc0_6[5] * %gd0_6[6] + %fc0_6[6] * %gd0_6[5] + %fc0_6[7] * %gd0_6[4],
        %fc0_6[0] * %fd0_6[4] + %fc0_6[1] * %fd0_6[3] + %fc0_6[2] * %fd0_6[2] + %fc0_6[3] * %fd0_6[1] + %fc0_6[4] * %fd0_6[0] + %fc0_6[5] * %gd0_6[7] + %fc0_6[6] * %gd0_6[6] + %fc0_6[7] * %gd0_6[5],
        %fc0_6[0] * %fd0_6[5] + %fc0_6[1] * %fd0_6[4] + %fc0_6[2] * %fd0_6[3] + %fc0_6[3] * %fd0_6[2] + %fc0_6[4] * %fd0_6[1] + %fc0_6[5] * %fd0_6[0] + %fc0_6[6] * %gd0_6[7] + %fc0_6[7] * %gd0_6[6],
        %fc0_6[0] * %fd0_6[6] + %fc0_6[1] * %fd0_6[5] + %fc0_6[2] * %fd0_6[4] + %fc0_6[3] * %fd0_6[3] + %fc0_6[4] * %fd0_6[2] + %fc0_6[5] * %fd0_6[1] + %fc0_6[6] * %fd0_6[0] + %fc0_6[7] * %gd0_6[7],
        %fc0_6[0] * %fd0_6[7] + %fc0_6[1] * %fd0_6[6] + %fc0_6[2] * %fd0_6[5] + %fc0_6[3] * %fd0_6[4] + %fc0_6[4] * %fd0_6[3] + %fc0_6[5] * %fd0_6[2] + %fc0_6[6] * %fd0_6[1] + %fc0_6[7] * %fd0_6[0]
    ] /\
    %conv1_6 = [
        %fc1_6[0] * %fd1_6[0] + %fc1_6[1] * %gd1_6[7] + %fc1_6[2] * %gd1_6[6] + %fc1_6[3] * %gd1_6[5] + %fc1_6[4] * %gd1_6[4] + %fc1_6[5] * %gd1_6[3] + %fc1_6[6] * %gd1_6[2] + %fc1_6[7] * %gd1_6[1],
        %fc1_6[0] * %fd1_6[1] + %fc1_6[1] * %fd1_6[0] + %fc1_6[2] * %gd1_6[7] + %fc1_6[3] * %gd1_6[6] + %fc1_6[4] * %gd1_6[5] + %fc1_6[5] * %gd1_6[4] + %fc1_6[6] * %gd1_6[3] + %fc1_6[7] * %gd1_6[2],
        %fc1_6[0] * %fd1_6[2] + %fc1_6[1] * %fd1_6[1] + %fc1_6[2] * %fd1_6[0] + %fc1_6[3] * %gd1_6[7] + %fc1_6[4] * %gd1_6[6] + %fc1_6[5] * %gd1_6[5] + %fc1_6[6] * %gd1_6[4] + %fc1_6[7] * %gd1_6[3],
        %fc1_6[0] * %fd1_6[3] + %fc1_6[1] * %fd1_6[2] + %fc1_6[2] * %fd1_6[1] + %fc1_6[3] * %fd1_6[0] + %fc1_6[4] * %gd1_6[7] + %fc1_6[5] * %gd1_6[6] + %fc1_6[6] * %gd1_6[5] + %fc1_6[7] * %gd1_6[4],
        %fc1_6[0] * %fd1_6[4] + %fc1_6[1] * %fd1_6[3] + %fc1_6[2] * %fd1_6[2] + %fc1_6[3] * %fd1_6[1] + %fc1_6[4] * %fd1_6[0] + %fc1_6[5] * %gd1_6[7] + %fc1_6[6] * %gd1_6[6] + %fc1_6[7] * %gd1_6[5],
        %fc1_6[0] * %fd1_6[5] + %fc1_6[1] * %fd1_6[4] + %fc1_6[2] * %fd1_6[3] + %fc1_6[3] * %fd1_6[2] + %fc1_6[4] * %fd1_6[1] + %fc1_6[5] * %fd1_6[0] + %fc1_6[6] * %gd1_6[7] + %fc1_6[7] * %gd1_6[6],
        %fc1_6[0] * %fd1_6[6] + %fc1_6[1] * %fd1_6[5] + %fc1_6[2] * %fd1_6[4] + %fc1_6[3] * %fd1_6[3] + %fc1_6[4] * %fd1_6[2] + %fc1_6[5] * %fd1_6[1] + %fc1_6[6] * %fd1_6[0] + %fc1_6[7] * %gd1_6[7],
        %fc1_6[0] * %fd1_6[7] + %fc1_6[1] * %fd1_6[6] + %fc1_6[2] * %fd1_6[5] + %fc1_6[3] * %fd1_6[4] + %fc1_6[4] * %fd1_6[3] + %fc1_6[5] * %fd1_6[2] + %fc1_6[6] * %fd1_6[1] + %fc1_6[7] * %fd1_6[0]
    ] /\

    %v0 ++ %v4 = %conv0_6 /\ %v3 ++ %v2 = %conv1_6,

    %v0 <= [524880000, 524880000, 524880000, 524880000] /\
    %v0 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v4 <= [524880000, 524880000, 524880000, 524880000] /\
    %v4 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v3 <= [524880000, 524880000, 524880000, 524880000] /\
    %v3 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v2 <= [524880000, 524880000, 524880000, 524880000] /\
    %v2 >= [-524880000, -524880000, -524880000, -524880000]

    prove with [algebra solver isl]
  &&
    %v0 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v0 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32] /\

    %v4 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v4 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32] /\

    %v3 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v3 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32] /\

    %v2 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v2 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32];

(* add	v1.4s, v3.4s, v0.4s                         #! PC = 0x5555551e68 *)
add %v1 %v3 %v0;
(* add	v6.4s, v2.4s, v4.4s                         #! PC = 0x5555551e6c *)
add %v6 %v2 %v4;
(* sub	v0.4s, v0.4s, v3.4s                         #! PC = 0x5555551e70 *)
sub %v0 %v0 %v3;
(* sub	v4.4s, v4.4s, v2.4s                         #! PC = 0x5555551e74 *)
sub %v4 %v4 %v2;

ghost %h0_6@sint32[8], %h1_6@sint32[8] :
    %h0_6 = %v1 ++ %v6 /\ %h1_6 = %v0 ++ %v4
  &&
    %h0_6 = %v1 ++ %v6 /\ %h1_6 = %v0 ++ %v4;

(* uzp1	v2.8h, v1.8h, v6.8h                        #! PC = 0x5555551e78 *)
mov %spl_join [%v1[0], %v1[1], %v1[2], %v1[3], %v6[0], %v6[1], %v6[2], %v6[3]]; spl %splh %v2 %spl_join 16; cast %v2@int16[8] %v2;
(* mul	v2.8h, v2.8h, v5.h[7]                       #! PC = 0x5555551e7c *)
broadcast %mul 8 [%v5[7]]; mull %dc %v2 %v2 %mul; cast %v2@int16[8] %v2;

ghost %m0_6@sint16[8] : %m0_6 = %v2 && %m0_6 = %v2;

(* sqdmulh	v2.8h, v2.8h, v5.h[6]                   #! PC = 0x5555551e80 *)
broadcast %mul 8 [%v5[6]]; smulj %LO %v2 %mul;
ssplit %LO0 %dc %LO 15; vpc %v2@sint16[8] %LO0;
(* uzp2	v1.8h, v1.8h, v6.8h                        #! PC = 0x5555551e84 *)
mov %spl_join [%v1[0], %v1[1], %v1[2], %v1[3], %v6[0], %v6[1], %v6[2], %v6[3]]; spl %v1 %spll %spl_join 16;
(* sshr	v2.8h, v2.8h, #1                           #! PC = 0x5555551e88 *)
split %v2 %dc %v2 1;
(* sub	v1.8h, v1.8h, v2.8h                         #! PC = 0x5555551e8c *)
sub %v1 %v1 %v2;

ghost %hh0_6@sint16[8] : %hh0_6 = %v1 && %hh0_6 = %v1;

assert
    %h0_6 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m0_6
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh0_6
    prove with [algebra solver isl]
    && true;

assume
    %h0_6 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m0_6
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh0_6
    && true;

(* sqrdmulh	v2.8h, v1.8h, v5.h[3]                  #! PC = 0x5555551e90 *)
broadcast %mul 8 [%v5[3]]; smulj %LO %v1 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v2 %LO11 %LO01;
(* mul	v1.8h, v1.8h, v5.h[2]                       #! PC = 0x5555551e94 *)
broadcast %mul 8 [%v5[2]]; mull %dc %v1 %v1 %mul; cast %v1@int16[8] %v1;
(* mls	v1.8h, v2.8h, v5.h[6]                       #! PC = 0x5555551e98 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v2 %mul;
cast %mls@int16[8] %mls; subc %dc %v1 %v1 %mls;

assert
    [1708, 1708, 1708, 1708, 1708, 1708, 1708, 1708] * %hh0_6
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v2
    = %v1
    prove with [algebra solver isl]
    && true;

assume
    [1708, 1708, 1708, 1708, 1708, 1708, 1708, 1708] * %hh0_6
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v2
    = %v1
    && true;

(* uzp1	v2.8h, v0.8h, v4.8h                        #! PC = 0x5555551e9c *)
mov %spl_join [%v0[0], %v0[1], %v0[2], %v0[3], %v4[0], %v4[1], %v4[2], %v4[3]]; spl %splh %v2 %spl_join 16; cast %v2@int16[8] %v2;
(* mul	v2.8h, v2.8h, v5.h[7]                       #! PC = 0x5555551ea0 *)
broadcast %mul 8 [%v5[7]]; mull %dc %v2 %v2 %mul; cast %v2@int16[8] %v2;

ghost %m1_6@sint16[8] : %m1_6 = %v2 && %m1_6 = %v2;

(* sqdmulh	v2.8h, v2.8h, v5.h[6]                   #! PC = 0x5555551ea4 *)
broadcast %mul 8 [%v5[6]]; smulj %LO %v2 %mul;
ssplit %LO0 %dc %LO 15; vpc %v2@sint16[8] %LO0;
(* uzp2	v0.8h, v0.8h, v4.8h                        #! PC = 0x5555551ea8 *)
mov %spl_join [%v0[0], %v0[1], %v0[2], %v0[3], %v4[0], %v4[1], %v4[2], %v4[3]]; spl %v0 %spll %spl_join 16;
(* sshr	v2.8h, v2.8h, #1                           #! PC = 0x5555551eac *)
split %v2 %dc %v2 1;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551eb0 *)
sub %v0 %v0 %v2;

ghost %hh1_6@sint16[8] : %hh1_6 = %v0 && %hh1_6 = %v0;

assert
    %h1_6 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m1_6
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh1_6
    prove with [algebra solver isl]
    && true;

assume
    %h1_6 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m1_6
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh1_6
    && true;

(* sqrdmulh	v2.8h, v0.8h, v5.h[5]                  #! PC = 0x5555551eb4 *)
broadcast %mul 8 [%v5[5]]; smulj %LO %v0 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v2 %LO11 %LO01;
(* mul	v0.8h, v0.8h, v5.h[4]                       #! PC = 0x5555551eb8 *)
broadcast %mul 8 [%v5[4]]; mull %dc %v0 %v0 %mul; cast %v0@int16[8] %v0;
(* mls	v0.8h, v2.8h, v5.h[6]                       #! PC = 0x5555551ebc *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v2 %mul;
cast %mls@int16[8] %mls; subc %dc %v0 %v0 %mls;

assert
    [-1095, -1095, -1095, -1095, -1095, -1095, -1095, -1095] * %hh1_6
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v2
    = %v0
    prove with [algebra solver isl]
    && true;

assume
    [-1095, -1095, -1095, -1095, -1095, -1095, -1095, -1095] * %hh1_6
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v2
    = %v0
    && true;

(* #b	0x5555551d18 <_ZN6xpower7basemul11low_basemulEPA2_A8_sS3_S3_+504>#! PC = 0x5555551ec0 *)
#b	0x5555551d18 <_ZN6xpower7basemul11low_basemulEPA2_A8_sS3_S3_+504>#! 0x5555551ec0 = 0x5555551ec0;


### i_iter epilogue

(* str	q1, [x2, x3]                                #! EA = L0x7fffffe270; PC = 0x5555551d18 *)
mov [L0x7fffffe270,L0x7fffffe272,L0x7fffffe274,L0x7fffffe276,L0x7fffffe278,L0x7fffffe27a,L0x7fffffe27c,L0x7fffffe27e] %v1;
(* str	q0, [x6, x3]                                #! EA = L0x7fffffe280; PC = 0x5555551d1c *)
mov [L0x7fffffe280,L0x7fffffe282,L0x7fffffe284,L0x7fffffe286,L0x7fffffe288,L0x7fffffe28a,L0x7fffffe28c,L0x7fffffe28e] %v0;
(* #b.eq	0x5555551ec4 <_ZN6xpower7basemul11low_basemulEPA2_A8_sS3_S3_+932>  // b.none#! PC = 0x5555551d30 *)
#b.eq	0x5555551ec4 <_ZN6xpower7basemul11low_basemulEPA2_A8_sS3_S3_+932>  // b.none#! 0x5555551d30 = 0x5555551d30;

assert
    %v1 <= [3450, 3450, 3450, 3450, 3450, 3450, 3450, 3450] /\
    %v1 >= [-3450, -3450, -3450, -3450, -3450, -3450, -3450, -3450] /\

    %v0 <= [4580, 4580, 4580, 4580, 4580, 4580, 4580, 4580] /\
    %v0 >= [-4580, -4580, -4580, -4580, -4580, -4580, -4580, -4580]

    prove with [algebra solver isl]
    && true;

assume
    true &&

    %v1 <=s [3450@16, 3450@16, 3450@16, 3450@16, 3450@16, 3450@16, 3450@16, 3450@16] /\
    %v1 >=s [(-3450)@16, (-3450)@16, (-3450)@16, (-3450)@16, (-3450)@16, (-3450)@16, (-3450)@16, (-3450)@16] /\

    %v0 <=s [4580@16, 4580@16, 4580@16, 4580@16, 4580@16, 4580@16, 4580@16, 4580@16] /\
    %v0 >=s [(-4580)@16, (-4580)@16, (-4580)@16, (-4580)@16, (-4580)@16, (-4580)@16, (-4580)@16, (-4580)@16];

cut (* 28 *)
    [L0x7fffffe270, L0x7fffffe272, L0x7fffffe274, L0x7fffffe276, L0x7fffffe278, L0x7fffffe27a, L0x7fffffe27c, L0x7fffffe27e] = %v1 /\
    [L0x7fffffe280, L0x7fffffe282, L0x7fffffe284, L0x7fffffe286, L0x7fffffe288, L0x7fffffe28a, L0x7fffffe28c, L0x7fffffe28e] = %v0 /\

    %v1 ++ %v0 = [1145, 1145, 1145, 1145, 1145, 1145, 1145, 1145, 1145, 1145, 1145, 1145, 1145, 1145, 1145, 1145] * [
        arr600_a * arr600_b + 1610 * arr601_a * arr617_b + 1610 * arr602_a * arr616_b + 1610 * arr603_a * arr615_b + 1610 * arr604_a * arr614_b + 1610 * arr605_a * arr613_b + 1610 * arr606_a * arr612_b + 1610 * arr607_a * arr611_b + 1610 * arr610_a * arr610_b + 1610 * arr611_a * arr607_b + 1610 * arr612_a * arr606_b + 1610 * arr613_a * arr605_b + 1610 * arr614_a * arr604_b + 1610 * arr615_a * arr603_b + 1610 * arr616_a * arr602_b + 1610 * arr617_a * arr601_b,
        arr600_a * arr601_b + arr601_a * arr600_b + 1610 * arr602_a * arr617_b + 1610 * arr603_a * arr616_b + 1610 * arr604_a * arr615_b + 1610 * arr605_a * arr614_b + 1610 * arr606_a * arr613_b + 1610 * arr607_a * arr612_b + 1610 * arr610_a * arr611_b + 1610 * arr611_a * arr610_b + 1610 * arr612_a * arr607_b + 1610 * arr613_a * arr606_b + 1610 * arr614_a * arr605_b + 1610 * arr615_a * arr604_b + 1610 * arr616_a * arr603_b + 1610 * arr617_a * arr602_b,
        arr600_a * arr602_b + arr601_a * arr601_b + arr602_a * arr600_b + 1610 * arr603_a * arr617_b + 1610 * arr604_a * arr616_b + 1610 * arr605_a * arr615_b + 1610 * arr606_a * arr614_b + 1610 * arr607_a * arr613_b + 1610 * arr610_a * arr612_b + 1610 * arr611_a * arr611_b + 1610 * arr612_a * arr610_b + 1610 * arr613_a * arr607_b + 1610 * arr614_a * arr606_b + 1610 * arr615_a * arr605_b + 1610 * arr616_a * arr604_b + 1610 * arr617_a * arr603_b,
        arr600_a * arr603_b + arr601_a * arr602_b + arr602_a * arr601_b + arr603_a * arr600_b + 1610 * arr604_a * arr617_b + 1610 * arr605_a * arr616_b + 1610 * arr606_a * arr615_b + 1610 * arr607_a * arr614_b + 1610 * arr610_a * arr613_b + 1610 * arr611_a * arr612_b + 1610 * arr612_a * arr611_b + 1610 * arr613_a * arr610_b + 1610 * arr614_a * arr607_b + 1610 * arr615_a * arr606_b + 1610 * arr616_a * arr605_b + 1610 * arr617_a * arr604_b,
        arr600_a * arr604_b + arr601_a * arr603_b + arr602_a * arr602_b + arr603_a * arr601_b + arr604_a * arr600_b + 1610 * arr605_a * arr617_b + 1610 * arr606_a * arr616_b + 1610 * arr607_a * arr615_b + 1610 * arr610_a * arr614_b + 1610 * arr611_a * arr613_b + 1610 * arr612_a * arr612_b + 1610 * arr613_a * arr611_b + 1610 * arr614_a * arr610_b + 1610 * arr615_a * arr607_b + 1610 * arr616_a * arr606_b + 1610 * arr617_a * arr605_b,
        arr600_a * arr605_b + arr601_a * arr604_b + arr602_a * arr603_b + arr603_a * arr602_b + arr604_a * arr601_b + arr605_a * arr600_b + 1610 * arr606_a * arr617_b + 1610 * arr607_a * arr616_b + 1610 * arr610_a * arr615_b + 1610 * arr611_a * arr614_b + 1610 * arr612_a * arr613_b + 1610 * arr613_a * arr612_b + 1610 * arr614_a * arr611_b + 1610 * arr615_a * arr610_b + 1610 * arr616_a * arr607_b + 1610 * arr617_a * arr606_b,
        arr600_a * arr606_b + arr601_a * arr605_b + arr602_a * arr604_b + arr603_a * arr603_b + arr604_a * arr602_b + arr605_a * arr601_b + arr606_a * arr600_b + 1610 * arr607_a * arr617_b + 1610 * arr610_a * arr616_b + 1610 * arr611_a * arr615_b + 1610 * arr612_a * arr614_b + 1610 * arr613_a * arr613_b + 1610 * arr614_a * arr612_b + 1610 * arr615_a * arr611_b + 1610 * arr616_a * arr610_b + 1610 * arr617_a * arr607_b,
        arr600_a * arr607_b + arr601_a * arr606_b + arr602_a * arr605_b + arr603_a * arr604_b + arr604_a * arr603_b + arr605_a * arr602_b + arr606_a * arr601_b + arr607_a * arr600_b + 1610 * arr610_a * arr617_b + 1610 * arr611_a * arr616_b + 1610 * arr612_a * arr615_b + 1610 * arr613_a * arr614_b + 1610 * arr614_a * arr613_b + 1610 * arr615_a * arr612_b + 1610 * arr616_a * arr611_b + 1610 * arr617_a * arr610_b,
        arr600_a * arr610_b + arr601_a * arr607_b + arr602_a * arr606_b + arr603_a * arr605_b + arr604_a * arr604_b + arr605_a * arr603_b + arr606_a * arr602_b + arr607_a * arr601_b + arr610_a * arr600_b + 1610 * arr611_a * arr617_b + 1610 * arr612_a * arr616_b + 1610 * arr613_a * arr615_b + 1610 * arr614_a * arr614_b + 1610 * arr615_a * arr613_b + 1610 * arr616_a * arr612_b + 1610 * arr617_a * arr611_b,
        arr600_a * arr611_b + arr601_a * arr610_b + arr602_a * arr607_b + arr603_a * arr606_b + arr604_a * arr605_b + arr605_a * arr604_b + arr606_a * arr603_b + arr607_a * arr602_b + arr610_a * arr601_b + arr611_a * arr600_b + 1610 * arr612_a * arr617_b + 1610 * arr613_a * arr616_b + 1610 * arr614_a * arr615_b + 1610 * arr615_a * arr614_b + 1610 * arr616_a * arr613_b + 1610 * arr617_a * arr612_b,
        arr600_a * arr612_b + arr601_a * arr611_b + arr602_a * arr610_b + arr603_a * arr607_b + arr604_a * arr606_b + arr605_a * arr605_b + arr606_a * arr604_b + arr607_a * arr603_b + arr610_a * arr602_b + arr611_a * arr601_b + arr612_a * arr600_b + 1610 * arr613_a * arr617_b + 1610 * arr614_a * arr616_b + 1610 * arr615_a * arr615_b + 1610 * arr616_a * arr614_b + 1610 * arr617_a * arr613_b,
        arr600_a * arr613_b + arr601_a * arr612_b + arr602_a * arr611_b + arr603_a * arr610_b + arr604_a * arr607_b + arr605_a * arr606_b + arr606_a * arr605_b + arr607_a * arr604_b + arr610_a * arr603_b + arr611_a * arr602_b + arr612_a * arr601_b + arr613_a * arr600_b + 1610 * arr614_a * arr617_b + 1610 * arr615_a * arr616_b + 1610 * arr616_a * arr615_b + 1610 * arr617_a * arr614_b,
        arr600_a * arr614_b + arr601_a * arr613_b + arr602_a * arr612_b + arr603_a * arr611_b + arr604_a * arr610_b + arr605_a * arr607_b + arr606_a * arr606_b + arr607_a * arr605_b + arr610_a * arr604_b + arr611_a * arr603_b + arr612_a * arr602_b + arr613_a * arr601_b + arr614_a * arr600_b + 1610 * arr615_a * arr617_b + 1610 * arr616_a * arr616_b + 1610 * arr617_a * arr615_b,
        arr600_a * arr615_b + arr601_a * arr614_b + arr602_a * arr613_b + arr603_a * arr612_b + arr604_a * arr611_b + arr605_a * arr610_b + arr606_a * arr607_b + arr607_a * arr606_b + arr610_a * arr605_b + arr611_a * arr604_b + arr612_a * arr603_b + arr613_a * arr602_b + arr614_a * arr601_b + arr615_a * arr600_b + 1610 * arr616_a * arr617_b + 1610 * arr617_a * arr616_b,
        arr600_a * arr616_b + arr601_a * arr615_b + arr602_a * arr614_b + arr603_a * arr613_b + arr604_a * arr612_b + arr605_a * arr611_b + arr606_a * arr610_b + arr607_a * arr607_b + arr610_a * arr606_b + arr611_a * arr605_b + arr612_a * arr604_b + arr613_a * arr603_b + arr614_a * arr602_b + arr615_a * arr601_b + arr616_a * arr600_b + 1610 * arr617_a * arr617_b,
        arr600_a * arr617_b + arr601_a * arr616_b + arr602_a * arr615_b + arr603_a * arr614_b + arr604_a * arr613_b + arr605_a * arr612_b + arr606_a * arr611_b + arr607_a * arr610_b + arr610_a * arr607_b + arr611_a * arr606_b + arr612_a * arr605_b + arr613_a * arr604_b + arr614_a * arr603_b + arr615_a * arr602_b + arr616_a * arr601_b + arr617_a * arr600_b
    ] ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] )

    prove with [cuts[0, 25, 26, 27]]
  &&
    [L0x7fffffe270, L0x7fffffe272, L0x7fffffe274, L0x7fffffe276, L0x7fffffe278, L0x7fffffe27a, L0x7fffffe27c, L0x7fffffe27e] = %v1 /\
    [L0x7fffffe280, L0x7fffffe282, L0x7fffffe284, L0x7fffffe286, L0x7fffffe288, L0x7fffffe28a, L0x7fffffe28c, L0x7fffffe28e] = %v0 /\

    %v1 <=s [3450@16, 3450@16, 3450@16, 3450@16, 3450@16, 3450@16, 3450@16, 3450@16] /\
    %v1 >=s [(-3450)@16, (-3450)@16, (-3450)@16, (-3450)@16, (-3450)@16, (-3450)@16, (-3450)@16, (-3450)@16] /\

    %v0 <=s [4580@16, 4580@16, 4580@16, 4580@16, 4580@16, 4580@16, 4580@16, 4580@16] /\
    %v0 >=s [(-4580)@16, (-4580)@16, (-4580)@16, (-4580)@16, (-4580)@16, (-4580)@16, (-4580)@16, (-4580)@16];


### i_iter prologue

(* ldr	q4, [x0, x3]                                #! EA = L0x7fffffe510; Value = 0x0000000000000000; PC = 0x5555551d34 *)
mov %v4 [L0x7fffffe510,L0x7fffffe512,L0x7fffffe514,L0x7fffffe516,L0x7fffffe518,L0x7fffffe51a,L0x7fffffe51c,L0x7fffffe51e];
(* ldr	q1, [x8, x3]                                #! EA = L0x7fffffe520; Value = 0x0000000000000000; PC = 0x5555551d38 *)
mov %v1 [L0x7fffffe520,L0x7fffffe522,L0x7fffffe524,L0x7fffffe526,L0x7fffffe528,L0x7fffffe52a,L0x7fffffe52c,L0x7fffffe52e];
(* ldr	q17, [x1, x3]                               #! EA = L0x7fffffe3d0; Value = 0x0000000000000000; PC = 0x5555551d3c *)
mov %v17 [L0x7fffffe3d0,L0x7fffffe3d2,L0x7fffffe3d4,L0x7fffffe3d6,L0x7fffffe3d8,L0x7fffffe3da,L0x7fffffe3dc,L0x7fffffe3de];
(* ldr	q18, [x7, x3]                               #! EA = L0x7fffffe3e0; Value = 0x0000000000000000; PC = 0x5555551d40 *)
mov %v18 [L0x7fffffe3e0,L0x7fffffe3e2,L0x7fffffe3e4,L0x7fffffe3e6,L0x7fffffe3e8,L0x7fffffe3ea,L0x7fffffe3ec,L0x7fffffe3ee];

ghost %fa0_7@sint16[8], %fa1_7@sint16[8], %fb0_7@sint16[8], %fb1_7@sint16[8] :
    %fa0_7 = %v4 /\ %fa1_7 = %v1 /\ %fb0_7 = %v17 /\ %fb1_7 = %v18
  &&
    %fa0_7 = %v4 /\ %fa1_7 = %v1 /\ %fb0_7 = %v17 /\ %fb1_7 = %v18;

cut (* 29 *)
    %fa0_7 = %v4 /\ %fa1_7 = %v1 /\ %fb0_7 = %v17 /\ %fb1_7 = %v18 /\
    %fa0_7 = [arr700_a, arr701_a, arr702_a, arr703_a, arr704_a, arr705_a, arr706_a, arr707_a] /\
    %fa1_7 = [arr710_a, arr711_a, arr712_a, arr713_a, arr714_a, arr715_a, arr716_a, arr717_a] /\
    %fb0_7 = [arr700_b, arr701_b, arr702_b, arr703_b, arr704_b, arr705_b, arr706_b, arr707_b] /\
    %fb1_7 = [arr710_b, arr711_b, arr712_b, arr713_b, arr714_b, arr715_b, arr716_b, arr717_b]
    prove with [cuts[0]]
  &&
    %fa0_7 = %v4 /\ %fa1_7 = %v1 /\ %fb0_7 = %v17 /\ %fb1_7 = %v18 /\
    %fa0_7 = [arr700_a, arr701_a, arr702_a, arr703_a, arr704_a, arr705_a, arr706_a, arr707_a] /\
    %fa1_7 = [arr710_a, arr711_a, arr712_a, arr713_a, arr714_a, arr715_a, arr716_a, arr717_a] /\
    %fb0_7 = [arr700_b, arr701_b, arr702_b, arr703_b, arr704_b, arr705_b, arr706_b, arr707_b] /\
    %fb1_7 = [arr710_b, arr711_b, arr712_b, arr713_b, arr714_b, arr715_b, arr716_b, arr717_b]
    prove with [cuts[0]];

#### karatsuba

(* ldr	q5, [x5]                                    #! EA = L0x5555552e70; Value = 0x07310102329a0717; PC = 0x5555551b44 *)
mov %v5 [L0x5555552e70,L0x5555552e72,L0x5555552e74,L0x5555552e76,L0x5555552e78,L0x5555552e7a,L0x5555552e7c,L0x5555552e7e];
(* sshr	v0.8h, v4.8h, #12                          #! PC = 0x5555551b48 *)
split %v0 %dc %v4 12;
(* cmlt	v2.8h, v4.8h, #0                           #! PC = 0x5555551b4c *)
split %v2 %dc %v4 15;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551b50 *)
sub %v0 %v0 %v2;
(* mls	v4.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551b54 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v4 %v4 %mls;

assert
    %fa0_7 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v4
    prove with [algebra solver isl, precondition, cuts[0, 29]]
    && true;

assume
    %fa0_7 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v4
    && true;

(* sshr	v0.8h, v1.8h, #12                          #! PC = 0x5555551b58 *)
split %v0 %dc %v1 12;
(* cmlt	v2.8h, v1.8h, #0                           #! PC = 0x5555551b5c *)
split %v2 %dc %v1 15;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551b60 *)
sub %v0 %v0 %v2;
(* mls	v1.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551b64 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v1 %v1 %mls;

assert
    %fa1_7 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v1
    prove with [algebra solver isl, precondition, cuts[0, 29]]
    && true;

assume
    %fa1_7 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v1
    && true;

(* sshr	v0.8h, v17.8h, #12                         #! PC = 0x5555551b68 *)
split %v0 %dc %v17 12;
(* cmlt	v2.8h, v17.8h, #0                          #! PC = 0x5555551b6c *)
split %v2 %dc %v17 15;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551b70 *)
sub %v0 %v0 %v2;
(* mls	v17.8h, v0.8h, v5.h[6]                      #! PC = 0x5555551b74 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v17 %v17 %mls;

assert
    %fb0_7 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v17
    prove with [algebra solver isl, precondition, cuts[0, 29]]
    && true;

assume
    %fb0_7 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v17
    && true;

(* sshr	v0.8h, v18.8h, #12                         #! PC = 0x5555551b78 *)
split %v0 %dc %v18 12;
(* cmlt	v2.8h, v18.8h, #0                          #! PC = 0x5555551b7c *)
split %v2 %dc %v18 15;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551b80 *)
sub %v0 %v0 %v2;
(* mls	v18.8h, v0.8h, v5.h[6]                      #! PC = 0x5555551b84 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v18 %v18 %mls;

assert
    %fb1_7 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v18
    prove with [algebra solver isl, precondition, cuts[0, 29]]
    && true;

assume
    %fb1_7 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v18
    && true;

ghost %fc0_7@sint16[8], %fc1_7@sint16[8], %fd0_7@sint16[8], %fd1_7@sint16[8] :
    %fc0_7 = %v4 /\ %fc1_7 = %v1 /\ %fd0_7 = %v17 /\ %fd1_7 = %v18
  &&
    %fc0_7 = %v4 /\ %fc1_7 = %v1 /\ %fd0_7 = %v17 /\ %fd1_7 = %v18;

(* sqrdmulh	v0.8h, v17.8h, v5.h[1]                 #! PC = 0x5555551b88 *)
broadcast %mul 8 [%v5[1]]; smulj %LO %v17 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v0 %LO11 %LO01;
(* mul	v6.8h, v17.8h, v5.h[0]                      #! PC = 0x5555551b8c *)
broadcast %mul 8 [%v5[0]]; mull %dc %v6 %v17 %mul; cast %v6@int16[8] %v6;
(* mov	v7.16b, v6.16b                              #! PC = 0x5555551b90 *)
mov %v7 %v6;
(* mls	v7.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551b94 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v7 %v7 %mls;

assert
    [1815, 1815, 1815, 1815, 1815, 1815, 1815, 1815] * %fd0_7
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v7
    prove with [algebra solver isl, precondition, cuts[0, 29]]
    && true;

assume
    [1815, 1815, 1815, 1815, 1815, 1815, 1815, 1815] * %fd0_7
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v7
    && true;

(* sqrdmulh	v0.8h, v18.8h, v5.h[1]                 #! PC = 0x5555551b98 *)
broadcast %mul 8 [%v5[1]]; smulj %LO %v18 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v0 %LO11 %LO01;
(* mul	v3.8h, v18.8h, v5.h[0]                      #! PC = 0x5555551b9c *)
broadcast %mul 8 [%v5[0]]; mull %dc %v3 %v18 %mul; cast %v3@int16[8] %v3;
(* mls	v3.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551ba0 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v3 %v3 %mls;

assert
    [1815, 1815, 1815, 1815, 1815, 1815, 1815, 1815] * %fd1_7
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v3
    prove with [algebra solver isl, precondition, cuts[0, 29]]
    && true;

assume
    [1815, 1815, 1815, 1815, 1815, 1815, 1815, 1815] * %fd1_7
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v3
    && true;

ghost %fe0_7@sint16[8], %fe1_7@sint16[8] :
    %fe0_7 = %v7 /\ %fe1_7 = %v3
  &&
    %fe0_7 = %v7 /\ %fe1_7 = %v3;

cut (* 30 *)
    %fc0_7 = %v4 /\ %fc1_7 = %v1 /\ %fd0_7 = %v17 /\ %fd1_7 = %v18 /\ %fe0_7 = %v7 /\ %fe1_7 = %v3 /\

    %fc0_7 = %fa0_7 ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\
    %fc1_7 = %fa1_7 ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\
    %fd0_7 = %fb0_7 ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\
    %fd1_7 = %fb1_7 ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\

    %fe0_7 = [1815, 1815, 1815, 1815, 1815, 1815, 1815, 1815] * %fd0_7
    ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\

    %fe1_7 = [1815, 1815, 1815, 1815, 1815, 1815, 1815, 1815] * %fd1_7
    ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ),

    %fc0_7 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %fc0_7 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %fc1_7 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %fc1_7 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %fd0_7 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %fd0_7 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %fd1_7 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %fd1_7 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %fe0_7 <= [3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000] /\
    %fe0_7 >= [-3000, -3000, -3000, -3000, -3000, -3000, -3000, -3000] /\

    %fe1_7 <= [3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000] /\
    %fe1_7 >= [-3000, -3000, -3000, -3000, -3000, -3000, -3000, -3000]

    prove with [algebra solver isl, precondition, cuts[0, 29]]
  &&
    true
    prove with [precondition, cuts[0, 29]];

assert
    %v4 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %v4 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %v1 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %v1 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %v17 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %v17 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %v18 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %v18 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %v7 <= [3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000] /\
    %v7 >= [-3000, -3000, -3000, -3000, -3000, -3000, -3000, -3000] /\

    %v3 <= [3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000] /\
    %v3 >= [-3000, -3000, -3000, -3000, -3000, -3000, -3000, -3000]

    prove with [algebra solver isl, cuts[30]]
    && true;

assume
    true &&
    %v4 <=s [4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16] /\
    %v4 >=s [(-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16] /\

    %v1 <=s [4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16] /\
    %v1 >=s [(-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16] /\

    %v17 <=s [4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16] /\
    %v17 >=s [(-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16] /\

    %v18 <=s [4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16] /\
    %v18 >=s [(-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16] /\

    %v7 <=s [3000@16, 3000@16, 3000@16, 3000@16, 3000@16, 3000@16, 3000@16, 3000@16] /\
    %v7 >=s [(-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16] /\

    %v3 <=s [3000@16, 3000@16, 3000@16, 3000@16, 3000@16, 3000@16, 3000@16, 3000@16] /\
    %v3 >=s [(-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16];

(* add	v6.8h, v4.8h, v1.8h                         #! PC = 0x5555551ba4 *)
add %v6 %v4 %v1;
(* smull	v0.4s, v17.4h, v6.h[0]                    #! PC = 0x5555551ba8 *)
broadcast %mull 4 [%v6[0]]; smulj %v0 [%v17[0],%v17[1],%v17[2],%v17[3]] %mull;
(* smull2	v2.4s, v17.8h, v6.h[0]                   #! PC = 0x5555551bac *)
broadcast %mull 4 [%v6[0]]; smulj %v2 [%v17[4],%v17[5],%v17[6],%v17[7]] %mull;
(* ext	v16.16b, v3.16b, v17.16b, #14               #! PC = 0x5555551bb0 *)
mov %v16 [%v3[7],%v17[0],%v17[1],%v17[2],%v17[3],%v17[4],%v17[5],%v17[6]];
(* smlal	v0.4s, v16.4h, v6.h[1]                    #! PC = 0x5555551bb4 *)
broadcast %mull 4 [%v6[1]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[1]                   #! PC = 0x5555551bb8 *)
broadcast %mull 4 [%v6[1]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v16.16b, v3.16b, v17.16b, #12               #! PC = 0x5555551bbc *)
mov %v16 [%v3[6],%v3[7],%v17[0],%v17[1],%v17[2],%v17[3],%v17[4],%v17[5]];
(* smlal	v0.4s, v16.4h, v6.h[2]                    #! PC = 0x5555551bc0 *)
broadcast %mull 4 [%v6[2]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[2]                   #! PC = 0x5555551bc4 *)
broadcast %mull 4 [%v6[2]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v16.16b, v3.16b, v17.16b, #10               #! PC = 0x5555551bc8 *)
mov %v16 [%v3[5],%v3[6],%v3[7],%v17[0],%v17[1],%v17[2],%v17[3],%v17[4]];
(* smlal	v0.4s, v16.4h, v6.h[3]                    #! PC = 0x5555551bcc *)
broadcast %mull 4 [%v6[3]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[3]                   #! PC = 0x5555551bd0 *)
broadcast %mull 4 [%v6[3]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v16.16b, v3.16b, v17.16b, #8                #! PC = 0x5555551bd4 *)
mov %v16 [%v3[4],%v3[5],%v3[6],%v3[7],%v17[0],%v17[1],%v17[2],%v17[3]];
(* smlal	v0.4s, v16.4h, v6.h[4]                    #! PC = 0x5555551bd8 *)
broadcast %mull 4 [%v6[4]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[4]                   #! PC = 0x5555551bdc *)
broadcast %mull 4 [%v6[4]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v16.16b, v3.16b, v17.16b, #6                #! PC = 0x5555551be0 *)
mov %v16 [%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v17[0],%v17[1],%v17[2]];
(* smlal	v0.4s, v16.4h, v6.h[5]                    #! PC = 0x5555551be4 *)
broadcast %mull 4 [%v6[5]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[5]                   #! PC = 0x5555551be8 *)
broadcast %mull 4 [%v6[5]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v16.16b, v3.16b, v17.16b, #4                #! PC = 0x5555551bec *)
mov %v16 [%v3[2],%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v17[0],%v17[1]];
(* smlal	v0.4s, v16.4h, v6.h[6]                    #! PC = 0x5555551bf0 *)
broadcast %mull 4 [%v6[6]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[6]                   #! PC = 0x5555551bf4 *)
broadcast %mull 4 [%v6[6]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v16.16b, v3.16b, v17.16b, #2                #! PC = 0x5555551bf8 *)
mov %v16 [%v3[1],%v3[2],%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v17[0]];
(* smlal	v0.4s, v16.4h, v6.h[7]                    #! PC = 0x5555551bfc *)
broadcast %mull 4 [%v6[7]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[7]                   #! PC = 0x5555551c00 *)
broadcast %mull 4 [%v6[7]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* sub	v6.8h, v7.8h, v3.8h                         #! PC = 0x5555551c04 *)
sub %v6 %v7 %v3;
(* sub	v3.8h, v3.8h, v17.8h                        #! PC = 0x5555551c08 *)
sub %v3 %v3 %v17;
(* mov	v16.16b, v0.16b                             #! PC = 0x5555551c0c *)
mov %v16 %v0;
(* smlal	v16.4s, v3.4h, v1.h[0]                    #! PC = 0x5555551c10 *)
broadcast %mull 4 [%v1[0]]; smulj %mlal [%v3[0],%v3[1],%v3[2],%v3[3]] %mull; adds %dc %v16 %v16 %mlal;
(* mov	v7.16b, v2.16b                              #! PC = 0x5555551c14 *)
mov %v7 %v2;
(* smlal2	v7.4s, v3.8h, v1.h[0]                    #! PC = 0x5555551c18 *)
broadcast %mull 4 [%v1[0]]; smulj %mlal [%v3[4],%v3[5],%v3[6],%v3[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v19.16b, v6.16b, v3.16b, #14                #! PC = 0x5555551c1c *)
mov %v19 [%v6[7],%v3[0],%v3[1],%v3[2],%v3[3],%v3[4],%v3[5],%v3[6]];
(* smlal	v16.4s, v19.4h, v1.h[1]                   #! PC = 0x5555551c20 *)
broadcast %mull 4 [%v1[1]]; smulj %mlal [%v19[0],%v19[1],%v19[2],%v19[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v19.8h, v1.h[1]                   #! PC = 0x5555551c24 *)
broadcast %mull 4 [%v1[1]]; smulj %mlal [%v19[4],%v19[5],%v19[6],%v19[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v19.16b, v6.16b, v3.16b, #12                #! PC = 0x5555551c28 *)
mov %v19 [%v6[6],%v6[7],%v3[0],%v3[1],%v3[2],%v3[3],%v3[4],%v3[5]];
(* smlal	v16.4s, v19.4h, v1.h[2]                   #! PC = 0x5555551c2c *)
broadcast %mull 4 [%v1[2]]; smulj %mlal [%v19[0],%v19[1],%v19[2],%v19[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v19.8h, v1.h[2]                   #! PC = 0x5555551c30 *)
broadcast %mull 4 [%v1[2]]; smulj %mlal [%v19[4],%v19[5],%v19[6],%v19[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v19.16b, v6.16b, v3.16b, #10                #! PC = 0x5555551c34 *)
mov %v19 [%v6[5],%v6[6],%v6[7],%v3[0],%v3[1],%v3[2],%v3[3],%v3[4]];
(* smlal	v16.4s, v19.4h, v1.h[3]                   #! PC = 0x5555551c38 *)
broadcast %mull 4 [%v1[3]]; smulj %mlal [%v19[0],%v19[1],%v19[2],%v19[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v19.8h, v1.h[3]                   #! PC = 0x5555551c3c *)
broadcast %mull 4 [%v1[3]]; smulj %mlal [%v19[4],%v19[5],%v19[6],%v19[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v19.16b, v6.16b, v3.16b, #8                 #! PC = 0x5555551c40 *)
mov %v19 [%v6[4],%v6[5],%v6[6],%v6[7],%v3[0],%v3[1],%v3[2],%v3[3]];
(* smlal	v16.4s, v19.4h, v1.h[4]                   #! PC = 0x5555551c44 *)
broadcast %mull 4 [%v1[4]]; smulj %mlal [%v19[0],%v19[1],%v19[2],%v19[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v19.8h, v1.h[4]                   #! PC = 0x5555551c48 *)
broadcast %mull 4 [%v1[4]]; smulj %mlal [%v19[4],%v19[5],%v19[6],%v19[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v19.16b, v6.16b, v3.16b, #6                 #! PC = 0x5555551c4c *)
mov %v19 [%v6[3],%v6[4],%v6[5],%v6[6],%v6[7],%v3[0],%v3[1],%v3[2]];
(* smlal	v16.4s, v19.4h, v1.h[5]                   #! PC = 0x5555551c50 *)
broadcast %mull 4 [%v1[5]]; smulj %mlal [%v19[0],%v19[1],%v19[2],%v19[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v19.8h, v1.h[5]                   #! PC = 0x5555551c54 *)
broadcast %mull 4 [%v1[5]]; smulj %mlal [%v19[4],%v19[5],%v19[6],%v19[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v19.16b, v6.16b, v3.16b, #4                 #! PC = 0x5555551c58 *)
mov %v19 [%v6[2],%v6[3],%v6[4],%v6[5],%v6[6],%v6[7],%v3[0],%v3[1]];
(* smlal	v16.4s, v19.4h, v1.h[6]                   #! PC = 0x5555551c5c *)
broadcast %mull 4 [%v1[6]]; smulj %mlal [%v19[0],%v19[1],%v19[2],%v19[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v19.8h, v1.h[6]                   #! PC = 0x5555551c60 *)
broadcast %mull 4 [%v1[6]]; smulj %mlal [%v19[4],%v19[5],%v19[6],%v19[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v6.16b, v6.16b, v3.16b, #2                  #! PC = 0x5555551c64 *)
mov %v6 [%v6[1],%v6[2],%v6[3],%v6[4],%v6[5],%v6[6],%v6[7],%v3[0]];
(* smlal	v16.4s, v6.4h, v1.h[7]                    #! PC = 0x5555551c68 *)
broadcast %mull 4 [%v1[7]]; smulj %mlal [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v6.8h, v1.h[7]                    #! PC = 0x5555551c6c *)
broadcast %mull 4 [%v1[7]]; smulj %mlal [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; adds %dc %v7 %v7 %mlal;
(* sub	v1.8h, v17.8h, v18.8h                       #! PC = 0x5555551c70 *)
sub %v1 %v17 %v18;
(* smlsl	v0.4s, v1.4h, v4.h[0]                     #! PC = 0x5555551c74 *)
broadcast %mull 4 [%v4[0]]; smulj %mlsl [%v1[0],%v1[1],%v1[2],%v1[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v1.8h, v4.h[0]                    #! PC = 0x5555551c78 *)
broadcast %mull 4 [%v4[0]]; smulj %mlsl [%v1[4],%v1[5],%v1[6],%v1[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v6.16b, v3.16b, v1.16b, #14                 #! PC = 0x5555551c7c *)
mov %v6 [%v3[7],%v1[0],%v1[1],%v1[2],%v1[3],%v1[4],%v1[5],%v1[6]];
(* smlsl	v0.4s, v6.4h, v4.h[1]                     #! PC = 0x5555551c80 *)
broadcast %mull 4 [%v4[1]]; smulj %mlsl [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v6.8h, v4.h[1]                    #! PC = 0x5555551c84 *)
broadcast %mull 4 [%v4[1]]; smulj %mlsl [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v6.16b, v3.16b, v1.16b, #12                 #! PC = 0x5555551c88 *)
mov %v6 [%v3[6],%v3[7],%v1[0],%v1[1],%v1[2],%v1[3],%v1[4],%v1[5]];
(* smlsl	v0.4s, v6.4h, v4.h[2]                     #! PC = 0x5555551c8c *)
broadcast %mull 4 [%v4[2]]; smulj %mlsl [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v6.8h, v4.h[2]                    #! PC = 0x5555551c90 *)
broadcast %mull 4 [%v4[2]]; smulj %mlsl [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v6.16b, v3.16b, v1.16b, #10                 #! PC = 0x5555551c94 *)
mov %v6 [%v3[5],%v3[6],%v3[7],%v1[0],%v1[1],%v1[2],%v1[3],%v1[4]];
(* smlsl	v0.4s, v6.4h, v4.h[3]                     #! PC = 0x5555551c98 *)
broadcast %mull 4 [%v4[3]]; smulj %mlsl [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v6.8h, v4.h[3]                    #! PC = 0x5555551c9c *)
broadcast %mull 4 [%v4[3]]; smulj %mlsl [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v6.16b, v3.16b, v1.16b, #8                  #! PC = 0x5555551ca0 *)
mov %v6 [%v3[4],%v3[5],%v3[6],%v3[7],%v1[0],%v1[1],%v1[2],%v1[3]];
(* smlsl	v0.4s, v6.4h, v4.h[4]                     #! PC = 0x5555551ca4 *)
broadcast %mull 4 [%v4[4]]; smulj %mlsl [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v6.8h, v4.h[4]                    #! PC = 0x5555551ca8 *)
broadcast %mull 4 [%v4[4]]; smulj %mlsl [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v6.16b, v3.16b, v1.16b, #6                  #! PC = 0x5555551cac *)
mov %v6 [%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v1[0],%v1[1],%v1[2]];
(* smlsl	v0.4s, v6.4h, v4.h[5]                     #! PC = 0x5555551cb0 *)
broadcast %mull 4 [%v4[5]]; smulj %mlsl [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v6.8h, v4.h[5]                    #! PC = 0x5555551cb4 *)
broadcast %mull 4 [%v4[5]]; smulj %mlsl [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v6.16b, v3.16b, v1.16b, #4                  #! PC = 0x5555551cb8 *)
mov %v6 [%v3[2],%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v1[0],%v1[1]];
(* smlsl	v0.4s, v6.4h, v4.h[6]                     #! PC = 0x5555551cbc *)
broadcast %mull 4 [%v4[6]]; smulj %mlsl [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v6.8h, v4.h[6]                    #! PC = 0x5555551cc0 *)
broadcast %mull 4 [%v4[6]]; smulj %mlsl [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v3.16b, v3.16b, v1.16b, #2                  #! PC = 0x5555551cc4 *)
mov %v3 [%v3[1],%v3[2],%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v1[0]];
(* smlsl	v0.4s, v3.4h, v4.h[7]                     #! PC = 0x5555551cc8 *)
broadcast %mull 4 [%v4[7]]; smulj %mlsl [%v3[0],%v3[1],%v3[2],%v3[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v3.8h, v4.h[7]                    #! PC = 0x5555551ccc *)
broadcast %mull 4 [%v4[7]]; smulj %mlsl [%v3[4],%v3[5],%v3[6],%v3[7]] %mull; subc %dc %v2 %v2 %mlsl;

ghost %conv0_7@sint32[8], %conv1_7@sint32[8] :
    %conv0_7 = [
        %fc0_7[0] * %fd0_7[0] + %fc0_7[1] * %fe1_7[7] + %fc0_7[2] * %fe1_7[6] + %fc0_7[3] * %fe1_7[5] + %fc0_7[4] * %fe1_7[4] + %fc0_7[5] * %fe1_7[3] + %fc0_7[6] * %fe1_7[2] + %fc0_7[7] * %fe1_7[1] +
        %fc1_7[0] * %fe1_7[0] + %fc1_7[1] * %fe0_7[7] + %fc1_7[2] * %fe0_7[6] + %fc1_7[3] * %fe0_7[5] + %fc1_7[4] * %fe0_7[4] + %fc1_7[5] * %fe0_7[3] + %fc1_7[6] * %fe0_7[2] + %fc1_7[7] * %fe0_7[1],
        %fc0_7[0] * %fd0_7[1] + %fc0_7[1] * %fd0_7[0] + %fc0_7[2] * %fe1_7[7] + %fc0_7[3] * %fe1_7[6] + %fc0_7[4] * %fe1_7[5] + %fc0_7[5] * %fe1_7[4] + %fc0_7[6] * %fe1_7[3] + %fc0_7[7] * %fe1_7[2] +
        %fc1_7[0] * %fe1_7[1] + %fc1_7[1] * %fe1_7[0] + %fc1_7[2] * %fe0_7[7] + %fc1_7[3] * %fe0_7[6] + %fc1_7[4] * %fe0_7[5] + %fc1_7[5] * %fe0_7[4] + %fc1_7[6] * %fe0_7[3] + %fc1_7[7] * %fe0_7[2],
        %fc0_7[0] * %fd0_7[2] + %fc0_7[1] * %fd0_7[1] + %fc0_7[2] * %fd0_7[0] + %fc0_7[3] * %fe1_7[7] + %fc0_7[4] * %fe1_7[6] + %fc0_7[5] * %fe1_7[5] + %fc0_7[6] * %fe1_7[4] + %fc0_7[7] * %fe1_7[3] +
        %fc1_7[0] * %fe1_7[2] + %fc1_7[1] * %fe1_7[1] + %fc1_7[2] * %fe1_7[0] + %fc1_7[3] * %fe0_7[7] + %fc1_7[4] * %fe0_7[6] + %fc1_7[5] * %fe0_7[5] + %fc1_7[6] * %fe0_7[4] + %fc1_7[7] * %fe0_7[3],
        %fc0_7[0] * %fd0_7[3] + %fc0_7[1] * %fd0_7[2] + %fc0_7[2] * %fd0_7[1] + %fc0_7[3] * %fd0_7[0] + %fc0_7[4] * %fe1_7[7] + %fc0_7[5] * %fe1_7[6] + %fc0_7[6] * %fe1_7[5] + %fc0_7[7] * %fe1_7[4] +
        %fc1_7[0] * %fe1_7[3] + %fc1_7[1] * %fe1_7[2] + %fc1_7[2] * %fe1_7[1] + %fc1_7[3] * %fe1_7[0] + %fc1_7[4] * %fe0_7[7] + %fc1_7[5] * %fe0_7[6] + %fc1_7[6] * %fe0_7[5] + %fc1_7[7] * %fe0_7[4],
        %fc0_7[0] * %fd0_7[4] + %fc0_7[1] * %fd0_7[3] + %fc0_7[2] * %fd0_7[2] + %fc0_7[3] * %fd0_7[1] + %fc0_7[4] * %fd0_7[0] + %fc0_7[5] * %fe1_7[7] + %fc0_7[6] * %fe1_7[6] + %fc0_7[7] * %fe1_7[5] +
        %fc1_7[0] * %fe1_7[4] + %fc1_7[1] * %fe1_7[3] + %fc1_7[2] * %fe1_7[2] + %fc1_7[3] * %fe1_7[1] + %fc1_7[4] * %fe1_7[0] + %fc1_7[5] * %fe0_7[7] + %fc1_7[6] * %fe0_7[6] + %fc1_7[7] * %fe0_7[5],
        %fc0_7[0] * %fd0_7[5] + %fc0_7[1] * %fd0_7[4] + %fc0_7[2] * %fd0_7[3] + %fc0_7[3] * %fd0_7[2] + %fc0_7[4] * %fd0_7[1] + %fc0_7[5] * %fd0_7[0] + %fc0_7[6] * %fe1_7[7] + %fc0_7[7] * %fe1_7[6] +
        %fc1_7[0] * %fe1_7[5] + %fc1_7[1] * %fe1_7[4] + %fc1_7[2] * %fe1_7[3] + %fc1_7[3] * %fe1_7[2] + %fc1_7[4] * %fe1_7[1] + %fc1_7[5] * %fe1_7[0] + %fc1_7[6] * %fe0_7[7] + %fc1_7[7] * %fe0_7[6],
        %fc0_7[0] * %fd0_7[6] + %fc0_7[1] * %fd0_7[5] + %fc0_7[2] * %fd0_7[4] + %fc0_7[3] * %fd0_7[3] + %fc0_7[4] * %fd0_7[2] + %fc0_7[5] * %fd0_7[1] + %fc0_7[6] * %fd0_7[0] + %fc0_7[7] * %fe1_7[7] +
        %fc1_7[0] * %fe1_7[6] + %fc1_7[1] * %fe1_7[5] + %fc1_7[2] * %fe1_7[4] + %fc1_7[3] * %fe1_7[3] + %fc1_7[4] * %fe1_7[2] + %fc1_7[5] * %fe1_7[1] + %fc1_7[6] * %fe1_7[0] + %fc1_7[7] * %fe0_7[7],
        %fc0_7[0] * %fd0_7[7] + %fc0_7[1] * %fd0_7[6] + %fc0_7[2] * %fd0_7[5] + %fc0_7[3] * %fd0_7[4] + %fc0_7[4] * %fd0_7[3] + %fc0_7[5] * %fd0_7[2] + %fc0_7[6] * %fd0_7[1] + %fc0_7[7] * %fd0_7[0] +
        %fc1_7[0] * %fe1_7[7] + %fc1_7[1] * %fe1_7[6] + %fc1_7[2] * %fe1_7[5] + %fc1_7[3] * %fe1_7[4] + %fc1_7[4] * %fe1_7[3] + %fc1_7[5] * %fe1_7[2] + %fc1_7[6] * %fe1_7[1] + %fc1_7[7] * %fe1_7[0]
    ] /\
    %conv1_7 = [
        %fc0_7[0] * %fd1_7[0] + %fc0_7[1] * %fd0_7[7] + %fc0_7[2] * %fd0_7[6] + %fc0_7[3] * %fd0_7[5] + %fc0_7[4] * %fd0_7[4] + %fc0_7[5] * %fd0_7[3] + %fc0_7[6] * %fd0_7[2] + %fc0_7[7] * %fd0_7[1] +
        %fc1_7[0] * %fd0_7[0] + %fc1_7[1] * %fe1_7[7] + %fc1_7[2] * %fe1_7[6] + %fc1_7[3] * %fe1_7[5] + %fc1_7[4] * %fe1_7[4] + %fc1_7[5] * %fe1_7[3] + %fc1_7[6] * %fe1_7[2] + %fc1_7[7] * %fe1_7[1],
        %fc0_7[0] * %fd1_7[1] + %fc0_7[1] * %fd1_7[0] + %fc0_7[2] * %fd0_7[7] + %fc0_7[3] * %fd0_7[6] + %fc0_7[4] * %fd0_7[5] + %fc0_7[5] * %fd0_7[4] + %fc0_7[6] * %fd0_7[3] + %fc0_7[7] * %fd0_7[2] +
        %fc1_7[0] * %fd0_7[1] + %fc1_7[1] * %fd0_7[0] + %fc1_7[2] * %fe1_7[7] + %fc1_7[3] * %fe1_7[6] + %fc1_7[4] * %fe1_7[5] + %fc1_7[5] * %fe1_7[4] + %fc1_7[6] * %fe1_7[3] + %fc1_7[7] * %fe1_7[2],
        %fc0_7[0] * %fd1_7[2] + %fc0_7[1] * %fd1_7[1] + %fc0_7[2] * %fd1_7[0] + %fc0_7[3] * %fd0_7[7] + %fc0_7[4] * %fd0_7[6] + %fc0_7[5] * %fd0_7[5] + %fc0_7[6] * %fd0_7[4] + %fc0_7[7] * %fd0_7[3] +
        %fc1_7[0] * %fd0_7[2] + %fc1_7[1] * %fd0_7[1] + %fc1_7[2] * %fd0_7[0] + %fc1_7[3] * %fe1_7[7] + %fc1_7[4] * %fe1_7[6] + %fc1_7[5] * %fe1_7[5] + %fc1_7[6] * %fe1_7[4] + %fc1_7[7] * %fe1_7[3],
        %fc0_7[0] * %fd1_7[3] + %fc0_7[1] * %fd1_7[2] + %fc0_7[2] * %fd1_7[1] + %fc0_7[3] * %fd1_7[0] + %fc0_7[4] * %fd0_7[7] + %fc0_7[5] * %fd0_7[6] + %fc0_7[6] * %fd0_7[5] + %fc0_7[7] * %fd0_7[4] +
        %fc1_7[0] * %fd0_7[3] + %fc1_7[1] * %fd0_7[2] + %fc1_7[2] * %fd0_7[1] + %fc1_7[3] * %fd0_7[0] + %fc1_7[4] * %fe1_7[7] + %fc1_7[5] * %fe1_7[6] + %fc1_7[6] * %fe1_7[5] + %fc1_7[7] * %fe1_7[4],
        %fc0_7[0] * %fd1_7[4] + %fc0_7[1] * %fd1_7[3] + %fc0_7[2] * %fd1_7[2] + %fc0_7[3] * %fd1_7[1] + %fc0_7[4] * %fd1_7[0] + %fc0_7[5] * %fd0_7[7] + %fc0_7[6] * %fd0_7[6] + %fc0_7[7] * %fd0_7[5] +
        %fc1_7[0] * %fd0_7[4] + %fc1_7[1] * %fd0_7[3] + %fc1_7[2] * %fd0_7[2] + %fc1_7[3] * %fd0_7[1] + %fc1_7[4] * %fd0_7[0] + %fc1_7[5] * %fe1_7[7] + %fc1_7[6] * %fe1_7[6] + %fc1_7[7] * %fe1_7[5],
        %fc0_7[0] * %fd1_7[5] + %fc0_7[1] * %fd1_7[4] + %fc0_7[2] * %fd1_7[3] + %fc0_7[3] * %fd1_7[2] + %fc0_7[4] * %fd1_7[1] + %fc0_7[5] * %fd1_7[0] + %fc0_7[6] * %fd0_7[7] + %fc0_7[7] * %fd0_7[6] +
        %fc1_7[0] * %fd0_7[5] + %fc1_7[1] * %fd0_7[4] + %fc1_7[2] * %fd0_7[3] + %fc1_7[3] * %fd0_7[2] + %fc1_7[4] * %fd0_7[1] + %fc1_7[5] * %fd0_7[0] + %fc1_7[6] * %fe1_7[7] + %fc1_7[7] * %fe1_7[6],
        %fc0_7[0] * %fd1_7[6] + %fc0_7[1] * %fd1_7[5] + %fc0_7[2] * %fd1_7[4] + %fc0_7[3] * %fd1_7[3] + %fc0_7[4] * %fd1_7[2] + %fc0_7[5] * %fd1_7[1] + %fc0_7[6] * %fd1_7[0] + %fc0_7[7] * %fd0_7[7] +
        %fc1_7[0] * %fd0_7[6] + %fc1_7[1] * %fd0_7[5] + %fc1_7[2] * %fd0_7[4] + %fc1_7[3] * %fd0_7[3] + %fc1_7[4] * %fd0_7[2] + %fc1_7[5] * %fd0_7[1] + %fc1_7[6] * %fd0_7[0] + %fc1_7[7] * %fe1_7[7],
        %fc0_7[0] * %fd1_7[7] + %fc0_7[1] * %fd1_7[6] + %fc0_7[2] * %fd1_7[5] + %fc0_7[3] * %fd1_7[4] + %fc0_7[4] * %fd1_7[3] + %fc0_7[5] * %fd1_7[2] + %fc0_7[6] * %fd1_7[1] + %fc0_7[7] * %fd1_7[0] +
        %fc1_7[0] * %fd0_7[7] + %fc1_7[1] * %fd0_7[6] + %fc1_7[2] * %fd0_7[5] + %fc1_7[3] * %fd0_7[4] + %fc1_7[4] * %fd0_7[3] + %fc1_7[5] * %fd0_7[2] + %fc1_7[6] * %fd0_7[1] + %fc1_7[7] * %fd0_7[0]
    ]
    && true;

assert
    %v16 ++ %v7 = %conv0_7 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] ) /\
    %v0 ++ %v2 = %conv1_7 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] )
    && true;

assume
    %v16 ++ %v7 = %conv0_7 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] ) /\
    %v0 ++ %v2 = %conv1_7 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] )
    && true;

assert
    %conv0_7 <= [268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456] /\
    %conv0_7 >= [-268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456] /\

    %conv1_7 <= [268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456] /\
    %conv1_7 >= [-268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456]
    prove with [algebra solver smt: z3]
    && true;

assume
    %conv0_7 <= [268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456] /\
    %conv0_7 >= [-268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456] /\

    %conv1_7 <= [268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456] /\
    %conv1_7 >= [-268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456]
    && true;

assert
    %v16 ++ %v7 = %conv0_7 /\ %v0 ++ %v2 = %conv1_7
    prove with [algebra solver isl]
    && true;

assume
    %v16 ++ %v7 = %conv0_7 /\ %v0 ++ %v2 = %conv1_7
    && true;

assert
    %v16 <= [268435456, 268435456, 268435456, 268435456] /\
    %v16 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v7 <= [268435456, 268435456, 268435456, 268435456] /\
    %v7 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v0 <= [268435456, 268435456, 268435456, 268435456] /\
    %v0 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v2 <= [268435456, 268435456, 268435456, 268435456] /\
    %v2 >= [-268435456, -268435456, -268435456, -268435456]

    prove with [algebra solver isl]
    && true;

assume
    %v16 <= [268435456, 268435456, 268435456, 268435456] /\
    %v16 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v7 <= [268435456, 268435456, 268435456, 268435456] /\
    %v7 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v0 <= [268435456, 268435456, 268435456, 268435456] /\
    %v0 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v2 <= [268435456, 268435456, 268435456, 268435456] /\
    %v2 >= [-268435456, -268435456, -268435456, -268435456]
  &&
    %v16 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v16 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32] /\

    %v7 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v7 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32] /\

    %v0 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v0 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32] /\

    %v2 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v2 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32];

cut (* 31 *)
    %conv0_7 = [
        %fc0_7[0] * %fd0_7[0] + %fc0_7[1] * %fe1_7[7] + %fc0_7[2] * %fe1_7[6] + %fc0_7[3] * %fe1_7[5] + %fc0_7[4] * %fe1_7[4] + %fc0_7[5] * %fe1_7[3] + %fc0_7[6] * %fe1_7[2] + %fc0_7[7] * %fe1_7[1] +
        %fc1_7[0] * %fe1_7[0] + %fc1_7[1] * %fe0_7[7] + %fc1_7[2] * %fe0_7[6] + %fc1_7[3] * %fe0_7[5] + %fc1_7[4] * %fe0_7[4] + %fc1_7[5] * %fe0_7[3] + %fc1_7[6] * %fe0_7[2] + %fc1_7[7] * %fe0_7[1],
        %fc0_7[0] * %fd0_7[1] + %fc0_7[1] * %fd0_7[0] + %fc0_7[2] * %fe1_7[7] + %fc0_7[3] * %fe1_7[6] + %fc0_7[4] * %fe1_7[5] + %fc0_7[5] * %fe1_7[4] + %fc0_7[6] * %fe1_7[3] + %fc0_7[7] * %fe1_7[2] +
        %fc1_7[0] * %fe1_7[1] + %fc1_7[1] * %fe1_7[0] + %fc1_7[2] * %fe0_7[7] + %fc1_7[3] * %fe0_7[6] + %fc1_7[4] * %fe0_7[5] + %fc1_7[5] * %fe0_7[4] + %fc1_7[6] * %fe0_7[3] + %fc1_7[7] * %fe0_7[2],
        %fc0_7[0] * %fd0_7[2] + %fc0_7[1] * %fd0_7[1] + %fc0_7[2] * %fd0_7[0] + %fc0_7[3] * %fe1_7[7] + %fc0_7[4] * %fe1_7[6] + %fc0_7[5] * %fe1_7[5] + %fc0_7[6] * %fe1_7[4] + %fc0_7[7] * %fe1_7[3] +
        %fc1_7[0] * %fe1_7[2] + %fc1_7[1] * %fe1_7[1] + %fc1_7[2] * %fe1_7[0] + %fc1_7[3] * %fe0_7[7] + %fc1_7[4] * %fe0_7[6] + %fc1_7[5] * %fe0_7[5] + %fc1_7[6] * %fe0_7[4] + %fc1_7[7] * %fe0_7[3],
        %fc0_7[0] * %fd0_7[3] + %fc0_7[1] * %fd0_7[2] + %fc0_7[2] * %fd0_7[1] + %fc0_7[3] * %fd0_7[0] + %fc0_7[4] * %fe1_7[7] + %fc0_7[5] * %fe1_7[6] + %fc0_7[6] * %fe1_7[5] + %fc0_7[7] * %fe1_7[4] +
        %fc1_7[0] * %fe1_7[3] + %fc1_7[1] * %fe1_7[2] + %fc1_7[2] * %fe1_7[1] + %fc1_7[3] * %fe1_7[0] + %fc1_7[4] * %fe0_7[7] + %fc1_7[5] * %fe0_7[6] + %fc1_7[6] * %fe0_7[5] + %fc1_7[7] * %fe0_7[4],
        %fc0_7[0] * %fd0_7[4] + %fc0_7[1] * %fd0_7[3] + %fc0_7[2] * %fd0_7[2] + %fc0_7[3] * %fd0_7[1] + %fc0_7[4] * %fd0_7[0] + %fc0_7[5] * %fe1_7[7] + %fc0_7[6] * %fe1_7[6] + %fc0_7[7] * %fe1_7[5] +
        %fc1_7[0] * %fe1_7[4] + %fc1_7[1] * %fe1_7[3] + %fc1_7[2] * %fe1_7[2] + %fc1_7[3] * %fe1_7[1] + %fc1_7[4] * %fe1_7[0] + %fc1_7[5] * %fe0_7[7] + %fc1_7[6] * %fe0_7[6] + %fc1_7[7] * %fe0_7[5],
        %fc0_7[0] * %fd0_7[5] + %fc0_7[1] * %fd0_7[4] + %fc0_7[2] * %fd0_7[3] + %fc0_7[3] * %fd0_7[2] + %fc0_7[4] * %fd0_7[1] + %fc0_7[5] * %fd0_7[0] + %fc0_7[6] * %fe1_7[7] + %fc0_7[7] * %fe1_7[6] +
        %fc1_7[0] * %fe1_7[5] + %fc1_7[1] * %fe1_7[4] + %fc1_7[2] * %fe1_7[3] + %fc1_7[3] * %fe1_7[2] + %fc1_7[4] * %fe1_7[1] + %fc1_7[5] * %fe1_7[0] + %fc1_7[6] * %fe0_7[7] + %fc1_7[7] * %fe0_7[6],
        %fc0_7[0] * %fd0_7[6] + %fc0_7[1] * %fd0_7[5] + %fc0_7[2] * %fd0_7[4] + %fc0_7[3] * %fd0_7[3] + %fc0_7[4] * %fd0_7[2] + %fc0_7[5] * %fd0_7[1] + %fc0_7[6] * %fd0_7[0] + %fc0_7[7] * %fe1_7[7] +
        %fc1_7[0] * %fe1_7[6] + %fc1_7[1] * %fe1_7[5] + %fc1_7[2] * %fe1_7[4] + %fc1_7[3] * %fe1_7[3] + %fc1_7[4] * %fe1_7[2] + %fc1_7[5] * %fe1_7[1] + %fc1_7[6] * %fe1_7[0] + %fc1_7[7] * %fe0_7[7],
        %fc0_7[0] * %fd0_7[7] + %fc0_7[1] * %fd0_7[6] + %fc0_7[2] * %fd0_7[5] + %fc0_7[3] * %fd0_7[4] + %fc0_7[4] * %fd0_7[3] + %fc0_7[5] * %fd0_7[2] + %fc0_7[6] * %fd0_7[1] + %fc0_7[7] * %fd0_7[0] +
        %fc1_7[0] * %fe1_7[7] + %fc1_7[1] * %fe1_7[6] + %fc1_7[2] * %fe1_7[5] + %fc1_7[3] * %fe1_7[4] + %fc1_7[4] * %fe1_7[3] + %fc1_7[5] * %fe1_7[2] + %fc1_7[6] * %fe1_7[1] + %fc1_7[7] * %fe1_7[0]
    ] /\
    %conv1_7 = [
        %fc0_7[0] * %fd1_7[0] + %fc0_7[1] * %fd0_7[7] + %fc0_7[2] * %fd0_7[6] + %fc0_7[3] * %fd0_7[5] + %fc0_7[4] * %fd0_7[4] + %fc0_7[5] * %fd0_7[3] + %fc0_7[6] * %fd0_7[2] + %fc0_7[7] * %fd0_7[1] +
        %fc1_7[0] * %fd0_7[0] + %fc1_7[1] * %fe1_7[7] + %fc1_7[2] * %fe1_7[6] + %fc1_7[3] * %fe1_7[5] + %fc1_7[4] * %fe1_7[4] + %fc1_7[5] * %fe1_7[3] + %fc1_7[6] * %fe1_7[2] + %fc1_7[7] * %fe1_7[1],
        %fc0_7[0] * %fd1_7[1] + %fc0_7[1] * %fd1_7[0] + %fc0_7[2] * %fd0_7[7] + %fc0_7[3] * %fd0_7[6] + %fc0_7[4] * %fd0_7[5] + %fc0_7[5] * %fd0_7[4] + %fc0_7[6] * %fd0_7[3] + %fc0_7[7] * %fd0_7[2] +
        %fc1_7[0] * %fd0_7[1] + %fc1_7[1] * %fd0_7[0] + %fc1_7[2] * %fe1_7[7] + %fc1_7[3] * %fe1_7[6] + %fc1_7[4] * %fe1_7[5] + %fc1_7[5] * %fe1_7[4] + %fc1_7[6] * %fe1_7[3] + %fc1_7[7] * %fe1_7[2],
        %fc0_7[0] * %fd1_7[2] + %fc0_7[1] * %fd1_7[1] + %fc0_7[2] * %fd1_7[0] + %fc0_7[3] * %fd0_7[7] + %fc0_7[4] * %fd0_7[6] + %fc0_7[5] * %fd0_7[5] + %fc0_7[6] * %fd0_7[4] + %fc0_7[7] * %fd0_7[3] +
        %fc1_7[0] * %fd0_7[2] + %fc1_7[1] * %fd0_7[1] + %fc1_7[2] * %fd0_7[0] + %fc1_7[3] * %fe1_7[7] + %fc1_7[4] * %fe1_7[6] + %fc1_7[5] * %fe1_7[5] + %fc1_7[6] * %fe1_7[4] + %fc1_7[7] * %fe1_7[3],
        %fc0_7[0] * %fd1_7[3] + %fc0_7[1] * %fd1_7[2] + %fc0_7[2] * %fd1_7[1] + %fc0_7[3] * %fd1_7[0] + %fc0_7[4] * %fd0_7[7] + %fc0_7[5] * %fd0_7[6] + %fc0_7[6] * %fd0_7[5] + %fc0_7[7] * %fd0_7[4] +
        %fc1_7[0] * %fd0_7[3] + %fc1_7[1] * %fd0_7[2] + %fc1_7[2] * %fd0_7[1] + %fc1_7[3] * %fd0_7[0] + %fc1_7[4] * %fe1_7[7] + %fc1_7[5] * %fe1_7[6] + %fc1_7[6] * %fe1_7[5] + %fc1_7[7] * %fe1_7[4],
        %fc0_7[0] * %fd1_7[4] + %fc0_7[1] * %fd1_7[3] + %fc0_7[2] * %fd1_7[2] + %fc0_7[3] * %fd1_7[1] + %fc0_7[4] * %fd1_7[0] + %fc0_7[5] * %fd0_7[7] + %fc0_7[6] * %fd0_7[6] + %fc0_7[7] * %fd0_7[5] +
        %fc1_7[0] * %fd0_7[4] + %fc1_7[1] * %fd0_7[3] + %fc1_7[2] * %fd0_7[2] + %fc1_7[3] * %fd0_7[1] + %fc1_7[4] * %fd0_7[0] + %fc1_7[5] * %fe1_7[7] + %fc1_7[6] * %fe1_7[6] + %fc1_7[7] * %fe1_7[5],
        %fc0_7[0] * %fd1_7[5] + %fc0_7[1] * %fd1_7[4] + %fc0_7[2] * %fd1_7[3] + %fc0_7[3] * %fd1_7[2] + %fc0_7[4] * %fd1_7[1] + %fc0_7[5] * %fd1_7[0] + %fc0_7[6] * %fd0_7[7] + %fc0_7[7] * %fd0_7[6] +
        %fc1_7[0] * %fd0_7[5] + %fc1_7[1] * %fd0_7[4] + %fc1_7[2] * %fd0_7[3] + %fc1_7[3] * %fd0_7[2] + %fc1_7[4] * %fd0_7[1] + %fc1_7[5] * %fd0_7[0] + %fc1_7[6] * %fe1_7[7] + %fc1_7[7] * %fe1_7[6],
        %fc0_7[0] * %fd1_7[6] + %fc0_7[1] * %fd1_7[5] + %fc0_7[2] * %fd1_7[4] + %fc0_7[3] * %fd1_7[3] + %fc0_7[4] * %fd1_7[2] + %fc0_7[5] * %fd1_7[1] + %fc0_7[6] * %fd1_7[0] + %fc0_7[7] * %fd0_7[7] +
        %fc1_7[0] * %fd0_7[6] + %fc1_7[1] * %fd0_7[5] + %fc1_7[2] * %fd0_7[4] + %fc1_7[3] * %fd0_7[3] + %fc1_7[4] * %fd0_7[2] + %fc1_7[5] * %fd0_7[1] + %fc1_7[6] * %fd0_7[0] + %fc1_7[7] * %fe1_7[7],
        %fc0_7[0] * %fd1_7[7] + %fc0_7[1] * %fd1_7[6] + %fc0_7[2] * %fd1_7[5] + %fc0_7[3] * %fd1_7[4] + %fc0_7[4] * %fd1_7[3] + %fc0_7[5] * %fd1_7[2] + %fc0_7[6] * %fd1_7[1] + %fc0_7[7] * %fd1_7[0] +
        %fc1_7[0] * %fd0_7[7] + %fc1_7[1] * %fd0_7[6] + %fc1_7[2] * %fd0_7[5] + %fc1_7[3] * %fd0_7[4] + %fc1_7[4] * %fd0_7[3] + %fc1_7[5] * %fd0_7[2] + %fc1_7[6] * %fd0_7[1] + %fc1_7[7] * %fd0_7[0]
    ] /\

    %v16 ++ %v7 = %conv0_7 /\ %v0 ++ %v2 = %conv1_7,

    %v16 <= [268435456, 268435456, 268435456, 268435456] /\
    %v16 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v7 <= [268435456, 268435456, 268435456, 268435456] /\
    %v7 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v0 <= [268435456, 268435456, 268435456, 268435456] /\
    %v0 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v2 <= [268435456, 268435456, 268435456, 268435456] /\
    %v2 >= [-268435456, -268435456, -268435456, -268435456]

    prove with [algebra solver isl]
  &&
    %v16 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v16 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32] /\

    %v7 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v7 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32] /\

    %v0 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v0 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32] /\

    %v2 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v2 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32];

ghost %h0_7@sint32[8], %h1_7@sint32[8] :
    %h0_7 = %v16 ++ %v7 /\ %h1_7 = %v0 ++ %v2
  &&
    %h0_7 = %v16 ++ %v7 /\ %h1_7 = %v0 ++ %v2;

(* uzp1	v3.8h, v16.8h, v7.8h                       #! PC = 0x5555551cd0 *)
mov %spl_join [%v16[0], %v16[1], %v16[2], %v16[3], %v7[0], %v7[1], %v7[2], %v7[3]]; spl %splh %v3 %spl_join 16; cast %v3@int16[8] %v3;
(* mul	v3.8h, v3.8h, v5.h[7]                       #! PC = 0x5555551cd4 *)
broadcast %mul 8 [%v5[7]]; mull %dc %v3 %v3 %mul; cast %v3@int16[8] %v3;

ghost %m0_7@sint16[8] : %m0_7 = %v3 && %m0_7 = %v3;

(* sqdmulh	v3.8h, v3.8h, v5.h[6]                   #! PC = 0x5555551cd8 *)
broadcast %mul 8 [%v5[6]]; smulj %LO %v3 %mul;
ssplit %LO0 %dc %LO 15; vpc %v3@sint16[8] %LO0;
(* uzp2	v1.8h, v16.8h, v7.8h                       #! PC = 0x5555551cdc *)
mov %spl_join [%v16[0], %v16[1], %v16[2], %v16[3], %v7[0], %v7[1], %v7[2], %v7[3]]; spl %v1 %spll %spl_join 16;
(* sshr	v3.8h, v3.8h, #1                           #! PC = 0x5555551ce0 *)
split %v3 %dc %v3 1;
(* sub	v1.8h, v1.8h, v3.8h                         #! PC = 0x5555551ce4 *)
sub %v1 %v1 %v3;

ghost %hh0_7@sint16[8] : %hh0_7 = %v1 && %hh0_7 = %v1;

assert
    %h0_7 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m0_7
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh0_7
    prove with [algebra solver isl]
    && true;

assume
    %h0_7 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m0_7
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh0_7
    && true;

(* sqrdmulh	v3.8h, v1.8h, v5.h[3]                  #! PC = 0x5555551ce8 *)
broadcast %mul 8 [%v5[3]]; smulj %LO %v1 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v3 %LO11 %LO01;
(* mul	v1.8h, v1.8h, v5.h[2]                       #! PC = 0x5555551cec *)
broadcast %mul 8 [%v5[2]]; mull %dc %v1 %v1 %mul; cast %v1@int16[8] %v1;
(* mls	v1.8h, v3.8h, v5.h[6]                       #! PC = 0x5555551cf0 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v3 %mul;
cast %mls@int16[8] %mls; subc %dc %v1 %v1 %mls;

assert
    [258, 258, 258, 258, 258, 258, 258, 258] * %hh0_7
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v3
    = %v1
    prove with [algebra solver isl]
    && true;

assume
    [258, 258, 258, 258, 258, 258, 258, 258] * %hh0_7
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v3
    = %v1
    && true;

(* uzp1	v3.8h, v0.8h, v2.8h                        #! PC = 0x5555551cf4 *)
mov %spl_join [%v0[0], %v0[1], %v0[2], %v0[3], %v2[0], %v2[1], %v2[2], %v2[3]]; spl %splh %v3 %spl_join 16; cast %v3@int16[8] %v3;
(* mul	v3.8h, v3.8h, v5.h[7]                       #! PC = 0x5555551cf8 *)
broadcast %mul 8 [%v5[7]]; mull %dc %v3 %v3 %mul; cast %v3@int16[8] %v3;

ghost %m1_7@sint16[8] : %m1_7 = %v3 && %m1_7 = %v3;

(* sqdmulh	v3.8h, v3.8h, v5.h[6]                   #! PC = 0x5555551cfc *)
broadcast %mul 8 [%v5[6]]; smulj %LO %v3 %mul;
ssplit %LO0 %dc %LO 15; vpc %v3@sint16[8] %LO0;
(* uzp2	v0.8h, v0.8h, v2.8h                        #! PC = 0x5555551d00 *)
mov %spl_join [%v0[0], %v0[1], %v0[2], %v0[3], %v2[0], %v2[1], %v2[2], %v2[3]]; spl %v0 %spll %spl_join 16;
(* sshr	v2.8h, v3.8h, #1                           #! PC = 0x5555551d04 *)
split %v2 %dc %v3 1;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551d08 *)
sub %v0 %v0 %v2;

ghost %hh1_7@sint16[8] : %hh1_7 = %v0 && %hh1_7 = %v0;

assert
    %h1_7 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m1_7
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh1_7
    prove with [algebra solver isl]
    && true;

assume
    %h1_7 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m1_7
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh1_7
    && true;

(* sqrdmulh	v2.8h, v0.8h, v5.h[3]                  #! PC = 0x5555551d0c *)
broadcast %mul 8 [%v5[3]]; smulj %LO %v0 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v2 %LO11 %LO01;
(* mul	v0.8h, v0.8h, v5.h[2]                       #! PC = 0x5555551d10 *)
broadcast %mul 8 [%v5[2]]; mull %dc %v0 %v0 %mul; cast %v0@int16[8] %v0;
(* mls	v0.8h, v2.8h, v5.h[6]                       #! PC = 0x5555551d14 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v2 %mul;
cast %mls@int16[8] %mls; subc %dc %v0 %v0 %mls;

assert
    [258, 258, 258, 258, 258, 258, 258, 258] * %hh1_7
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v2
    = %v0
    prove with [algebra solver isl]
    && true;

assume
    [258, 258, 258, 258, 258, 258, 258, 258] * %hh1_7
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v2
    = %v0
    && true;


### i_iter epilogue

(* str	q1, [x2, x3]                                #! EA = L0x7fffffe290; PC = 0x5555551d18 *)
mov [L0x7fffffe290,L0x7fffffe292,L0x7fffffe294,L0x7fffffe296,L0x7fffffe298,L0x7fffffe29a,L0x7fffffe29c,L0x7fffffe29e] %v1;
(* str	q0, [x6, x3]                                #! EA = L0x7fffffe2a0; PC = 0x5555551d1c *)
mov [L0x7fffffe2a0,L0x7fffffe2a2,L0x7fffffe2a4,L0x7fffffe2a6,L0x7fffffe2a8,L0x7fffffe2aa,L0x7fffffe2ac,L0x7fffffe2ae] %v0;
(* #b.eq	0x5555551ec4 <_ZN6xpower7basemul11low_basemulEPA2_A8_sS3_S3_+932>  // b.none#! PC = 0x5555551d30 *)
#b.eq	0x5555551ec4 <_ZN6xpower7basemul11low_basemulEPA2_A8_sS3_S3_+932>  // b.none#! 0x5555551d30 = 0x5555551d30;

assert
    %v1 <= [2700, 2700, 2700, 2700, 2700, 2700, 2700, 2700] /\
    %v1 >= [-2700, -2700, -2700, -2700, -2700, -2700, -2700, -2700] /\

    %v0 <= [2700, 2700, 2700, 2700, 2700, 2700, 2700, 2700] /\
    %v0 >= [-2700, -2700, -2700, -2700, -2700, -2700, -2700, -2700]

    prove with [algebra solver isl]
    && true;

assume
    true &&

    %v1 <=s [2700@16, 2700@16, 2700@16, 2700@16, 2700@16, 2700@16, 2700@16, 2700@16] /\
    %v1 >=s [(-2700)@16, (-2700)@16, (-2700)@16, (-2700)@16, (-2700)@16, (-2700)@16, (-2700)@16, (-2700)@16] /\

    %v0 <=s [2700@16, 2700@16, 2700@16, 2700@16, 2700@16, 2700@16, 2700@16, 2700@16] /\
    %v0 >=s [(-2700)@16, (-2700)@16, (-2700)@16, (-2700)@16, (-2700)@16, (-2700)@16, (-2700)@16, (-2700)@16];

cut (* 32 *)
    [L0x7fffffe290, L0x7fffffe292, L0x7fffffe294, L0x7fffffe296, L0x7fffffe298, L0x7fffffe29a, L0x7fffffe29c, L0x7fffffe29e] = %v1 /\
    [L0x7fffffe2a0, L0x7fffffe2a2, L0x7fffffe2a4, L0x7fffffe2a6, L0x7fffffe2a8, L0x7fffffe2aa, L0x7fffffe2ac, L0x7fffffe2ae] = %v0 /\

    %v1 ++ %v0 = [2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132] * [
        arr700_a * arr700_b + 1815 * arr701_a * arr717_b + 1815 * arr702_a * arr716_b + 1815 * arr703_a * arr715_b + 1815 * arr704_a * arr714_b + 1815 * arr705_a * arr713_b + 1815 * arr706_a * arr712_b + 1815 * arr707_a * arr711_b + 1815 * arr710_a * arr710_b + 1815 * arr711_a * arr707_b + 1815 * arr712_a * arr706_b + 1815 * arr713_a * arr705_b + 1815 * arr714_a * arr704_b + 1815 * arr715_a * arr703_b + 1815 * arr716_a * arr702_b + 1815 * arr717_a * arr701_b,
        arr700_a * arr701_b + arr701_a * arr700_b + 1815 * arr702_a * arr717_b + 1815 * arr703_a * arr716_b + 1815 * arr704_a * arr715_b + 1815 * arr705_a * arr714_b + 1815 * arr706_a * arr713_b + 1815 * arr707_a * arr712_b + 1815 * arr710_a * arr711_b + 1815 * arr711_a * arr710_b + 1815 * arr712_a * arr707_b + 1815 * arr713_a * arr706_b + 1815 * arr714_a * arr705_b + 1815 * arr715_a * arr704_b + 1815 * arr716_a * arr703_b + 1815 * arr717_a * arr702_b,
        arr700_a * arr702_b + arr701_a * arr701_b + arr702_a * arr700_b + 1815 * arr703_a * arr717_b + 1815 * arr704_a * arr716_b + 1815 * arr705_a * arr715_b + 1815 * arr706_a * arr714_b + 1815 * arr707_a * arr713_b + 1815 * arr710_a * arr712_b + 1815 * arr711_a * arr711_b + 1815 * arr712_a * arr710_b + 1815 * arr713_a * arr707_b + 1815 * arr714_a * arr706_b + 1815 * arr715_a * arr705_b + 1815 * arr716_a * arr704_b + 1815 * arr717_a * arr703_b,
        arr700_a * arr703_b + arr701_a * arr702_b + arr702_a * arr701_b + arr703_a * arr700_b + 1815 * arr704_a * arr717_b + 1815 * arr705_a * arr716_b + 1815 * arr706_a * arr715_b + 1815 * arr707_a * arr714_b + 1815 * arr710_a * arr713_b + 1815 * arr711_a * arr712_b + 1815 * arr712_a * arr711_b + 1815 * arr713_a * arr710_b + 1815 * arr714_a * arr707_b + 1815 * arr715_a * arr706_b + 1815 * arr716_a * arr705_b + 1815 * arr717_a * arr704_b,
        arr700_a * arr704_b + arr701_a * arr703_b + arr702_a * arr702_b + arr703_a * arr701_b + arr704_a * arr700_b + 1815 * arr705_a * arr717_b + 1815 * arr706_a * arr716_b + 1815 * arr707_a * arr715_b + 1815 * arr710_a * arr714_b + 1815 * arr711_a * arr713_b + 1815 * arr712_a * arr712_b + 1815 * arr713_a * arr711_b + 1815 * arr714_a * arr710_b + 1815 * arr715_a * arr707_b + 1815 * arr716_a * arr706_b + 1815 * arr717_a * arr705_b,
        arr700_a * arr705_b + arr701_a * arr704_b + arr702_a * arr703_b + arr703_a * arr702_b + arr704_a * arr701_b + arr705_a * arr700_b + 1815 * arr706_a * arr717_b + 1815 * arr707_a * arr716_b + 1815 * arr710_a * arr715_b + 1815 * arr711_a * arr714_b + 1815 * arr712_a * arr713_b + 1815 * arr713_a * arr712_b + 1815 * arr714_a * arr711_b + 1815 * arr715_a * arr710_b + 1815 * arr716_a * arr707_b + 1815 * arr717_a * arr706_b,
        arr700_a * arr706_b + arr701_a * arr705_b + arr702_a * arr704_b + arr703_a * arr703_b + arr704_a * arr702_b + arr705_a * arr701_b + arr706_a * arr700_b + 1815 * arr707_a * arr717_b + 1815 * arr710_a * arr716_b + 1815 * arr711_a * arr715_b + 1815 * arr712_a * arr714_b + 1815 * arr713_a * arr713_b + 1815 * arr714_a * arr712_b + 1815 * arr715_a * arr711_b + 1815 * arr716_a * arr710_b + 1815 * arr717_a * arr707_b,
        arr700_a * arr707_b + arr701_a * arr706_b + arr702_a * arr705_b + arr703_a * arr704_b + arr704_a * arr703_b + arr705_a * arr702_b + arr706_a * arr701_b + arr707_a * arr700_b + 1815 * arr710_a * arr717_b + 1815 * arr711_a * arr716_b + 1815 * arr712_a * arr715_b + 1815 * arr713_a * arr714_b + 1815 * arr714_a * arr713_b + 1815 * arr715_a * arr712_b + 1815 * arr716_a * arr711_b + 1815 * arr717_a * arr710_b,
        arr700_a * arr710_b + arr701_a * arr707_b + arr702_a * arr706_b + arr703_a * arr705_b + arr704_a * arr704_b + arr705_a * arr703_b + arr706_a * arr702_b + arr707_a * arr701_b + arr710_a * arr700_b + 1815 * arr711_a * arr717_b + 1815 * arr712_a * arr716_b + 1815 * arr713_a * arr715_b + 1815 * arr714_a * arr714_b + 1815 * arr715_a * arr713_b + 1815 * arr716_a * arr712_b + 1815 * arr717_a * arr711_b,
        arr700_a * arr711_b + arr701_a * arr710_b + arr702_a * arr707_b + arr703_a * arr706_b + arr704_a * arr705_b + arr705_a * arr704_b + arr706_a * arr703_b + arr707_a * arr702_b + arr710_a * arr701_b + arr711_a * arr700_b + 1815 * arr712_a * arr717_b + 1815 * arr713_a * arr716_b + 1815 * arr714_a * arr715_b + 1815 * arr715_a * arr714_b + 1815 * arr716_a * arr713_b + 1815 * arr717_a * arr712_b,
        arr700_a * arr712_b + arr701_a * arr711_b + arr702_a * arr710_b + arr703_a * arr707_b + arr704_a * arr706_b + arr705_a * arr705_b + arr706_a * arr704_b + arr707_a * arr703_b + arr710_a * arr702_b + arr711_a * arr701_b + arr712_a * arr700_b + 1815 * arr713_a * arr717_b + 1815 * arr714_a * arr716_b + 1815 * arr715_a * arr715_b + 1815 * arr716_a * arr714_b + 1815 * arr717_a * arr713_b,
        arr700_a * arr713_b + arr701_a * arr712_b + arr702_a * arr711_b + arr703_a * arr710_b + arr704_a * arr707_b + arr705_a * arr706_b + arr706_a * arr705_b + arr707_a * arr704_b + arr710_a * arr703_b + arr711_a * arr702_b + arr712_a * arr701_b + arr713_a * arr700_b + 1815 * arr714_a * arr717_b + 1815 * arr715_a * arr716_b + 1815 * arr716_a * arr715_b + 1815 * arr717_a * arr714_b,
        arr700_a * arr714_b + arr701_a * arr713_b + arr702_a * arr712_b + arr703_a * arr711_b + arr704_a * arr710_b + arr705_a * arr707_b + arr706_a * arr706_b + arr707_a * arr705_b + arr710_a * arr704_b + arr711_a * arr703_b + arr712_a * arr702_b + arr713_a * arr701_b + arr714_a * arr700_b + 1815 * arr715_a * arr717_b + 1815 * arr716_a * arr716_b + 1815 * arr717_a * arr715_b,
        arr700_a * arr715_b + arr701_a * arr714_b + arr702_a * arr713_b + arr703_a * arr712_b + arr704_a * arr711_b + arr705_a * arr710_b + arr706_a * arr707_b + arr707_a * arr706_b + arr710_a * arr705_b + arr711_a * arr704_b + arr712_a * arr703_b + arr713_a * arr702_b + arr714_a * arr701_b + arr715_a * arr700_b + 1815 * arr716_a * arr717_b + 1815 * arr717_a * arr716_b,
        arr700_a * arr716_b + arr701_a * arr715_b + arr702_a * arr714_b + arr703_a * arr713_b + arr704_a * arr712_b + arr705_a * arr711_b + arr706_a * arr710_b + arr707_a * arr707_b + arr710_a * arr706_b + arr711_a * arr705_b + arr712_a * arr704_b + arr713_a * arr703_b + arr714_a * arr702_b + arr715_a * arr701_b + arr716_a * arr700_b + 1815 * arr717_a * arr717_b,
        arr700_a * arr717_b + arr701_a * arr716_b + arr702_a * arr715_b + arr703_a * arr714_b + arr704_a * arr713_b + arr705_a * arr712_b + arr706_a * arr711_b + arr707_a * arr710_b + arr710_a * arr707_b + arr711_a * arr706_b + arr712_a * arr705_b + arr713_a * arr704_b + arr714_a * arr703_b + arr715_a * arr702_b + arr716_a * arr701_b + arr717_a * arr700_b
    ] ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] )

    prove with [cuts[0, 29, 30, 31]]
  &&
    [L0x7fffffe290, L0x7fffffe292, L0x7fffffe294, L0x7fffffe296, L0x7fffffe298, L0x7fffffe29a, L0x7fffffe29c, L0x7fffffe29e] = %v1 /\
    [L0x7fffffe2a0, L0x7fffffe2a2, L0x7fffffe2a4, L0x7fffffe2a6, L0x7fffffe2a8, L0x7fffffe2aa, L0x7fffffe2ac, L0x7fffffe2ae] = %v0 /\

    %v1 <=s [2700@16, 2700@16, 2700@16, 2700@16, 2700@16, 2700@16, 2700@16, 2700@16] /\
    %v1 >=s [(-2700)@16, (-2700)@16, (-2700)@16, (-2700)@16, (-2700)@16, (-2700)@16, (-2700)@16, (-2700)@16] /\

    %v0 <=s [2700@16, 2700@16, 2700@16, 2700@16, 2700@16, 2700@16, 2700@16, 2700@16] /\
    %v0 >=s [(-2700)@16, (-2700)@16, (-2700)@16, (-2700)@16, (-2700)@16, (-2700)@16, (-2700)@16, (-2700)@16];


### i_iter prologue

(* ldr	q4, [x0, x3]                                #! EA = L0x7fffffe530; Value = 0x0000000000000000; PC = 0x5555551d34 *)
mov %v4 [L0x7fffffe530,L0x7fffffe532,L0x7fffffe534,L0x7fffffe536,L0x7fffffe538,L0x7fffffe53a,L0x7fffffe53c,L0x7fffffe53e];
(* ldr	q1, [x8, x3]                                #! EA = L0x7fffffe540; Value = 0x0000000000000000; PC = 0x5555551d38 *)
mov %v1 [L0x7fffffe540,L0x7fffffe542,L0x7fffffe544,L0x7fffffe546,L0x7fffffe548,L0x7fffffe54a,L0x7fffffe54c,L0x7fffffe54e];
(* ldr	q17, [x1, x3]                               #! EA = L0x7fffffe3f0; Value = 0x0000000000000000; PC = 0x5555551d3c *)
mov %v17 [L0x7fffffe3f0,L0x7fffffe3f2,L0x7fffffe3f4,L0x7fffffe3f6,L0x7fffffe3f8,L0x7fffffe3fa,L0x7fffffe3fc,L0x7fffffe3fe];
(* ldr	q18, [x7, x3]                               #! EA = L0x7fffffe400; Value = 0x0000000000000000; PC = 0x5555551d40 *)
mov %v18 [L0x7fffffe400,L0x7fffffe402,L0x7fffffe404,L0x7fffffe406,L0x7fffffe408,L0x7fffffe40a,L0x7fffffe40c,L0x7fffffe40e];

ghost %fa0_8@sint16[8], %fa1_8@sint16[8], %fb0_8@sint16[8], %fb1_8@sint16[8] :
    %fa0_8 = %v4 /\ %fa1_8 = %v1 /\ %fb0_8 = %v17 /\ %fb1_8 = %v18
  &&
    %fa0_8 = %v4 /\ %fa1_8 = %v1 /\ %fb0_8 = %v17 /\ %fb1_8 = %v18;

cut (* 33 *)
    %fa0_8 = %v4 /\ %fa1_8 = %v1 /\ %fb0_8 = %v17 /\ %fb1_8 = %v18 /\
    %fa0_8 = [arr800_a, arr801_a, arr802_a, arr803_a, arr804_a, arr805_a, arr806_a, arr807_a] /\
    %fa1_8 = [arr810_a, arr811_a, arr812_a, arr813_a, arr814_a, arr815_a, arr816_a, arr817_a] /\
    %fb0_8 = [arr800_b, arr801_b, arr802_b, arr803_b, arr804_b, arr805_b, arr806_b, arr807_b] /\
    %fb1_8 = [arr810_b, arr811_b, arr812_b, arr813_b, arr814_b, arr815_b, arr816_b, arr817_b]
    prove with [cuts[0]]
  &&
    %fa0_8 = %v4 /\ %fa1_8 = %v1 /\ %fb0_8 = %v17 /\ %fb1_8 = %v18 /\
    %fa0_8 = [arr800_a, arr801_a, arr802_a, arr803_a, arr804_a, arr805_a, arr806_a, arr807_a] /\
    %fa1_8 = [arr810_a, arr811_a, arr812_a, arr813_a, arr814_a, arr815_a, arr816_a, arr817_a] /\
    %fb0_8 = [arr800_b, arr801_b, arr802_b, arr803_b, arr804_b, arr805_b, arr806_b, arr807_b] /\
    %fb1_8 = [arr810_b, arr811_b, arr812_b, arr813_b, arr814_b, arr815_b, arr816_b, arr817_b]
    prove with [cuts[0]];

#### radix2

(* ldr	q5, [x5]                                    #! EA = L0x5555552e80; Value = 0xe179fbb9c517f7bf; PC = 0x5555551d48 *)
mov %v5 [L0x5555552e80,L0x5555552e82,L0x5555552e84,L0x5555552e86,L0x5555552e88,L0x5555552e8a,L0x5555552e8c,L0x5555552e8e];
(* sshr	v0.8h, v4.8h, #12                          #! PC = 0x5555551d4c *)
split %v0 %dc %v4 12;
(* cmlt	v2.8h, v4.8h, #0                           #! PC = 0x5555551d50 *)
split %v2 %dc %v4 15;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551d54 *)
sub %v0 %v0 %v2;
(* mls	v4.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551d58 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v4 %v4 %mls;

assert
    %fa0_8 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v4
    prove with [algebra solver isl, precondition, cuts[0, 33]]
    && true;

assume
    %fa0_8 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v4
    && true;

(* sshr	v0.8h, v17.8h, #12                         #! PC = 0x5555551d5c *)
split %v0 %dc %v17 12;
(* cmlt	v2.8h, v17.8h, #0                          #! PC = 0x5555551d60 *)
split %v2 %dc %v17 15;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551d64 *)
sub %v0 %v0 %v2;
(* mls	v17.8h, v0.8h, v5.h[6]                      #! PC = 0x5555551d68 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v17 %v17 %mls;

assert
    %fb0_8 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v17
    prove with [algebra solver isl, precondition, cuts[0, 33]]
    && true;

assume
    %fb0_8 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v17
    && true;

(* sqrdmulh	v0.8h, v1.8h, v5.h[1]                  #! PC = 0x5555551d6c *)
broadcast %mul 8 [%v5[1]]; smulj %LO %v1 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v0 %LO11 %LO01;
(* mul	v1.8h, v1.8h, v5.h[0]                       #! PC = 0x5555551d70 *)
broadcast %mul 8 [%v5[0]]; mull %dc %v1 %v1 %mul; cast %v1@int16[8] %v1;
(* mls	v1.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551d74 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v1 %v1 %mls;

assert
    [-2113, -2113, -2113, -2113, -2113, -2113, -2113, -2113] * %fa1_8
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v1
    prove with [algebra solver isl, precondition, cuts[0, 33]]
    && true;

assume
    [-2113, -2113, -2113, -2113, -2113, -2113, -2113, -2113] * %fa1_8
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v1
    && true;

(* sqrdmulh	v0.8h, v18.8h, v5.h[1]                 #! PC = 0x5555551d78 *)
broadcast %mul 8 [%v5[1]]; smulj %LO %v18 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v0 %LO11 %LO01;
(* mul	v18.8h, v18.8h, v5.h[0]                     #! PC = 0x5555551d7c *)
broadcast %mul 8 [%v5[0]]; mull %dc %v18 %v18 %mul; cast %v18@int16[8] %v18;
(* mls	v18.8h, v0.8h, v5.h[6]                      #! PC = 0x5555551d80 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v18 %v18 %mls;

assert
    [-2113, -2113, -2113, -2113, -2113, -2113, -2113, -2113] * %fb1_8
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v18
    prove with [algebra solver isl, precondition, cuts[0, 33]]
    && true;

assume
    [-2113, -2113, -2113, -2113, -2113, -2113, -2113, -2113] * %fb1_8
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v18
    && true;

(* add	v2.8h, v4.8h, v1.8h                         #! PC = 0x5555551d84 *)
add %v2 %v4 %v1;
(* sub	v1.8h, v4.8h, v1.8h                         #! PC = 0x5555551d88 *)
sub %v1 %v4 %v1;
(* add	v7.8h, v17.8h, v18.8h                       #! PC = 0x5555551d8c *)
add %v7 %v17 %v18;
(* sub	v18.8h, v17.8h, v18.8h                      #! PC = 0x5555551d90 *)
sub %v18 %v17 %v18;

ghost %fc0_8@sint16[8], %fc1_8@sint16[8], %fd0_8@sint16[8], %fd1_8@sint16[8] :
    %fc0_8 = %v2 /\ %fc1_8 = %v1 /\ %fd0_8 = %v7 /\ %fd1_8 = %v18
  &&
    %fc0_8 = %v2 /\ %fc1_8 = %v1 /\ %fd0_8 = %v7 /\ %fd1_8 = %v18;

(* sqrdmulh	v0.8h, v7.8h, v5.h[1]                  #! PC = 0x5555551d94 *)
broadcast %mul 8 [%v5[1]]; smulj %LO %v7 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v0 %LO11 %LO01;
(* mul	v3.8h, v7.8h, v5.h[0]                       #! PC = 0x5555551d98 *)
broadcast %mul 8 [%v5[0]]; mull %dc %v3 %v7 %mul; cast %v3@int16[8] %v3;
(* mls	v3.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551d9c *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v3 %v3 %mls;

assert
    [-2113, -2113, -2113, -2113, -2113, -2113, -2113, -2113] * %fd0_8
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v3
    prove with [algebra solver isl, precondition, cuts[0, 33]]
    && true;

assume
    [-2113, -2113, -2113, -2113, -2113, -2113, -2113, -2113] * %fd0_8
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v3
    && true;

(* sqrdmulh	v0.8h, v18.8h, v5.h[1]                 #! PC = 0x5555551da0 *)
broadcast %mul 8 [%v5[1]]; smulj %LO %v18 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v0 %LO11 %LO01;
(* mul	v6.8h, v18.8h, v5.h[0]                      #! PC = 0x5555551da4 *)
broadcast %mul 8 [%v5[0]]; mull %dc %v6 %v18 %mul; cast %v6@int16[8] %v6;
(* mls	v6.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551da8 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v6 %v6 %mls;

assert
    [-2113, -2113, -2113, -2113, -2113, -2113, -2113, -2113] * %fd1_8
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v6
    prove with [algebra solver isl, precondition, cuts[0, 33]]
    && true;

assume
    [-2113, -2113, -2113, -2113, -2113, -2113, -2113, -2113] * %fd1_8
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v6
    && true;

(* neg	v6.8h, v6.8h                                #! PC = 0x5555551dac *)
broadcast %zero 8 [0@sint16]; sub %v6 %zero %v6;

ghost %gd0_8@sint16[8], %gd1_8@sint16[8] :
    %gd0_8 = %v3 /\ %gd1_8 = %v6
  &&
    %gd0_8 = %v3 /\ %gd1_8 = %v6;

cut (* 34 *)
    %fc0_8 = %v2 /\ %fc1_8 = %v1 /\ %fd0_8 = %v7 /\ %fd1_8 = %v18 /\ %gd0_8 = %v3 /\ %gd1_8 = %v6 /\

    %fc0_8 = %fa0_8 + [-2113, -2113, -2113, -2113, -2113, -2113, -2113, -2113] * %fa1_8
        ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\
    %fc1_8 = %fa0_8 - [-2113, -2113, -2113, -2113, -2113, -2113, -2113, -2113] * %fa1_8
        ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\

    %fd0_8 = %fb0_8 + [-2113, -2113, -2113, -2113, -2113, -2113, -2113, -2113] * %fb1_8
        ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\
    %fd1_8 = %fb0_8 - [-2113, -2113, -2113, -2113, -2113, -2113, -2113, -2113] * %fb1_8
        ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\

    %gd0_8 =  [-2113, -2113, -2113, -2113, -2113, -2113, -2113, -2113] * %fd0_8 ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\
    %gd1_8 = -[-2113, -2113, -2113, -2113, -2113, -2113, -2113, -2113] * %fd1_8 ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ),

    %fc0_8 <= [8100, 8100, 8100, 8100, 8100, 8100, 8100, 8100] /\
    %fc0_8 >= [-8100, -8100, -8100, -8100, -8100, -8100, -8100, -8100] /\

    %fc1_8 <= [8100, 8100, 8100, 8100, 8100, 8100, 8100, 8100] /\
    %fc1_8 >= [-8100, -8100, -8100, -8100, -8100, -8100, -8100, -8100] /\

    %fd0_8 <= [8100, 8100, 8100, 8100, 8100, 8100, 8100, 8100] /\
    %fd0_8 >= [-8100, -8100, -8100, -8100, -8100, -8100, -8100, -8100] /\

    %fd1_8 <= [8100, 8100, 8100, 8100, 8100, 8100, 8100, 8100] /\
    %fd1_8 >= [-8100, -8100, -8100, -8100, -8100, -8100, -8100, -8100] /\

    %gd0_8 <= [3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000] /\
    %gd0_8 >= [-3000, -3000, -3000, -3000, -3000, -3000, -3000, -3000] /\

    %gd1_8 <= [3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000] /\
    %gd1_8 >= [-3000, -3000, -3000, -3000, -3000, -3000, -3000, -3000]

    prove with [algebra solver isl, precondition, cuts[0, 33]]
  &&
    true
    prove with [precondition, cuts[0, 33]];

(* smull	v0.4s, v7.4h, v2.h[0]                     #! PC = 0x5555551db0 *)
broadcast %mull 4 [%v2[0]]; smulj %v0 [%v7[0],%v7[1],%v7[2],%v7[3]] %mull;
(* smull2	v4.4s, v7.8h, v2.h[0]                    #! PC = 0x5555551db4 *)
broadcast %mull 4 [%v2[0]]; smulj %v4 [%v7[4],%v7[5],%v7[6],%v7[7]] %mull;
(* ext	v16.16b, v3.16b, v7.16b, #14                #! PC = 0x5555551db8 *)
mov %v16 [%v3[7],%v7[0],%v7[1],%v7[2],%v7[3],%v7[4],%v7[5],%v7[6]];
(* smlal	v0.4s, v16.4h, v2.h[1]                    #! PC = 0x5555551dbc *)
broadcast %mull 4 [%v2[1]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v16.8h, v2.h[1]                   #! PC = 0x5555551dc0 *)
broadcast %mull 4 [%v2[1]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v4 %v4 %mlal;
(* ext	v16.16b, v3.16b, v7.16b, #12                #! PC = 0x5555551dc4 *)
mov %v16 [%v3[6],%v3[7],%v7[0],%v7[1],%v7[2],%v7[3],%v7[4],%v7[5]];
(* smlal	v0.4s, v16.4h, v2.h[2]                    #! PC = 0x5555551dc8 *)
broadcast %mull 4 [%v2[2]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v16.8h, v2.h[2]                   #! PC = 0x5555551dcc *)
broadcast %mull 4 [%v2[2]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v4 %v4 %mlal;
(* ext	v16.16b, v3.16b, v7.16b, #10                #! PC = 0x5555551dd0 *)
mov %v16 [%v3[5],%v3[6],%v3[7],%v7[0],%v7[1],%v7[2],%v7[3],%v7[4]];
(* smlal	v0.4s, v16.4h, v2.h[3]                    #! PC = 0x5555551dd4 *)
broadcast %mull 4 [%v2[3]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v16.8h, v2.h[3]                   #! PC = 0x5555551dd8 *)
broadcast %mull 4 [%v2[3]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v4 %v4 %mlal;
(* ext	v16.16b, v3.16b, v7.16b, #8                 #! PC = 0x5555551ddc *)
mov %v16 [%v3[4],%v3[5],%v3[6],%v3[7],%v7[0],%v7[1],%v7[2],%v7[3]];
(* smlal	v0.4s, v16.4h, v2.h[4]                    #! PC = 0x5555551de0 *)
broadcast %mull 4 [%v2[4]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v16.8h, v2.h[4]                   #! PC = 0x5555551de4 *)
broadcast %mull 4 [%v2[4]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v4 %v4 %mlal;
(* ext	v16.16b, v3.16b, v7.16b, #6                 #! PC = 0x5555551de8 *)
mov %v16 [%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v7[0],%v7[1],%v7[2]];
(* smlal	v0.4s, v16.4h, v2.h[5]                    #! PC = 0x5555551dec *)
broadcast %mull 4 [%v2[5]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v16.8h, v2.h[5]                   #! PC = 0x5555551df0 *)
broadcast %mull 4 [%v2[5]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v4 %v4 %mlal;
(* ext	v16.16b, v3.16b, v7.16b, #4                 #! PC = 0x5555551df4 *)
mov %v16 [%v3[2],%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v7[0],%v7[1]];
(* smlal	v0.4s, v16.4h, v2.h[6]                    #! PC = 0x5555551df8 *)
broadcast %mull 4 [%v2[6]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v16.8h, v2.h[6]                   #! PC = 0x5555551dfc *)
broadcast %mull 4 [%v2[6]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v4 %v4 %mlal;
(* ext	v3.16b, v3.16b, v7.16b, #2                  #! PC = 0x5555551e00 *)
mov %v3 [%v3[1],%v3[2],%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v7[0]];
(* smlal	v0.4s, v3.4h, v2.h[7]                     #! PC = 0x5555551e04 *)
broadcast %mull 4 [%v2[7]]; smulj %mlal [%v3[0],%v3[1],%v3[2],%v3[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v4.4s, v3.8h, v2.h[7]                    #! PC = 0x5555551e08 *)
broadcast %mull 4 [%v2[7]]; smulj %mlal [%v3[4],%v3[5],%v3[6],%v3[7]] %mull; adds %dc %v4 %v4 %mlal;
(* smull	v3.4s, v18.4h, v1.h[0]                    #! PC = 0x5555551e0c *)
broadcast %mull 4 [%v1[0]]; smulj %v3 [%v18[0],%v18[1],%v18[2],%v18[3]] %mull;
(* smull2	v2.4s, v18.8h, v1.h[0]                   #! PC = 0x5555551e10 *)
broadcast %mull 4 [%v1[0]]; smulj %v2 [%v18[4],%v18[5],%v18[6],%v18[7]] %mull;
(* ext	v7.16b, v6.16b, v18.16b, #14                #! PC = 0x5555551e14 *)
mov %v7 [%v6[7],%v18[0],%v18[1],%v18[2],%v18[3],%v18[4],%v18[5],%v18[6]];
(* smlal	v3.4s, v7.4h, v1.h[1]                     #! PC = 0x5555551e18 *)
broadcast %mull 4 [%v1[1]]; smulj %mlal [%v7[0],%v7[1],%v7[2],%v7[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v7.8h, v1.h[1]                    #! PC = 0x5555551e1c *)
broadcast %mull 4 [%v1[1]]; smulj %mlal [%v7[4],%v7[5],%v7[6],%v7[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v7.16b, v6.16b, v18.16b, #12                #! PC = 0x5555551e20 *)
mov %v7 [%v6[6],%v6[7],%v18[0],%v18[1],%v18[2],%v18[3],%v18[4],%v18[5]];
(* smlal	v3.4s, v7.4h, v1.h[2]                     #! PC = 0x5555551e24 *)
broadcast %mull 4 [%v1[2]]; smulj %mlal [%v7[0],%v7[1],%v7[2],%v7[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v7.8h, v1.h[2]                    #! PC = 0x5555551e28 *)
broadcast %mull 4 [%v1[2]]; smulj %mlal [%v7[4],%v7[5],%v7[6],%v7[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v7.16b, v6.16b, v18.16b, #10                #! PC = 0x5555551e2c *)
mov %v7 [%v6[5],%v6[6],%v6[7],%v18[0],%v18[1],%v18[2],%v18[3],%v18[4]];
(* smlal	v3.4s, v7.4h, v1.h[3]                     #! PC = 0x5555551e30 *)
broadcast %mull 4 [%v1[3]]; smulj %mlal [%v7[0],%v7[1],%v7[2],%v7[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v7.8h, v1.h[3]                    #! PC = 0x5555551e34 *)
broadcast %mull 4 [%v1[3]]; smulj %mlal [%v7[4],%v7[5],%v7[6],%v7[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v7.16b, v6.16b, v18.16b, #8                 #! PC = 0x5555551e38 *)
mov %v7 [%v6[4],%v6[5],%v6[6],%v6[7],%v18[0],%v18[1],%v18[2],%v18[3]];
(* smlal	v3.4s, v7.4h, v1.h[4]                     #! PC = 0x5555551e3c *)
broadcast %mull 4 [%v1[4]]; smulj %mlal [%v7[0],%v7[1],%v7[2],%v7[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v7.8h, v1.h[4]                    #! PC = 0x5555551e40 *)
broadcast %mull 4 [%v1[4]]; smulj %mlal [%v7[4],%v7[5],%v7[6],%v7[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v7.16b, v6.16b, v18.16b, #6                 #! PC = 0x5555551e44 *)
mov %v7 [%v6[3],%v6[4],%v6[5],%v6[6],%v6[7],%v18[0],%v18[1],%v18[2]];
(* smlal	v3.4s, v7.4h, v1.h[5]                     #! PC = 0x5555551e48 *)
broadcast %mull 4 [%v1[5]]; smulj %mlal [%v7[0],%v7[1],%v7[2],%v7[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v7.8h, v1.h[5]                    #! PC = 0x5555551e4c *)
broadcast %mull 4 [%v1[5]]; smulj %mlal [%v7[4],%v7[5],%v7[6],%v7[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v7.16b, v6.16b, v18.16b, #4                 #! PC = 0x5555551e50 *)
mov %v7 [%v6[2],%v6[3],%v6[4],%v6[5],%v6[6],%v6[7],%v18[0],%v18[1]];
(* smlal	v3.4s, v7.4h, v1.h[6]                     #! PC = 0x5555551e54 *)
broadcast %mull 4 [%v1[6]]; smulj %mlal [%v7[0],%v7[1],%v7[2],%v7[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v7.8h, v1.h[6]                    #! PC = 0x5555551e58 *)
broadcast %mull 4 [%v1[6]]; smulj %mlal [%v7[4],%v7[5],%v7[6],%v7[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v6.16b, v6.16b, v18.16b, #2                 #! PC = 0x5555551e5c *)
mov %v6 [%v6[1],%v6[2],%v6[3],%v6[4],%v6[5],%v6[6],%v6[7],%v18[0]];
(* smlal	v3.4s, v6.4h, v1.h[7]                     #! PC = 0x5555551e60 *)
broadcast %mull 4 [%v1[7]]; smulj %mlal [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; adds %dc %v3 %v3 %mlal;
(* smlal2	v2.4s, v6.8h, v1.h[7]                    #! PC = 0x5555551e64 *)
broadcast %mull 4 [%v1[7]]; smulj %mlal [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; adds %dc %v2 %v2 %mlal;

ghost %conv0_8@sint32[8], %conv1_8@sint32[8] :
    %conv0_8 = [
        %fc0_8[0] * %fd0_8[0] + %fc0_8[1] * %gd0_8[7] + %fc0_8[2] * %gd0_8[6] + %fc0_8[3] * %gd0_8[5] + %fc0_8[4] * %gd0_8[4] + %fc0_8[5] * %gd0_8[3] + %fc0_8[6] * %gd0_8[2] + %fc0_8[7] * %gd0_8[1],
        %fc0_8[0] * %fd0_8[1] + %fc0_8[1] * %fd0_8[0] + %fc0_8[2] * %gd0_8[7] + %fc0_8[3] * %gd0_8[6] + %fc0_8[4] * %gd0_8[5] + %fc0_8[5] * %gd0_8[4] + %fc0_8[6] * %gd0_8[3] + %fc0_8[7] * %gd0_8[2],
        %fc0_8[0] * %fd0_8[2] + %fc0_8[1] * %fd0_8[1] + %fc0_8[2] * %fd0_8[0] + %fc0_8[3] * %gd0_8[7] + %fc0_8[4] * %gd0_8[6] + %fc0_8[5] * %gd0_8[5] + %fc0_8[6] * %gd0_8[4] + %fc0_8[7] * %gd0_8[3],
        %fc0_8[0] * %fd0_8[3] + %fc0_8[1] * %fd0_8[2] + %fc0_8[2] * %fd0_8[1] + %fc0_8[3] * %fd0_8[0] + %fc0_8[4] * %gd0_8[7] + %fc0_8[5] * %gd0_8[6] + %fc0_8[6] * %gd0_8[5] + %fc0_8[7] * %gd0_8[4],
        %fc0_8[0] * %fd0_8[4] + %fc0_8[1] * %fd0_8[3] + %fc0_8[2] * %fd0_8[2] + %fc0_8[3] * %fd0_8[1] + %fc0_8[4] * %fd0_8[0] + %fc0_8[5] * %gd0_8[7] + %fc0_8[6] * %gd0_8[6] + %fc0_8[7] * %gd0_8[5],
        %fc0_8[0] * %fd0_8[5] + %fc0_8[1] * %fd0_8[4] + %fc0_8[2] * %fd0_8[3] + %fc0_8[3] * %fd0_8[2] + %fc0_8[4] * %fd0_8[1] + %fc0_8[5] * %fd0_8[0] + %fc0_8[6] * %gd0_8[7] + %fc0_8[7] * %gd0_8[6],
        %fc0_8[0] * %fd0_8[6] + %fc0_8[1] * %fd0_8[5] + %fc0_8[2] * %fd0_8[4] + %fc0_8[3] * %fd0_8[3] + %fc0_8[4] * %fd0_8[2] + %fc0_8[5] * %fd0_8[1] + %fc0_8[6] * %fd0_8[0] + %fc0_8[7] * %gd0_8[7],
        %fc0_8[0] * %fd0_8[7] + %fc0_8[1] * %fd0_8[6] + %fc0_8[2] * %fd0_8[5] + %fc0_8[3] * %fd0_8[4] + %fc0_8[4] * %fd0_8[3] + %fc0_8[5] * %fd0_8[2] + %fc0_8[6] * %fd0_8[1] + %fc0_8[7] * %fd0_8[0]
    ] /\
    %conv1_8 = [
        %fc1_8[0] * %fd1_8[0] + %fc1_8[1] * %gd1_8[7] + %fc1_8[2] * %gd1_8[6] + %fc1_8[3] * %gd1_8[5] + %fc1_8[4] * %gd1_8[4] + %fc1_8[5] * %gd1_8[3] + %fc1_8[6] * %gd1_8[2] + %fc1_8[7] * %gd1_8[1],
        %fc1_8[0] * %fd1_8[1] + %fc1_8[1] * %fd1_8[0] + %fc1_8[2] * %gd1_8[7] + %fc1_8[3] * %gd1_8[6] + %fc1_8[4] * %gd1_8[5] + %fc1_8[5] * %gd1_8[4] + %fc1_8[6] * %gd1_8[3] + %fc1_8[7] * %gd1_8[2],
        %fc1_8[0] * %fd1_8[2] + %fc1_8[1] * %fd1_8[1] + %fc1_8[2] * %fd1_8[0] + %fc1_8[3] * %gd1_8[7] + %fc1_8[4] * %gd1_8[6] + %fc1_8[5] * %gd1_8[5] + %fc1_8[6] * %gd1_8[4] + %fc1_8[7] * %gd1_8[3],
        %fc1_8[0] * %fd1_8[3] + %fc1_8[1] * %fd1_8[2] + %fc1_8[2] * %fd1_8[1] + %fc1_8[3] * %fd1_8[0] + %fc1_8[4] * %gd1_8[7] + %fc1_8[5] * %gd1_8[6] + %fc1_8[6] * %gd1_8[5] + %fc1_8[7] * %gd1_8[4],
        %fc1_8[0] * %fd1_8[4] + %fc1_8[1] * %fd1_8[3] + %fc1_8[2] * %fd1_8[2] + %fc1_8[3] * %fd1_8[1] + %fc1_8[4] * %fd1_8[0] + %fc1_8[5] * %gd1_8[7] + %fc1_8[6] * %gd1_8[6] + %fc1_8[7] * %gd1_8[5],
        %fc1_8[0] * %fd1_8[5] + %fc1_8[1] * %fd1_8[4] + %fc1_8[2] * %fd1_8[3] + %fc1_8[3] * %fd1_8[2] + %fc1_8[4] * %fd1_8[1] + %fc1_8[5] * %fd1_8[0] + %fc1_8[6] * %gd1_8[7] + %fc1_8[7] * %gd1_8[6],
        %fc1_8[0] * %fd1_8[6] + %fc1_8[1] * %fd1_8[5] + %fc1_8[2] * %fd1_8[4] + %fc1_8[3] * %fd1_8[3] + %fc1_8[4] * %fd1_8[2] + %fc1_8[5] * %fd1_8[1] + %fc1_8[6] * %fd1_8[0] + %fc1_8[7] * %gd1_8[7],
        %fc1_8[0] * %fd1_8[7] + %fc1_8[1] * %fd1_8[6] + %fc1_8[2] * %fd1_8[5] + %fc1_8[3] * %fd1_8[4] + %fc1_8[4] * %fd1_8[3] + %fc1_8[5] * %fd1_8[2] + %fc1_8[6] * %fd1_8[1] + %fc1_8[7] * %fd1_8[0]
    ]
    && true;

assert
    %v0 ++ %v4 = %conv0_8 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] ) /\
    %v3 ++ %v2 = %conv1_8 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] )
    && true;

assume
    %v0 ++ %v4 = %conv0_8 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] ) /\
    %v3 ++ %v2 = %conv1_8 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] )
    && true;

assert
    %conv0_8 <= [524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000] /\
    %conv0_8 >= [-524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000] /\

    %conv1_8 <= [524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000] /\
    %conv1_8 >= [-524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000]
    prove with [algebra solver smt: z3]
    && true;

assume
    %conv0_8 <= [524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000] /\
    %conv0_8 >= [-524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000] /\

    %conv1_8 <= [524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000, 524880000] /\
    %conv1_8 >= [-524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000, -524880000]
    && true;

assert
    %v0 ++ %v4 = %conv0_8 /\ %v3 ++ %v2 = %conv1_8
    prove with [algebra solver isl]
    && true;

assume
    %v0 ++ %v4 = %conv0_8 /\ %v3 ++ %v2 = %conv1_8
    && true;

assert
    %v0 <= [524880000, 524880000, 524880000, 524880000] /\
    %v0 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v4 <= [524880000, 524880000, 524880000, 524880000] /\
    %v4 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v3 <= [524880000, 524880000, 524880000, 524880000] /\
    %v3 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v2 <= [524880000, 524880000, 524880000, 524880000] /\
    %v2 >= [-524880000, -524880000, -524880000, -524880000]

    prove with [algebra solver isl]
    && true;

assume
    %v0 <= [524880000, 524880000, 524880000, 524880000] /\
    %v0 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v4 <= [524880000, 524880000, 524880000, 524880000] /\
    %v4 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v3 <= [524880000, 524880000, 524880000, 524880000] /\
    %v3 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v2 <= [524880000, 524880000, 524880000, 524880000] /\
    %v2 >= [-524880000, -524880000, -524880000, -524880000]
  &&
    %v0 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v0 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32] /\

    %v4 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v4 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32] /\

    %v3 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v3 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32] /\

    %v2 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v2 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32];

cut (* 35 *)
    %conv0_8 = [
        %fc0_8[0] * %fd0_8[0] + %fc0_8[1] * %gd0_8[7] + %fc0_8[2] * %gd0_8[6] + %fc0_8[3] * %gd0_8[5] + %fc0_8[4] * %gd0_8[4] + %fc0_8[5] * %gd0_8[3] + %fc0_8[6] * %gd0_8[2] + %fc0_8[7] * %gd0_8[1],
        %fc0_8[0] * %fd0_8[1] + %fc0_8[1] * %fd0_8[0] + %fc0_8[2] * %gd0_8[7] + %fc0_8[3] * %gd0_8[6] + %fc0_8[4] * %gd0_8[5] + %fc0_8[5] * %gd0_8[4] + %fc0_8[6] * %gd0_8[3] + %fc0_8[7] * %gd0_8[2],
        %fc0_8[0] * %fd0_8[2] + %fc0_8[1] * %fd0_8[1] + %fc0_8[2] * %fd0_8[0] + %fc0_8[3] * %gd0_8[7] + %fc0_8[4] * %gd0_8[6] + %fc0_8[5] * %gd0_8[5] + %fc0_8[6] * %gd0_8[4] + %fc0_8[7] * %gd0_8[3],
        %fc0_8[0] * %fd0_8[3] + %fc0_8[1] * %fd0_8[2] + %fc0_8[2] * %fd0_8[1] + %fc0_8[3] * %fd0_8[0] + %fc0_8[4] * %gd0_8[7] + %fc0_8[5] * %gd0_8[6] + %fc0_8[6] * %gd0_8[5] + %fc0_8[7] * %gd0_8[4],
        %fc0_8[0] * %fd0_8[4] + %fc0_8[1] * %fd0_8[3] + %fc0_8[2] * %fd0_8[2] + %fc0_8[3] * %fd0_8[1] + %fc0_8[4] * %fd0_8[0] + %fc0_8[5] * %gd0_8[7] + %fc0_8[6] * %gd0_8[6] + %fc0_8[7] * %gd0_8[5],
        %fc0_8[0] * %fd0_8[5] + %fc0_8[1] * %fd0_8[4] + %fc0_8[2] * %fd0_8[3] + %fc0_8[3] * %fd0_8[2] + %fc0_8[4] * %fd0_8[1] + %fc0_8[5] * %fd0_8[0] + %fc0_8[6] * %gd0_8[7] + %fc0_8[7] * %gd0_8[6],
        %fc0_8[0] * %fd0_8[6] + %fc0_8[1] * %fd0_8[5] + %fc0_8[2] * %fd0_8[4] + %fc0_8[3] * %fd0_8[3] + %fc0_8[4] * %fd0_8[2] + %fc0_8[5] * %fd0_8[1] + %fc0_8[6] * %fd0_8[0] + %fc0_8[7] * %gd0_8[7],
        %fc0_8[0] * %fd0_8[7] + %fc0_8[1] * %fd0_8[6] + %fc0_8[2] * %fd0_8[5] + %fc0_8[3] * %fd0_8[4] + %fc0_8[4] * %fd0_8[3] + %fc0_8[5] * %fd0_8[2] + %fc0_8[6] * %fd0_8[1] + %fc0_8[7] * %fd0_8[0]
    ] /\
    %conv1_8 = [
        %fc1_8[0] * %fd1_8[0] + %fc1_8[1] * %gd1_8[7] + %fc1_8[2] * %gd1_8[6] + %fc1_8[3] * %gd1_8[5] + %fc1_8[4] * %gd1_8[4] + %fc1_8[5] * %gd1_8[3] + %fc1_8[6] * %gd1_8[2] + %fc1_8[7] * %gd1_8[1],
        %fc1_8[0] * %fd1_8[1] + %fc1_8[1] * %fd1_8[0] + %fc1_8[2] * %gd1_8[7] + %fc1_8[3] * %gd1_8[6] + %fc1_8[4] * %gd1_8[5] + %fc1_8[5] * %gd1_8[4] + %fc1_8[6] * %gd1_8[3] + %fc1_8[7] * %gd1_8[2],
        %fc1_8[0] * %fd1_8[2] + %fc1_8[1] * %fd1_8[1] + %fc1_8[2] * %fd1_8[0] + %fc1_8[3] * %gd1_8[7] + %fc1_8[4] * %gd1_8[6] + %fc1_8[5] * %gd1_8[5] + %fc1_8[6] * %gd1_8[4] + %fc1_8[7] * %gd1_8[3],
        %fc1_8[0] * %fd1_8[3] + %fc1_8[1] * %fd1_8[2] + %fc1_8[2] * %fd1_8[1] + %fc1_8[3] * %fd1_8[0] + %fc1_8[4] * %gd1_8[7] + %fc1_8[5] * %gd1_8[6] + %fc1_8[6] * %gd1_8[5] + %fc1_8[7] * %gd1_8[4],
        %fc1_8[0] * %fd1_8[4] + %fc1_8[1] * %fd1_8[3] + %fc1_8[2] * %fd1_8[2] + %fc1_8[3] * %fd1_8[1] + %fc1_8[4] * %fd1_8[0] + %fc1_8[5] * %gd1_8[7] + %fc1_8[6] * %gd1_8[6] + %fc1_8[7] * %gd1_8[5],
        %fc1_8[0] * %fd1_8[5] + %fc1_8[1] * %fd1_8[4] + %fc1_8[2] * %fd1_8[3] + %fc1_8[3] * %fd1_8[2] + %fc1_8[4] * %fd1_8[1] + %fc1_8[5] * %fd1_8[0] + %fc1_8[6] * %gd1_8[7] + %fc1_8[7] * %gd1_8[6],
        %fc1_8[0] * %fd1_8[6] + %fc1_8[1] * %fd1_8[5] + %fc1_8[2] * %fd1_8[4] + %fc1_8[3] * %fd1_8[3] + %fc1_8[4] * %fd1_8[2] + %fc1_8[5] * %fd1_8[1] + %fc1_8[6] * %fd1_8[0] + %fc1_8[7] * %gd1_8[7],
        %fc1_8[0] * %fd1_8[7] + %fc1_8[1] * %fd1_8[6] + %fc1_8[2] * %fd1_8[5] + %fc1_8[3] * %fd1_8[4] + %fc1_8[4] * %fd1_8[3] + %fc1_8[5] * %fd1_8[2] + %fc1_8[6] * %fd1_8[1] + %fc1_8[7] * %fd1_8[0]
    ] /\

    %v0 ++ %v4 = %conv0_8 /\ %v3 ++ %v2 = %conv1_8,

    %v0 <= [524880000, 524880000, 524880000, 524880000] /\
    %v0 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v4 <= [524880000, 524880000, 524880000, 524880000] /\
    %v4 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v3 <= [524880000, 524880000, 524880000, 524880000] /\
    %v3 >= [-524880000, -524880000, -524880000, -524880000] /\

    %v2 <= [524880000, 524880000, 524880000, 524880000] /\
    %v2 >= [-524880000, -524880000, -524880000, -524880000]

    prove with [algebra solver isl]
  &&
    %v0 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v0 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32] /\

    %v4 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v4 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32] /\

    %v3 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v3 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32] /\

    %v2 <=s [524880000@32, 524880000@32, 524880000@32, 524880000@32] /\
    %v2 >=s [(-524880000)@32, (-524880000)@32, (-524880000)@32, (-524880000)@32];

(* add	v1.4s, v3.4s, v0.4s                         #! PC = 0x5555551e68 *)
add %v1 %v3 %v0;
(* add	v6.4s, v2.4s, v4.4s                         #! PC = 0x5555551e6c *)
add %v6 %v2 %v4;
(* sub	v0.4s, v0.4s, v3.4s                         #! PC = 0x5555551e70 *)
sub %v0 %v0 %v3;
(* sub	v4.4s, v4.4s, v2.4s                         #! PC = 0x5555551e74 *)
sub %v4 %v4 %v2;

ghost %h0_8@sint32[8], %h1_8@sint32[8] :
    %h0_8 = %v1 ++ %v6 /\ %h1_8 = %v0 ++ %v4
  &&
    %h0_8 = %v1 ++ %v6 /\ %h1_8 = %v0 ++ %v4;

(* uzp1	v2.8h, v1.8h, v6.8h                        #! PC = 0x5555551e78 *)
mov %spl_join [%v1[0], %v1[1], %v1[2], %v1[3], %v6[0], %v6[1], %v6[2], %v6[3]]; spl %splh %v2 %spl_join 16; cast %v2@int16[8] %v2;
(* mul	v2.8h, v2.8h, v5.h[7]                       #! PC = 0x5555551e7c *)
broadcast %mul 8 [%v5[7]]; mull %dc %v2 %v2 %mul; cast %v2@int16[8] %v2;

ghost %m0_8@sint16[8] : %m0_8 = %v2 && %m0_8 = %v2;

(* sqdmulh	v2.8h, v2.8h, v5.h[6]                   #! PC = 0x5555551e80 *)
broadcast %mul 8 [%v5[6]]; smulj %LO %v2 %mul;
ssplit %LO0 %dc %LO 15; vpc %v2@sint16[8] %LO0;
(* uzp2	v1.8h, v1.8h, v6.8h                        #! PC = 0x5555551e84 *)
mov %spl_join [%v1[0], %v1[1], %v1[2], %v1[3], %v6[0], %v6[1], %v6[2], %v6[3]]; spl %v1 %spll %spl_join 16;
(* sshr	v2.8h, v2.8h, #1                           #! PC = 0x5555551e88 *)
split %v2 %dc %v2 1;
(* sub	v1.8h, v1.8h, v2.8h                         #! PC = 0x5555551e8c *)
sub %v1 %v1 %v2;

ghost %hh0_8@sint16[8] : %hh0_8 = %v1 && %hh0_8 = %v1;

assert
    %h0_8 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m0_8
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh0_8
    prove with [algebra solver isl]
    && true;

assume
    %h0_8 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m0_8
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh0_8
    && true;

(* sqrdmulh	v2.8h, v1.8h, v5.h[3]                  #! PC = 0x5555551e90 *)
broadcast %mul 8 [%v5[3]]; smulj %LO %v1 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v2 %LO11 %LO01;
(* mul	v1.8h, v1.8h, v5.h[2]                       #! PC = 0x5555551e94 *)
broadcast %mul 8 [%v5[2]]; mull %dc %v1 %v1 %mul; cast %v1@int16[8] %v1;
(* mls	v1.8h, v2.8h, v5.h[6]                       #! PC = 0x5555551e98 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v2 %mul;
cast %mls@int16[8] %mls; subc %dc %v1 %v1 %mls;

assert
    [-1095, -1095, -1095, -1095, -1095, -1095, -1095, -1095] * %hh0_8
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v2
    = %v1
    prove with [algebra solver isl]
    && true;

assume
    [-1095, -1095, -1095, -1095, -1095, -1095, -1095, -1095] * %hh0_8
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v2
    = %v1
    && true;

(* uzp1	v2.8h, v0.8h, v4.8h                        #! PC = 0x5555551e9c *)
mov %spl_join [%v0[0], %v0[1], %v0[2], %v0[3], %v4[0], %v4[1], %v4[2], %v4[3]]; spl %splh %v2 %spl_join 16; cast %v2@int16[8] %v2;
(* mul	v2.8h, v2.8h, v5.h[7]                       #! PC = 0x5555551ea0 *)
broadcast %mul 8 [%v5[7]]; mull %dc %v2 %v2 %mul; cast %v2@int16[8] %v2;

ghost %m1_8@sint16[8] : %m1_8 = %v2 && %m1_8 = %v2;

(* sqdmulh	v2.8h, v2.8h, v5.h[6]                   #! PC = 0x5555551ea4 *)
broadcast %mul 8 [%v5[6]]; smulj %LO %v2 %mul;
ssplit %LO0 %dc %LO 15; vpc %v2@sint16[8] %LO0;
(* uzp2	v0.8h, v0.8h, v4.8h                        #! PC = 0x5555551ea8 *)
mov %spl_join [%v0[0], %v0[1], %v0[2], %v0[3], %v4[0], %v4[1], %v4[2], %v4[3]]; spl %v0 %spll %spl_join 16;
(* sshr	v2.8h, v2.8h, #1                           #! PC = 0x5555551eac *)
split %v2 %dc %v2 1;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551eb0 *)
sub %v0 %v0 %v2;

ghost %hh1_8@sint16[8] : %hh1_8 = %v0 && %hh1_8 = %v0;

assert
    %h1_8 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m1_8
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh1_8
    prove with [algebra solver isl]
    && true;

assume
    %h1_8 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m1_8
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh1_8
    && true;

(* sqrdmulh	v2.8h, v0.8h, v5.h[5]                  #! PC = 0x5555551eb4 *)
broadcast %mul 8 [%v5[5]]; smulj %LO %v0 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v2 %LO11 %LO01;
(* mul	v0.8h, v0.8h, v5.h[4]                       #! PC = 0x5555551eb8 *)
broadcast %mul 8 [%v5[4]]; mull %dc %v0 %v0 %mul; cast %v0@int16[8] %v0;
(* mls	v0.8h, v2.8h, v5.h[6]                       #! PC = 0x5555551ebc *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v2 %mul;
cast %mls@int16[8] %mls; subc %dc %v0 %v0 %mls;

assert
    [-6, -6, -6, -6, -6, -6, -6, -6] * %hh1_8
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v2
    = %v0
    prove with [algebra solver isl]
    && true;

assume
    [-6, -6, -6, -6, -6, -6, -6, -6] * %hh1_8
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v2
    = %v0
    && true;

(* #b	0x5555551d18 <_ZN6xpower7basemul11low_basemulEPA2_A8_sS3_S3_+504>#! PC = 0x5555551ec0 *)
#b	0x5555551d18 <_ZN6xpower7basemul11low_basemulEPA2_A8_sS3_S3_+504>#! 0x5555551ec0 = 0x5555551ec0;


### i_iter epilogue

(* str	q1, [x2, x3]                                #! EA = L0x7fffffe2b0; PC = 0x5555551d18 *)
mov [L0x7fffffe2b0,L0x7fffffe2b2,L0x7fffffe2b4,L0x7fffffe2b6,L0x7fffffe2b8,L0x7fffffe2ba,L0x7fffffe2bc,L0x7fffffe2be] %v1;
(* str	q0, [x6, x3]                                #! EA = L0x7fffffe2c0; PC = 0x5555551d1c *)
mov [L0x7fffffe2c0,L0x7fffffe2c2,L0x7fffffe2c4,L0x7fffffe2c6,L0x7fffffe2c8,L0x7fffffe2ca,L0x7fffffe2cc,L0x7fffffe2ce] %v0;
(* #b.eq	0x5555551ec4 <_ZN6xpower7basemul11low_basemulEPA2_A8_sS3_S3_+932>  // b.none#! PC = 0x5555551d30 *)
#b.eq	0x5555551ec4 <_ZN6xpower7basemul11low_basemulEPA2_A8_sS3_S3_+932>  // b.none#! 0x5555551d30 = 0x5555551d30;

assert
    %v1 <= [4580, 4580, 4580, 4580, 4580, 4580, 4580, 4580] /\
    %v1 >= [-4580, -4580, -4580, -4580, -4580, -4580, -4580, -4580] /\

    %v0 <= [3100, 3100, 3100, 3100, 3100, 3100, 3100, 3100] /\
    %v0 >= [-3100, -3100, -3100, -3100, -3100, -3100, -3100, -3100]

    prove with [algebra solver isl]
    && true;

assume
    true &&

    %v1 <=s [4580@16, 4580@16, 4580@16, 4580@16, 4580@16, 4580@16, 4580@16, 4580@16] /\
    %v1 >=s [(-4580)@16, (-4580)@16, (-4580)@16, (-4580)@16, (-4580)@16, (-4580)@16, (-4580)@16, (-4580)@16] /\

    %v0 <=s [3100@16, 3100@16, 3100@16, 3100@16, 3100@16, 3100@16, 3100@16, 3100@16] /\
    %v0 >=s [(-3100)@16, (-3100)@16, (-3100)@16, (-3100)@16, (-3100)@16, (-3100)@16, (-3100)@16, (-3100)@16];

cut (* 36 *)
    [L0x7fffffe2b0, L0x7fffffe2b2, L0x7fffffe2b4, L0x7fffffe2b6, L0x7fffffe2b8, L0x7fffffe2ba, L0x7fffffe2bc, L0x7fffffe2be] = %v1 /\
    [L0x7fffffe2c0, L0x7fffffe2c2, L0x7fffffe2c4, L0x7fffffe2c6, L0x7fffffe2c8, L0x7fffffe2ca, L0x7fffffe2cc, L0x7fffffe2ce] = %v0 /\

    %v1 ++ %v0 = [1548, 1548, 1548, 1548, 1548, 1548, 1548, 1548, 1548, 1548, 1548, 1548, 1548, 1548, 1548, 1548] * [
        arr800_a * arr800_b + -2274 * arr801_a * arr817_b + -2274 * arr802_a * arr816_b + -2274 * arr803_a * arr815_b + -2274 * arr804_a * arr814_b + -2274 * arr805_a * arr813_b + -2274 * arr806_a * arr812_b + -2274 * arr807_a * arr811_b + -2274 * arr810_a * arr810_b + -2274 * arr811_a * arr807_b + -2274 * arr812_a * arr806_b + -2274 * arr813_a * arr805_b + -2274 * arr814_a * arr804_b + -2274 * arr815_a * arr803_b + -2274 * arr816_a * arr802_b + -2274 * arr817_a * arr801_b,
        arr800_a * arr801_b + arr801_a * arr800_b + -2274 * arr802_a * arr817_b + -2274 * arr803_a * arr816_b + -2274 * arr804_a * arr815_b + -2274 * arr805_a * arr814_b + -2274 * arr806_a * arr813_b + -2274 * arr807_a * arr812_b + -2274 * arr810_a * arr811_b + -2274 * arr811_a * arr810_b + -2274 * arr812_a * arr807_b + -2274 * arr813_a * arr806_b + -2274 * arr814_a * arr805_b + -2274 * arr815_a * arr804_b + -2274 * arr816_a * arr803_b + -2274 * arr817_a * arr802_b,
        arr800_a * arr802_b + arr801_a * arr801_b + arr802_a * arr800_b + -2274 * arr803_a * arr817_b + -2274 * arr804_a * arr816_b + -2274 * arr805_a * arr815_b + -2274 * arr806_a * arr814_b + -2274 * arr807_a * arr813_b + -2274 * arr810_a * arr812_b + -2274 * arr811_a * arr811_b + -2274 * arr812_a * arr810_b + -2274 * arr813_a * arr807_b + -2274 * arr814_a * arr806_b + -2274 * arr815_a * arr805_b + -2274 * arr816_a * arr804_b + -2274 * arr817_a * arr803_b,
        arr800_a * arr803_b + arr801_a * arr802_b + arr802_a * arr801_b + arr803_a * arr800_b + -2274 * arr804_a * arr817_b + -2274 * arr805_a * arr816_b + -2274 * arr806_a * arr815_b + -2274 * arr807_a * arr814_b + -2274 * arr810_a * arr813_b + -2274 * arr811_a * arr812_b + -2274 * arr812_a * arr811_b + -2274 * arr813_a * arr810_b + -2274 * arr814_a * arr807_b + -2274 * arr815_a * arr806_b + -2274 * arr816_a * arr805_b + -2274 * arr817_a * arr804_b,
        arr800_a * arr804_b + arr801_a * arr803_b + arr802_a * arr802_b + arr803_a * arr801_b + arr804_a * arr800_b + -2274 * arr805_a * arr817_b + -2274 * arr806_a * arr816_b + -2274 * arr807_a * arr815_b + -2274 * arr810_a * arr814_b + -2274 * arr811_a * arr813_b + -2274 * arr812_a * arr812_b + -2274 * arr813_a * arr811_b + -2274 * arr814_a * arr810_b + -2274 * arr815_a * arr807_b + -2274 * arr816_a * arr806_b + -2274 * arr817_a * arr805_b,
        arr800_a * arr805_b + arr801_a * arr804_b + arr802_a * arr803_b + arr803_a * arr802_b + arr804_a * arr801_b + arr805_a * arr800_b + -2274 * arr806_a * arr817_b + -2274 * arr807_a * arr816_b + -2274 * arr810_a * arr815_b + -2274 * arr811_a * arr814_b + -2274 * arr812_a * arr813_b + -2274 * arr813_a * arr812_b + -2274 * arr814_a * arr811_b + -2274 * arr815_a * arr810_b + -2274 * arr816_a * arr807_b + -2274 * arr817_a * arr806_b,
        arr800_a * arr806_b + arr801_a * arr805_b + arr802_a * arr804_b + arr803_a * arr803_b + arr804_a * arr802_b + arr805_a * arr801_b + arr806_a * arr800_b + -2274 * arr807_a * arr817_b + -2274 * arr810_a * arr816_b + -2274 * arr811_a * arr815_b + -2274 * arr812_a * arr814_b + -2274 * arr813_a * arr813_b + -2274 * arr814_a * arr812_b + -2274 * arr815_a * arr811_b + -2274 * arr816_a * arr810_b + -2274 * arr817_a * arr807_b,
        arr800_a * arr807_b + arr801_a * arr806_b + arr802_a * arr805_b + arr803_a * arr804_b + arr804_a * arr803_b + arr805_a * arr802_b + arr806_a * arr801_b + arr807_a * arr800_b + -2274 * arr810_a * arr817_b + -2274 * arr811_a * arr816_b + -2274 * arr812_a * arr815_b + -2274 * arr813_a * arr814_b + -2274 * arr814_a * arr813_b + -2274 * arr815_a * arr812_b + -2274 * arr816_a * arr811_b + -2274 * arr817_a * arr810_b,
        arr800_a * arr810_b + arr801_a * arr807_b + arr802_a * arr806_b + arr803_a * arr805_b + arr804_a * arr804_b + arr805_a * arr803_b + arr806_a * arr802_b + arr807_a * arr801_b + arr810_a * arr800_b + -2274 * arr811_a * arr817_b + -2274 * arr812_a * arr816_b + -2274 * arr813_a * arr815_b + -2274 * arr814_a * arr814_b + -2274 * arr815_a * arr813_b + -2274 * arr816_a * arr812_b + -2274 * arr817_a * arr811_b,
        arr800_a * arr811_b + arr801_a * arr810_b + arr802_a * arr807_b + arr803_a * arr806_b + arr804_a * arr805_b + arr805_a * arr804_b + arr806_a * arr803_b + arr807_a * arr802_b + arr810_a * arr801_b + arr811_a * arr800_b + -2274 * arr812_a * arr817_b + -2274 * arr813_a * arr816_b + -2274 * arr814_a * arr815_b + -2274 * arr815_a * arr814_b + -2274 * arr816_a * arr813_b + -2274 * arr817_a * arr812_b,
        arr800_a * arr812_b + arr801_a * arr811_b + arr802_a * arr810_b + arr803_a * arr807_b + arr804_a * arr806_b + arr805_a * arr805_b + arr806_a * arr804_b + arr807_a * arr803_b + arr810_a * arr802_b + arr811_a * arr801_b + arr812_a * arr800_b + -2274 * arr813_a * arr817_b + -2274 * arr814_a * arr816_b + -2274 * arr815_a * arr815_b + -2274 * arr816_a * arr814_b + -2274 * arr817_a * arr813_b,
        arr800_a * arr813_b + arr801_a * arr812_b + arr802_a * arr811_b + arr803_a * arr810_b + arr804_a * arr807_b + arr805_a * arr806_b + arr806_a * arr805_b + arr807_a * arr804_b + arr810_a * arr803_b + arr811_a * arr802_b + arr812_a * arr801_b + arr813_a * arr800_b + -2274 * arr814_a * arr817_b + -2274 * arr815_a * arr816_b + -2274 * arr816_a * arr815_b + -2274 * arr817_a * arr814_b,
        arr800_a * arr814_b + arr801_a * arr813_b + arr802_a * arr812_b + arr803_a * arr811_b + arr804_a * arr810_b + arr805_a * arr807_b + arr806_a * arr806_b + arr807_a * arr805_b + arr810_a * arr804_b + arr811_a * arr803_b + arr812_a * arr802_b + arr813_a * arr801_b + arr814_a * arr800_b + -2274 * arr815_a * arr817_b + -2274 * arr816_a * arr816_b + -2274 * arr817_a * arr815_b,
        arr800_a * arr815_b + arr801_a * arr814_b + arr802_a * arr813_b + arr803_a * arr812_b + arr804_a * arr811_b + arr805_a * arr810_b + arr806_a * arr807_b + arr807_a * arr806_b + arr810_a * arr805_b + arr811_a * arr804_b + arr812_a * arr803_b + arr813_a * arr802_b + arr814_a * arr801_b + arr815_a * arr800_b + -2274 * arr816_a * arr817_b + -2274 * arr817_a * arr816_b,
        arr800_a * arr816_b + arr801_a * arr815_b + arr802_a * arr814_b + arr803_a * arr813_b + arr804_a * arr812_b + arr805_a * arr811_b + arr806_a * arr810_b + arr807_a * arr807_b + arr810_a * arr806_b + arr811_a * arr805_b + arr812_a * arr804_b + arr813_a * arr803_b + arr814_a * arr802_b + arr815_a * arr801_b + arr816_a * arr800_b + -2274 * arr817_a * arr817_b,
        arr800_a * arr817_b + arr801_a * arr816_b + arr802_a * arr815_b + arr803_a * arr814_b + arr804_a * arr813_b + arr805_a * arr812_b + arr806_a * arr811_b + arr807_a * arr810_b + arr810_a * arr807_b + arr811_a * arr806_b + arr812_a * arr805_b + arr813_a * arr804_b + arr814_a * arr803_b + arr815_a * arr802_b + arr816_a * arr801_b + arr817_a * arr800_b
    ] ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] )

    prove with [cuts[0, 33, 34, 35]]
  &&
    [L0x7fffffe2b0, L0x7fffffe2b2, L0x7fffffe2b4, L0x7fffffe2b6, L0x7fffffe2b8, L0x7fffffe2ba, L0x7fffffe2bc, L0x7fffffe2be] = %v1 /\
    [L0x7fffffe2c0, L0x7fffffe2c2, L0x7fffffe2c4, L0x7fffffe2c6, L0x7fffffe2c8, L0x7fffffe2ca, L0x7fffffe2cc, L0x7fffffe2ce] = %v0 /\

    %v1 <=s [4580@16, 4580@16, 4580@16, 4580@16, 4580@16, 4580@16, 4580@16, 4580@16] /\
    %v1 >=s [(-4580)@16, (-4580)@16, (-4580)@16, (-4580)@16, (-4580)@16, (-4580)@16, (-4580)@16, (-4580)@16] /\

    %v0 <=s [3100@16, 3100@16, 3100@16, 3100@16, 3100@16, 3100@16, 3100@16, 3100@16] /\
    %v0 >=s [(-3100)@16, (-3100)@16, (-3100)@16, (-3100)@16, (-3100)@16, (-3100)@16, (-3100)@16, (-3100)@16];


### i_iter prologue

(* ldr	q4, [x0, x3]                                #! EA = L0x7fffffe550; Value = 0x0000000000000000; PC = 0x5555551d34 *)
mov %v4 [L0x7fffffe550,L0x7fffffe552,L0x7fffffe554,L0x7fffffe556,L0x7fffffe558,L0x7fffffe55a,L0x7fffffe55c,L0x7fffffe55e];
(* ldr	q1, [x8, x3]                                #! EA = L0x7fffffe560; Value = 0x0000000000000000; PC = 0x5555551d38 *)
mov %v1 [L0x7fffffe560,L0x7fffffe562,L0x7fffffe564,L0x7fffffe566,L0x7fffffe568,L0x7fffffe56a,L0x7fffffe56c,L0x7fffffe56e];
(* ldr	q17, [x1, x3]                               #! EA = L0x7fffffe410; Value = 0x0000000000000000; PC = 0x5555551d3c *)
mov %v17 [L0x7fffffe410,L0x7fffffe412,L0x7fffffe414,L0x7fffffe416,L0x7fffffe418,L0x7fffffe41a,L0x7fffffe41c,L0x7fffffe41e];
(* ldr	q18, [x7, x3]                               #! EA = L0x7fffffe420; Value = 0x0000000000000000; PC = 0x5555551d40 *)
mov %v18 [L0x7fffffe420,L0x7fffffe422,L0x7fffffe424,L0x7fffffe426,L0x7fffffe428,L0x7fffffe42a,L0x7fffffe42c,L0x7fffffe42e];

ghost %fa0_9@sint16[8], %fa1_9@sint16[8], %fb0_9@sint16[8], %fb1_9@sint16[8] :
    %fa0_9 = %v4 /\ %fa1_9 = %v1 /\ %fb0_9 = %v17 /\ %fb1_9 = %v18
  &&
    %fa0_9 = %v4 /\ %fa1_9 = %v1 /\ %fb0_9 = %v17 /\ %fb1_9 = %v18;

cut (* 37 *)
    %fa0_9 = %v4 /\ %fa1_9 = %v1 /\ %fb0_9 = %v17 /\ %fb1_9 = %v18 /\
    %fa0_9 = [arr900_a, arr901_a, arr902_a, arr903_a, arr904_a, arr905_a, arr906_a, arr907_a] /\
    %fa1_9 = [arr910_a, arr911_a, arr912_a, arr913_a, arr914_a, arr915_a, arr916_a, arr917_a] /\
    %fb0_9 = [arr900_b, arr901_b, arr902_b, arr903_b, arr904_b, arr905_b, arr906_b, arr907_b] /\
    %fb1_9 = [arr910_b, arr911_b, arr912_b, arr913_b, arr914_b, arr915_b, arr916_b, arr917_b]
    prove with [cuts[0]]
  &&
    %fa0_9 = %v4 /\ %fa1_9 = %v1 /\ %fb0_9 = %v17 /\ %fb1_9 = %v18 /\
    %fa0_9 = [arr900_a, arr901_a, arr902_a, arr903_a, arr904_a, arr905_a, arr906_a, arr907_a] /\
    %fa1_9 = [arr910_a, arr911_a, arr912_a, arr913_a, arr914_a, arr915_a, arr916_a, arr917_a] /\
    %fb0_9 = [arr900_b, arr901_b, arr902_b, arr903_b, arr904_b, arr905_b, arr906_b, arr907_b] /\
    %fb1_9 = [arr910_b, arr911_b, arr912_b, arr913_b, arr914_b, arr915_b, arr916_b, arr917_b]
    prove with [cuts[0]];

#### karatsuba

(* ldr	q5, [x5]                                    #! EA = L0x5555552e90; Value = 0x0056000c3ae90841; PC = 0x5555551b44 *)
mov %v5 [L0x5555552e90,L0x5555552e92,L0x5555552e94,L0x5555552e96,L0x5555552e98,L0x5555552e9a,L0x5555552e9c,L0x5555552e9e];
(* sshr	v0.8h, v4.8h, #12                          #! PC = 0x5555551b48 *)
split %v0 %dc %v4 12;
(* cmlt	v2.8h, v4.8h, #0                           #! PC = 0x5555551b4c *)
split %v2 %dc %v4 15;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551b50 *)
sub %v0 %v0 %v2;
(* mls	v4.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551b54 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v4 %v4 %mls;

assert
    %fa0_9 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v4
    prove with [algebra solver isl, precondition, cuts[0, 37]]
    && true;

assume
    %fa0_9 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v4
    && true;

(* sshr	v0.8h, v1.8h, #12                          #! PC = 0x5555551b58 *)
split %v0 %dc %v1 12;
(* cmlt	v2.8h, v1.8h, #0                           #! PC = 0x5555551b5c *)
split %v2 %dc %v1 15;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551b60 *)
sub %v0 %v0 %v2;
(* mls	v1.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551b64 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v1 %v1 %mls;

assert
    %fa1_9 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v1
    prove with [algebra solver isl, precondition, cuts[0, 37]]
    && true;

assume
    %fa1_9 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v1
    && true;

(* sshr	v0.8h, v17.8h, #12                         #! PC = 0x5555551b68 *)
split %v0 %dc %v17 12;
(* cmlt	v2.8h, v17.8h, #0                          #! PC = 0x5555551b6c *)
split %v2 %dc %v17 15;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551b70 *)
sub %v0 %v0 %v2;
(* mls	v17.8h, v0.8h, v5.h[6]                      #! PC = 0x5555551b74 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v17 %v17 %mls;

assert
    %fb0_9 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v17
    prove with [algebra solver isl, precondition, cuts[0, 37]]
    && true;

assume
    %fb0_9 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v17
    && true;

(* sshr	v0.8h, v18.8h, #12                         #! PC = 0x5555551b78 *)
split %v0 %dc %v18 12;
(* cmlt	v2.8h, v18.8h, #0                          #! PC = 0x5555551b7c *)
split %v2 %dc %v18 15;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551b80 *)
sub %v0 %v0 %v2;
(* mls	v18.8h, v0.8h, v5.h[6]                      #! PC = 0x5555551b84 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v18 %v18 %mls;

assert
    %fb1_9 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v18
    prove with [algebra solver isl, precondition, cuts[0, 37]]
    && true;

assume
    %fb1_9 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v18
    && true;

ghost %fc0_9@sint16[8], %fc1_9@sint16[8], %fd0_9@sint16[8], %fd1_9@sint16[8] :
    %fc0_9 = %v4 /\ %fc1_9 = %v1 /\ %fd0_9 = %v17 /\ %fd1_9 = %v18
  &&
    %fc0_9 = %v4 /\ %fc1_9 = %v1 /\ %fd0_9 = %v17 /\ %fd1_9 = %v18;

(* sqrdmulh	v0.8h, v17.8h, v5.h[1]                 #! PC = 0x5555551b88 *)
broadcast %mul 8 [%v5[1]]; smulj %LO %v17 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v0 %LO11 %LO01;
(* mul	v6.8h, v17.8h, v5.h[0]                      #! PC = 0x5555551b8c *)
broadcast %mul 8 [%v5[0]]; mull %dc %v6 %v17 %mul; cast %v6@int16[8] %v6;
(* mov	v7.16b, v6.16b                              #! PC = 0x5555551b90 *)
mov %v7 %v6;
(* mls	v7.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551b94 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v7 %v7 %mls;

assert
    [2113, 2113, 2113, 2113, 2113, 2113, 2113, 2113] * %fd0_9
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v7
    prove with [algebra solver isl, precondition, cuts[0, 37]]
    && true;

assume
    [2113, 2113, 2113, 2113, 2113, 2113, 2113, 2113] * %fd0_9
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v7
    && true;

(* sqrdmulh	v0.8h, v18.8h, v5.h[1]                 #! PC = 0x5555551b98 *)
broadcast %mul 8 [%v5[1]]; smulj %LO %v18 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v0 %LO11 %LO01;
(* mul	v3.8h, v18.8h, v5.h[0]                      #! PC = 0x5555551b9c *)
broadcast %mul 8 [%v5[0]]; mull %dc %v3 %v18 %mul; cast %v3@int16[8] %v3;
(* mls	v3.8h, v0.8h, v5.h[6]                       #! PC = 0x5555551ba0 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v0 %mul;
cast %mls@int16[8] %mls; subc %dc %v3 %v3 %mls;

assert
    [2113, 2113, 2113, 2113, 2113, 2113, 2113, 2113] * %fd1_9
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v3
    prove with [algebra solver isl, precondition, cuts[0, 37]]
    && true;

assume
    [2113, 2113, 2113, 2113, 2113, 2113, 2113, 2113] * %fd1_9
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v0
    = %v3
    && true;

ghost %fe0_9@sint16[8], %fe1_9@sint16[8] :
    %fe0_9 = %v7 /\ %fe1_9 = %v3
  &&
    %fe0_9 = %v7 /\ %fe1_9 = %v3;

cut (* 38 *)
    %fc0_9 = %v4 /\ %fc1_9 = %v1 /\ %fd0_9 = %v17 /\ %fd1_9 = %v18 /\ %fe0_9 = %v7 /\ %fe1_9 = %v3 /\

    %fc0_9 = %fa0_9 ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\
    %fc1_9 = %fa1_9 ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\
    %fd0_9 = %fb0_9 ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\
    %fd1_9 = %fb1_9 ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\

    %fe0_9 = [2113, 2113, 2113, 2113, 2113, 2113, 2113, 2113] * %fd0_9
    ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ) /\

    %fe1_9 = [2113, 2113, 2113, 2113, 2113, 2113, 2113, 2113] * %fd1_9
    ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] ),

    %fc0_9 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %fc0_9 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %fc1_9 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %fc1_9 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %fd0_9 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %fd0_9 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %fd1_9 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %fd1_9 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %fe0_9 <= [3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000] /\
    %fe0_9 >= [-3000, -3000, -3000, -3000, -3000, -3000, -3000, -3000] /\

    %fe1_9 <= [3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000] /\
    %fe1_9 >= [-3000, -3000, -3000, -3000, -3000, -3000, -3000, -3000]

    prove with [algebra solver isl, precondition, cuts[0, 37]]
  &&
    true
    prove with [precondition, cuts[0, 37]];

assert
    %v4 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %v4 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %v1 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %v1 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %v17 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %v17 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %v18 <= [4096, 4096, 4096, 4096, 4096, 4096, 4096, 4096] /\
    %v18 >= [-4096, -4096, -4096, -4096, -4096, -4096, -4096, -4096] /\

    %v7 <= [3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000] /\
    %v7 >= [-3000, -3000, -3000, -3000, -3000, -3000, -3000, -3000] /\

    %v3 <= [3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000] /\
    %v3 >= [-3000, -3000, -3000, -3000, -3000, -3000, -3000, -3000]

    prove with [algebra solver isl, cuts[38]]
    && true;

assume
    true &&
    %v4 <=s [4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16] /\
    %v4 >=s [(-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16] /\

    %v1 <=s [4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16] /\
    %v1 >=s [(-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16] /\

    %v17 <=s [4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16] /\
    %v17 >=s [(-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16] /\

    %v18 <=s [4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16, 4096@16] /\
    %v18 >=s [(-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16, (-4096)@16] /\

    %v7 <=s [3000@16, 3000@16, 3000@16, 3000@16, 3000@16, 3000@16, 3000@16, 3000@16] /\
    %v7 >=s [(-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16] /\

    %v3 <=s [3000@16, 3000@16, 3000@16, 3000@16, 3000@16, 3000@16, 3000@16, 3000@16] /\
    %v3 >=s [(-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16, (-3000)@16];

(* add	v6.8h, v4.8h, v1.8h                         #! PC = 0x5555551ba4 *)
add %v6 %v4 %v1;
(* smull	v0.4s, v17.4h, v6.h[0]                    #! PC = 0x5555551ba8 *)
broadcast %mull 4 [%v6[0]]; smulj %v0 [%v17[0],%v17[1],%v17[2],%v17[3]] %mull;
(* smull2	v2.4s, v17.8h, v6.h[0]                   #! PC = 0x5555551bac *)
broadcast %mull 4 [%v6[0]]; smulj %v2 [%v17[4],%v17[5],%v17[6],%v17[7]] %mull;
(* ext	v16.16b, v3.16b, v17.16b, #14               #! PC = 0x5555551bb0 *)
mov %v16 [%v3[7],%v17[0],%v17[1],%v17[2],%v17[3],%v17[4],%v17[5],%v17[6]];
(* smlal	v0.4s, v16.4h, v6.h[1]                    #! PC = 0x5555551bb4 *)
broadcast %mull 4 [%v6[1]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[1]                   #! PC = 0x5555551bb8 *)
broadcast %mull 4 [%v6[1]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v16.16b, v3.16b, v17.16b, #12               #! PC = 0x5555551bbc *)
mov %v16 [%v3[6],%v3[7],%v17[0],%v17[1],%v17[2],%v17[3],%v17[4],%v17[5]];
(* smlal	v0.4s, v16.4h, v6.h[2]                    #! PC = 0x5555551bc0 *)
broadcast %mull 4 [%v6[2]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[2]                   #! PC = 0x5555551bc4 *)
broadcast %mull 4 [%v6[2]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v16.16b, v3.16b, v17.16b, #10               #! PC = 0x5555551bc8 *)
mov %v16 [%v3[5],%v3[6],%v3[7],%v17[0],%v17[1],%v17[2],%v17[3],%v17[4]];
(* smlal	v0.4s, v16.4h, v6.h[3]                    #! PC = 0x5555551bcc *)
broadcast %mull 4 [%v6[3]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[3]                   #! PC = 0x5555551bd0 *)
broadcast %mull 4 [%v6[3]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v16.16b, v3.16b, v17.16b, #8                #! PC = 0x5555551bd4 *)
mov %v16 [%v3[4],%v3[5],%v3[6],%v3[7],%v17[0],%v17[1],%v17[2],%v17[3]];
(* smlal	v0.4s, v16.4h, v6.h[4]                    #! PC = 0x5555551bd8 *)
broadcast %mull 4 [%v6[4]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[4]                   #! PC = 0x5555551bdc *)
broadcast %mull 4 [%v6[4]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v16.16b, v3.16b, v17.16b, #6                #! PC = 0x5555551be0 *)
mov %v16 [%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v17[0],%v17[1],%v17[2]];
(* smlal	v0.4s, v16.4h, v6.h[5]                    #! PC = 0x5555551be4 *)
broadcast %mull 4 [%v6[5]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[5]                   #! PC = 0x5555551be8 *)
broadcast %mull 4 [%v6[5]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v16.16b, v3.16b, v17.16b, #4                #! PC = 0x5555551bec *)
mov %v16 [%v3[2],%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v17[0],%v17[1]];
(* smlal	v0.4s, v16.4h, v6.h[6]                    #! PC = 0x5555551bf0 *)
broadcast %mull 4 [%v6[6]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[6]                   #! PC = 0x5555551bf4 *)
broadcast %mull 4 [%v6[6]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* ext	v16.16b, v3.16b, v17.16b, #2                #! PC = 0x5555551bf8 *)
mov %v16 [%v3[1],%v3[2],%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v17[0]];
(* smlal	v0.4s, v16.4h, v6.h[7]                    #! PC = 0x5555551bfc *)
broadcast %mull 4 [%v6[7]]; smulj %mlal [%v16[0],%v16[1],%v16[2],%v16[3]] %mull; adds %dc %v0 %v0 %mlal;
(* smlal2	v2.4s, v16.8h, v6.h[7]                   #! PC = 0x5555551c00 *)
broadcast %mull 4 [%v6[7]]; smulj %mlal [%v16[4],%v16[5],%v16[6],%v16[7]] %mull; adds %dc %v2 %v2 %mlal;
(* sub	v6.8h, v7.8h, v3.8h                         #! PC = 0x5555551c04 *)
sub %v6 %v7 %v3;
(* sub	v3.8h, v3.8h, v17.8h                        #! PC = 0x5555551c08 *)
sub %v3 %v3 %v17;
(* mov	v16.16b, v0.16b                             #! PC = 0x5555551c0c *)
mov %v16 %v0;
(* smlal	v16.4s, v3.4h, v1.h[0]                    #! PC = 0x5555551c10 *)
broadcast %mull 4 [%v1[0]]; smulj %mlal [%v3[0],%v3[1],%v3[2],%v3[3]] %mull; adds %dc %v16 %v16 %mlal;
(* mov	v7.16b, v2.16b                              #! PC = 0x5555551c14 *)
mov %v7 %v2;
(* smlal2	v7.4s, v3.8h, v1.h[0]                    #! PC = 0x5555551c18 *)
broadcast %mull 4 [%v1[0]]; smulj %mlal [%v3[4],%v3[5],%v3[6],%v3[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v19.16b, v6.16b, v3.16b, #14                #! PC = 0x5555551c1c *)
mov %v19 [%v6[7],%v3[0],%v3[1],%v3[2],%v3[3],%v3[4],%v3[5],%v3[6]];
(* smlal	v16.4s, v19.4h, v1.h[1]                   #! PC = 0x5555551c20 *)
broadcast %mull 4 [%v1[1]]; smulj %mlal [%v19[0],%v19[1],%v19[2],%v19[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v19.8h, v1.h[1]                   #! PC = 0x5555551c24 *)
broadcast %mull 4 [%v1[1]]; smulj %mlal [%v19[4],%v19[5],%v19[6],%v19[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v19.16b, v6.16b, v3.16b, #12                #! PC = 0x5555551c28 *)
mov %v19 [%v6[6],%v6[7],%v3[0],%v3[1],%v3[2],%v3[3],%v3[4],%v3[5]];
(* smlal	v16.4s, v19.4h, v1.h[2]                   #! PC = 0x5555551c2c *)
broadcast %mull 4 [%v1[2]]; smulj %mlal [%v19[0],%v19[1],%v19[2],%v19[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v19.8h, v1.h[2]                   #! PC = 0x5555551c30 *)
broadcast %mull 4 [%v1[2]]; smulj %mlal [%v19[4],%v19[5],%v19[6],%v19[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v19.16b, v6.16b, v3.16b, #10                #! PC = 0x5555551c34 *)
mov %v19 [%v6[5],%v6[6],%v6[7],%v3[0],%v3[1],%v3[2],%v3[3],%v3[4]];
(* smlal	v16.4s, v19.4h, v1.h[3]                   #! PC = 0x5555551c38 *)
broadcast %mull 4 [%v1[3]]; smulj %mlal [%v19[0],%v19[1],%v19[2],%v19[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v19.8h, v1.h[3]                   #! PC = 0x5555551c3c *)
broadcast %mull 4 [%v1[3]]; smulj %mlal [%v19[4],%v19[5],%v19[6],%v19[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v19.16b, v6.16b, v3.16b, #8                 #! PC = 0x5555551c40 *)
mov %v19 [%v6[4],%v6[5],%v6[6],%v6[7],%v3[0],%v3[1],%v3[2],%v3[3]];
(* smlal	v16.4s, v19.4h, v1.h[4]                   #! PC = 0x5555551c44 *)
broadcast %mull 4 [%v1[4]]; smulj %mlal [%v19[0],%v19[1],%v19[2],%v19[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v19.8h, v1.h[4]                   #! PC = 0x5555551c48 *)
broadcast %mull 4 [%v1[4]]; smulj %mlal [%v19[4],%v19[5],%v19[6],%v19[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v19.16b, v6.16b, v3.16b, #6                 #! PC = 0x5555551c4c *)
mov %v19 [%v6[3],%v6[4],%v6[5],%v6[6],%v6[7],%v3[0],%v3[1],%v3[2]];
(* smlal	v16.4s, v19.4h, v1.h[5]                   #! PC = 0x5555551c50 *)
broadcast %mull 4 [%v1[5]]; smulj %mlal [%v19[0],%v19[1],%v19[2],%v19[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v19.8h, v1.h[5]                   #! PC = 0x5555551c54 *)
broadcast %mull 4 [%v1[5]]; smulj %mlal [%v19[4],%v19[5],%v19[6],%v19[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v19.16b, v6.16b, v3.16b, #4                 #! PC = 0x5555551c58 *)
mov %v19 [%v6[2],%v6[3],%v6[4],%v6[5],%v6[6],%v6[7],%v3[0],%v3[1]];
(* smlal	v16.4s, v19.4h, v1.h[6]                   #! PC = 0x5555551c5c *)
broadcast %mull 4 [%v1[6]]; smulj %mlal [%v19[0],%v19[1],%v19[2],%v19[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v19.8h, v1.h[6]                   #! PC = 0x5555551c60 *)
broadcast %mull 4 [%v1[6]]; smulj %mlal [%v19[4],%v19[5],%v19[6],%v19[7]] %mull; adds %dc %v7 %v7 %mlal;
(* ext	v6.16b, v6.16b, v3.16b, #2                  #! PC = 0x5555551c64 *)
mov %v6 [%v6[1],%v6[2],%v6[3],%v6[4],%v6[5],%v6[6],%v6[7],%v3[0]];
(* smlal	v16.4s, v6.4h, v1.h[7]                    #! PC = 0x5555551c68 *)
broadcast %mull 4 [%v1[7]]; smulj %mlal [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; adds %dc %v16 %v16 %mlal;
(* smlal2	v7.4s, v6.8h, v1.h[7]                    #! PC = 0x5555551c6c *)
broadcast %mull 4 [%v1[7]]; smulj %mlal [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; adds %dc %v7 %v7 %mlal;
(* sub	v1.8h, v17.8h, v18.8h                       #! PC = 0x5555551c70 *)
sub %v1 %v17 %v18;
(* smlsl	v0.4s, v1.4h, v4.h[0]                     #! PC = 0x5555551c74 *)
broadcast %mull 4 [%v4[0]]; smulj %mlsl [%v1[0],%v1[1],%v1[2],%v1[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v1.8h, v4.h[0]                    #! PC = 0x5555551c78 *)
broadcast %mull 4 [%v4[0]]; smulj %mlsl [%v1[4],%v1[5],%v1[6],%v1[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v6.16b, v3.16b, v1.16b, #14                 #! PC = 0x5555551c7c *)
mov %v6 [%v3[7],%v1[0],%v1[1],%v1[2],%v1[3],%v1[4],%v1[5],%v1[6]];
(* smlsl	v0.4s, v6.4h, v4.h[1]                     #! PC = 0x5555551c80 *)
broadcast %mull 4 [%v4[1]]; smulj %mlsl [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v6.8h, v4.h[1]                    #! PC = 0x5555551c84 *)
broadcast %mull 4 [%v4[1]]; smulj %mlsl [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v6.16b, v3.16b, v1.16b, #12                 #! PC = 0x5555551c88 *)
mov %v6 [%v3[6],%v3[7],%v1[0],%v1[1],%v1[2],%v1[3],%v1[4],%v1[5]];
(* smlsl	v0.4s, v6.4h, v4.h[2]                     #! PC = 0x5555551c8c *)
broadcast %mull 4 [%v4[2]]; smulj %mlsl [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v6.8h, v4.h[2]                    #! PC = 0x5555551c90 *)
broadcast %mull 4 [%v4[2]]; smulj %mlsl [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v6.16b, v3.16b, v1.16b, #10                 #! PC = 0x5555551c94 *)
mov %v6 [%v3[5],%v3[6],%v3[7],%v1[0],%v1[1],%v1[2],%v1[3],%v1[4]];
(* smlsl	v0.4s, v6.4h, v4.h[3]                     #! PC = 0x5555551c98 *)
broadcast %mull 4 [%v4[3]]; smulj %mlsl [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v6.8h, v4.h[3]                    #! PC = 0x5555551c9c *)
broadcast %mull 4 [%v4[3]]; smulj %mlsl [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v6.16b, v3.16b, v1.16b, #8                  #! PC = 0x5555551ca0 *)
mov %v6 [%v3[4],%v3[5],%v3[6],%v3[7],%v1[0],%v1[1],%v1[2],%v1[3]];
(* smlsl	v0.4s, v6.4h, v4.h[4]                     #! PC = 0x5555551ca4 *)
broadcast %mull 4 [%v4[4]]; smulj %mlsl [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v6.8h, v4.h[4]                    #! PC = 0x5555551ca8 *)
broadcast %mull 4 [%v4[4]]; smulj %mlsl [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v6.16b, v3.16b, v1.16b, #6                  #! PC = 0x5555551cac *)
mov %v6 [%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v1[0],%v1[1],%v1[2]];
(* smlsl	v0.4s, v6.4h, v4.h[5]                     #! PC = 0x5555551cb0 *)
broadcast %mull 4 [%v4[5]]; smulj %mlsl [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v6.8h, v4.h[5]                    #! PC = 0x5555551cb4 *)
broadcast %mull 4 [%v4[5]]; smulj %mlsl [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v6.16b, v3.16b, v1.16b, #4                  #! PC = 0x5555551cb8 *)
mov %v6 [%v3[2],%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v1[0],%v1[1]];
(* smlsl	v0.4s, v6.4h, v4.h[6]                     #! PC = 0x5555551cbc *)
broadcast %mull 4 [%v4[6]]; smulj %mlsl [%v6[0],%v6[1],%v6[2],%v6[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v6.8h, v4.h[6]                    #! PC = 0x5555551cc0 *)
broadcast %mull 4 [%v4[6]]; smulj %mlsl [%v6[4],%v6[5],%v6[6],%v6[7]] %mull; subc %dc %v2 %v2 %mlsl;
(* ext	v3.16b, v3.16b, v1.16b, #2                  #! PC = 0x5555551cc4 *)
mov %v3 [%v3[1],%v3[2],%v3[3],%v3[4],%v3[5],%v3[6],%v3[7],%v1[0]];
(* smlsl	v0.4s, v3.4h, v4.h[7]                     #! PC = 0x5555551cc8 *)
broadcast %mull 4 [%v4[7]]; smulj %mlsl [%v3[0],%v3[1],%v3[2],%v3[3]] %mull; subc %dc %v0 %v0 %mlsl;
(* smlsl2	v2.4s, v3.8h, v4.h[7]                    #! PC = 0x5555551ccc *)
broadcast %mull 4 [%v4[7]]; smulj %mlsl [%v3[4],%v3[5],%v3[6],%v3[7]] %mull; subc %dc %v2 %v2 %mlsl;

ghost %conv0_9@sint32[8], %conv1_9@sint32[8] :
    %conv0_9 = [
        %fc0_9[0] * %fd0_9[0] + %fc0_9[1] * %fe1_9[7] + %fc0_9[2] * %fe1_9[6] + %fc0_9[3] * %fe1_9[5] + %fc0_9[4] * %fe1_9[4] + %fc0_9[5] * %fe1_9[3] + %fc0_9[6] * %fe1_9[2] + %fc0_9[7] * %fe1_9[1] +
        %fc1_9[0] * %fe1_9[0] + %fc1_9[1] * %fe0_9[7] + %fc1_9[2] * %fe0_9[6] + %fc1_9[3] * %fe0_9[5] + %fc1_9[4] * %fe0_9[4] + %fc1_9[5] * %fe0_9[3] + %fc1_9[6] * %fe0_9[2] + %fc1_9[7] * %fe0_9[1],
        %fc0_9[0] * %fd0_9[1] + %fc0_9[1] * %fd0_9[0] + %fc0_9[2] * %fe1_9[7] + %fc0_9[3] * %fe1_9[6] + %fc0_9[4] * %fe1_9[5] + %fc0_9[5] * %fe1_9[4] + %fc0_9[6] * %fe1_9[3] + %fc0_9[7] * %fe1_9[2] +
        %fc1_9[0] * %fe1_9[1] + %fc1_9[1] * %fe1_9[0] + %fc1_9[2] * %fe0_9[7] + %fc1_9[3] * %fe0_9[6] + %fc1_9[4] * %fe0_9[5] + %fc1_9[5] * %fe0_9[4] + %fc1_9[6] * %fe0_9[3] + %fc1_9[7] * %fe0_9[2],
        %fc0_9[0] * %fd0_9[2] + %fc0_9[1] * %fd0_9[1] + %fc0_9[2] * %fd0_9[0] + %fc0_9[3] * %fe1_9[7] + %fc0_9[4] * %fe1_9[6] + %fc0_9[5] * %fe1_9[5] + %fc0_9[6] * %fe1_9[4] + %fc0_9[7] * %fe1_9[3] +
        %fc1_9[0] * %fe1_9[2] + %fc1_9[1] * %fe1_9[1] + %fc1_9[2] * %fe1_9[0] + %fc1_9[3] * %fe0_9[7] + %fc1_9[4] * %fe0_9[6] + %fc1_9[5] * %fe0_9[5] + %fc1_9[6] * %fe0_9[4] + %fc1_9[7] * %fe0_9[3],
        %fc0_9[0] * %fd0_9[3] + %fc0_9[1] * %fd0_9[2] + %fc0_9[2] * %fd0_9[1] + %fc0_9[3] * %fd0_9[0] + %fc0_9[4] * %fe1_9[7] + %fc0_9[5] * %fe1_9[6] + %fc0_9[6] * %fe1_9[5] + %fc0_9[7] * %fe1_9[4] +
        %fc1_9[0] * %fe1_9[3] + %fc1_9[1] * %fe1_9[2] + %fc1_9[2] * %fe1_9[1] + %fc1_9[3] * %fe1_9[0] + %fc1_9[4] * %fe0_9[7] + %fc1_9[5] * %fe0_9[6] + %fc1_9[6] * %fe0_9[5] + %fc1_9[7] * %fe0_9[4],
        %fc0_9[0] * %fd0_9[4] + %fc0_9[1] * %fd0_9[3] + %fc0_9[2] * %fd0_9[2] + %fc0_9[3] * %fd0_9[1] + %fc0_9[4] * %fd0_9[0] + %fc0_9[5] * %fe1_9[7] + %fc0_9[6] * %fe1_9[6] + %fc0_9[7] * %fe1_9[5] +
        %fc1_9[0] * %fe1_9[4] + %fc1_9[1] * %fe1_9[3] + %fc1_9[2] * %fe1_9[2] + %fc1_9[3] * %fe1_9[1] + %fc1_9[4] * %fe1_9[0] + %fc1_9[5] * %fe0_9[7] + %fc1_9[6] * %fe0_9[6] + %fc1_9[7] * %fe0_9[5],
        %fc0_9[0] * %fd0_9[5] + %fc0_9[1] * %fd0_9[4] + %fc0_9[2] * %fd0_9[3] + %fc0_9[3] * %fd0_9[2] + %fc0_9[4] * %fd0_9[1] + %fc0_9[5] * %fd0_9[0] + %fc0_9[6] * %fe1_9[7] + %fc0_9[7] * %fe1_9[6] +
        %fc1_9[0] * %fe1_9[5] + %fc1_9[1] * %fe1_9[4] + %fc1_9[2] * %fe1_9[3] + %fc1_9[3] * %fe1_9[2] + %fc1_9[4] * %fe1_9[1] + %fc1_9[5] * %fe1_9[0] + %fc1_9[6] * %fe0_9[7] + %fc1_9[7] * %fe0_9[6],
        %fc0_9[0] * %fd0_9[6] + %fc0_9[1] * %fd0_9[5] + %fc0_9[2] * %fd0_9[4] + %fc0_9[3] * %fd0_9[3] + %fc0_9[4] * %fd0_9[2] + %fc0_9[5] * %fd0_9[1] + %fc0_9[6] * %fd0_9[0] + %fc0_9[7] * %fe1_9[7] +
        %fc1_9[0] * %fe1_9[6] + %fc1_9[1] * %fe1_9[5] + %fc1_9[2] * %fe1_9[4] + %fc1_9[3] * %fe1_9[3] + %fc1_9[4] * %fe1_9[2] + %fc1_9[5] * %fe1_9[1] + %fc1_9[6] * %fe1_9[0] + %fc1_9[7] * %fe0_9[7],
        %fc0_9[0] * %fd0_9[7] + %fc0_9[1] * %fd0_9[6] + %fc0_9[2] * %fd0_9[5] + %fc0_9[3] * %fd0_9[4] + %fc0_9[4] * %fd0_9[3] + %fc0_9[5] * %fd0_9[2] + %fc0_9[6] * %fd0_9[1] + %fc0_9[7] * %fd0_9[0] +
        %fc1_9[0] * %fe1_9[7] + %fc1_9[1] * %fe1_9[6] + %fc1_9[2] * %fe1_9[5] + %fc1_9[3] * %fe1_9[4] + %fc1_9[4] * %fe1_9[3] + %fc1_9[5] * %fe1_9[2] + %fc1_9[6] * %fe1_9[1] + %fc1_9[7] * %fe1_9[0]
    ] /\
    %conv1_9 = [
        %fc0_9[0] * %fd1_9[0] + %fc0_9[1] * %fd0_9[7] + %fc0_9[2] * %fd0_9[6] + %fc0_9[3] * %fd0_9[5] + %fc0_9[4] * %fd0_9[4] + %fc0_9[5] * %fd0_9[3] + %fc0_9[6] * %fd0_9[2] + %fc0_9[7] * %fd0_9[1] +
        %fc1_9[0] * %fd0_9[0] + %fc1_9[1] * %fe1_9[7] + %fc1_9[2] * %fe1_9[6] + %fc1_9[3] * %fe1_9[5] + %fc1_9[4] * %fe1_9[4] + %fc1_9[5] * %fe1_9[3] + %fc1_9[6] * %fe1_9[2] + %fc1_9[7] * %fe1_9[1],
        %fc0_9[0] * %fd1_9[1] + %fc0_9[1] * %fd1_9[0] + %fc0_9[2] * %fd0_9[7] + %fc0_9[3] * %fd0_9[6] + %fc0_9[4] * %fd0_9[5] + %fc0_9[5] * %fd0_9[4] + %fc0_9[6] * %fd0_9[3] + %fc0_9[7] * %fd0_9[2] +
        %fc1_9[0] * %fd0_9[1] + %fc1_9[1] * %fd0_9[0] + %fc1_9[2] * %fe1_9[7] + %fc1_9[3] * %fe1_9[6] + %fc1_9[4] * %fe1_9[5] + %fc1_9[5] * %fe1_9[4] + %fc1_9[6] * %fe1_9[3] + %fc1_9[7] * %fe1_9[2],
        %fc0_9[0] * %fd1_9[2] + %fc0_9[1] * %fd1_9[1] + %fc0_9[2] * %fd1_9[0] + %fc0_9[3] * %fd0_9[7] + %fc0_9[4] * %fd0_9[6] + %fc0_9[5] * %fd0_9[5] + %fc0_9[6] * %fd0_9[4] + %fc0_9[7] * %fd0_9[3] +
        %fc1_9[0] * %fd0_9[2] + %fc1_9[1] * %fd0_9[1] + %fc1_9[2] * %fd0_9[0] + %fc1_9[3] * %fe1_9[7] + %fc1_9[4] * %fe1_9[6] + %fc1_9[5] * %fe1_9[5] + %fc1_9[6] * %fe1_9[4] + %fc1_9[7] * %fe1_9[3],
        %fc0_9[0] * %fd1_9[3] + %fc0_9[1] * %fd1_9[2] + %fc0_9[2] * %fd1_9[1] + %fc0_9[3] * %fd1_9[0] + %fc0_9[4] * %fd0_9[7] + %fc0_9[5] * %fd0_9[6] + %fc0_9[6] * %fd0_9[5] + %fc0_9[7] * %fd0_9[4] +
        %fc1_9[0] * %fd0_9[3] + %fc1_9[1] * %fd0_9[2] + %fc1_9[2] * %fd0_9[1] + %fc1_9[3] * %fd0_9[0] + %fc1_9[4] * %fe1_9[7] + %fc1_9[5] * %fe1_9[6] + %fc1_9[6] * %fe1_9[5] + %fc1_9[7] * %fe1_9[4],
        %fc0_9[0] * %fd1_9[4] + %fc0_9[1] * %fd1_9[3] + %fc0_9[2] * %fd1_9[2] + %fc0_9[3] * %fd1_9[1] + %fc0_9[4] * %fd1_9[0] + %fc0_9[5] * %fd0_9[7] + %fc0_9[6] * %fd0_9[6] + %fc0_9[7] * %fd0_9[5] +
        %fc1_9[0] * %fd0_9[4] + %fc1_9[1] * %fd0_9[3] + %fc1_9[2] * %fd0_9[2] + %fc1_9[3] * %fd0_9[1] + %fc1_9[4] * %fd0_9[0] + %fc1_9[5] * %fe1_9[7] + %fc1_9[6] * %fe1_9[6] + %fc1_9[7] * %fe1_9[5],
        %fc0_9[0] * %fd1_9[5] + %fc0_9[1] * %fd1_9[4] + %fc0_9[2] * %fd1_9[3] + %fc0_9[3] * %fd1_9[2] + %fc0_9[4] * %fd1_9[1] + %fc0_9[5] * %fd1_9[0] + %fc0_9[6] * %fd0_9[7] + %fc0_9[7] * %fd0_9[6] +
        %fc1_9[0] * %fd0_9[5] + %fc1_9[1] * %fd0_9[4] + %fc1_9[2] * %fd0_9[3] + %fc1_9[3] * %fd0_9[2] + %fc1_9[4] * %fd0_9[1] + %fc1_9[5] * %fd0_9[0] + %fc1_9[6] * %fe1_9[7] + %fc1_9[7] * %fe1_9[6],
        %fc0_9[0] * %fd1_9[6] + %fc0_9[1] * %fd1_9[5] + %fc0_9[2] * %fd1_9[4] + %fc0_9[3] * %fd1_9[3] + %fc0_9[4] * %fd1_9[2] + %fc0_9[5] * %fd1_9[1] + %fc0_9[6] * %fd1_9[0] + %fc0_9[7] * %fd0_9[7] +
        %fc1_9[0] * %fd0_9[6] + %fc1_9[1] * %fd0_9[5] + %fc1_9[2] * %fd0_9[4] + %fc1_9[3] * %fd0_9[3] + %fc1_9[4] * %fd0_9[2] + %fc1_9[5] * %fd0_9[1] + %fc1_9[6] * %fd0_9[0] + %fc1_9[7] * %fe1_9[7],
        %fc0_9[0] * %fd1_9[7] + %fc0_9[1] * %fd1_9[6] + %fc0_9[2] * %fd1_9[5] + %fc0_9[3] * %fd1_9[4] + %fc0_9[4] * %fd1_9[3] + %fc0_9[5] * %fd1_9[2] + %fc0_9[6] * %fd1_9[1] + %fc0_9[7] * %fd1_9[0] +
        %fc1_9[0] * %fd0_9[7] + %fc1_9[1] * %fd0_9[6] + %fc1_9[2] * %fd0_9[5] + %fc1_9[3] * %fd0_9[4] + %fc1_9[4] * %fd0_9[3] + %fc1_9[5] * %fd0_9[2] + %fc1_9[6] * %fd0_9[1] + %fc1_9[7] * %fd0_9[0]
    ]
    && true;

assert
    %v16 ++ %v7 = %conv0_9 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] ) /\
    %v0 ++ %v2 = %conv1_9 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] )
    && true;

assume
    %v16 ++ %v7 = %conv0_9 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] ) /\
    %v0 ++ %v2 = %conv1_9 ( mod [4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296, 4294967296] )
    && true;

assert
    %conv0_9 <= [268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456] /\
    %conv0_9 >= [-268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456] /\

    %conv1_9 <= [268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456] /\
    %conv1_9 >= [-268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456]
    prove with [algebra solver smt: z3]
    && true;

assume
    %conv0_9 <= [268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456] /\
    %conv0_9 >= [-268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456] /\

    %conv1_9 <= [268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456, 268435456] /\
    %conv1_9 >= [-268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456, -268435456]
    && true;

assert
    %v16 ++ %v7 = %conv0_9 /\ %v0 ++ %v2 = %conv1_9
    prove with [algebra solver isl]
    && true;

assume
    %v16 ++ %v7 = %conv0_9 /\ %v0 ++ %v2 = %conv1_9
    && true;

assert
    %v16 <= [268435456, 268435456, 268435456, 268435456] /\
    %v16 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v7 <= [268435456, 268435456, 268435456, 268435456] /\
    %v7 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v0 <= [268435456, 268435456, 268435456, 268435456] /\
    %v0 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v2 <= [268435456, 268435456, 268435456, 268435456] /\
    %v2 >= [-268435456, -268435456, -268435456, -268435456]

    prove with [algebra solver isl]
    && true;

assume
    %v16 <= [268435456, 268435456, 268435456, 268435456] /\
    %v16 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v7 <= [268435456, 268435456, 268435456, 268435456] /\
    %v7 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v0 <= [268435456, 268435456, 268435456, 268435456] /\
    %v0 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v2 <= [268435456, 268435456, 268435456, 268435456] /\
    %v2 >= [-268435456, -268435456, -268435456, -268435456]
  &&
    %v16 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v16 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32] /\

    %v7 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v7 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32] /\

    %v0 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v0 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32] /\

    %v2 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v2 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32];

cut (* 39 *)
    %conv0_9 = [
        %fc0_9[0] * %fd0_9[0] + %fc0_9[1] * %fe1_9[7] + %fc0_9[2] * %fe1_9[6] + %fc0_9[3] * %fe1_9[5] + %fc0_9[4] * %fe1_9[4] + %fc0_9[5] * %fe1_9[3] + %fc0_9[6] * %fe1_9[2] + %fc0_9[7] * %fe1_9[1] +
        %fc1_9[0] * %fe1_9[0] + %fc1_9[1] * %fe0_9[7] + %fc1_9[2] * %fe0_9[6] + %fc1_9[3] * %fe0_9[5] + %fc1_9[4] * %fe0_9[4] + %fc1_9[5] * %fe0_9[3] + %fc1_9[6] * %fe0_9[2] + %fc1_9[7] * %fe0_9[1],
        %fc0_9[0] * %fd0_9[1] + %fc0_9[1] * %fd0_9[0] + %fc0_9[2] * %fe1_9[7] + %fc0_9[3] * %fe1_9[6] + %fc0_9[4] * %fe1_9[5] + %fc0_9[5] * %fe1_9[4] + %fc0_9[6] * %fe1_9[3] + %fc0_9[7] * %fe1_9[2] +
        %fc1_9[0] * %fe1_9[1] + %fc1_9[1] * %fe1_9[0] + %fc1_9[2] * %fe0_9[7] + %fc1_9[3] * %fe0_9[6] + %fc1_9[4] * %fe0_9[5] + %fc1_9[5] * %fe0_9[4] + %fc1_9[6] * %fe0_9[3] + %fc1_9[7] * %fe0_9[2],
        %fc0_9[0] * %fd0_9[2] + %fc0_9[1] * %fd0_9[1] + %fc0_9[2] * %fd0_9[0] + %fc0_9[3] * %fe1_9[7] + %fc0_9[4] * %fe1_9[6] + %fc0_9[5] * %fe1_9[5] + %fc0_9[6] * %fe1_9[4] + %fc0_9[7] * %fe1_9[3] +
        %fc1_9[0] * %fe1_9[2] + %fc1_9[1] * %fe1_9[1] + %fc1_9[2] * %fe1_9[0] + %fc1_9[3] * %fe0_9[7] + %fc1_9[4] * %fe0_9[6] + %fc1_9[5] * %fe0_9[5] + %fc1_9[6] * %fe0_9[4] + %fc1_9[7] * %fe0_9[3],
        %fc0_9[0] * %fd0_9[3] + %fc0_9[1] * %fd0_9[2] + %fc0_9[2] * %fd0_9[1] + %fc0_9[3] * %fd0_9[0] + %fc0_9[4] * %fe1_9[7] + %fc0_9[5] * %fe1_9[6] + %fc0_9[6] * %fe1_9[5] + %fc0_9[7] * %fe1_9[4] +
        %fc1_9[0] * %fe1_9[3] + %fc1_9[1] * %fe1_9[2] + %fc1_9[2] * %fe1_9[1] + %fc1_9[3] * %fe1_9[0] + %fc1_9[4] * %fe0_9[7] + %fc1_9[5] * %fe0_9[6] + %fc1_9[6] * %fe0_9[5] + %fc1_9[7] * %fe0_9[4],
        %fc0_9[0] * %fd0_9[4] + %fc0_9[1] * %fd0_9[3] + %fc0_9[2] * %fd0_9[2] + %fc0_9[3] * %fd0_9[1] + %fc0_9[4] * %fd0_9[0] + %fc0_9[5] * %fe1_9[7] + %fc0_9[6] * %fe1_9[6] + %fc0_9[7] * %fe1_9[5] +
        %fc1_9[0] * %fe1_9[4] + %fc1_9[1] * %fe1_9[3] + %fc1_9[2] * %fe1_9[2] + %fc1_9[3] * %fe1_9[1] + %fc1_9[4] * %fe1_9[0] + %fc1_9[5] * %fe0_9[7] + %fc1_9[6] * %fe0_9[6] + %fc1_9[7] * %fe0_9[5],
        %fc0_9[0] * %fd0_9[5] + %fc0_9[1] * %fd0_9[4] + %fc0_9[2] * %fd0_9[3] + %fc0_9[3] * %fd0_9[2] + %fc0_9[4] * %fd0_9[1] + %fc0_9[5] * %fd0_9[0] + %fc0_9[6] * %fe1_9[7] + %fc0_9[7] * %fe1_9[6] +
        %fc1_9[0] * %fe1_9[5] + %fc1_9[1] * %fe1_9[4] + %fc1_9[2] * %fe1_9[3] + %fc1_9[3] * %fe1_9[2] + %fc1_9[4] * %fe1_9[1] + %fc1_9[5] * %fe1_9[0] + %fc1_9[6] * %fe0_9[7] + %fc1_9[7] * %fe0_9[6],
        %fc0_9[0] * %fd0_9[6] + %fc0_9[1] * %fd0_9[5] + %fc0_9[2] * %fd0_9[4] + %fc0_9[3] * %fd0_9[3] + %fc0_9[4] * %fd0_9[2] + %fc0_9[5] * %fd0_9[1] + %fc0_9[6] * %fd0_9[0] + %fc0_9[7] * %fe1_9[7] +
        %fc1_9[0] * %fe1_9[6] + %fc1_9[1] * %fe1_9[5] + %fc1_9[2] * %fe1_9[4] + %fc1_9[3] * %fe1_9[3] + %fc1_9[4] * %fe1_9[2] + %fc1_9[5] * %fe1_9[1] + %fc1_9[6] * %fe1_9[0] + %fc1_9[7] * %fe0_9[7],
        %fc0_9[0] * %fd0_9[7] + %fc0_9[1] * %fd0_9[6] + %fc0_9[2] * %fd0_9[5] + %fc0_9[3] * %fd0_9[4] + %fc0_9[4] * %fd0_9[3] + %fc0_9[5] * %fd0_9[2] + %fc0_9[6] * %fd0_9[1] + %fc0_9[7] * %fd0_9[0] +
        %fc1_9[0] * %fe1_9[7] + %fc1_9[1] * %fe1_9[6] + %fc1_9[2] * %fe1_9[5] + %fc1_9[3] * %fe1_9[4] + %fc1_9[4] * %fe1_9[3] + %fc1_9[5] * %fe1_9[2] + %fc1_9[6] * %fe1_9[1] + %fc1_9[7] * %fe1_9[0]
    ] /\
    %conv1_9 = [
        %fc0_9[0] * %fd1_9[0] + %fc0_9[1] * %fd0_9[7] + %fc0_9[2] * %fd0_9[6] + %fc0_9[3] * %fd0_9[5] + %fc0_9[4] * %fd0_9[4] + %fc0_9[5] * %fd0_9[3] + %fc0_9[6] * %fd0_9[2] + %fc0_9[7] * %fd0_9[1] +
        %fc1_9[0] * %fd0_9[0] + %fc1_9[1] * %fe1_9[7] + %fc1_9[2] * %fe1_9[6] + %fc1_9[3] * %fe1_9[5] + %fc1_9[4] * %fe1_9[4] + %fc1_9[5] * %fe1_9[3] + %fc1_9[6] * %fe1_9[2] + %fc1_9[7] * %fe1_9[1],
        %fc0_9[0] * %fd1_9[1] + %fc0_9[1] * %fd1_9[0] + %fc0_9[2] * %fd0_9[7] + %fc0_9[3] * %fd0_9[6] + %fc0_9[4] * %fd0_9[5] + %fc0_9[5] * %fd0_9[4] + %fc0_9[6] * %fd0_9[3] + %fc0_9[7] * %fd0_9[2] +
        %fc1_9[0] * %fd0_9[1] + %fc1_9[1] * %fd0_9[0] + %fc1_9[2] * %fe1_9[7] + %fc1_9[3] * %fe1_9[6] + %fc1_9[4] * %fe1_9[5] + %fc1_9[5] * %fe1_9[4] + %fc1_9[6] * %fe1_9[3] + %fc1_9[7] * %fe1_9[2],
        %fc0_9[0] * %fd1_9[2] + %fc0_9[1] * %fd1_9[1] + %fc0_9[2] * %fd1_9[0] + %fc0_9[3] * %fd0_9[7] + %fc0_9[4] * %fd0_9[6] + %fc0_9[5] * %fd0_9[5] + %fc0_9[6] * %fd0_9[4] + %fc0_9[7] * %fd0_9[3] +
        %fc1_9[0] * %fd0_9[2] + %fc1_9[1] * %fd0_9[1] + %fc1_9[2] * %fd0_9[0] + %fc1_9[3] * %fe1_9[7] + %fc1_9[4] * %fe1_9[6] + %fc1_9[5] * %fe1_9[5] + %fc1_9[6] * %fe1_9[4] + %fc1_9[7] * %fe1_9[3],
        %fc0_9[0] * %fd1_9[3] + %fc0_9[1] * %fd1_9[2] + %fc0_9[2] * %fd1_9[1] + %fc0_9[3] * %fd1_9[0] + %fc0_9[4] * %fd0_9[7] + %fc0_9[5] * %fd0_9[6] + %fc0_9[6] * %fd0_9[5] + %fc0_9[7] * %fd0_9[4] +
        %fc1_9[0] * %fd0_9[3] + %fc1_9[1] * %fd0_9[2] + %fc1_9[2] * %fd0_9[1] + %fc1_9[3] * %fd0_9[0] + %fc1_9[4] * %fe1_9[7] + %fc1_9[5] * %fe1_9[6] + %fc1_9[6] * %fe1_9[5] + %fc1_9[7] * %fe1_9[4],
        %fc0_9[0] * %fd1_9[4] + %fc0_9[1] * %fd1_9[3] + %fc0_9[2] * %fd1_9[2] + %fc0_9[3] * %fd1_9[1] + %fc0_9[4] * %fd1_9[0] + %fc0_9[5] * %fd0_9[7] + %fc0_9[6] * %fd0_9[6] + %fc0_9[7] * %fd0_9[5] +
        %fc1_9[0] * %fd0_9[4] + %fc1_9[1] * %fd0_9[3] + %fc1_9[2] * %fd0_9[2] + %fc1_9[3] * %fd0_9[1] + %fc1_9[4] * %fd0_9[0] + %fc1_9[5] * %fe1_9[7] + %fc1_9[6] * %fe1_9[6] + %fc1_9[7] * %fe1_9[5],
        %fc0_9[0] * %fd1_9[5] + %fc0_9[1] * %fd1_9[4] + %fc0_9[2] * %fd1_9[3] + %fc0_9[3] * %fd1_9[2] + %fc0_9[4] * %fd1_9[1] + %fc0_9[5] * %fd1_9[0] + %fc0_9[6] * %fd0_9[7] + %fc0_9[7] * %fd0_9[6] +
        %fc1_9[0] * %fd0_9[5] + %fc1_9[1] * %fd0_9[4] + %fc1_9[2] * %fd0_9[3] + %fc1_9[3] * %fd0_9[2] + %fc1_9[4] * %fd0_9[1] + %fc1_9[5] * %fd0_9[0] + %fc1_9[6] * %fe1_9[7] + %fc1_9[7] * %fe1_9[6],
        %fc0_9[0] * %fd1_9[6] + %fc0_9[1] * %fd1_9[5] + %fc0_9[2] * %fd1_9[4] + %fc0_9[3] * %fd1_9[3] + %fc0_9[4] * %fd1_9[2] + %fc0_9[5] * %fd1_9[1] + %fc0_9[6] * %fd1_9[0] + %fc0_9[7] * %fd0_9[7] +
        %fc1_9[0] * %fd0_9[6] + %fc1_9[1] * %fd0_9[5] + %fc1_9[2] * %fd0_9[4] + %fc1_9[3] * %fd0_9[3] + %fc1_9[4] * %fd0_9[2] + %fc1_9[5] * %fd0_9[1] + %fc1_9[6] * %fd0_9[0] + %fc1_9[7] * %fe1_9[7],
        %fc0_9[0] * %fd1_9[7] + %fc0_9[1] * %fd1_9[6] + %fc0_9[2] * %fd1_9[5] + %fc0_9[3] * %fd1_9[4] + %fc0_9[4] * %fd1_9[3] + %fc0_9[5] * %fd1_9[2] + %fc0_9[6] * %fd1_9[1] + %fc0_9[7] * %fd1_9[0] +
        %fc1_9[0] * %fd0_9[7] + %fc1_9[1] * %fd0_9[6] + %fc1_9[2] * %fd0_9[5] + %fc1_9[3] * %fd0_9[4] + %fc1_9[4] * %fd0_9[3] + %fc1_9[5] * %fd0_9[2] + %fc1_9[6] * %fd0_9[1] + %fc1_9[7] * %fd0_9[0]
    ] /\

    %v16 ++ %v7 = %conv0_9 /\ %v0 ++ %v2 = %conv1_9,

    %v16 <= [268435456, 268435456, 268435456, 268435456] /\
    %v16 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v7 <= [268435456, 268435456, 268435456, 268435456] /\
    %v7 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v0 <= [268435456, 268435456, 268435456, 268435456] /\
    %v0 >= [-268435456, -268435456, -268435456, -268435456] /\

    %v2 <= [268435456, 268435456, 268435456, 268435456] /\
    %v2 >= [-268435456, -268435456, -268435456, -268435456]

    prove with [algebra solver isl]
  &&
    %v16 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v16 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32] /\

    %v7 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v7 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32] /\

    %v0 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v0 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32] /\

    %v2 <=s [268435456@32, 268435456@32, 268435456@32, 268435456@32] /\
    %v2 >=s [(-268435456)@32, (-268435456)@32, (-268435456)@32, (-268435456)@32];

ghost %h0_9@sint32[8], %h1_9@sint32[8] :
    %h0_9 = %v16 ++ %v7 /\ %h1_9 = %v0 ++ %v2
  &&
    %h0_9 = %v16 ++ %v7 /\ %h1_9 = %v0 ++ %v2;

(* uzp1	v3.8h, v16.8h, v7.8h                       #! PC = 0x5555551cd0 *)
mov %spl_join [%v16[0], %v16[1], %v16[2], %v16[3], %v7[0], %v7[1], %v7[2], %v7[3]]; spl %splh %v3 %spl_join 16; cast %v3@int16[8] %v3;
(* mul	v3.8h, v3.8h, v5.h[7]                       #! PC = 0x5555551cd4 *)
broadcast %mul 8 [%v5[7]]; mull %dc %v3 %v3 %mul; cast %v3@int16[8] %v3;

ghost %m0_9@sint16[8] : %m0_9 = %v3 && %m0_9 = %v3;

(* sqdmulh	v3.8h, v3.8h, v5.h[6]                   #! PC = 0x5555551cd8 *)
broadcast %mul 8 [%v5[6]]; smulj %LO %v3 %mul;
ssplit %LO0 %dc %LO 15; vpc %v3@sint16[8] %LO0;
(* uzp2	v1.8h, v16.8h, v7.8h                       #! PC = 0x5555551cdc *)
mov %spl_join [%v16[0], %v16[1], %v16[2], %v16[3], %v7[0], %v7[1], %v7[2], %v7[3]]; spl %v1 %spll %spl_join 16;
(* sshr	v3.8h, v3.8h, #1                           #! PC = 0x5555551ce0 *)
split %v3 %dc %v3 1;
(* sub	v1.8h, v1.8h, v3.8h                         #! PC = 0x5555551ce4 *)
sub %v1 %v1 %v3;

ghost %hh0_9@sint16[8] : %hh0_9 = %v1 && %hh0_9 = %v1;

assert
    %h0_9 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m0_9
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh0_9
    prove with [algebra solver isl]
    && true;

assume
    %h0_9 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m0_9
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh0_9
    && true;

(* sqrdmulh	v3.8h, v1.8h, v5.h[3]                  #! PC = 0x5555551ce8 *)
broadcast %mul 8 [%v5[3]]; smulj %LO %v1 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v3 %LO11 %LO01;
(* mul	v1.8h, v1.8h, v5.h[2]                       #! PC = 0x5555551cec *)
broadcast %mul 8 [%v5[2]]; mull %dc %v1 %v1 %mul; cast %v1@int16[8] %v1;
(* mls	v1.8h, v3.8h, v5.h[6]                       #! PC = 0x5555551cf0 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v3 %mul;
cast %mls@int16[8] %mls; subc %dc %v1 %v1 %mls;

assert
    [12, 12, 12, 12, 12, 12, 12, 12] * %hh0_9
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v3
    = %v1
    prove with [algebra solver isl]
    && true;

assume
    [12, 12, 12, 12, 12, 12, 12, 12] * %hh0_9
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v3
    = %v1
    && true;

(* uzp1	v3.8h, v0.8h, v2.8h                        #! PC = 0x5555551cf4 *)
mov %spl_join [%v0[0], %v0[1], %v0[2], %v0[3], %v2[0], %v2[1], %v2[2], %v2[3]]; spl %splh %v3 %spl_join 16; cast %v3@int16[8] %v3;
(* mul	v3.8h, v3.8h, v5.h[7]                       #! PC = 0x5555551cf8 *)
broadcast %mul 8 [%v5[7]]; mull %dc %v3 %v3 %mul; cast %v3@int16[8] %v3;

ghost %m1_9@sint16[8] : %m1_9 = %v3 && %m1_9 = %v3;

(* sqdmulh	v3.8h, v3.8h, v5.h[6]                   #! PC = 0x5555551cfc *)
broadcast %mul 8 [%v5[6]]; smulj %LO %v3 %mul;
ssplit %LO0 %dc %LO 15; vpc %v3@sint16[8] %LO0;
(* uzp2	v0.8h, v0.8h, v2.8h                        #! PC = 0x5555551d00 *)
mov %spl_join [%v0[0], %v0[1], %v0[2], %v0[3], %v2[0], %v2[1], %v2[2], %v2[3]]; spl %v0 %spll %spl_join 16;
(* sshr	v2.8h, v3.8h, #1                           #! PC = 0x5555551d04 *)
split %v2 %dc %v3 1;
(* sub	v0.8h, v0.8h, v2.8h                         #! PC = 0x5555551d08 *)
sub %v0 %v0 %v2;

ghost %hh1_9@sint16[8] : %hh1_9 = %v0 && %hh1_9 = %v0;

assert
    %h1_9 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m1_9
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh1_9
    prove with [algebra solver isl]
    && true;

assume
    %h1_9 - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %m1_9
    = [65536, 65536, 65536, 65536, 65536, 65536, 65536, 65536] * %hh1_9
    && true;

(* sqrdmulh	v2.8h, v0.8h, v5.h[3]                  #! PC = 0x5555551d0c *)
broadcast %mul 8 [%v5[3]]; smulj %LO %v0 %mul;
ssplit %LO1 %LO0 %LO 15; usplit %LO00 %dc %LO0 14;
vpc %LO01@sint16[8] %LO00; vpc %LO11@sint16[8] %LO1;
add %v2 %LO11 %LO01;
(* mul	v0.8h, v0.8h, v5.h[2]                       #! PC = 0x5555551d10 *)
broadcast %mul 8 [%v5[2]]; mull %dc %v0 %v0 %mul; cast %v0@int16[8] %v0;
(* mls	v0.8h, v2.8h, v5.h[6]                       #! PC = 0x5555551d14 *)
broadcast %mul 8 [%v5[6]]; mull %dc %mls %v2 %mul;
cast %mls@int16[8] %mls; subc %dc %v0 %v0 %mls;

assert
    [12, 12, 12, 12, 12, 12, 12, 12] * %hh1_9
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v2
    = %v0
    prove with [algebra solver isl]
    && true;

assume
    [12, 12, 12, 12, 12, 12, 12, 12] * %hh1_9
    - [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] * %v2
    = %v0
    && true;


### i_iter epilogue

(* str	q1, [x2, x3]                                #! EA = L0x7fffffe2d0; PC = 0x5555551d18 *)
mov [L0x7fffffe2d0,L0x7fffffe2d2,L0x7fffffe2d4,L0x7fffffe2d6,L0x7fffffe2d8,L0x7fffffe2da,L0x7fffffe2dc,L0x7fffffe2de] %v1;
(* str	q0, [x6, x3]                                #! EA = L0x7fffffe2e0; PC = 0x5555551d1c *)
mov [L0x7fffffe2e0,L0x7fffffe2e2,L0x7fffffe2e4,L0x7fffffe2e6,L0x7fffffe2e8,L0x7fffffe2ea,L0x7fffffe2ec,L0x7fffffe2ee] %v0;
(* #b.eq	0x5555551ec4 <_ZN6xpower7basemul11low_basemulEPA2_A8_sS3_S3_+932>  // b.none#! PC = 0x5555551d30 *)
#b.eq	0x5555551ec4 <_ZN6xpower7basemul11low_basemulEPA2_A8_sS3_S3_+932>  // b.none#! 0x5555551d30 = 0x5555551d30;

assert
    %v1 <= [2650, 2650, 2650, 2650, 2650, 2650, 2650, 2650] /\
    %v1 >= [-2650, -2650, -2650, -2650, -2650, -2650, -2650, -2650] /\

    %v0 <= [2650, 2650, 2650, 2650, 2650, 2650, 2650, 2650] /\
    %v0 >= [-2650, -2650, -2650, -2650, -2650, -2650, -2650, -2650]

    prove with [algebra solver isl]
    && true;

assume
    true &&

    %v1 <=s [2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16] /\
    %v1 >=s [(-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16] /\

    %v0 <=s [2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16] /\
    %v0 >=s [(-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16];

cut (* 40 *)
    [L0x7fffffe2d0, L0x7fffffe2d2, L0x7fffffe2d4, L0x7fffffe2d6, L0x7fffffe2d8, L0x7fffffe2da, L0x7fffffe2dc, L0x7fffffe2de] = %v1 /\
    [L0x7fffffe2e0, L0x7fffffe2e2, L0x7fffffe2e4, L0x7fffffe2e6, L0x7fffffe2e8, L0x7fffffe2ea, L0x7fffffe2ec, L0x7fffffe2ee] = %v0 /\

    %v1 ++ %v0 = [633, 633, 633, 633, 633, 633, 633, 633, 633, 633, 633, 633, 633, 633, 633, 633] * [
        arr900_a * arr900_b + 2113 * arr901_a * arr917_b + 2113 * arr902_a * arr916_b + 2113 * arr903_a * arr915_b + 2113 * arr904_a * arr914_b + 2113 * arr905_a * arr913_b + 2113 * arr906_a * arr912_b + 2113 * arr907_a * arr911_b + 2113 * arr910_a * arr910_b + 2113 * arr911_a * arr907_b + 2113 * arr912_a * arr906_b + 2113 * arr913_a * arr905_b + 2113 * arr914_a * arr904_b + 2113 * arr915_a * arr903_b + 2113 * arr916_a * arr902_b + 2113 * arr917_a * arr901_b,
        arr900_a * arr901_b + arr901_a * arr900_b + 2113 * arr902_a * arr917_b + 2113 * arr903_a * arr916_b + 2113 * arr904_a * arr915_b + 2113 * arr905_a * arr914_b + 2113 * arr906_a * arr913_b + 2113 * arr907_a * arr912_b + 2113 * arr910_a * arr911_b + 2113 * arr911_a * arr910_b + 2113 * arr912_a * arr907_b + 2113 * arr913_a * arr906_b + 2113 * arr914_a * arr905_b + 2113 * arr915_a * arr904_b + 2113 * arr916_a * arr903_b + 2113 * arr917_a * arr902_b,
        arr900_a * arr902_b + arr901_a * arr901_b + arr902_a * arr900_b + 2113 * arr903_a * arr917_b + 2113 * arr904_a * arr916_b + 2113 * arr905_a * arr915_b + 2113 * arr906_a * arr914_b + 2113 * arr907_a * arr913_b + 2113 * arr910_a * arr912_b + 2113 * arr911_a * arr911_b + 2113 * arr912_a * arr910_b + 2113 * arr913_a * arr907_b + 2113 * arr914_a * arr906_b + 2113 * arr915_a * arr905_b + 2113 * arr916_a * arr904_b + 2113 * arr917_a * arr903_b,
        arr900_a * arr903_b + arr901_a * arr902_b + arr902_a * arr901_b + arr903_a * arr900_b + 2113 * arr904_a * arr917_b + 2113 * arr905_a * arr916_b + 2113 * arr906_a * arr915_b + 2113 * arr907_a * arr914_b + 2113 * arr910_a * arr913_b + 2113 * arr911_a * arr912_b + 2113 * arr912_a * arr911_b + 2113 * arr913_a * arr910_b + 2113 * arr914_a * arr907_b + 2113 * arr915_a * arr906_b + 2113 * arr916_a * arr905_b + 2113 * arr917_a * arr904_b,
        arr900_a * arr904_b + arr901_a * arr903_b + arr902_a * arr902_b + arr903_a * arr901_b + arr904_a * arr900_b + 2113 * arr905_a * arr917_b + 2113 * arr906_a * arr916_b + 2113 * arr907_a * arr915_b + 2113 * arr910_a * arr914_b + 2113 * arr911_a * arr913_b + 2113 * arr912_a * arr912_b + 2113 * arr913_a * arr911_b + 2113 * arr914_a * arr910_b + 2113 * arr915_a * arr907_b + 2113 * arr916_a * arr906_b + 2113 * arr917_a * arr905_b,
        arr900_a * arr905_b + arr901_a * arr904_b + arr902_a * arr903_b + arr903_a * arr902_b + arr904_a * arr901_b + arr905_a * arr900_b + 2113 * arr906_a * arr917_b + 2113 * arr907_a * arr916_b + 2113 * arr910_a * arr915_b + 2113 * arr911_a * arr914_b + 2113 * arr912_a * arr913_b + 2113 * arr913_a * arr912_b + 2113 * arr914_a * arr911_b + 2113 * arr915_a * arr910_b + 2113 * arr916_a * arr907_b + 2113 * arr917_a * arr906_b,
        arr900_a * arr906_b + arr901_a * arr905_b + arr902_a * arr904_b + arr903_a * arr903_b + arr904_a * arr902_b + arr905_a * arr901_b + arr906_a * arr900_b + 2113 * arr907_a * arr917_b + 2113 * arr910_a * arr916_b + 2113 * arr911_a * arr915_b + 2113 * arr912_a * arr914_b + 2113 * arr913_a * arr913_b + 2113 * arr914_a * arr912_b + 2113 * arr915_a * arr911_b + 2113 * arr916_a * arr910_b + 2113 * arr917_a * arr907_b,
        arr900_a * arr907_b + arr901_a * arr906_b + arr902_a * arr905_b + arr903_a * arr904_b + arr904_a * arr903_b + arr905_a * arr902_b + arr906_a * arr901_b + arr907_a * arr900_b + 2113 * arr910_a * arr917_b + 2113 * arr911_a * arr916_b + 2113 * arr912_a * arr915_b + 2113 * arr913_a * arr914_b + 2113 * arr914_a * arr913_b + 2113 * arr915_a * arr912_b + 2113 * arr916_a * arr911_b + 2113 * arr917_a * arr910_b,
        arr900_a * arr910_b + arr901_a * arr907_b + arr902_a * arr906_b + arr903_a * arr905_b + arr904_a * arr904_b + arr905_a * arr903_b + arr906_a * arr902_b + arr907_a * arr901_b + arr910_a * arr900_b + 2113 * arr911_a * arr917_b + 2113 * arr912_a * arr916_b + 2113 * arr913_a * arr915_b + 2113 * arr914_a * arr914_b + 2113 * arr915_a * arr913_b + 2113 * arr916_a * arr912_b + 2113 * arr917_a * arr911_b,
        arr900_a * arr911_b + arr901_a * arr910_b + arr902_a * arr907_b + arr903_a * arr906_b + arr904_a * arr905_b + arr905_a * arr904_b + arr906_a * arr903_b + arr907_a * arr902_b + arr910_a * arr901_b + arr911_a * arr900_b + 2113 * arr912_a * arr917_b + 2113 * arr913_a * arr916_b + 2113 * arr914_a * arr915_b + 2113 * arr915_a * arr914_b + 2113 * arr916_a * arr913_b + 2113 * arr917_a * arr912_b,
        arr900_a * arr912_b + arr901_a * arr911_b + arr902_a * arr910_b + arr903_a * arr907_b + arr904_a * arr906_b + arr905_a * arr905_b + arr906_a * arr904_b + arr907_a * arr903_b + arr910_a * arr902_b + arr911_a * arr901_b + arr912_a * arr900_b + 2113 * arr913_a * arr917_b + 2113 * arr914_a * arr916_b + 2113 * arr915_a * arr915_b + 2113 * arr916_a * arr914_b + 2113 * arr917_a * arr913_b,
        arr900_a * arr913_b + arr901_a * arr912_b + arr902_a * arr911_b + arr903_a * arr910_b + arr904_a * arr907_b + arr905_a * arr906_b + arr906_a * arr905_b + arr907_a * arr904_b + arr910_a * arr903_b + arr911_a * arr902_b + arr912_a * arr901_b + arr913_a * arr900_b + 2113 * arr914_a * arr917_b + 2113 * arr915_a * arr916_b + 2113 * arr916_a * arr915_b + 2113 * arr917_a * arr914_b,
        arr900_a * arr914_b + arr901_a * arr913_b + arr902_a * arr912_b + arr903_a * arr911_b + arr904_a * arr910_b + arr905_a * arr907_b + arr906_a * arr906_b + arr907_a * arr905_b + arr910_a * arr904_b + arr911_a * arr903_b + arr912_a * arr902_b + arr913_a * arr901_b + arr914_a * arr900_b + 2113 * arr915_a * arr917_b + 2113 * arr916_a * arr916_b + 2113 * arr917_a * arr915_b,
        arr900_a * arr915_b + arr901_a * arr914_b + arr902_a * arr913_b + arr903_a * arr912_b + arr904_a * arr911_b + arr905_a * arr910_b + arr906_a * arr907_b + arr907_a * arr906_b + arr910_a * arr905_b + arr911_a * arr904_b + arr912_a * arr903_b + arr913_a * arr902_b + arr914_a * arr901_b + arr915_a * arr900_b + 2113 * arr916_a * arr917_b + 2113 * arr917_a * arr916_b,
        arr900_a * arr916_b + arr901_a * arr915_b + arr902_a * arr914_b + arr903_a * arr913_b + arr904_a * arr912_b + arr905_a * arr911_b + arr906_a * arr910_b + arr907_a * arr907_b + arr910_a * arr906_b + arr911_a * arr905_b + arr912_a * arr904_b + arr913_a * arr903_b + arr914_a * arr902_b + arr915_a * arr901_b + arr916_a * arr900_b + 2113 * arr917_a * arr917_b,
        arr900_a * arr917_b + arr901_a * arr916_b + arr902_a * arr915_b + arr903_a * arr914_b + arr904_a * arr913_b + arr905_a * arr912_b + arr906_a * arr911_b + arr907_a * arr910_b + arr910_a * arr907_b + arr911_a * arr906_b + arr912_a * arr905_b + arr913_a * arr904_b + arr914_a * arr903_b + arr915_a * arr902_b + arr916_a * arr901_b + arr917_a * arr900_b
    ] ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591] )

    prove with [cuts[0, 37, 38, 39]]
  &&
    [L0x7fffffe2d0, L0x7fffffe2d2, L0x7fffffe2d4, L0x7fffffe2d6, L0x7fffffe2d8, L0x7fffffe2da, L0x7fffffe2dc, L0x7fffffe2de] = %v1 /\
    [L0x7fffffe2e0, L0x7fffffe2e2, L0x7fffffe2e4, L0x7fffffe2e6, L0x7fffffe2e8, L0x7fffffe2ea, L0x7fffffe2ec, L0x7fffffe2ee] = %v0 /\

    %v1 <=s [2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16] /\
    %v1 >=s [(-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16] /\

    %v0 <=s [2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16] /\
    %v0 >=s [(-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16];


# epilogue

(* #! <- SP = 0x7fffffe170 *)
#! 0x7fffffe170 = 0x7fffffe170;
(* #ret                                            #! PC = 0x5555551ec4 *)
#ret                                            #! 0x5555551ec4 = 0x5555551ec4;


# output

mov [arr000_c, arr001_c, arr002_c, arr003_c, arr004_c, arr005_c, arr006_c, arr007_c] [L0x7fffffe1b0, L0x7fffffe1b2, L0x7fffffe1b4, L0x7fffffe1b6, L0x7fffffe1b8, L0x7fffffe1ba, L0x7fffffe1bc, L0x7fffffe1be];
mov [arr010_c, arr011_c, arr012_c, arr013_c, arr014_c, arr015_c, arr016_c, arr017_c] [L0x7fffffe1c0, L0x7fffffe1c2, L0x7fffffe1c4, L0x7fffffe1c6, L0x7fffffe1c8, L0x7fffffe1ca, L0x7fffffe1cc, L0x7fffffe1ce];
mov [arr100_c, arr101_c, arr102_c, arr103_c, arr104_c, arr105_c, arr106_c, arr107_c] [L0x7fffffe1d0, L0x7fffffe1d2, L0x7fffffe1d4, L0x7fffffe1d6, L0x7fffffe1d8, L0x7fffffe1da, L0x7fffffe1dc, L0x7fffffe1de];
mov [arr110_c, arr111_c, arr112_c, arr113_c, arr114_c, arr115_c, arr116_c, arr117_c] [L0x7fffffe1e0, L0x7fffffe1e2, L0x7fffffe1e4, L0x7fffffe1e6, L0x7fffffe1e8, L0x7fffffe1ea, L0x7fffffe1ec, L0x7fffffe1ee];
mov [arr200_c, arr201_c, arr202_c, arr203_c, arr204_c, arr205_c, arr206_c, arr207_c] [L0x7fffffe1f0, L0x7fffffe1f2, L0x7fffffe1f4, L0x7fffffe1f6, L0x7fffffe1f8, L0x7fffffe1fa, L0x7fffffe1fc, L0x7fffffe1fe];
mov [arr210_c, arr211_c, arr212_c, arr213_c, arr214_c, arr215_c, arr216_c, arr217_c] [L0x7fffffe200, L0x7fffffe202, L0x7fffffe204, L0x7fffffe206, L0x7fffffe208, L0x7fffffe20a, L0x7fffffe20c, L0x7fffffe20e];
mov [arr300_c, arr301_c, arr302_c, arr303_c, arr304_c, arr305_c, arr306_c, arr307_c] [L0x7fffffe210, L0x7fffffe212, L0x7fffffe214, L0x7fffffe216, L0x7fffffe218, L0x7fffffe21a, L0x7fffffe21c, L0x7fffffe21e];
mov [arr310_c, arr311_c, arr312_c, arr313_c, arr314_c, arr315_c, arr316_c, arr317_c] [L0x7fffffe220, L0x7fffffe222, L0x7fffffe224, L0x7fffffe226, L0x7fffffe228, L0x7fffffe22a, L0x7fffffe22c, L0x7fffffe22e];
mov [arr400_c, arr401_c, arr402_c, arr403_c, arr404_c, arr405_c, arr406_c, arr407_c] [L0x7fffffe230, L0x7fffffe232, L0x7fffffe234, L0x7fffffe236, L0x7fffffe238, L0x7fffffe23a, L0x7fffffe23c, L0x7fffffe23e];
mov [arr410_c, arr411_c, arr412_c, arr413_c, arr414_c, arr415_c, arr416_c, arr417_c] [L0x7fffffe240, L0x7fffffe242, L0x7fffffe244, L0x7fffffe246, L0x7fffffe248, L0x7fffffe24a, L0x7fffffe24c, L0x7fffffe24e];
mov [arr500_c, arr501_c, arr502_c, arr503_c, arr504_c, arr505_c, arr506_c, arr507_c] [L0x7fffffe250, L0x7fffffe252, L0x7fffffe254, L0x7fffffe256, L0x7fffffe258, L0x7fffffe25a, L0x7fffffe25c, L0x7fffffe25e];
mov [arr510_c, arr511_c, arr512_c, arr513_c, arr514_c, arr515_c, arr516_c, arr517_c] [L0x7fffffe260, L0x7fffffe262, L0x7fffffe264, L0x7fffffe266, L0x7fffffe268, L0x7fffffe26a, L0x7fffffe26c, L0x7fffffe26e];
mov [arr600_c, arr601_c, arr602_c, arr603_c, arr604_c, arr605_c, arr606_c, arr607_c] [L0x7fffffe270, L0x7fffffe272, L0x7fffffe274, L0x7fffffe276, L0x7fffffe278, L0x7fffffe27a, L0x7fffffe27c, L0x7fffffe27e];
mov [arr610_c, arr611_c, arr612_c, arr613_c, arr614_c, arr615_c, arr616_c, arr617_c] [L0x7fffffe280, L0x7fffffe282, L0x7fffffe284, L0x7fffffe286, L0x7fffffe288, L0x7fffffe28a, L0x7fffffe28c, L0x7fffffe28e];
mov [arr700_c, arr701_c, arr702_c, arr703_c, arr704_c, arr705_c, arr706_c, arr707_c] [L0x7fffffe290, L0x7fffffe292, L0x7fffffe294, L0x7fffffe296, L0x7fffffe298, L0x7fffffe29a, L0x7fffffe29c, L0x7fffffe29e];
mov [arr710_c, arr711_c, arr712_c, arr713_c, arr714_c, arr715_c, arr716_c, arr717_c] [L0x7fffffe2a0, L0x7fffffe2a2, L0x7fffffe2a4, L0x7fffffe2a6, L0x7fffffe2a8, L0x7fffffe2aa, L0x7fffffe2ac, L0x7fffffe2ae];
mov [arr800_c, arr801_c, arr802_c, arr803_c, arr804_c, arr805_c, arr806_c, arr807_c] [L0x7fffffe2b0, L0x7fffffe2b2, L0x7fffffe2b4, L0x7fffffe2b6, L0x7fffffe2b8, L0x7fffffe2ba, L0x7fffffe2bc, L0x7fffffe2be];
mov [arr810_c, arr811_c, arr812_c, arr813_c, arr814_c, arr815_c, arr816_c, arr817_c] [L0x7fffffe2c0, L0x7fffffe2c2, L0x7fffffe2c4, L0x7fffffe2c6, L0x7fffffe2c8, L0x7fffffe2ca, L0x7fffffe2cc, L0x7fffffe2ce];
mov [arr900_c, arr901_c, arr902_c, arr903_c, arr904_c, arr905_c, arr906_c, arr907_c] [L0x7fffffe2d0, L0x7fffffe2d2, L0x7fffffe2d4, L0x7fffffe2d6, L0x7fffffe2d8, L0x7fffffe2da, L0x7fffffe2dc, L0x7fffffe2de];
mov [arr910_c, arr911_c, arr912_c, arr913_c, arr914_c, arr915_c, arr916_c, arr917_c] [L0x7fffffe2e0, L0x7fffffe2e2, L0x7fffffe2e4, L0x7fffffe2e6, L0x7fffffe2e8, L0x7fffffe2ea, L0x7fffffe2ec, L0x7fffffe2ee];

{
    [arr000_c, arr001_c, arr002_c, arr003_c, arr004_c, arr005_c, arr006_c, arr007_c, arr010_c, arr011_c, arr012_c, arr013_c, arr014_c, arr015_c, arr016_c, arr017_c] = [72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72] * [
        arr000_a * arr000_b + 1 * arr001_a * arr017_b + 1 * arr002_a * arr016_b + 1 * arr003_a * arr015_b + 1 * arr004_a * arr014_b + 1 * arr005_a * arr013_b + 1 * arr006_a * arr012_b + 1 * arr007_a * arr011_b + 1 * arr010_a * arr010_b + 1 * arr011_a * arr007_b + 1 * arr012_a * arr006_b + 1 * arr013_a * arr005_b + 1 * arr014_a * arr004_b + 1 * arr015_a * arr003_b + 1 * arr016_a * arr002_b + 1 * arr017_a * arr001_b,
        arr000_a * arr001_b + arr001_a * arr000_b + 1 * arr002_a * arr017_b + 1 * arr003_a * arr016_b + 1 * arr004_a * arr015_b + 1 * arr005_a * arr014_b + 1 * arr006_a * arr013_b + 1 * arr007_a * arr012_b + 1 * arr010_a * arr011_b + 1 * arr011_a * arr010_b + 1 * arr012_a * arr007_b + 1 * arr013_a * arr006_b + 1 * arr014_a * arr005_b + 1 * arr015_a * arr004_b + 1 * arr016_a * arr003_b + 1 * arr017_a * arr002_b,
        arr000_a * arr002_b + arr001_a * arr001_b + arr002_a * arr000_b + 1 * arr003_a * arr017_b + 1 * arr004_a * arr016_b + 1 * arr005_a * arr015_b + 1 * arr006_a * arr014_b + 1 * arr007_a * arr013_b + 1 * arr010_a * arr012_b + 1 * arr011_a * arr011_b + 1 * arr012_a * arr010_b + 1 * arr013_a * arr007_b + 1 * arr014_a * arr006_b + 1 * arr015_a * arr005_b + 1 * arr016_a * arr004_b + 1 * arr017_a * arr003_b,
        arr000_a * arr003_b + arr001_a * arr002_b + arr002_a * arr001_b + arr003_a * arr000_b + 1 * arr004_a * arr017_b + 1 * arr005_a * arr016_b + 1 * arr006_a * arr015_b + 1 * arr007_a * arr014_b + 1 * arr010_a * arr013_b + 1 * arr011_a * arr012_b + 1 * arr012_a * arr011_b + 1 * arr013_a * arr010_b + 1 * arr014_a * arr007_b + 1 * arr015_a * arr006_b + 1 * arr016_a * arr005_b + 1 * arr017_a * arr004_b,
        arr000_a * arr004_b + arr001_a * arr003_b + arr002_a * arr002_b + arr003_a * arr001_b + arr004_a * arr000_b + 1 * arr005_a * arr017_b + 1 * arr006_a * arr016_b + 1 * arr007_a * arr015_b + 1 * arr010_a * arr014_b + 1 * arr011_a * arr013_b + 1 * arr012_a * arr012_b + 1 * arr013_a * arr011_b + 1 * arr014_a * arr010_b + 1 * arr015_a * arr007_b + 1 * arr016_a * arr006_b + 1 * arr017_a * arr005_b,
        arr000_a * arr005_b + arr001_a * arr004_b + arr002_a * arr003_b + arr003_a * arr002_b + arr004_a * arr001_b + arr005_a * arr000_b + 1 * arr006_a * arr017_b + 1 * arr007_a * arr016_b + 1 * arr010_a * arr015_b + 1 * arr011_a * arr014_b + 1 * arr012_a * arr013_b + 1 * arr013_a * arr012_b + 1 * arr014_a * arr011_b + 1 * arr015_a * arr010_b + 1 * arr016_a * arr007_b + 1 * arr017_a * arr006_b,
        arr000_a * arr006_b + arr001_a * arr005_b + arr002_a * arr004_b + arr003_a * arr003_b + arr004_a * arr002_b + arr005_a * arr001_b + arr006_a * arr000_b + 1 * arr007_a * arr017_b + 1 * arr010_a * arr016_b + 1 * arr011_a * arr015_b + 1 * arr012_a * arr014_b + 1 * arr013_a * arr013_b + 1 * arr014_a * arr012_b + 1 * arr015_a * arr011_b + 1 * arr016_a * arr010_b + 1 * arr017_a * arr007_b,
        arr000_a * arr007_b + arr001_a * arr006_b + arr002_a * arr005_b + arr003_a * arr004_b + arr004_a * arr003_b + arr005_a * arr002_b + arr006_a * arr001_b + arr007_a * arr000_b + 1 * arr010_a * arr017_b + 1 * arr011_a * arr016_b + 1 * arr012_a * arr015_b + 1 * arr013_a * arr014_b + 1 * arr014_a * arr013_b + 1 * arr015_a * arr012_b + 1 * arr016_a * arr011_b + 1 * arr017_a * arr010_b,
        arr000_a * arr010_b + arr001_a * arr007_b + arr002_a * arr006_b + arr003_a * arr005_b + arr004_a * arr004_b + arr005_a * arr003_b + arr006_a * arr002_b + arr007_a * arr001_b + arr010_a * arr000_b + 1 * arr011_a * arr017_b + 1 * arr012_a * arr016_b + 1 * arr013_a * arr015_b + 1 * arr014_a * arr014_b + 1 * arr015_a * arr013_b + 1 * arr016_a * arr012_b + 1 * arr017_a * arr011_b,
        arr000_a * arr011_b + arr001_a * arr010_b + arr002_a * arr007_b + arr003_a * arr006_b + arr004_a * arr005_b + arr005_a * arr004_b + arr006_a * arr003_b + arr007_a * arr002_b + arr010_a * arr001_b + arr011_a * arr000_b + 1 * arr012_a * arr017_b + 1 * arr013_a * arr016_b + 1 * arr014_a * arr015_b + 1 * arr015_a * arr014_b + 1 * arr016_a * arr013_b + 1 * arr017_a * arr012_b,
        arr000_a * arr012_b + arr001_a * arr011_b + arr002_a * arr010_b + arr003_a * arr007_b + arr004_a * arr006_b + arr005_a * arr005_b + arr006_a * arr004_b + arr007_a * arr003_b + arr010_a * arr002_b + arr011_a * arr001_b + arr012_a * arr000_b + 1 * arr013_a * arr017_b + 1 * arr014_a * arr016_b + 1 * arr015_a * arr015_b + 1 * arr016_a * arr014_b + 1 * arr017_a * arr013_b,
        arr000_a * arr013_b + arr001_a * arr012_b + arr002_a * arr011_b + arr003_a * arr010_b + arr004_a * arr007_b + arr005_a * arr006_b + arr006_a * arr005_b + arr007_a * arr004_b + arr010_a * arr003_b + arr011_a * arr002_b + arr012_a * arr001_b + arr013_a * arr000_b + 1 * arr014_a * arr017_b + 1 * arr015_a * arr016_b + 1 * arr016_a * arr015_b + 1 * arr017_a * arr014_b,
        arr000_a * arr014_b + arr001_a * arr013_b + arr002_a * arr012_b + arr003_a * arr011_b + arr004_a * arr010_b + arr005_a * arr007_b + arr006_a * arr006_b + arr007_a * arr005_b + arr010_a * arr004_b + arr011_a * arr003_b + arr012_a * arr002_b + arr013_a * arr001_b + arr014_a * arr000_b + 1 * arr015_a * arr017_b + 1 * arr016_a * arr016_b + 1 * arr017_a * arr015_b,
        arr000_a * arr015_b + arr001_a * arr014_b + arr002_a * arr013_b + arr003_a * arr012_b + arr004_a * arr011_b + arr005_a * arr010_b + arr006_a * arr007_b + arr007_a * arr006_b + arr010_a * arr005_b + arr011_a * arr004_b + arr012_a * arr003_b + arr013_a * arr002_b + arr014_a * arr001_b + arr015_a * arr000_b + 1 * arr016_a * arr017_b + 1 * arr017_a * arr016_b,
        arr000_a * arr016_b + arr001_a * arr015_b + arr002_a * arr014_b + arr003_a * arr013_b + arr004_a * arr012_b + arr005_a * arr011_b + arr006_a * arr010_b + arr007_a * arr007_b + arr010_a * arr006_b + arr011_a * arr005_b + arr012_a * arr004_b + arr013_a * arr003_b + arr014_a * arr002_b + arr015_a * arr001_b + arr016_a * arr000_b + 1 * arr017_a * arr017_b,
        arr000_a * arr017_b + arr001_a * arr016_b + arr002_a * arr015_b + arr003_a * arr014_b + arr004_a * arr013_b + arr005_a * arr012_b + arr006_a * arr011_b + arr007_a * arr010_b + arr010_a * arr007_b + arr011_a * arr006_b + arr012_a * arr005_b + arr013_a * arr004_b + arr014_a * arr003_b + arr015_a * arr002_b + arr016_a * arr001_b + arr017_a * arr000_b
    ] ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591]) /\

    [arr100_c, arr101_c, arr102_c, arr103_c, arr104_c, arr105_c, arr106_c, arr107_c, arr110_c, arr111_c, arr112_c, arr113_c, arr114_c, arr115_c, arr116_c, arr117_c] = [-1145, -1145, -1145, -1145, -1145, -1145, -1145, -1145, -1145, -1145, -1145, -1145, -1145, -1145, -1145, -1145] * [
        arr100_a * arr100_b + -1610 * arr101_a * arr117_b + -1610 * arr102_a * arr116_b + -1610 * arr103_a * arr115_b + -1610 * arr104_a * arr114_b + -1610 * arr105_a * arr113_b + -1610 * arr106_a * arr112_b + -1610 * arr107_a * arr111_b + -1610 * arr110_a * arr110_b + -1610 * arr111_a * arr107_b + -1610 * arr112_a * arr106_b + -1610 * arr113_a * arr105_b + -1610 * arr114_a * arr104_b + -1610 * arr115_a * arr103_b + -1610 * arr116_a * arr102_b + -1610 * arr117_a * arr101_b,
        arr100_a * arr101_b + arr101_a * arr100_b + -1610 * arr102_a * arr117_b + -1610 * arr103_a * arr116_b + -1610 * arr104_a * arr115_b + -1610 * arr105_a * arr114_b + -1610 * arr106_a * arr113_b + -1610 * arr107_a * arr112_b + -1610 * arr110_a * arr111_b + -1610 * arr111_a * arr110_b + -1610 * arr112_a * arr107_b + -1610 * arr113_a * arr106_b + -1610 * arr114_a * arr105_b + -1610 * arr115_a * arr104_b + -1610 * arr116_a * arr103_b + -1610 * arr117_a * arr102_b,
        arr100_a * arr102_b + arr101_a * arr101_b + arr102_a * arr100_b + -1610 * arr103_a * arr117_b + -1610 * arr104_a * arr116_b + -1610 * arr105_a * arr115_b + -1610 * arr106_a * arr114_b + -1610 * arr107_a * arr113_b + -1610 * arr110_a * arr112_b + -1610 * arr111_a * arr111_b + -1610 * arr112_a * arr110_b + -1610 * arr113_a * arr107_b + -1610 * arr114_a * arr106_b + -1610 * arr115_a * arr105_b + -1610 * arr116_a * arr104_b + -1610 * arr117_a * arr103_b,
        arr100_a * arr103_b + arr101_a * arr102_b + arr102_a * arr101_b + arr103_a * arr100_b + -1610 * arr104_a * arr117_b + -1610 * arr105_a * arr116_b + -1610 * arr106_a * arr115_b + -1610 * arr107_a * arr114_b + -1610 * arr110_a * arr113_b + -1610 * arr111_a * arr112_b + -1610 * arr112_a * arr111_b + -1610 * arr113_a * arr110_b + -1610 * arr114_a * arr107_b + -1610 * arr115_a * arr106_b + -1610 * arr116_a * arr105_b + -1610 * arr117_a * arr104_b,
        arr100_a * arr104_b + arr101_a * arr103_b + arr102_a * arr102_b + arr103_a * arr101_b + arr104_a * arr100_b + -1610 * arr105_a * arr117_b + -1610 * arr106_a * arr116_b + -1610 * arr107_a * arr115_b + -1610 * arr110_a * arr114_b + -1610 * arr111_a * arr113_b + -1610 * arr112_a * arr112_b + -1610 * arr113_a * arr111_b + -1610 * arr114_a * arr110_b + -1610 * arr115_a * arr107_b + -1610 * arr116_a * arr106_b + -1610 * arr117_a * arr105_b,
        arr100_a * arr105_b + arr101_a * arr104_b + arr102_a * arr103_b + arr103_a * arr102_b + arr104_a * arr101_b + arr105_a * arr100_b + -1610 * arr106_a * arr117_b + -1610 * arr107_a * arr116_b + -1610 * arr110_a * arr115_b + -1610 * arr111_a * arr114_b + -1610 * arr112_a * arr113_b + -1610 * arr113_a * arr112_b + -1610 * arr114_a * arr111_b + -1610 * arr115_a * arr110_b + -1610 * arr116_a * arr107_b + -1610 * arr117_a * arr106_b,
        arr100_a * arr106_b + arr101_a * arr105_b + arr102_a * arr104_b + arr103_a * arr103_b + arr104_a * arr102_b + arr105_a * arr101_b + arr106_a * arr100_b + -1610 * arr107_a * arr117_b + -1610 * arr110_a * arr116_b + -1610 * arr111_a * arr115_b + -1610 * arr112_a * arr114_b + -1610 * arr113_a * arr113_b + -1610 * arr114_a * arr112_b + -1610 * arr115_a * arr111_b + -1610 * arr116_a * arr110_b + -1610 * arr117_a * arr107_b,
        arr100_a * arr107_b + arr101_a * arr106_b + arr102_a * arr105_b + arr103_a * arr104_b + arr104_a * arr103_b + arr105_a * arr102_b + arr106_a * arr101_b + arr107_a * arr100_b + -1610 * arr110_a * arr117_b + -1610 * arr111_a * arr116_b + -1610 * arr112_a * arr115_b + -1610 * arr113_a * arr114_b + -1610 * arr114_a * arr113_b + -1610 * arr115_a * arr112_b + -1610 * arr116_a * arr111_b + -1610 * arr117_a * arr110_b,
        arr100_a * arr110_b + arr101_a * arr107_b + arr102_a * arr106_b + arr103_a * arr105_b + arr104_a * arr104_b + arr105_a * arr103_b + arr106_a * arr102_b + arr107_a * arr101_b + arr110_a * arr100_b + -1610 * arr111_a * arr117_b + -1610 * arr112_a * arr116_b + -1610 * arr113_a * arr115_b + -1610 * arr114_a * arr114_b + -1610 * arr115_a * arr113_b + -1610 * arr116_a * arr112_b + -1610 * arr117_a * arr111_b,
        arr100_a * arr111_b + arr101_a * arr110_b + arr102_a * arr107_b + arr103_a * arr106_b + arr104_a * arr105_b + arr105_a * arr104_b + arr106_a * arr103_b + arr107_a * arr102_b + arr110_a * arr101_b + arr111_a * arr100_b + -1610 * arr112_a * arr117_b + -1610 * arr113_a * arr116_b + -1610 * arr114_a * arr115_b + -1610 * arr115_a * arr114_b + -1610 * arr116_a * arr113_b + -1610 * arr117_a * arr112_b,
        arr100_a * arr112_b + arr101_a * arr111_b + arr102_a * arr110_b + arr103_a * arr107_b + arr104_a * arr106_b + arr105_a * arr105_b + arr106_a * arr104_b + arr107_a * arr103_b + arr110_a * arr102_b + arr111_a * arr101_b + arr112_a * arr100_b + -1610 * arr113_a * arr117_b + -1610 * arr114_a * arr116_b + -1610 * arr115_a * arr115_b + -1610 * arr116_a * arr114_b + -1610 * arr117_a * arr113_b,
        arr100_a * arr113_b + arr101_a * arr112_b + arr102_a * arr111_b + arr103_a * arr110_b + arr104_a * arr107_b + arr105_a * arr106_b + arr106_a * arr105_b + arr107_a * arr104_b + arr110_a * arr103_b + arr111_a * arr102_b + arr112_a * arr101_b + arr113_a * arr100_b + -1610 * arr114_a * arr117_b + -1610 * arr115_a * arr116_b + -1610 * arr116_a * arr115_b + -1610 * arr117_a * arr114_b,
        arr100_a * arr114_b + arr101_a * arr113_b + arr102_a * arr112_b + arr103_a * arr111_b + arr104_a * arr110_b + arr105_a * arr107_b + arr106_a * arr106_b + arr107_a * arr105_b + arr110_a * arr104_b + arr111_a * arr103_b + arr112_a * arr102_b + arr113_a * arr101_b + arr114_a * arr100_b + -1610 * arr115_a * arr117_b + -1610 * arr116_a * arr116_b + -1610 * arr117_a * arr115_b,
        arr100_a * arr115_b + arr101_a * arr114_b + arr102_a * arr113_b + arr103_a * arr112_b + arr104_a * arr111_b + arr105_a * arr110_b + arr106_a * arr107_b + arr107_a * arr106_b + arr110_a * arr105_b + arr111_a * arr104_b + arr112_a * arr103_b + arr113_a * arr102_b + arr114_a * arr101_b + arr115_a * arr100_b + -1610 * arr116_a * arr117_b + -1610 * arr117_a * arr116_b,
        arr100_a * arr116_b + arr101_a * arr115_b + arr102_a * arr114_b + arr103_a * arr113_b + arr104_a * arr112_b + arr105_a * arr111_b + arr106_a * arr110_b + arr107_a * arr107_b + arr110_a * arr106_b + arr111_a * arr105_b + arr112_a * arr104_b + arr113_a * arr103_b + arr114_a * arr102_b + arr115_a * arr101_b + arr116_a * arr100_b + -1610 * arr117_a * arr117_b,
        arr100_a * arr117_b + arr101_a * arr116_b + arr102_a * arr115_b + arr103_a * arr114_b + arr104_a * arr113_b + arr105_a * arr112_b + arr106_a * arr111_b + arr107_a * arr110_b + arr110_a * arr107_b + arr111_a * arr106_b + arr112_a * arr105_b + arr113_a * arr104_b + arr114_a * arr103_b + arr115_a * arr102_b + arr116_a * arr101_b + arr117_a * arr100_b
    ] ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591]) /\

    [arr200_c, arr201_c, arr202_c, arr203_c, arr204_c, arr205_c, arr206_c, arr207_c, arr210_c, arr211_c, arr212_c, arr213_c, arr214_c, arr215_c, arr216_c, arr217_c] = [-2132, -2132, -2132, -2132, -2132, -2132, -2132, -2132, -2132, -2132, -2132, -2132, -2132, -2132, -2132, -2132] * [
        arr200_a * arr200_b + -1815 * arr201_a * arr217_b + -1815 * arr202_a * arr216_b + -1815 * arr203_a * arr215_b + -1815 * arr204_a * arr214_b + -1815 * arr205_a * arr213_b + -1815 * arr206_a * arr212_b + -1815 * arr207_a * arr211_b + -1815 * arr210_a * arr210_b + -1815 * arr211_a * arr207_b + -1815 * arr212_a * arr206_b + -1815 * arr213_a * arr205_b + -1815 * arr214_a * arr204_b + -1815 * arr215_a * arr203_b + -1815 * arr216_a * arr202_b + -1815 * arr217_a * arr201_b,
        arr200_a * arr201_b + arr201_a * arr200_b + -1815 * arr202_a * arr217_b + -1815 * arr203_a * arr216_b + -1815 * arr204_a * arr215_b + -1815 * arr205_a * arr214_b + -1815 * arr206_a * arr213_b + -1815 * arr207_a * arr212_b + -1815 * arr210_a * arr211_b + -1815 * arr211_a * arr210_b + -1815 * arr212_a * arr207_b + -1815 * arr213_a * arr206_b + -1815 * arr214_a * arr205_b + -1815 * arr215_a * arr204_b + -1815 * arr216_a * arr203_b + -1815 * arr217_a * arr202_b,
        arr200_a * arr202_b + arr201_a * arr201_b + arr202_a * arr200_b + -1815 * arr203_a * arr217_b + -1815 * arr204_a * arr216_b + -1815 * arr205_a * arr215_b + -1815 * arr206_a * arr214_b + -1815 * arr207_a * arr213_b + -1815 * arr210_a * arr212_b + -1815 * arr211_a * arr211_b + -1815 * arr212_a * arr210_b + -1815 * arr213_a * arr207_b + -1815 * arr214_a * arr206_b + -1815 * arr215_a * arr205_b + -1815 * arr216_a * arr204_b + -1815 * arr217_a * arr203_b,
        arr200_a * arr203_b + arr201_a * arr202_b + arr202_a * arr201_b + arr203_a * arr200_b + -1815 * arr204_a * arr217_b + -1815 * arr205_a * arr216_b + -1815 * arr206_a * arr215_b + -1815 * arr207_a * arr214_b + -1815 * arr210_a * arr213_b + -1815 * arr211_a * arr212_b + -1815 * arr212_a * arr211_b + -1815 * arr213_a * arr210_b + -1815 * arr214_a * arr207_b + -1815 * arr215_a * arr206_b + -1815 * arr216_a * arr205_b + -1815 * arr217_a * arr204_b,
        arr200_a * arr204_b + arr201_a * arr203_b + arr202_a * arr202_b + arr203_a * arr201_b + arr204_a * arr200_b + -1815 * arr205_a * arr217_b + -1815 * arr206_a * arr216_b + -1815 * arr207_a * arr215_b + -1815 * arr210_a * arr214_b + -1815 * arr211_a * arr213_b + -1815 * arr212_a * arr212_b + -1815 * arr213_a * arr211_b + -1815 * arr214_a * arr210_b + -1815 * arr215_a * arr207_b + -1815 * arr216_a * arr206_b + -1815 * arr217_a * arr205_b,
        arr200_a * arr205_b + arr201_a * arr204_b + arr202_a * arr203_b + arr203_a * arr202_b + arr204_a * arr201_b + arr205_a * arr200_b + -1815 * arr206_a * arr217_b + -1815 * arr207_a * arr216_b + -1815 * arr210_a * arr215_b + -1815 * arr211_a * arr214_b + -1815 * arr212_a * arr213_b + -1815 * arr213_a * arr212_b + -1815 * arr214_a * arr211_b + -1815 * arr215_a * arr210_b + -1815 * arr216_a * arr207_b + -1815 * arr217_a * arr206_b,
        arr200_a * arr206_b + arr201_a * arr205_b + arr202_a * arr204_b + arr203_a * arr203_b + arr204_a * arr202_b + arr205_a * arr201_b + arr206_a * arr200_b + -1815 * arr207_a * arr217_b + -1815 * arr210_a * arr216_b + -1815 * arr211_a * arr215_b + -1815 * arr212_a * arr214_b + -1815 * arr213_a * arr213_b + -1815 * arr214_a * arr212_b + -1815 * arr215_a * arr211_b + -1815 * arr216_a * arr210_b + -1815 * arr217_a * arr207_b,
        arr200_a * arr207_b + arr201_a * arr206_b + arr202_a * arr205_b + arr203_a * arr204_b + arr204_a * arr203_b + arr205_a * arr202_b + arr206_a * arr201_b + arr207_a * arr200_b + -1815 * arr210_a * arr217_b + -1815 * arr211_a * arr216_b + -1815 * arr212_a * arr215_b + -1815 * arr213_a * arr214_b + -1815 * arr214_a * arr213_b + -1815 * arr215_a * arr212_b + -1815 * arr216_a * arr211_b + -1815 * arr217_a * arr210_b,
        arr200_a * arr210_b + arr201_a * arr207_b + arr202_a * arr206_b + arr203_a * arr205_b + arr204_a * arr204_b + arr205_a * arr203_b + arr206_a * arr202_b + arr207_a * arr201_b + arr210_a * arr200_b + -1815 * arr211_a * arr217_b + -1815 * arr212_a * arr216_b + -1815 * arr213_a * arr215_b + -1815 * arr214_a * arr214_b + -1815 * arr215_a * arr213_b + -1815 * arr216_a * arr212_b + -1815 * arr217_a * arr211_b,
        arr200_a * arr211_b + arr201_a * arr210_b + arr202_a * arr207_b + arr203_a * arr206_b + arr204_a * arr205_b + arr205_a * arr204_b + arr206_a * arr203_b + arr207_a * arr202_b + arr210_a * arr201_b + arr211_a * arr200_b + -1815 * arr212_a * arr217_b + -1815 * arr213_a * arr216_b + -1815 * arr214_a * arr215_b + -1815 * arr215_a * arr214_b + -1815 * arr216_a * arr213_b + -1815 * arr217_a * arr212_b,
        arr200_a * arr212_b + arr201_a * arr211_b + arr202_a * arr210_b + arr203_a * arr207_b + arr204_a * arr206_b + arr205_a * arr205_b + arr206_a * arr204_b + arr207_a * arr203_b + arr210_a * arr202_b + arr211_a * arr201_b + arr212_a * arr200_b + -1815 * arr213_a * arr217_b + -1815 * arr214_a * arr216_b + -1815 * arr215_a * arr215_b + -1815 * arr216_a * arr214_b + -1815 * arr217_a * arr213_b,
        arr200_a * arr213_b + arr201_a * arr212_b + arr202_a * arr211_b + arr203_a * arr210_b + arr204_a * arr207_b + arr205_a * arr206_b + arr206_a * arr205_b + arr207_a * arr204_b + arr210_a * arr203_b + arr211_a * arr202_b + arr212_a * arr201_b + arr213_a * arr200_b + -1815 * arr214_a * arr217_b + -1815 * arr215_a * arr216_b + -1815 * arr216_a * arr215_b + -1815 * arr217_a * arr214_b,
        arr200_a * arr214_b + arr201_a * arr213_b + arr202_a * arr212_b + arr203_a * arr211_b + arr204_a * arr210_b + arr205_a * arr207_b + arr206_a * arr206_b + arr207_a * arr205_b + arr210_a * arr204_b + arr211_a * arr203_b + arr212_a * arr202_b + arr213_a * arr201_b + arr214_a * arr200_b + -1815 * arr215_a * arr217_b + -1815 * arr216_a * arr216_b + -1815 * arr217_a * arr215_b,
        arr200_a * arr215_b + arr201_a * arr214_b + arr202_a * arr213_b + arr203_a * arr212_b + arr204_a * arr211_b + arr205_a * arr210_b + arr206_a * arr207_b + arr207_a * arr206_b + arr210_a * arr205_b + arr211_a * arr204_b + arr212_a * arr203_b + arr213_a * arr202_b + arr214_a * arr201_b + arr215_a * arr200_b + -1815 * arr216_a * arr217_b + -1815 * arr217_a * arr216_b,
        arr200_a * arr216_b + arr201_a * arr215_b + arr202_a * arr214_b + arr203_a * arr213_b + arr204_a * arr212_b + arr205_a * arr211_b + arr206_a * arr210_b + arr207_a * arr207_b + arr210_a * arr206_b + arr211_a * arr205_b + arr212_a * arr204_b + arr213_a * arr203_b + arr214_a * arr202_b + arr215_a * arr201_b + arr216_a * arr200_b + -1815 * arr217_a * arr217_b,
        arr200_a * arr217_b + arr201_a * arr216_b + arr202_a * arr215_b + arr203_a * arr214_b + arr204_a * arr213_b + arr205_a * arr212_b + arr206_a * arr211_b + arr207_a * arr210_b + arr210_a * arr207_b + arr211_a * arr206_b + arr212_a * arr205_b + arr213_a * arr204_b + arr214_a * arr203_b + arr215_a * arr202_b + arr216_a * arr201_b + arr217_a * arr200_b
    ] ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591]) /\

    [arr300_c, arr301_c, arr302_c, arr303_c, arr304_c, arr305_c, arr306_c, arr307_c, arr310_c, arr311_c, arr312_c, arr313_c, arr314_c, arr315_c, arr316_c, arr317_c] = [-1548, -1548, -1548, -1548, -1548, -1548, -1548, -1548, -1548, -1548, -1548, -1548, -1548, -1548, -1548, -1548] * [
        arr300_a * arr300_b + 2274 * arr301_a * arr317_b + 2274 * arr302_a * arr316_b + 2274 * arr303_a * arr315_b + 2274 * arr304_a * arr314_b + 2274 * arr305_a * arr313_b + 2274 * arr306_a * arr312_b + 2274 * arr307_a * arr311_b + 2274 * arr310_a * arr310_b + 2274 * arr311_a * arr307_b + 2274 * arr312_a * arr306_b + 2274 * arr313_a * arr305_b + 2274 * arr314_a * arr304_b + 2274 * arr315_a * arr303_b + 2274 * arr316_a * arr302_b + 2274 * arr317_a * arr301_b,
        arr300_a * arr301_b + arr301_a * arr300_b + 2274 * arr302_a * arr317_b + 2274 * arr303_a * arr316_b + 2274 * arr304_a * arr315_b + 2274 * arr305_a * arr314_b + 2274 * arr306_a * arr313_b + 2274 * arr307_a * arr312_b + 2274 * arr310_a * arr311_b + 2274 * arr311_a * arr310_b + 2274 * arr312_a * arr307_b + 2274 * arr313_a * arr306_b + 2274 * arr314_a * arr305_b + 2274 * arr315_a * arr304_b + 2274 * arr316_a * arr303_b + 2274 * arr317_a * arr302_b,
        arr300_a * arr302_b + arr301_a * arr301_b + arr302_a * arr300_b + 2274 * arr303_a * arr317_b + 2274 * arr304_a * arr316_b + 2274 * arr305_a * arr315_b + 2274 * arr306_a * arr314_b + 2274 * arr307_a * arr313_b + 2274 * arr310_a * arr312_b + 2274 * arr311_a * arr311_b + 2274 * arr312_a * arr310_b + 2274 * arr313_a * arr307_b + 2274 * arr314_a * arr306_b + 2274 * arr315_a * arr305_b + 2274 * arr316_a * arr304_b + 2274 * arr317_a * arr303_b,
        arr300_a * arr303_b + arr301_a * arr302_b + arr302_a * arr301_b + arr303_a * arr300_b + 2274 * arr304_a * arr317_b + 2274 * arr305_a * arr316_b + 2274 * arr306_a * arr315_b + 2274 * arr307_a * arr314_b + 2274 * arr310_a * arr313_b + 2274 * arr311_a * arr312_b + 2274 * arr312_a * arr311_b + 2274 * arr313_a * arr310_b + 2274 * arr314_a * arr307_b + 2274 * arr315_a * arr306_b + 2274 * arr316_a * arr305_b + 2274 * arr317_a * arr304_b,
        arr300_a * arr304_b + arr301_a * arr303_b + arr302_a * arr302_b + arr303_a * arr301_b + arr304_a * arr300_b + 2274 * arr305_a * arr317_b + 2274 * arr306_a * arr316_b + 2274 * arr307_a * arr315_b + 2274 * arr310_a * arr314_b + 2274 * arr311_a * arr313_b + 2274 * arr312_a * arr312_b + 2274 * arr313_a * arr311_b + 2274 * arr314_a * arr310_b + 2274 * arr315_a * arr307_b + 2274 * arr316_a * arr306_b + 2274 * arr317_a * arr305_b,
        arr300_a * arr305_b + arr301_a * arr304_b + arr302_a * arr303_b + arr303_a * arr302_b + arr304_a * arr301_b + arr305_a * arr300_b + 2274 * arr306_a * arr317_b + 2274 * arr307_a * arr316_b + 2274 * arr310_a * arr315_b + 2274 * arr311_a * arr314_b + 2274 * arr312_a * arr313_b + 2274 * arr313_a * arr312_b + 2274 * arr314_a * arr311_b + 2274 * arr315_a * arr310_b + 2274 * arr316_a * arr307_b + 2274 * arr317_a * arr306_b,
        arr300_a * arr306_b + arr301_a * arr305_b + arr302_a * arr304_b + arr303_a * arr303_b + arr304_a * arr302_b + arr305_a * arr301_b + arr306_a * arr300_b + 2274 * arr307_a * arr317_b + 2274 * arr310_a * arr316_b + 2274 * arr311_a * arr315_b + 2274 * arr312_a * arr314_b + 2274 * arr313_a * arr313_b + 2274 * arr314_a * arr312_b + 2274 * arr315_a * arr311_b + 2274 * arr316_a * arr310_b + 2274 * arr317_a * arr307_b,
        arr300_a * arr307_b + arr301_a * arr306_b + arr302_a * arr305_b + arr303_a * arr304_b + arr304_a * arr303_b + arr305_a * arr302_b + arr306_a * arr301_b + arr307_a * arr300_b + 2274 * arr310_a * arr317_b + 2274 * arr311_a * arr316_b + 2274 * arr312_a * arr315_b + 2274 * arr313_a * arr314_b + 2274 * arr314_a * arr313_b + 2274 * arr315_a * arr312_b + 2274 * arr316_a * arr311_b + 2274 * arr317_a * arr310_b,
        arr300_a * arr310_b + arr301_a * arr307_b + arr302_a * arr306_b + arr303_a * arr305_b + arr304_a * arr304_b + arr305_a * arr303_b + arr306_a * arr302_b + arr307_a * arr301_b + arr310_a * arr300_b + 2274 * arr311_a * arr317_b + 2274 * arr312_a * arr316_b + 2274 * arr313_a * arr315_b + 2274 * arr314_a * arr314_b + 2274 * arr315_a * arr313_b + 2274 * arr316_a * arr312_b + 2274 * arr317_a * arr311_b,
        arr300_a * arr311_b + arr301_a * arr310_b + arr302_a * arr307_b + arr303_a * arr306_b + arr304_a * arr305_b + arr305_a * arr304_b + arr306_a * arr303_b + arr307_a * arr302_b + arr310_a * arr301_b + arr311_a * arr300_b + 2274 * arr312_a * arr317_b + 2274 * arr313_a * arr316_b + 2274 * arr314_a * arr315_b + 2274 * arr315_a * arr314_b + 2274 * arr316_a * arr313_b + 2274 * arr317_a * arr312_b,
        arr300_a * arr312_b + arr301_a * arr311_b + arr302_a * arr310_b + arr303_a * arr307_b + arr304_a * arr306_b + arr305_a * arr305_b + arr306_a * arr304_b + arr307_a * arr303_b + arr310_a * arr302_b + arr311_a * arr301_b + arr312_a * arr300_b + 2274 * arr313_a * arr317_b + 2274 * arr314_a * arr316_b + 2274 * arr315_a * arr315_b + 2274 * arr316_a * arr314_b + 2274 * arr317_a * arr313_b,
        arr300_a * arr313_b + arr301_a * arr312_b + arr302_a * arr311_b + arr303_a * arr310_b + arr304_a * arr307_b + arr305_a * arr306_b + arr306_a * arr305_b + arr307_a * arr304_b + arr310_a * arr303_b + arr311_a * arr302_b + arr312_a * arr301_b + arr313_a * arr300_b + 2274 * arr314_a * arr317_b + 2274 * arr315_a * arr316_b + 2274 * arr316_a * arr315_b + 2274 * arr317_a * arr314_b,
        arr300_a * arr314_b + arr301_a * arr313_b + arr302_a * arr312_b + arr303_a * arr311_b + arr304_a * arr310_b + arr305_a * arr307_b + arr306_a * arr306_b + arr307_a * arr305_b + arr310_a * arr304_b + arr311_a * arr303_b + arr312_a * arr302_b + arr313_a * arr301_b + arr314_a * arr300_b + 2274 * arr315_a * arr317_b + 2274 * arr316_a * arr316_b + 2274 * arr317_a * arr315_b,
        arr300_a * arr315_b + arr301_a * arr314_b + arr302_a * arr313_b + arr303_a * arr312_b + arr304_a * arr311_b + arr305_a * arr310_b + arr306_a * arr307_b + arr307_a * arr306_b + arr310_a * arr305_b + arr311_a * arr304_b + arr312_a * arr303_b + arr313_a * arr302_b + arr314_a * arr301_b + arr315_a * arr300_b + 2274 * arr316_a * arr317_b + 2274 * arr317_a * arr316_b,
        arr300_a * arr316_b + arr301_a * arr315_b + arr302_a * arr314_b + arr303_a * arr313_b + arr304_a * arr312_b + arr305_a * arr311_b + arr306_a * arr310_b + arr307_a * arr307_b + arr310_a * arr306_b + arr311_a * arr305_b + arr312_a * arr304_b + arr313_a * arr303_b + arr314_a * arr302_b + arr315_a * arr301_b + arr316_a * arr300_b + 2274 * arr317_a * arr317_b,
        arr300_a * arr317_b + arr301_a * arr316_b + arr302_a * arr315_b + arr303_a * arr314_b + arr304_a * arr313_b + arr305_a * arr312_b + arr306_a * arr311_b + arr307_a * arr310_b + arr310_a * arr307_b + arr311_a * arr306_b + arr312_a * arr305_b + arr313_a * arr304_b + arr314_a * arr303_b + arr315_a * arr302_b + arr316_a * arr301_b + arr317_a * arr300_b
    ] ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591]) /\

    [arr400_c, arr401_c, arr402_c, arr403_c, arr404_c, arr405_c, arr406_c, arr407_c, arr410_c, arr411_c, arr412_c, arr413_c, arr414_c, arr415_c, arr416_c, arr417_c] = [-633, -633, -633, -633, -633, -633, -633, -633, -633, -633, -633, -633, -633, -633, -633, -633] * [
        arr400_a * arr400_b + -2113 * arr401_a * arr417_b + -2113 * arr402_a * arr416_b + -2113 * arr403_a * arr415_b + -2113 * arr404_a * arr414_b + -2113 * arr405_a * arr413_b + -2113 * arr406_a * arr412_b + -2113 * arr407_a * arr411_b + -2113 * arr410_a * arr410_b + -2113 * arr411_a * arr407_b + -2113 * arr412_a * arr406_b + -2113 * arr413_a * arr405_b + -2113 * arr414_a * arr404_b + -2113 * arr415_a * arr403_b + -2113 * arr416_a * arr402_b + -2113 * arr417_a * arr401_b,
        arr400_a * arr401_b + arr401_a * arr400_b + -2113 * arr402_a * arr417_b + -2113 * arr403_a * arr416_b + -2113 * arr404_a * arr415_b + -2113 * arr405_a * arr414_b + -2113 * arr406_a * arr413_b + -2113 * arr407_a * arr412_b + -2113 * arr410_a * arr411_b + -2113 * arr411_a * arr410_b + -2113 * arr412_a * arr407_b + -2113 * arr413_a * arr406_b + -2113 * arr414_a * arr405_b + -2113 * arr415_a * arr404_b + -2113 * arr416_a * arr403_b + -2113 * arr417_a * arr402_b,
        arr400_a * arr402_b + arr401_a * arr401_b + arr402_a * arr400_b + -2113 * arr403_a * arr417_b + -2113 * arr404_a * arr416_b + -2113 * arr405_a * arr415_b + -2113 * arr406_a * arr414_b + -2113 * arr407_a * arr413_b + -2113 * arr410_a * arr412_b + -2113 * arr411_a * arr411_b + -2113 * arr412_a * arr410_b + -2113 * arr413_a * arr407_b + -2113 * arr414_a * arr406_b + -2113 * arr415_a * arr405_b + -2113 * arr416_a * arr404_b + -2113 * arr417_a * arr403_b,
        arr400_a * arr403_b + arr401_a * arr402_b + arr402_a * arr401_b + arr403_a * arr400_b + -2113 * arr404_a * arr417_b + -2113 * arr405_a * arr416_b + -2113 * arr406_a * arr415_b + -2113 * arr407_a * arr414_b + -2113 * arr410_a * arr413_b + -2113 * arr411_a * arr412_b + -2113 * arr412_a * arr411_b + -2113 * arr413_a * arr410_b + -2113 * arr414_a * arr407_b + -2113 * arr415_a * arr406_b + -2113 * arr416_a * arr405_b + -2113 * arr417_a * arr404_b,
        arr400_a * arr404_b + arr401_a * arr403_b + arr402_a * arr402_b + arr403_a * arr401_b + arr404_a * arr400_b + -2113 * arr405_a * arr417_b + -2113 * arr406_a * arr416_b + -2113 * arr407_a * arr415_b + -2113 * arr410_a * arr414_b + -2113 * arr411_a * arr413_b + -2113 * arr412_a * arr412_b + -2113 * arr413_a * arr411_b + -2113 * arr414_a * arr410_b + -2113 * arr415_a * arr407_b + -2113 * arr416_a * arr406_b + -2113 * arr417_a * arr405_b,
        arr400_a * arr405_b + arr401_a * arr404_b + arr402_a * arr403_b + arr403_a * arr402_b + arr404_a * arr401_b + arr405_a * arr400_b + -2113 * arr406_a * arr417_b + -2113 * arr407_a * arr416_b + -2113 * arr410_a * arr415_b + -2113 * arr411_a * arr414_b + -2113 * arr412_a * arr413_b + -2113 * arr413_a * arr412_b + -2113 * arr414_a * arr411_b + -2113 * arr415_a * arr410_b + -2113 * arr416_a * arr407_b + -2113 * arr417_a * arr406_b,
        arr400_a * arr406_b + arr401_a * arr405_b + arr402_a * arr404_b + arr403_a * arr403_b + arr404_a * arr402_b + arr405_a * arr401_b + arr406_a * arr400_b + -2113 * arr407_a * arr417_b + -2113 * arr410_a * arr416_b + -2113 * arr411_a * arr415_b + -2113 * arr412_a * arr414_b + -2113 * arr413_a * arr413_b + -2113 * arr414_a * arr412_b + -2113 * arr415_a * arr411_b + -2113 * arr416_a * arr410_b + -2113 * arr417_a * arr407_b,
        arr400_a * arr407_b + arr401_a * arr406_b + arr402_a * arr405_b + arr403_a * arr404_b + arr404_a * arr403_b + arr405_a * arr402_b + arr406_a * arr401_b + arr407_a * arr400_b + -2113 * arr410_a * arr417_b + -2113 * arr411_a * arr416_b + -2113 * arr412_a * arr415_b + -2113 * arr413_a * arr414_b + -2113 * arr414_a * arr413_b + -2113 * arr415_a * arr412_b + -2113 * arr416_a * arr411_b + -2113 * arr417_a * arr410_b,
        arr400_a * arr410_b + arr401_a * arr407_b + arr402_a * arr406_b + arr403_a * arr405_b + arr404_a * arr404_b + arr405_a * arr403_b + arr406_a * arr402_b + arr407_a * arr401_b + arr410_a * arr400_b + -2113 * arr411_a * arr417_b + -2113 * arr412_a * arr416_b + -2113 * arr413_a * arr415_b + -2113 * arr414_a * arr414_b + -2113 * arr415_a * arr413_b + -2113 * arr416_a * arr412_b + -2113 * arr417_a * arr411_b,
        arr400_a * arr411_b + arr401_a * arr410_b + arr402_a * arr407_b + arr403_a * arr406_b + arr404_a * arr405_b + arr405_a * arr404_b + arr406_a * arr403_b + arr407_a * arr402_b + arr410_a * arr401_b + arr411_a * arr400_b + -2113 * arr412_a * arr417_b + -2113 * arr413_a * arr416_b + -2113 * arr414_a * arr415_b + -2113 * arr415_a * arr414_b + -2113 * arr416_a * arr413_b + -2113 * arr417_a * arr412_b,
        arr400_a * arr412_b + arr401_a * arr411_b + arr402_a * arr410_b + arr403_a * arr407_b + arr404_a * arr406_b + arr405_a * arr405_b + arr406_a * arr404_b + arr407_a * arr403_b + arr410_a * arr402_b + arr411_a * arr401_b + arr412_a * arr400_b + -2113 * arr413_a * arr417_b + -2113 * arr414_a * arr416_b + -2113 * arr415_a * arr415_b + -2113 * arr416_a * arr414_b + -2113 * arr417_a * arr413_b,
        arr400_a * arr413_b + arr401_a * arr412_b + arr402_a * arr411_b + arr403_a * arr410_b + arr404_a * arr407_b + arr405_a * arr406_b + arr406_a * arr405_b + arr407_a * arr404_b + arr410_a * arr403_b + arr411_a * arr402_b + arr412_a * arr401_b + arr413_a * arr400_b + -2113 * arr414_a * arr417_b + -2113 * arr415_a * arr416_b + -2113 * arr416_a * arr415_b + -2113 * arr417_a * arr414_b,
        arr400_a * arr414_b + arr401_a * arr413_b + arr402_a * arr412_b + arr403_a * arr411_b + arr404_a * arr410_b + arr405_a * arr407_b + arr406_a * arr406_b + arr407_a * arr405_b + arr410_a * arr404_b + arr411_a * arr403_b + arr412_a * arr402_b + arr413_a * arr401_b + arr414_a * arr400_b + -2113 * arr415_a * arr417_b + -2113 * arr416_a * arr416_b + -2113 * arr417_a * arr415_b,
        arr400_a * arr415_b + arr401_a * arr414_b + arr402_a * arr413_b + arr403_a * arr412_b + arr404_a * arr411_b + arr405_a * arr410_b + arr406_a * arr407_b + arr407_a * arr406_b + arr410_a * arr405_b + arr411_a * arr404_b + arr412_a * arr403_b + arr413_a * arr402_b + arr414_a * arr401_b + arr415_a * arr400_b + -2113 * arr416_a * arr417_b + -2113 * arr417_a * arr416_b,
        arr400_a * arr416_b + arr401_a * arr415_b + arr402_a * arr414_b + arr403_a * arr413_b + arr404_a * arr412_b + arr405_a * arr411_b + arr406_a * arr410_b + arr407_a * arr407_b + arr410_a * arr406_b + arr411_a * arr405_b + arr412_a * arr404_b + arr413_a * arr403_b + arr414_a * arr402_b + arr415_a * arr401_b + arr416_a * arr400_b + -2113 * arr417_a * arr417_b,
        arr400_a * arr417_b + arr401_a * arr416_b + arr402_a * arr415_b + arr403_a * arr414_b + arr404_a * arr413_b + arr405_a * arr412_b + arr406_a * arr411_b + arr407_a * arr410_b + arr410_a * arr407_b + arr411_a * arr406_b + arr412_a * arr405_b + arr413_a * arr404_b + arr414_a * arr403_b + arr415_a * arr402_b + arr416_a * arr401_b + arr417_a * arr400_b
    ] ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591]) /\

    [arr500_c, arr501_c, arr502_c, arr503_c, arr504_c, arr505_c, arr506_c, arr507_c, arr510_c, arr511_c, arr512_c, arr513_c, arr514_c, arr515_c, arr516_c, arr517_c] = [-72, -72, -72, -72, -72, -72, -72, -72, -72, -72, -72, -72, -72, -72, -72, -72] * [
        arr500_a * arr500_b + -1 * arr501_a * arr517_b + -1 * arr502_a * arr516_b + -1 * arr503_a * arr515_b + -1 * arr504_a * arr514_b + -1 * arr505_a * arr513_b + -1 * arr506_a * arr512_b + -1 * arr507_a * arr511_b + -1 * arr510_a * arr510_b + -1 * arr511_a * arr507_b + -1 * arr512_a * arr506_b + -1 * arr513_a * arr505_b + -1 * arr514_a * arr504_b + -1 * arr515_a * arr503_b + -1 * arr516_a * arr502_b + -1 * arr517_a * arr501_b,
        arr500_a * arr501_b + arr501_a * arr500_b + -1 * arr502_a * arr517_b + -1 * arr503_a * arr516_b + -1 * arr504_a * arr515_b + -1 * arr505_a * arr514_b + -1 * arr506_a * arr513_b + -1 * arr507_a * arr512_b + -1 * arr510_a * arr511_b + -1 * arr511_a * arr510_b + -1 * arr512_a * arr507_b + -1 * arr513_a * arr506_b + -1 * arr514_a * arr505_b + -1 * arr515_a * arr504_b + -1 * arr516_a * arr503_b + -1 * arr517_a * arr502_b,
        arr500_a * arr502_b + arr501_a * arr501_b + arr502_a * arr500_b + -1 * arr503_a * arr517_b + -1 * arr504_a * arr516_b + -1 * arr505_a * arr515_b + -1 * arr506_a * arr514_b + -1 * arr507_a * arr513_b + -1 * arr510_a * arr512_b + -1 * arr511_a * arr511_b + -1 * arr512_a * arr510_b + -1 * arr513_a * arr507_b + -1 * arr514_a * arr506_b + -1 * arr515_a * arr505_b + -1 * arr516_a * arr504_b + -1 * arr517_a * arr503_b,
        arr500_a * arr503_b + arr501_a * arr502_b + arr502_a * arr501_b + arr503_a * arr500_b + -1 * arr504_a * arr517_b + -1 * arr505_a * arr516_b + -1 * arr506_a * arr515_b + -1 * arr507_a * arr514_b + -1 * arr510_a * arr513_b + -1 * arr511_a * arr512_b + -1 * arr512_a * arr511_b + -1 * arr513_a * arr510_b + -1 * arr514_a * arr507_b + -1 * arr515_a * arr506_b + -1 * arr516_a * arr505_b + -1 * arr517_a * arr504_b,
        arr500_a * arr504_b + arr501_a * arr503_b + arr502_a * arr502_b + arr503_a * arr501_b + arr504_a * arr500_b + -1 * arr505_a * arr517_b + -1 * arr506_a * arr516_b + -1 * arr507_a * arr515_b + -1 * arr510_a * arr514_b + -1 * arr511_a * arr513_b + -1 * arr512_a * arr512_b + -1 * arr513_a * arr511_b + -1 * arr514_a * arr510_b + -1 * arr515_a * arr507_b + -1 * arr516_a * arr506_b + -1 * arr517_a * arr505_b,
        arr500_a * arr505_b + arr501_a * arr504_b + arr502_a * arr503_b + arr503_a * arr502_b + arr504_a * arr501_b + arr505_a * arr500_b + -1 * arr506_a * arr517_b + -1 * arr507_a * arr516_b + -1 * arr510_a * arr515_b + -1 * arr511_a * arr514_b + -1 * arr512_a * arr513_b + -1 * arr513_a * arr512_b + -1 * arr514_a * arr511_b + -1 * arr515_a * arr510_b + -1 * arr516_a * arr507_b + -1 * arr517_a * arr506_b,
        arr500_a * arr506_b + arr501_a * arr505_b + arr502_a * arr504_b + arr503_a * arr503_b + arr504_a * arr502_b + arr505_a * arr501_b + arr506_a * arr500_b + -1 * arr507_a * arr517_b + -1 * arr510_a * arr516_b + -1 * arr511_a * arr515_b + -1 * arr512_a * arr514_b + -1 * arr513_a * arr513_b + -1 * arr514_a * arr512_b + -1 * arr515_a * arr511_b + -1 * arr516_a * arr510_b + -1 * arr517_a * arr507_b,
        arr500_a * arr507_b + arr501_a * arr506_b + arr502_a * arr505_b + arr503_a * arr504_b + arr504_a * arr503_b + arr505_a * arr502_b + arr506_a * arr501_b + arr507_a * arr500_b + -1 * arr510_a * arr517_b + -1 * arr511_a * arr516_b + -1 * arr512_a * arr515_b + -1 * arr513_a * arr514_b + -1 * arr514_a * arr513_b + -1 * arr515_a * arr512_b + -1 * arr516_a * arr511_b + -1 * arr517_a * arr510_b,
        arr500_a * arr510_b + arr501_a * arr507_b + arr502_a * arr506_b + arr503_a * arr505_b + arr504_a * arr504_b + arr505_a * arr503_b + arr506_a * arr502_b + arr507_a * arr501_b + arr510_a * arr500_b + -1 * arr511_a * arr517_b + -1 * arr512_a * arr516_b + -1 * arr513_a * arr515_b + -1 * arr514_a * arr514_b + -1 * arr515_a * arr513_b + -1 * arr516_a * arr512_b + -1 * arr517_a * arr511_b,
        arr500_a * arr511_b + arr501_a * arr510_b + arr502_a * arr507_b + arr503_a * arr506_b + arr504_a * arr505_b + arr505_a * arr504_b + arr506_a * arr503_b + arr507_a * arr502_b + arr510_a * arr501_b + arr511_a * arr500_b + -1 * arr512_a * arr517_b + -1 * arr513_a * arr516_b + -1 * arr514_a * arr515_b + -1 * arr515_a * arr514_b + -1 * arr516_a * arr513_b + -1 * arr517_a * arr512_b,
        arr500_a * arr512_b + arr501_a * arr511_b + arr502_a * arr510_b + arr503_a * arr507_b + arr504_a * arr506_b + arr505_a * arr505_b + arr506_a * arr504_b + arr507_a * arr503_b + arr510_a * arr502_b + arr511_a * arr501_b + arr512_a * arr500_b + -1 * arr513_a * arr517_b + -1 * arr514_a * arr516_b + -1 * arr515_a * arr515_b + -1 * arr516_a * arr514_b + -1 * arr517_a * arr513_b,
        arr500_a * arr513_b + arr501_a * arr512_b + arr502_a * arr511_b + arr503_a * arr510_b + arr504_a * arr507_b + arr505_a * arr506_b + arr506_a * arr505_b + arr507_a * arr504_b + arr510_a * arr503_b + arr511_a * arr502_b + arr512_a * arr501_b + arr513_a * arr500_b + -1 * arr514_a * arr517_b + -1 * arr515_a * arr516_b + -1 * arr516_a * arr515_b + -1 * arr517_a * arr514_b,
        arr500_a * arr514_b + arr501_a * arr513_b + arr502_a * arr512_b + arr503_a * arr511_b + arr504_a * arr510_b + arr505_a * arr507_b + arr506_a * arr506_b + arr507_a * arr505_b + arr510_a * arr504_b + arr511_a * arr503_b + arr512_a * arr502_b + arr513_a * arr501_b + arr514_a * arr500_b + -1 * arr515_a * arr517_b + -1 * arr516_a * arr516_b + -1 * arr517_a * arr515_b,
        arr500_a * arr515_b + arr501_a * arr514_b + arr502_a * arr513_b + arr503_a * arr512_b + arr504_a * arr511_b + arr505_a * arr510_b + arr506_a * arr507_b + arr507_a * arr506_b + arr510_a * arr505_b + arr511_a * arr504_b + arr512_a * arr503_b + arr513_a * arr502_b + arr514_a * arr501_b + arr515_a * arr500_b + -1 * arr516_a * arr517_b + -1 * arr517_a * arr516_b,
        arr500_a * arr516_b + arr501_a * arr515_b + arr502_a * arr514_b + arr503_a * arr513_b + arr504_a * arr512_b + arr505_a * arr511_b + arr506_a * arr510_b + arr507_a * arr507_b + arr510_a * arr506_b + arr511_a * arr505_b + arr512_a * arr504_b + arr513_a * arr503_b + arr514_a * arr502_b + arr515_a * arr501_b + arr516_a * arr500_b + -1 * arr517_a * arr517_b,
        arr500_a * arr517_b + arr501_a * arr516_b + arr502_a * arr515_b + arr503_a * arr514_b + arr504_a * arr513_b + arr505_a * arr512_b + arr506_a * arr511_b + arr507_a * arr510_b + arr510_a * arr507_b + arr511_a * arr506_b + arr512_a * arr505_b + arr513_a * arr504_b + arr514_a * arr503_b + arr515_a * arr502_b + arr516_a * arr501_b + arr517_a * arr500_b
    ] ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591]) /\

    [arr600_c, arr601_c, arr602_c, arr603_c, arr604_c, arr605_c, arr606_c, arr607_c, arr610_c, arr611_c, arr612_c, arr613_c, arr614_c, arr615_c, arr616_c, arr617_c] = [1145, 1145, 1145, 1145, 1145, 1145, 1145, 1145, 1145, 1145, 1145, 1145, 1145, 1145, 1145, 1145] * [
        arr600_a * arr600_b + 1610 * arr601_a * arr617_b + 1610 * arr602_a * arr616_b + 1610 * arr603_a * arr615_b + 1610 * arr604_a * arr614_b + 1610 * arr605_a * arr613_b + 1610 * arr606_a * arr612_b + 1610 * arr607_a * arr611_b + 1610 * arr610_a * arr610_b + 1610 * arr611_a * arr607_b + 1610 * arr612_a * arr606_b + 1610 * arr613_a * arr605_b + 1610 * arr614_a * arr604_b + 1610 * arr615_a * arr603_b + 1610 * arr616_a * arr602_b + 1610 * arr617_a * arr601_b,
        arr600_a * arr601_b + arr601_a * arr600_b + 1610 * arr602_a * arr617_b + 1610 * arr603_a * arr616_b + 1610 * arr604_a * arr615_b + 1610 * arr605_a * arr614_b + 1610 * arr606_a * arr613_b + 1610 * arr607_a * arr612_b + 1610 * arr610_a * arr611_b + 1610 * arr611_a * arr610_b + 1610 * arr612_a * arr607_b + 1610 * arr613_a * arr606_b + 1610 * arr614_a * arr605_b + 1610 * arr615_a * arr604_b + 1610 * arr616_a * arr603_b + 1610 * arr617_a * arr602_b,
        arr600_a * arr602_b + arr601_a * arr601_b + arr602_a * arr600_b + 1610 * arr603_a * arr617_b + 1610 * arr604_a * arr616_b + 1610 * arr605_a * arr615_b + 1610 * arr606_a * arr614_b + 1610 * arr607_a * arr613_b + 1610 * arr610_a * arr612_b + 1610 * arr611_a * arr611_b + 1610 * arr612_a * arr610_b + 1610 * arr613_a * arr607_b + 1610 * arr614_a * arr606_b + 1610 * arr615_a * arr605_b + 1610 * arr616_a * arr604_b + 1610 * arr617_a * arr603_b,
        arr600_a * arr603_b + arr601_a * arr602_b + arr602_a * arr601_b + arr603_a * arr600_b + 1610 * arr604_a * arr617_b + 1610 * arr605_a * arr616_b + 1610 * arr606_a * arr615_b + 1610 * arr607_a * arr614_b + 1610 * arr610_a * arr613_b + 1610 * arr611_a * arr612_b + 1610 * arr612_a * arr611_b + 1610 * arr613_a * arr610_b + 1610 * arr614_a * arr607_b + 1610 * arr615_a * arr606_b + 1610 * arr616_a * arr605_b + 1610 * arr617_a * arr604_b,
        arr600_a * arr604_b + arr601_a * arr603_b + arr602_a * arr602_b + arr603_a * arr601_b + arr604_a * arr600_b + 1610 * arr605_a * arr617_b + 1610 * arr606_a * arr616_b + 1610 * arr607_a * arr615_b + 1610 * arr610_a * arr614_b + 1610 * arr611_a * arr613_b + 1610 * arr612_a * arr612_b + 1610 * arr613_a * arr611_b + 1610 * arr614_a * arr610_b + 1610 * arr615_a * arr607_b + 1610 * arr616_a * arr606_b + 1610 * arr617_a * arr605_b,
        arr600_a * arr605_b + arr601_a * arr604_b + arr602_a * arr603_b + arr603_a * arr602_b + arr604_a * arr601_b + arr605_a * arr600_b + 1610 * arr606_a * arr617_b + 1610 * arr607_a * arr616_b + 1610 * arr610_a * arr615_b + 1610 * arr611_a * arr614_b + 1610 * arr612_a * arr613_b + 1610 * arr613_a * arr612_b + 1610 * arr614_a * arr611_b + 1610 * arr615_a * arr610_b + 1610 * arr616_a * arr607_b + 1610 * arr617_a * arr606_b,
        arr600_a * arr606_b + arr601_a * arr605_b + arr602_a * arr604_b + arr603_a * arr603_b + arr604_a * arr602_b + arr605_a * arr601_b + arr606_a * arr600_b + 1610 * arr607_a * arr617_b + 1610 * arr610_a * arr616_b + 1610 * arr611_a * arr615_b + 1610 * arr612_a * arr614_b + 1610 * arr613_a * arr613_b + 1610 * arr614_a * arr612_b + 1610 * arr615_a * arr611_b + 1610 * arr616_a * arr610_b + 1610 * arr617_a * arr607_b,
        arr600_a * arr607_b + arr601_a * arr606_b + arr602_a * arr605_b + arr603_a * arr604_b + arr604_a * arr603_b + arr605_a * arr602_b + arr606_a * arr601_b + arr607_a * arr600_b + 1610 * arr610_a * arr617_b + 1610 * arr611_a * arr616_b + 1610 * arr612_a * arr615_b + 1610 * arr613_a * arr614_b + 1610 * arr614_a * arr613_b + 1610 * arr615_a * arr612_b + 1610 * arr616_a * arr611_b + 1610 * arr617_a * arr610_b,
        arr600_a * arr610_b + arr601_a * arr607_b + arr602_a * arr606_b + arr603_a * arr605_b + arr604_a * arr604_b + arr605_a * arr603_b + arr606_a * arr602_b + arr607_a * arr601_b + arr610_a * arr600_b + 1610 * arr611_a * arr617_b + 1610 * arr612_a * arr616_b + 1610 * arr613_a * arr615_b + 1610 * arr614_a * arr614_b + 1610 * arr615_a * arr613_b + 1610 * arr616_a * arr612_b + 1610 * arr617_a * arr611_b,
        arr600_a * arr611_b + arr601_a * arr610_b + arr602_a * arr607_b + arr603_a * arr606_b + arr604_a * arr605_b + arr605_a * arr604_b + arr606_a * arr603_b + arr607_a * arr602_b + arr610_a * arr601_b + arr611_a * arr600_b + 1610 * arr612_a * arr617_b + 1610 * arr613_a * arr616_b + 1610 * arr614_a * arr615_b + 1610 * arr615_a * arr614_b + 1610 * arr616_a * arr613_b + 1610 * arr617_a * arr612_b,
        arr600_a * arr612_b + arr601_a * arr611_b + arr602_a * arr610_b + arr603_a * arr607_b + arr604_a * arr606_b + arr605_a * arr605_b + arr606_a * arr604_b + arr607_a * arr603_b + arr610_a * arr602_b + arr611_a * arr601_b + arr612_a * arr600_b + 1610 * arr613_a * arr617_b + 1610 * arr614_a * arr616_b + 1610 * arr615_a * arr615_b + 1610 * arr616_a * arr614_b + 1610 * arr617_a * arr613_b,
        arr600_a * arr613_b + arr601_a * arr612_b + arr602_a * arr611_b + arr603_a * arr610_b + arr604_a * arr607_b + arr605_a * arr606_b + arr606_a * arr605_b + arr607_a * arr604_b + arr610_a * arr603_b + arr611_a * arr602_b + arr612_a * arr601_b + arr613_a * arr600_b + 1610 * arr614_a * arr617_b + 1610 * arr615_a * arr616_b + 1610 * arr616_a * arr615_b + 1610 * arr617_a * arr614_b,
        arr600_a * arr614_b + arr601_a * arr613_b + arr602_a * arr612_b + arr603_a * arr611_b + arr604_a * arr610_b + arr605_a * arr607_b + arr606_a * arr606_b + arr607_a * arr605_b + arr610_a * arr604_b + arr611_a * arr603_b + arr612_a * arr602_b + arr613_a * arr601_b + arr614_a * arr600_b + 1610 * arr615_a * arr617_b + 1610 * arr616_a * arr616_b + 1610 * arr617_a * arr615_b,
        arr600_a * arr615_b + arr601_a * arr614_b + arr602_a * arr613_b + arr603_a * arr612_b + arr604_a * arr611_b + arr605_a * arr610_b + arr606_a * arr607_b + arr607_a * arr606_b + arr610_a * arr605_b + arr611_a * arr604_b + arr612_a * arr603_b + arr613_a * arr602_b + arr614_a * arr601_b + arr615_a * arr600_b + 1610 * arr616_a * arr617_b + 1610 * arr617_a * arr616_b,
        arr600_a * arr616_b + arr601_a * arr615_b + arr602_a * arr614_b + arr603_a * arr613_b + arr604_a * arr612_b + arr605_a * arr611_b + arr606_a * arr610_b + arr607_a * arr607_b + arr610_a * arr606_b + arr611_a * arr605_b + arr612_a * arr604_b + arr613_a * arr603_b + arr614_a * arr602_b + arr615_a * arr601_b + arr616_a * arr600_b + 1610 * arr617_a * arr617_b,
        arr600_a * arr617_b + arr601_a * arr616_b + arr602_a * arr615_b + arr603_a * arr614_b + arr604_a * arr613_b + arr605_a * arr612_b + arr606_a * arr611_b + arr607_a * arr610_b + arr610_a * arr607_b + arr611_a * arr606_b + arr612_a * arr605_b + arr613_a * arr604_b + arr614_a * arr603_b + arr615_a * arr602_b + arr616_a * arr601_b + arr617_a * arr600_b
    ] ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591]) /\

    [arr700_c, arr701_c, arr702_c, arr703_c, arr704_c, arr705_c, arr706_c, arr707_c, arr710_c, arr711_c, arr712_c, arr713_c, arr714_c, arr715_c, arr716_c, arr717_c] = [2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132] * [
        arr700_a * arr700_b + 1815 * arr701_a * arr717_b + 1815 * arr702_a * arr716_b + 1815 * arr703_a * arr715_b + 1815 * arr704_a * arr714_b + 1815 * arr705_a * arr713_b + 1815 * arr706_a * arr712_b + 1815 * arr707_a * arr711_b + 1815 * arr710_a * arr710_b + 1815 * arr711_a * arr707_b + 1815 * arr712_a * arr706_b + 1815 * arr713_a * arr705_b + 1815 * arr714_a * arr704_b + 1815 * arr715_a * arr703_b + 1815 * arr716_a * arr702_b + 1815 * arr717_a * arr701_b,
        arr700_a * arr701_b + arr701_a * arr700_b + 1815 * arr702_a * arr717_b + 1815 * arr703_a * arr716_b + 1815 * arr704_a * arr715_b + 1815 * arr705_a * arr714_b + 1815 * arr706_a * arr713_b + 1815 * arr707_a * arr712_b + 1815 * arr710_a * arr711_b + 1815 * arr711_a * arr710_b + 1815 * arr712_a * arr707_b + 1815 * arr713_a * arr706_b + 1815 * arr714_a * arr705_b + 1815 * arr715_a * arr704_b + 1815 * arr716_a * arr703_b + 1815 * arr717_a * arr702_b,
        arr700_a * arr702_b + arr701_a * arr701_b + arr702_a * arr700_b + 1815 * arr703_a * arr717_b + 1815 * arr704_a * arr716_b + 1815 * arr705_a * arr715_b + 1815 * arr706_a * arr714_b + 1815 * arr707_a * arr713_b + 1815 * arr710_a * arr712_b + 1815 * arr711_a * arr711_b + 1815 * arr712_a * arr710_b + 1815 * arr713_a * arr707_b + 1815 * arr714_a * arr706_b + 1815 * arr715_a * arr705_b + 1815 * arr716_a * arr704_b + 1815 * arr717_a * arr703_b,
        arr700_a * arr703_b + arr701_a * arr702_b + arr702_a * arr701_b + arr703_a * arr700_b + 1815 * arr704_a * arr717_b + 1815 * arr705_a * arr716_b + 1815 * arr706_a * arr715_b + 1815 * arr707_a * arr714_b + 1815 * arr710_a * arr713_b + 1815 * arr711_a * arr712_b + 1815 * arr712_a * arr711_b + 1815 * arr713_a * arr710_b + 1815 * arr714_a * arr707_b + 1815 * arr715_a * arr706_b + 1815 * arr716_a * arr705_b + 1815 * arr717_a * arr704_b,
        arr700_a * arr704_b + arr701_a * arr703_b + arr702_a * arr702_b + arr703_a * arr701_b + arr704_a * arr700_b + 1815 * arr705_a * arr717_b + 1815 * arr706_a * arr716_b + 1815 * arr707_a * arr715_b + 1815 * arr710_a * arr714_b + 1815 * arr711_a * arr713_b + 1815 * arr712_a * arr712_b + 1815 * arr713_a * arr711_b + 1815 * arr714_a * arr710_b + 1815 * arr715_a * arr707_b + 1815 * arr716_a * arr706_b + 1815 * arr717_a * arr705_b,
        arr700_a * arr705_b + arr701_a * arr704_b + arr702_a * arr703_b + arr703_a * arr702_b + arr704_a * arr701_b + arr705_a * arr700_b + 1815 * arr706_a * arr717_b + 1815 * arr707_a * arr716_b + 1815 * arr710_a * arr715_b + 1815 * arr711_a * arr714_b + 1815 * arr712_a * arr713_b + 1815 * arr713_a * arr712_b + 1815 * arr714_a * arr711_b + 1815 * arr715_a * arr710_b + 1815 * arr716_a * arr707_b + 1815 * arr717_a * arr706_b,
        arr700_a * arr706_b + arr701_a * arr705_b + arr702_a * arr704_b + arr703_a * arr703_b + arr704_a * arr702_b + arr705_a * arr701_b + arr706_a * arr700_b + 1815 * arr707_a * arr717_b + 1815 * arr710_a * arr716_b + 1815 * arr711_a * arr715_b + 1815 * arr712_a * arr714_b + 1815 * arr713_a * arr713_b + 1815 * arr714_a * arr712_b + 1815 * arr715_a * arr711_b + 1815 * arr716_a * arr710_b + 1815 * arr717_a * arr707_b,
        arr700_a * arr707_b + arr701_a * arr706_b + arr702_a * arr705_b + arr703_a * arr704_b + arr704_a * arr703_b + arr705_a * arr702_b + arr706_a * arr701_b + arr707_a * arr700_b + 1815 * arr710_a * arr717_b + 1815 * arr711_a * arr716_b + 1815 * arr712_a * arr715_b + 1815 * arr713_a * arr714_b + 1815 * arr714_a * arr713_b + 1815 * arr715_a * arr712_b + 1815 * arr716_a * arr711_b + 1815 * arr717_a * arr710_b,
        arr700_a * arr710_b + arr701_a * arr707_b + arr702_a * arr706_b + arr703_a * arr705_b + arr704_a * arr704_b + arr705_a * arr703_b + arr706_a * arr702_b + arr707_a * arr701_b + arr710_a * arr700_b + 1815 * arr711_a * arr717_b + 1815 * arr712_a * arr716_b + 1815 * arr713_a * arr715_b + 1815 * arr714_a * arr714_b + 1815 * arr715_a * arr713_b + 1815 * arr716_a * arr712_b + 1815 * arr717_a * arr711_b,
        arr700_a * arr711_b + arr701_a * arr710_b + arr702_a * arr707_b + arr703_a * arr706_b + arr704_a * arr705_b + arr705_a * arr704_b + arr706_a * arr703_b + arr707_a * arr702_b + arr710_a * arr701_b + arr711_a * arr700_b + 1815 * arr712_a * arr717_b + 1815 * arr713_a * arr716_b + 1815 * arr714_a * arr715_b + 1815 * arr715_a * arr714_b + 1815 * arr716_a * arr713_b + 1815 * arr717_a * arr712_b,
        arr700_a * arr712_b + arr701_a * arr711_b + arr702_a * arr710_b + arr703_a * arr707_b + arr704_a * arr706_b + arr705_a * arr705_b + arr706_a * arr704_b + arr707_a * arr703_b + arr710_a * arr702_b + arr711_a * arr701_b + arr712_a * arr700_b + 1815 * arr713_a * arr717_b + 1815 * arr714_a * arr716_b + 1815 * arr715_a * arr715_b + 1815 * arr716_a * arr714_b + 1815 * arr717_a * arr713_b,
        arr700_a * arr713_b + arr701_a * arr712_b + arr702_a * arr711_b + arr703_a * arr710_b + arr704_a * arr707_b + arr705_a * arr706_b + arr706_a * arr705_b + arr707_a * arr704_b + arr710_a * arr703_b + arr711_a * arr702_b + arr712_a * arr701_b + arr713_a * arr700_b + 1815 * arr714_a * arr717_b + 1815 * arr715_a * arr716_b + 1815 * arr716_a * arr715_b + 1815 * arr717_a * arr714_b,
        arr700_a * arr714_b + arr701_a * arr713_b + arr702_a * arr712_b + arr703_a * arr711_b + arr704_a * arr710_b + arr705_a * arr707_b + arr706_a * arr706_b + arr707_a * arr705_b + arr710_a * arr704_b + arr711_a * arr703_b + arr712_a * arr702_b + arr713_a * arr701_b + arr714_a * arr700_b + 1815 * arr715_a * arr717_b + 1815 * arr716_a * arr716_b + 1815 * arr717_a * arr715_b,
        arr700_a * arr715_b + arr701_a * arr714_b + arr702_a * arr713_b + arr703_a * arr712_b + arr704_a * arr711_b + arr705_a * arr710_b + arr706_a * arr707_b + arr707_a * arr706_b + arr710_a * arr705_b + arr711_a * arr704_b + arr712_a * arr703_b + arr713_a * arr702_b + arr714_a * arr701_b + arr715_a * arr700_b + 1815 * arr716_a * arr717_b + 1815 * arr717_a * arr716_b,
        arr700_a * arr716_b + arr701_a * arr715_b + arr702_a * arr714_b + arr703_a * arr713_b + arr704_a * arr712_b + arr705_a * arr711_b + arr706_a * arr710_b + arr707_a * arr707_b + arr710_a * arr706_b + arr711_a * arr705_b + arr712_a * arr704_b + arr713_a * arr703_b + arr714_a * arr702_b + arr715_a * arr701_b + arr716_a * arr700_b + 1815 * arr717_a * arr717_b,
        arr700_a * arr717_b + arr701_a * arr716_b + arr702_a * arr715_b + arr703_a * arr714_b + arr704_a * arr713_b + arr705_a * arr712_b + arr706_a * arr711_b + arr707_a * arr710_b + arr710_a * arr707_b + arr711_a * arr706_b + arr712_a * arr705_b + arr713_a * arr704_b + arr714_a * arr703_b + arr715_a * arr702_b + arr716_a * arr701_b + arr717_a * arr700_b
    ] ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591]) /\

    [arr800_c, arr801_c, arr802_c, arr803_c, arr804_c, arr805_c, arr806_c, arr807_c, arr810_c, arr811_c, arr812_c, arr813_c, arr814_c, arr815_c, arr816_c, arr817_c] = [1548, 1548, 1548, 1548, 1548, 1548, 1548, 1548, 1548, 1548, 1548, 1548, 1548, 1548, 1548, 1548] * [
        arr800_a * arr800_b + -2274 * arr801_a * arr817_b + -2274 * arr802_a * arr816_b + -2274 * arr803_a * arr815_b + -2274 * arr804_a * arr814_b + -2274 * arr805_a * arr813_b + -2274 * arr806_a * arr812_b + -2274 * arr807_a * arr811_b + -2274 * arr810_a * arr810_b + -2274 * arr811_a * arr807_b + -2274 * arr812_a * arr806_b + -2274 * arr813_a * arr805_b + -2274 * arr814_a * arr804_b + -2274 * arr815_a * arr803_b + -2274 * arr816_a * arr802_b + -2274 * arr817_a * arr801_b,
        arr800_a * arr801_b + arr801_a * arr800_b + -2274 * arr802_a * arr817_b + -2274 * arr803_a * arr816_b + -2274 * arr804_a * arr815_b + -2274 * arr805_a * arr814_b + -2274 * arr806_a * arr813_b + -2274 * arr807_a * arr812_b + -2274 * arr810_a * arr811_b + -2274 * arr811_a * arr810_b + -2274 * arr812_a * arr807_b + -2274 * arr813_a * arr806_b + -2274 * arr814_a * arr805_b + -2274 * arr815_a * arr804_b + -2274 * arr816_a * arr803_b + -2274 * arr817_a * arr802_b,
        arr800_a * arr802_b + arr801_a * arr801_b + arr802_a * arr800_b + -2274 * arr803_a * arr817_b + -2274 * arr804_a * arr816_b + -2274 * arr805_a * arr815_b + -2274 * arr806_a * arr814_b + -2274 * arr807_a * arr813_b + -2274 * arr810_a * arr812_b + -2274 * arr811_a * arr811_b + -2274 * arr812_a * arr810_b + -2274 * arr813_a * arr807_b + -2274 * arr814_a * arr806_b + -2274 * arr815_a * arr805_b + -2274 * arr816_a * arr804_b + -2274 * arr817_a * arr803_b,
        arr800_a * arr803_b + arr801_a * arr802_b + arr802_a * arr801_b + arr803_a * arr800_b + -2274 * arr804_a * arr817_b + -2274 * arr805_a * arr816_b + -2274 * arr806_a * arr815_b + -2274 * arr807_a * arr814_b + -2274 * arr810_a * arr813_b + -2274 * arr811_a * arr812_b + -2274 * arr812_a * arr811_b + -2274 * arr813_a * arr810_b + -2274 * arr814_a * arr807_b + -2274 * arr815_a * arr806_b + -2274 * arr816_a * arr805_b + -2274 * arr817_a * arr804_b,
        arr800_a * arr804_b + arr801_a * arr803_b + arr802_a * arr802_b + arr803_a * arr801_b + arr804_a * arr800_b + -2274 * arr805_a * arr817_b + -2274 * arr806_a * arr816_b + -2274 * arr807_a * arr815_b + -2274 * arr810_a * arr814_b + -2274 * arr811_a * arr813_b + -2274 * arr812_a * arr812_b + -2274 * arr813_a * arr811_b + -2274 * arr814_a * arr810_b + -2274 * arr815_a * arr807_b + -2274 * arr816_a * arr806_b + -2274 * arr817_a * arr805_b,
        arr800_a * arr805_b + arr801_a * arr804_b + arr802_a * arr803_b + arr803_a * arr802_b + arr804_a * arr801_b + arr805_a * arr800_b + -2274 * arr806_a * arr817_b + -2274 * arr807_a * arr816_b + -2274 * arr810_a * arr815_b + -2274 * arr811_a * arr814_b + -2274 * arr812_a * arr813_b + -2274 * arr813_a * arr812_b + -2274 * arr814_a * arr811_b + -2274 * arr815_a * arr810_b + -2274 * arr816_a * arr807_b + -2274 * arr817_a * arr806_b,
        arr800_a * arr806_b + arr801_a * arr805_b + arr802_a * arr804_b + arr803_a * arr803_b + arr804_a * arr802_b + arr805_a * arr801_b + arr806_a * arr800_b + -2274 * arr807_a * arr817_b + -2274 * arr810_a * arr816_b + -2274 * arr811_a * arr815_b + -2274 * arr812_a * arr814_b + -2274 * arr813_a * arr813_b + -2274 * arr814_a * arr812_b + -2274 * arr815_a * arr811_b + -2274 * arr816_a * arr810_b + -2274 * arr817_a * arr807_b,
        arr800_a * arr807_b + arr801_a * arr806_b + arr802_a * arr805_b + arr803_a * arr804_b + arr804_a * arr803_b + arr805_a * arr802_b + arr806_a * arr801_b + arr807_a * arr800_b + -2274 * arr810_a * arr817_b + -2274 * arr811_a * arr816_b + -2274 * arr812_a * arr815_b + -2274 * arr813_a * arr814_b + -2274 * arr814_a * arr813_b + -2274 * arr815_a * arr812_b + -2274 * arr816_a * arr811_b + -2274 * arr817_a * arr810_b,
        arr800_a * arr810_b + arr801_a * arr807_b + arr802_a * arr806_b + arr803_a * arr805_b + arr804_a * arr804_b + arr805_a * arr803_b + arr806_a * arr802_b + arr807_a * arr801_b + arr810_a * arr800_b + -2274 * arr811_a * arr817_b + -2274 * arr812_a * arr816_b + -2274 * arr813_a * arr815_b + -2274 * arr814_a * arr814_b + -2274 * arr815_a * arr813_b + -2274 * arr816_a * arr812_b + -2274 * arr817_a * arr811_b,
        arr800_a * arr811_b + arr801_a * arr810_b + arr802_a * arr807_b + arr803_a * arr806_b + arr804_a * arr805_b + arr805_a * arr804_b + arr806_a * arr803_b + arr807_a * arr802_b + arr810_a * arr801_b + arr811_a * arr800_b + -2274 * arr812_a * arr817_b + -2274 * arr813_a * arr816_b + -2274 * arr814_a * arr815_b + -2274 * arr815_a * arr814_b + -2274 * arr816_a * arr813_b + -2274 * arr817_a * arr812_b,
        arr800_a * arr812_b + arr801_a * arr811_b + arr802_a * arr810_b + arr803_a * arr807_b + arr804_a * arr806_b + arr805_a * arr805_b + arr806_a * arr804_b + arr807_a * arr803_b + arr810_a * arr802_b + arr811_a * arr801_b + arr812_a * arr800_b + -2274 * arr813_a * arr817_b + -2274 * arr814_a * arr816_b + -2274 * arr815_a * arr815_b + -2274 * arr816_a * arr814_b + -2274 * arr817_a * arr813_b,
        arr800_a * arr813_b + arr801_a * arr812_b + arr802_a * arr811_b + arr803_a * arr810_b + arr804_a * arr807_b + arr805_a * arr806_b + arr806_a * arr805_b + arr807_a * arr804_b + arr810_a * arr803_b + arr811_a * arr802_b + arr812_a * arr801_b + arr813_a * arr800_b + -2274 * arr814_a * arr817_b + -2274 * arr815_a * arr816_b + -2274 * arr816_a * arr815_b + -2274 * arr817_a * arr814_b,
        arr800_a * arr814_b + arr801_a * arr813_b + arr802_a * arr812_b + arr803_a * arr811_b + arr804_a * arr810_b + arr805_a * arr807_b + arr806_a * arr806_b + arr807_a * arr805_b + arr810_a * arr804_b + arr811_a * arr803_b + arr812_a * arr802_b + arr813_a * arr801_b + arr814_a * arr800_b + -2274 * arr815_a * arr817_b + -2274 * arr816_a * arr816_b + -2274 * arr817_a * arr815_b,
        arr800_a * arr815_b + arr801_a * arr814_b + arr802_a * arr813_b + arr803_a * arr812_b + arr804_a * arr811_b + arr805_a * arr810_b + arr806_a * arr807_b + arr807_a * arr806_b + arr810_a * arr805_b + arr811_a * arr804_b + arr812_a * arr803_b + arr813_a * arr802_b + arr814_a * arr801_b + arr815_a * arr800_b + -2274 * arr816_a * arr817_b + -2274 * arr817_a * arr816_b,
        arr800_a * arr816_b + arr801_a * arr815_b + arr802_a * arr814_b + arr803_a * arr813_b + arr804_a * arr812_b + arr805_a * arr811_b + arr806_a * arr810_b + arr807_a * arr807_b + arr810_a * arr806_b + arr811_a * arr805_b + arr812_a * arr804_b + arr813_a * arr803_b + arr814_a * arr802_b + arr815_a * arr801_b + arr816_a * arr800_b + -2274 * arr817_a * arr817_b,
        arr800_a * arr817_b + arr801_a * arr816_b + arr802_a * arr815_b + arr803_a * arr814_b + arr804_a * arr813_b + arr805_a * arr812_b + arr806_a * arr811_b + arr807_a * arr810_b + arr810_a * arr807_b + arr811_a * arr806_b + arr812_a * arr805_b + arr813_a * arr804_b + arr814_a * arr803_b + arr815_a * arr802_b + arr816_a * arr801_b + arr817_a * arr800_b
    ] ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591]) /\

    [arr900_c, arr901_c, arr902_c, arr903_c, arr904_c, arr905_c, arr906_c, arr907_c, arr910_c, arr911_c, arr912_c, arr913_c, arr914_c, arr915_c, arr916_c, arr917_c] = [633, 633, 633, 633, 633, 633, 633, 633, 633, 633, 633, 633, 633, 633, 633, 633] * [
        arr900_a * arr900_b + 2113 * arr901_a * arr917_b + 2113 * arr902_a * arr916_b + 2113 * arr903_a * arr915_b + 2113 * arr904_a * arr914_b + 2113 * arr905_a * arr913_b + 2113 * arr906_a * arr912_b + 2113 * arr907_a * arr911_b + 2113 * arr910_a * arr910_b + 2113 * arr911_a * arr907_b + 2113 * arr912_a * arr906_b + 2113 * arr913_a * arr905_b + 2113 * arr914_a * arr904_b + 2113 * arr915_a * arr903_b + 2113 * arr916_a * arr902_b + 2113 * arr917_a * arr901_b,
        arr900_a * arr901_b + arr901_a * arr900_b + 2113 * arr902_a * arr917_b + 2113 * arr903_a * arr916_b + 2113 * arr904_a * arr915_b + 2113 * arr905_a * arr914_b + 2113 * arr906_a * arr913_b + 2113 * arr907_a * arr912_b + 2113 * arr910_a * arr911_b + 2113 * arr911_a * arr910_b + 2113 * arr912_a * arr907_b + 2113 * arr913_a * arr906_b + 2113 * arr914_a * arr905_b + 2113 * arr915_a * arr904_b + 2113 * arr916_a * arr903_b + 2113 * arr917_a * arr902_b,
        arr900_a * arr902_b + arr901_a * arr901_b + arr902_a * arr900_b + 2113 * arr903_a * arr917_b + 2113 * arr904_a * arr916_b + 2113 * arr905_a * arr915_b + 2113 * arr906_a * arr914_b + 2113 * arr907_a * arr913_b + 2113 * arr910_a * arr912_b + 2113 * arr911_a * arr911_b + 2113 * arr912_a * arr910_b + 2113 * arr913_a * arr907_b + 2113 * arr914_a * arr906_b + 2113 * arr915_a * arr905_b + 2113 * arr916_a * arr904_b + 2113 * arr917_a * arr903_b,
        arr900_a * arr903_b + arr901_a * arr902_b + arr902_a * arr901_b + arr903_a * arr900_b + 2113 * arr904_a * arr917_b + 2113 * arr905_a * arr916_b + 2113 * arr906_a * arr915_b + 2113 * arr907_a * arr914_b + 2113 * arr910_a * arr913_b + 2113 * arr911_a * arr912_b + 2113 * arr912_a * arr911_b + 2113 * arr913_a * arr910_b + 2113 * arr914_a * arr907_b + 2113 * arr915_a * arr906_b + 2113 * arr916_a * arr905_b + 2113 * arr917_a * arr904_b,
        arr900_a * arr904_b + arr901_a * arr903_b + arr902_a * arr902_b + arr903_a * arr901_b + arr904_a * arr900_b + 2113 * arr905_a * arr917_b + 2113 * arr906_a * arr916_b + 2113 * arr907_a * arr915_b + 2113 * arr910_a * arr914_b + 2113 * arr911_a * arr913_b + 2113 * arr912_a * arr912_b + 2113 * arr913_a * arr911_b + 2113 * arr914_a * arr910_b + 2113 * arr915_a * arr907_b + 2113 * arr916_a * arr906_b + 2113 * arr917_a * arr905_b,
        arr900_a * arr905_b + arr901_a * arr904_b + arr902_a * arr903_b + arr903_a * arr902_b + arr904_a * arr901_b + arr905_a * arr900_b + 2113 * arr906_a * arr917_b + 2113 * arr907_a * arr916_b + 2113 * arr910_a * arr915_b + 2113 * arr911_a * arr914_b + 2113 * arr912_a * arr913_b + 2113 * arr913_a * arr912_b + 2113 * arr914_a * arr911_b + 2113 * arr915_a * arr910_b + 2113 * arr916_a * arr907_b + 2113 * arr917_a * arr906_b,
        arr900_a * arr906_b + arr901_a * arr905_b + arr902_a * arr904_b + arr903_a * arr903_b + arr904_a * arr902_b + arr905_a * arr901_b + arr906_a * arr900_b + 2113 * arr907_a * arr917_b + 2113 * arr910_a * arr916_b + 2113 * arr911_a * arr915_b + 2113 * arr912_a * arr914_b + 2113 * arr913_a * arr913_b + 2113 * arr914_a * arr912_b + 2113 * arr915_a * arr911_b + 2113 * arr916_a * arr910_b + 2113 * arr917_a * arr907_b,
        arr900_a * arr907_b + arr901_a * arr906_b + arr902_a * arr905_b + arr903_a * arr904_b + arr904_a * arr903_b + arr905_a * arr902_b + arr906_a * arr901_b + arr907_a * arr900_b + 2113 * arr910_a * arr917_b + 2113 * arr911_a * arr916_b + 2113 * arr912_a * arr915_b + 2113 * arr913_a * arr914_b + 2113 * arr914_a * arr913_b + 2113 * arr915_a * arr912_b + 2113 * arr916_a * arr911_b + 2113 * arr917_a * arr910_b,
        arr900_a * arr910_b + arr901_a * arr907_b + arr902_a * arr906_b + arr903_a * arr905_b + arr904_a * arr904_b + arr905_a * arr903_b + arr906_a * arr902_b + arr907_a * arr901_b + arr910_a * arr900_b + 2113 * arr911_a * arr917_b + 2113 * arr912_a * arr916_b + 2113 * arr913_a * arr915_b + 2113 * arr914_a * arr914_b + 2113 * arr915_a * arr913_b + 2113 * arr916_a * arr912_b + 2113 * arr917_a * arr911_b,
        arr900_a * arr911_b + arr901_a * arr910_b + arr902_a * arr907_b + arr903_a * arr906_b + arr904_a * arr905_b + arr905_a * arr904_b + arr906_a * arr903_b + arr907_a * arr902_b + arr910_a * arr901_b + arr911_a * arr900_b + 2113 * arr912_a * arr917_b + 2113 * arr913_a * arr916_b + 2113 * arr914_a * arr915_b + 2113 * arr915_a * arr914_b + 2113 * arr916_a * arr913_b + 2113 * arr917_a * arr912_b,
        arr900_a * arr912_b + arr901_a * arr911_b + arr902_a * arr910_b + arr903_a * arr907_b + arr904_a * arr906_b + arr905_a * arr905_b + arr906_a * arr904_b + arr907_a * arr903_b + arr910_a * arr902_b + arr911_a * arr901_b + arr912_a * arr900_b + 2113 * arr913_a * arr917_b + 2113 * arr914_a * arr916_b + 2113 * arr915_a * arr915_b + 2113 * arr916_a * arr914_b + 2113 * arr917_a * arr913_b,
        arr900_a * arr913_b + arr901_a * arr912_b + arr902_a * arr911_b + arr903_a * arr910_b + arr904_a * arr907_b + arr905_a * arr906_b + arr906_a * arr905_b + arr907_a * arr904_b + arr910_a * arr903_b + arr911_a * arr902_b + arr912_a * arr901_b + arr913_a * arr900_b + 2113 * arr914_a * arr917_b + 2113 * arr915_a * arr916_b + 2113 * arr916_a * arr915_b + 2113 * arr917_a * arr914_b,
        arr900_a * arr914_b + arr901_a * arr913_b + arr902_a * arr912_b + arr903_a * arr911_b + arr904_a * arr910_b + arr905_a * arr907_b + arr906_a * arr906_b + arr907_a * arr905_b + arr910_a * arr904_b + arr911_a * arr903_b + arr912_a * arr902_b + arr913_a * arr901_b + arr914_a * arr900_b + 2113 * arr915_a * arr917_b + 2113 * arr916_a * arr916_b + 2113 * arr917_a * arr915_b,
        arr900_a * arr915_b + arr901_a * arr914_b + arr902_a * arr913_b + arr903_a * arr912_b + arr904_a * arr911_b + arr905_a * arr910_b + arr906_a * arr907_b + arr907_a * arr906_b + arr910_a * arr905_b + arr911_a * arr904_b + arr912_a * arr903_b + arr913_a * arr902_b + arr914_a * arr901_b + arr915_a * arr900_b + 2113 * arr916_a * arr917_b + 2113 * arr917_a * arr916_b,
        arr900_a * arr916_b + arr901_a * arr915_b + arr902_a * arr914_b + arr903_a * arr913_b + arr904_a * arr912_b + arr905_a * arr911_b + arr906_a * arr910_b + arr907_a * arr907_b + arr910_a * arr906_b + arr911_a * arr905_b + arr912_a * arr904_b + arr913_a * arr903_b + arr914_a * arr902_b + arr915_a * arr901_b + arr916_a * arr900_b + 2113 * arr917_a * arr917_b,
        arr900_a * arr917_b + arr901_a * arr916_b + arr902_a * arr915_b + arr903_a * arr914_b + arr904_a * arr913_b + arr905_a * arr912_b + arr906_a * arr911_b + arr907_a * arr910_b + arr910_a * arr907_b + arr911_a * arr906_b + arr912_a * arr905_b + arr913_a * arr904_b + arr914_a * arr903_b + arr915_a * arr902_b + arr916_a * arr901_b + arr917_a * arr900_b
    ] ( mod [4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591, 4591]) /\

    true
    prove with [all cuts]
  &&
    [arr000_c, arr001_c, arr002_c, arr003_c, arr004_c, arr005_c, arr006_c, arr007_c] <=s [3700@16, 3700@16, 3700@16, 3700@16, 3700@16, 3700@16, 3700@16, 3700@16] /\
    [arr000_c, arr001_c, arr002_c, arr003_c, arr004_c, arr005_c, arr006_c, arr007_c] >=s [(-3700)@16, (-3700)@16, (-3700)@16, (-3700)@16, (-3700)@16, (-3700)@16, (-3700)@16, (-3700)@16] /\

    [arr010_c, arr011_c, arr012_c, arr013_c, arr014_c, arr015_c, arr016_c, arr017_c] <=s [3700@16, 3700@16, 3700@16, 3700@16, 3700@16, 3700@16, 3700@16, 3700@16] /\
    [arr010_c, arr011_c, arr012_c, arr013_c, arr014_c, arr015_c, arr016_c, arr017_c] >=s [(-3700)@16, (-3700)@16, (-3700)@16, (-3700)@16, (-3700)@16, (-3700)@16, (-3700)@16, (-3700)@16] /\

    [arr100_c, arr101_c, arr102_c, arr103_c, arr104_c, arr105_c, arr106_c, arr107_c] <=s [2750@16, 2750@16, 2750@16, 2750@16, 2750@16, 2750@16, 2750@16, 2750@16] /\
    [arr100_c, arr101_c, arr102_c, arr103_c, arr104_c, arr105_c, arr106_c, arr107_c] >=s [(-2750)@16, (-2750)@16, (-2750)@16, (-2750)@16, (-2750)@16, (-2750)@16, (-2750)@16, (-2750)@16] /\

    [arr110_c, arr111_c, arr112_c, arr113_c, arr114_c, arr115_c, arr116_c, arr117_c] <=s [2750@16, 2750@16, 2750@16, 2750@16, 2750@16, 2750@16, 2750@16, 2750@16] /\
    [arr110_c, arr111_c, arr112_c, arr113_c, arr114_c, arr115_c, arr116_c, arr117_c] >=s [(-2750)@16, (-2750)@16, (-2750)@16, (-2750)@16, (-2750)@16, (-2750)@16, (-2750)@16, (-2750)@16] /\

    [arr200_c, arr201_c, arr202_c, arr203_c, arr204_c, arr205_c, arr206_c, arr207_c] <=s [3550@16, 3550@16, 3550@16, 3550@16, 3550@16, 3550@16, 3550@16, 3550@16] /\
    [arr200_c, arr201_c, arr202_c, arr203_c, arr204_c, arr205_c, arr206_c, arr207_c] >=s [(-3550)@16, (-3550)@16, (-3550)@16, (-3550)@16, (-3550)@16, (-3550)@16, (-3550)@16, (-3550)@16] /\

    [arr210_c, arr211_c, arr212_c, arr213_c, arr214_c, arr215_c, arr216_c, arr217_c] <=s [3450@16, 3450@16, 3450@16, 3450@16, 3450@16, 3450@16, 3450@16, 3450@16] /\
    [arr210_c, arr211_c, arr212_c, arr213_c, arr214_c, arr215_c, arr216_c, arr217_c] >=s [(-3450)@16, (-3450)@16, (-3450)@16, (-3450)@16, (-3450)@16, (-3450)@16, (-3450)@16, (-3450)@16] /\

    [arr300_c, arr301_c, arr302_c, arr303_c, arr304_c, arr305_c, arr306_c, arr307_c] <=s [2300@16, 2300@16, 2300@16, 2300@16, 2300@16, 2300@16, 2300@16, 2300@16] /\
    [arr300_c, arr301_c, arr302_c, arr303_c, arr304_c, arr305_c, arr306_c, arr307_c] >=s [(-2300)@16, (-2300)@16, (-2300)@16, (-2300)@16, (-2300)@16, (-2300)@16, (-2300)@16, (-2300)@16] /\

    [arr310_c, arr311_c, arr312_c, arr313_c, arr314_c, arr315_c, arr316_c, arr317_c] <=s [2300@16, 2300@16, 2300@16, 2300@16, 2300@16, 2300@16, 2300@16, 2300@16] /\
    [arr310_c, arr311_c, arr312_c, arr313_c, arr314_c, arr315_c, arr316_c, arr317_c] >=s [(-2300)@16, (-2300)@16, (-2300)@16, (-2300)@16, (-2300)@16, (-2300)@16, (-2300)@16, (-2300)@16] /\

    [arr400_c, arr401_c, arr402_c, arr403_c, arr404_c, arr405_c, arr406_c, arr407_c] <=s [3100@16, 3100@16, 3100@16, 3100@16, 3100@16, 3100@16, 3100@16, 3100@16] /\
    [arr400_c, arr401_c, arr402_c, arr403_c, arr404_c, arr405_c, arr406_c, arr407_c] >=s [(-3100)@16, (-3100)@16, (-3100)@16, (-3100)@16, (-3100)@16, (-3100)@16, (-3100)@16, (-3100)@16] /\

    [arr410_c, arr411_c, arr412_c, arr413_c, arr414_c, arr415_c, arr416_c, arr417_c] <=s [3550@16, 3550@16, 3550@16, 3550@16, 3550@16, 3550@16, 3550@16, 3550@16] /\
    [arr410_c, arr411_c, arr412_c, arr413_c, arr414_c, arr415_c, arr416_c, arr417_c] >=s [(-3550)@16, (-3550)@16, (-3550)@16, (-3550)@16, (-3550)@16, (-3550)@16, (-3550)@16, (-3550)@16] /\

    [arr500_c, arr501_c, arr502_c, arr503_c, arr504_c, arr505_c, arr506_c, arr507_c] <=s [2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16] /\
    [arr500_c, arr501_c, arr502_c, arr503_c, arr504_c, arr505_c, arr506_c, arr507_c] >=s [(-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16] /\

    [arr510_c, arr511_c, arr512_c, arr513_c, arr514_c, arr515_c, arr516_c, arr517_c] <=s [2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16] /\
    [arr510_c, arr511_c, arr512_c, arr513_c, arr514_c, arr515_c, arr516_c, arr517_c] >=s [(-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16] /\

    [arr600_c, arr601_c, arr602_c, arr603_c, arr604_c, arr605_c, arr606_c, arr607_c] <=s [3450@16, 3450@16, 3450@16, 3450@16, 3450@16, 3450@16, 3450@16, 3450@16] /\
    [arr600_c, arr601_c, arr602_c, arr603_c, arr604_c, arr605_c, arr606_c, arr607_c] >=s [(-3450)@16, (-3450)@16, (-3450)@16, (-3450)@16, (-3450)@16, (-3450)@16, (-3450)@16, (-3450)@16] /\

    [arr610_c, arr611_c, arr612_c, arr613_c, arr614_c, arr615_c, arr616_c, arr617_c] <=s [4580@16, 4580@16, 4580@16, 4580@16, 4580@16, 4580@16, 4580@16, 4580@16] /\
    [arr610_c, arr611_c, arr612_c, arr613_c, arr614_c, arr615_c, arr616_c, arr617_c] >=s [(-4580)@16, (-4580)@16, (-4580)@16, (-4580)@16, (-4580)@16, (-4580)@16, (-4580)@16, (-4580)@16] /\

    [arr700_c, arr701_c, arr702_c, arr703_c, arr704_c, arr705_c, arr706_c, arr707_c] <=s [2700@16, 2700@16, 2700@16, 2700@16, 2700@16, 2700@16, 2700@16, 2700@16] /\
    [arr700_c, arr701_c, arr702_c, arr703_c, arr704_c, arr705_c, arr706_c, arr707_c] >=s [(-2700)@16, (-2700)@16, (-2700)@16, (-2700)@16, (-2700)@16, (-2700)@16, (-2700)@16, (-2700)@16] /\

    [arr710_c, arr711_c, arr712_c, arr713_c, arr714_c, arr715_c, arr716_c, arr717_c] <=s [2700@16, 2700@16, 2700@16, 2700@16, 2700@16, 2700@16, 2700@16, 2700@16] /\
    [arr710_c, arr711_c, arr712_c, arr713_c, arr714_c, arr715_c, arr716_c, arr717_c] >=s [(-2700)@16, (-2700)@16, (-2700)@16, (-2700)@16, (-2700)@16, (-2700)@16, (-2700)@16, (-2700)@16] /\

    [arr800_c, arr801_c, arr802_c, arr803_c, arr804_c, arr805_c, arr806_c, arr807_c] <=s [4580@16, 4580@16, 4580@16, 4580@16, 4580@16, 4580@16, 4580@16, 4580@16] /\
    [arr800_c, arr801_c, arr802_c, arr803_c, arr804_c, arr805_c, arr806_c, arr807_c] >=s [(-4580)@16, (-4580)@16, (-4580)@16, (-4580)@16, (-4580)@16, (-4580)@16, (-4580)@16, (-4580)@16] /\

    [arr810_c, arr811_c, arr812_c, arr813_c, arr814_c, arr815_c, arr816_c, arr817_c] <=s [3100@16, 3100@16, 3100@16, 3100@16, 3100@16, 3100@16, 3100@16, 3100@16] /\
    [arr810_c, arr811_c, arr812_c, arr813_c, arr814_c, arr815_c, arr816_c, arr817_c] >=s [(-3100)@16, (-3100)@16, (-3100)@16, (-3100)@16, (-3100)@16, (-3100)@16, (-3100)@16, (-3100)@16] /\

    [arr900_c, arr901_c, arr902_c, arr903_c, arr904_c, arr905_c, arr906_c, arr907_c] <=s [2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16] /\
    [arr900_c, arr901_c, arr902_c, arr903_c, arr904_c, arr905_c, arr906_c, arr907_c] >=s [(-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16] /\

    [arr910_c, arr911_c, arr912_c, arr913_c, arr914_c, arr915_c, arr916_c, arr917_c] <=s [2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16, 2650@16] /\
    [arr910_c, arr911_c, arr912_c, arr913_c, arr914_c, arr915_c, arr916_c, arr917_c] >=s [(-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16, (-2650)@16]

    prove with [all cuts]
}
